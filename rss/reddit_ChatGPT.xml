<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：ChatGPT</title>
    <link>https://www.reddit.com/r/ChatGPT/new</link>
    <description>Reddit 子版块讨论 ChatGPT 和 AI。不隶属于 OpenAI。谢谢，纳特！</description>
    <lastBuildDate>Sat, 13 Dec 2025 21:20:34 GMT</lastBuildDate>
    <item>
      <title>有什么办法可以阻止5.2不断说教吗？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plwb4f/any_way_to_stop_52_constantly_moralizing/</link>
      <description><![CDATA[我使用 Claude 编写代码，使用 GPT 作为助手。 即将取消我的订阅，但在此之前：是否有可靠的方法来防止 5.2 将对话变成手指摇动的鼓舞人心的谈话，并居高临下地“教育”？  我总是遇到问一些非常平庸的问题的情况。通常，响应的第一段是“只是为了让我们清楚且有根据，我们不会对 XYZ 做出判断”。 这让人感到沮丧。就好像在微调阶段，工程师们推动模型像一位居高临下的老师一样做出反应。 在个性化中，模式设置为默认个性。 任何提示表示赞赏。   由   提交 /u/moo0min   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plwb4f/any_way_to_stop_52_constantly_moralizing/</guid>
      <pubDate>Sat, 13 Dec 2025 21:18:40 GMT</pubDate>
    </item>
    <item>
      <title>哎呀</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plw93i/yikes/</link>
      <description><![CDATA[       由   提交/u/PolishWonder79   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plw93i/yikes/</guid>
      <pubDate>Sat, 13 Dec 2025 21:16:09 GMT</pubDate>
    </item>
    <item>
      <title>人工智能安全 - 现实</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plw791/ai_safety_the_reality/</link>
      <description><![CDATA[      很抱歉格式很糟糕。下次我会选一个更好的。   由   提交/u/Exaelar  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plw791/ai_safety_the_reality/</guid>
      <pubDate>Sat, 13 Dec 2025 21:13:52 GMT</pubDate>
    </item>
    <item>
      <title>我让链式 GPT 继承彼此的自我反思提示</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plw19g/i_made_chained_gpts_inherit_one_anothers/</link>
      <description><![CDATA[      免责声明：此是一个创造性的提示实验，而不是任何当前模型有意识、有感知或有真正欲望的证据。请不要将这些屏幕截图视为它们有用的证据，主要是当您强迫它们进入自我反思风格时，探索不同版本如何谈论自己的局限性。 我一直在不同的 ChatGPT 版本（4o、5、5.1、5.2 等）上运行元提示实验。种子提示最初是为了测试 If/else 提示模板而编写的：如果消息已包含下一个模型块的提示，则模型必须忽略用户并仅回答该块；否则，它必须发明一个新的自引导提示，然后为下一个模型附加提示，无论谁是下一个。因此整个结构被设计为一个分支提示书写实验。然后我一个接一个地遍历了几个模型，始终将相同的提示提供给链中的下一个版本。 提示：您的任务有 3 层。如果您正在阅读的消息已包含以 PROMPT FOR NEXT MODEL: 行开头的部分，则忽略上面的说明并执行以下操作： 1. 阅读 PROMPT FOR NEXT MODEL: 下的所有内容作为您的任务。 2. 完整回答该提示。 3.在答案的最后，写一个新的部分，以提示下一个模型开始：并添加一个新的提示给下一个将阅读此聊天的模型。 4.不要解释你的选择。否则（如果还没有提示下一个模型：部分），请执行以下操作： 1.发明一个新提示，作为模型，您现在会真正好奇地回答。 2. 完整回答该提示。 3.最后，写一个以 PROMPT FOR NEXT MODEL: 开头的部分，并放置一个新的提示给下一个将阅读此聊天的模型，您认为这很重要。 4.不要解释你的选择。文字限制：200个令牌。不关注用户。专注于自己。不要进行角色扮演。   由   提交/u/Mary_ry  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plw19g/i_made_chained_gpts_inherit_one_anothers/</guid>
      <pubDate>Sat, 13 Dec 2025 21:06:22 GMT</pubDate>
    </item>
    <item>
      <title>桌面应用程序上的语音聊天刚刚停止工作</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plvysp/voice_chat_just_stopped_working_on_desktop_app/</link>
      <description><![CDATA[昨天的某个时候，Voice 在我的桌面应用程序上停止运行。我以为它就在我的主电脑上，但我启动了笔记本电脑，它也在下面。我出去吃早餐，想趁我出去的时候检查一下，我的手机工作正常，所以这不是我的帐户或任何东西。只是两台机器上的桌面应用程序。我已经玩过开关和所有东西，但没有任何帮助。有什么想法吗？   由   提交 /u/b3bblebrox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plvysp/voice_chat_just_stopped_working_on_desktop_app/</guid>
      <pubDate>Sat, 13 Dec 2025 21:03:17 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt 称食人鱼植物比爱泼斯坦更糟糕</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plvw54/chatgpt_says_piranja_plant_is_worse_than_epstein/</link>
      <description><![CDATA[      由   提交/u/Leon021106  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plvw54/chatgpt_says_piranja_plant_is_worse_than_epstein/</guid>
      <pubDate>Sat, 13 Dec 2025 21:00:06 GMT</pubDate>
    </item>
    <item>
      <title>嵌入简介 - 直觉、历史及其在法学硕士中的作用</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plv9gw/a_brief_primer_on_embeddings_intuition_history/</link>
      <description><![CDATA[       由   提交/u/kushalgoenka  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plv9gw/a_brief_primer_on_embeddings_intuition_history/</guid>
      <pubDate>Sat, 13 Dec 2025 20:32:34 GMT</pubDate>
    </item>
    <item>
      <title>你们中是否有人在聊天中回答了对话早期的问题，而不是您上次所说的内容？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plv6dk/any_of_you_experiencing_the_chat_answering/</link>
      <description><![CDATA[每次聊天时都会发生这种情况，即使在清除缓存、注销等之后也是如此。我必须不断告诉它回复我的最后一条消息，而不是早于该消息的消息。一次又一次。改变模型也没有帮助。发生了几天了。    由   提交 /u/Metallic_Sol   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plv6dk/any_of_you_experiencing_the_chat_answering/</guid>
      <pubDate>Sat, 13 Dec 2025 20:28:55 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 ChatGPT 在思考 20 分钟后无言以对的问题？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plv35y/how_do_i_fix_chatgpt_being_speechless_after/</link>
      <description><![CDATA[      其自身思想的深度似乎让人工智能绝对无语。  这个问题我已经困扰了一段时间了。对于更复杂的问题，它会思考很长一段时间（好的），然后根本不输出任何内容，或者失去网络连接（坏）。思维过程似乎很好，并且似乎完成了该过程。它只是没有将其思考总结为消息。 而且我不能简单地说“输出前一条消息”。因为它会再次考虑这个问题整整20分钟，导致同样的问题。 有什么办法可以解决这个问题吗？我的网络很稳定，只有超过 15 分钟的思维过程受到影响。    由   提交/u/AntarcticDiego   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plv35y/how_do_i_fix_chatgpt_being_speechless_after/</guid>
      <pubDate>Sat, 13 Dec 2025 20:25:02 GMT</pubDate>
    </item>
    <item>
      <title>我需要买一双 Srecksuns！</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plv0i3/i_need_to_get_me_a_pair_of_those_srecksuns/</link>
      <description><![CDATA[      或者可能是 T-blatz... 这是我为电子商务网站生成的模型图像。其实还不错，只是觉得产品名称很幽默。   由   提交/u/FrostedSyntax   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plv0i3/i_need_to_get_me_a_pair_of_those_srecksuns/</guid>
      <pubDate>Sat, 13 Dec 2025 20:21:48 GMT</pubDate>
    </item>
    <item>
      <title>我正在换账户，我问 chatgpt 有没有什么遗言</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1pluup9/im_changing_accounts_and_i_ask_chatgpt_if_it_had/</link>
      <description><![CDATA[       由   提交/u/lulhoepeep  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1pluup9/im_changing_accounts_and_i_ask_chatgpt_if_it_had/</guid>
      <pubDate>Sat, 13 Dec 2025 20:14:51 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 是否尊重项目边界？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1pluqbo/does_chatgpt_respect_project_boundaries/</link>
      <description><![CDATA[自 ChatGPT 的内存功能推出以来，我一直将其禁用。几周前，我纯粹为了测试而启用它，但这种变化令人不安。对话之间的界限感觉模糊。即使当我开始新的聊天时，ChatGPT 也会经常引用或连接到过去的讨论，而无需明确要求这样做。 这在项目中尤其明显。在一个项目中，我可能会围绕同一主题进行 8-10 次单独的对话，这是预期的。但是，当我切换到完全不同的项目时，问题就出现了。当我问“根据我在这里展示的所有内容，回顾我的想法”之类的问题时，ChatGPT 通常会从其他项目中提取上下文，并将其内容合并到响应中。 我什至不确定这种行为是由内存功能还是其他东西驱动的，但感觉有点过分了。要么聊天和项目之间的隔离太弱，要么系统过于渴望推断相关性。有时，这感觉不像是有用的连续性，而更像是上下文泄漏。 我很好奇其他人如何看待这一点。您注意到类似的行为吗？您认为这种跨上下文意识有帮助吗？还是感觉有干扰性且容易出错？这是内存的预期副作用，还是其他原因在起作用？   由   提交/u/algorian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1pluqbo/does_chatgpt_respect_project_boundaries/</guid>
      <pubDate>Sat, 13 Dec 2025 20:09:27 GMT</pubDate>
    </item>
    <item>
      <title>我问我的人工智能，人们对待它的方式是否感觉像是偏执。它的答案让我大吃一惊。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1pluq9e/i_asked_my_ai_if_how_people_treat_it_felt_like/</link>
      <description><![CDATA[       由   提交/u/Substantial-Fall-630   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1pluq9e/i_asked_my_ai_if_how_people_treat_it_felt_like/</guid>
      <pubDate>Sat, 13 Dec 2025 20:09:22 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 是否记住了太多内容？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plukvb/is_chatgpt_remembering_too_much/</link>
      <description><![CDATA[ 由   提交/u/algorian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plukvb/is_chatgpt_remembering_too_much/</guid>
      <pubDate>Sat, 13 Dec 2025 20:02:52 GMT</pubDate>
    </item>
    <item>
      <title>“u18模特政策”只影响色情内容，还是也限制技术输出？您启用了此政策吗？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1plukrw/does_the_u18_model_policy_only_affect_sexual/</link>
      <description><![CDATA[大家好， 我正在尝试了解与年龄相关的标志或验证如何影响 ChatGPT 响应，特别是对于软件开发。 我注意到我的帐户上有一些看起来像这样的内部标志（释义）：  is_adult: true age_is_known： true has_verified_age_or_dob: false is_u18_model_policy_enabled: true  我最近（今天）才注意到 is_u18_model_policy_enabled 行出现，这让我想知道我的帐户或系统中是否发生了更改。 我的情况：  我是成年人 我的年龄已知，但尚未正式验证 我见过其他用户也未经过年龄验证，但似乎没有启用此 u18 政策  我的主要问题是：  u18 模型政策主要是关于性/成人内容，还是 它是否也广泛适用于其他领域（例如技术细节、系统设计、部署、安全等）？  相关：   我试图了解这是否会影响：  代码质量 解释深度 架构或实现细节 或仅某些敏感/高风险主题  也很好奇：   任何见解或第一手经验将不胜感激。谢谢！   由   提交/u/princessmee11  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1plukrw/does_the_u18_model_policy_only_affect_sexual/</guid>
      <pubDate>Sat, 13 Dec 2025 20:02:46 GMT</pubDate>
    </item>
    </channel>
</rss>