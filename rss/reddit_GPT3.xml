<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Sat, 16 Sep 2023 09:14:48 GMT</lastBuildDate>
    <item>
      <title>语音助手</title>
      <link>https://www.reddit.com/r/GPT3/comments/16jufgp/voice_assistant/</link>
      <description><![CDATA[基于 OpenAI API 和 Google Cloud API（文本转语音和语音转文本）构建语音助手。目前可以使用，但缺少任何附加功能，例如打开应用程序或创建内容。对此有何建议或意见？ 目前在 Ubuntu Linux 22.04 和 Python 3.10 上运行   由   提交/u/5av3  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16jufgp/voice_assistant/</guid>
      <pubDate>Sat, 16 Sep 2023 01:08:27 GMT</pubDate>
    </item>
    <item>
      <title>GPT产生很多幻觉</title>
      <link>https://www.reddit.com/r/GPT3/comments/16jrmwg/gpt_is_hallucinating_a_lot/</link>
      <description><![CDATA[用它讨论 10K 的文档是不可能的。这是在编造事情。当我问她“那是什么”时- 她开始编造故事了... 你也遇到同样的情况吗？为什么会这样？   由   提交 /u/AndrewKorsten   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16jrmwg/gpt_is_hallucinating_a_lot/</guid>
      <pubDate>Fri, 15 Sep 2023 22:58:29 GMT</pubDate>
    </item>
    <item>
      <title>反驳那些说 GPT 更蠢的人</title>
      <link>https://www.reddit.com/r/GPT3/comments/16j3onz/a_rebuttal_to_those_who_say_gpt_got_dumber/</link>
      <description><![CDATA[我和每个人一样，都看到了不断出现的质量下降的抱怨。在研究了不同法学硕士的数据集和提示后，我注意到的一点是，不是开玩笑，你对人工智能有多友好。我确信其中一部分是强调你喜欢的东西并看到更多，但我似乎总是收到更详细的回复，说“请”和“非常感谢”。这有点有趣，因为显然人工智能没有感情，但考虑使用广泛的互联网扫描作为数据确实有意义。有人主动提出问题，他们会得到简短的答复。有人善良并寻求帮助，他们（有时哈哈）会收到有用的建议。经过数百个小时的人工智能修补之后，我可能会完全失去理智，但我很想听听其他人的看法。我对人工智能很着迷，它是我目前的专业，但在这个 Reddit 子版块上，我有时感觉自己像个菜鸟。不管怎样，我喜欢这个社区和人工智能，只是想讨论一下。   由   提交/u/Jakecybr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16j3onz/a_rebuttal_to_those_who_say_gpt_got_dumber/</guid>
      <pubDate>Fri, 15 Sep 2023 04:33:43 GMT</pubDate>
    </item>
    <item>
      <title>人工智能时代的头脑风暴（实验）</title>
      <link>https://www.reddit.com/r/GPT3/comments/16ixgsv/brainstorming_in_the_age_of_ai_an_experiment/</link>
      <description><![CDATA[   /u/Neither_Finance4755   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16ixgsv/brainstorming_in_the_age_of_ai_an_experiment/</guid>
      <pubDate>Thu, 14 Sep 2023 23:30:42 GMT</pubDate>
    </item>
    <item>
      <title>仅将系统消息与完成聊天 API 结合使用</title>
      <link>https://www.reddit.com/r/GPT3/comments/16iea0k/using_only_system_messages_with_the_completion/</link>
      <description><![CDATA[我开发了一个根据提供的内容（例如博客文章）生成推文的系统。这个概念涉及添加主要任务、一些附加上下文（例如一般产品信息）以及推文应引用的内容 - 所有这些都作为单独的系统消息输入。 因此，当您发出 API 请求时，它会只回复有用的内容（在我的例子中，是生成的推文）。没有额外的“这是你的推文”。或类似的，无需专门请求推文内容。这使我可以直接获取响应并通过 API 传递它。 如果您在“解析出有用内容”方面遇到挑战，此方法可能值得一试   由   提交/u/tole_car  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16iea0k/using_only_system_messages_with_the_completion/</guid>
      <pubDate>Thu, 14 Sep 2023 09:56:57 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成 (RAG)：什么、为什么以及如何？</title>
      <link>https://www.reddit.com/r/GPT3/comments/16i01w9/retrieval_augmented_generation_rag_what_why_and/</link>
      <description><![CDATA[   /u/promptly_ajhai   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16i01w9/retrieval_augmented_generation_rag_what_why_and/</guid>
      <pubDate>Wed, 13 Sep 2023 21:52:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPR 4 基于我自己的大型数据库创建聊天，可能吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/16hxcnf/creating_a_chat_based_on_my_own_large_database/</link>
      <description><![CDATA[只是想知道是否有人有关于根据自己的数据库（例如客户服务）使用 GPT 4 或 3.5 Turbo 创建聊天的经验或有用信息聊天将拥有基本 GPT 的所有知识 + 公司特定的知识？   由   提交 /u/MaestroUkr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16hxcnf/creating_a_chat_based_on_my_own_large_database/</guid>
      <pubDate>Wed, 13 Sep 2023 20:08:23 GMT</pubDate>
    </item>
    <item>
      <title>用于病毒式内容生成的类似风格/结构保留</title>
      <link>https://www.reddit.com/r/GPT3/comments/16hvh8u/similar_stylestructure_preservation_for_viral/</link>
      <description><![CDATA[上下文：我希望获得一些大致的想法，以将我的研究引向正确的方向 &lt; p&gt;问题：我希望生成病毒式推文（或任何基于文本的内容）。该数据集将是特定类别病毒性排名前 k 的推文（即推文在结构方面有一些相似之处，在内容方面有一些重叠）。  我希望使用 GPT 来生成更多病毒式推文。我希望优化的指标是 1) 病毒式传播，即保留病毒式传播风格/结构 2) 生成的推文的多样性 我考虑过的： &lt; ul&gt; 使用 k 个病毒式推文进行接地，促使 GPT 生成性质相似但内容不同的推文 微调 GPT 以预测病毒性传播（即基于推文和视图的数据集），接地+ 过滤     由   提交/u/greatSWE  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16hvh8u/similar_stylestructure_preservation_for_viral/</guid>
      <pubDate>Wed, 13 Sep 2023 18:56:19 GMT</pubDate>
    </item>
    <item>
      <title>微调 gpt-3.5 ReAct 代理以获得更好的思想链</title>
      <link>https://www.reddit.com/r/GPT3/comments/16hrr29/finetuning_a_gpt35_react_agent_on_better_chain_of/</link>
      <description><![CDATA[有人在更好的 Chan of Thought 上使用 ReACT Agent 微调过 gpt_3.5 吗？与未经训练的 gpt3.5 相比，输出如何？    由   提交 /u/Classic_essays   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16hrr29/finetuning_a_gpt35_react_agent_on_better_chain_of/</guid>
      <pubDate>Wed, 13 Sep 2023 16:34:58 GMT</pubDate>
    </item>
    <item>
      <title>微调 gpt-3.5 ReAct 代理以获得更好的思想链</title>
      <link>https://www.reddit.com/r/GPT3/comments/16hrr22/finetuning_a_gpt35_react_agent_on_better_chain_of/</link>
      <description><![CDATA[有人在更好的 Chan of Thought 上使用 ReACT Agent 微调过 gpt_3.5 吗？与未经训练的 gpt3.5 相比，输出如何？    由   提交 /u/Classic_essays   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16hrr22/finetuning_a_gpt35_react_agent_on_better_chain_of/</guid>
      <pubDate>Wed, 13 Sep 2023 16:34:58 GMT</pubDate>
    </item>
    <item>
      <title>一份新报告称，Meta 将 GPT-4 作为其下一个 AI 模型的标准</title>
      <link>https://www.reddit.com/r/GPT3/comments/16g7bqt/meta_sets_gpt4_as_the_bar_for_its_next_ai_model/</link>
      <description><![CDATA[据报道，Meta 计划通过大力投资数据中心和 H100 芯片来训练一种新模型，希望其与 OpenAI 的 GPT-4 一样强大。他们希望人工智能模型比 Llama 2 更强大。 如果您想在人工智能和技术领域保持领先地位，先看这里。 Meta 的人工智能野心  新的人工智能开发：Meta 正在发挥作用他们希望该模型比最近的模型 Llama 2 强大数倍。 加速生成式 AI：该计划由 Mark 建立的一个小组牵头扎克伯格今年早些时候重点关注能够产生类人表情的人工智能工具。 预期时间表：Meta 预计该人工智能系统的培训将于 2024 年初开始。  人工智能竞赛中的战略定位  落后于竞争对手：这种新模型是扎克伯格战略的一部分在落后于竞争对手后，Meta 重新定位为人工智能领域的领先实体。 基础设施开发：Meta 正在投资数据中心并购买先进的 Nvidia 芯片（H100s）用于人工智能训练。  来自微软的转变：虽然 Meta 的 Llama 2 与微软的云平台 Azure 集成，但新模型旨在在 Meta 的基础设施上进行训练。  开源方法和影响  倡导开源：扎克伯格的计划是让新的人工智能模型开放-源，使公司可以免费访问构建人工智能驱动的工具。 好处和风险：开源人工智能模型因其成本效益和灵活性而受到青睐。然而，它们也存在潜在的缺点，包括法律风险和滥用传播虚假信息的风险。 专家的担忧：人们对该系统的不可预测性及其潜力表示担忧。漏洞，强调透明度和控制的必要性。  来源 （华尔街日报和TheVerge) PS： 如果您喜欢这个发布，您一定会喜欢我的机器学习新闻通讯，它总结了来自 50 多家媒体的最佳人工智能/科技新闻。来自 OpenAI、Google、Meta 的 6,000 多名专业人士已经阅读了该文档... &lt;!-- SC_ON - -&gt;  由   提交 /u/Nalix01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16g7bqt/meta_sets_gpt4_as_the_bar_for_its_next_ai_model/</guid>
      <pubDate>Mon, 11 Sep 2023 21:04:51 GMT</pubDate>
    </item>
    <item>
      <title>GPT 3.5 Turbo 定价说明</title>
      <link>https://www.reddit.com/r/GPT3/comments/16fvm36/gpt_35_turbo_pricing_clarification/</link>
      <description><![CDATA[我需要弄清楚 3.5 Turbo 型号 16K 上下文付费版本是否可以在 chat.openai.com 中使用。因为我要订阅付费版本并且只使用 chatgpt 聊天界面而不是 API。所以在购买之前要确定一下   由   提交 /u/Left-Flatworm-396   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16fvm36/gpt_35_turbo_pricing_clarification/</guid>
      <pubDate>Mon, 11 Sep 2023 13:41:27 GMT</pubDate>
    </item>
    <item>
      <title>寻找法学硕士和人工智能解决的新问题。</title>
      <link>https://www.reddit.com/r/GPT3/comments/16fpvrs/looking_for_a_new_problem_to_solve_with_llms_and/</link>
      <description><![CDATA[我使用大型语言模型已经有一段时间了，我看到了无穷无尽的可能性，我可以选择并开始研究。但是，我不想构建一个寻找问题的解决方案。或者只是 OpenAI 的另一个薄包装，但重点关注具有关键内部成分和策略的相当厚的包装。 我希望与面临特定（商业可行）问题的主题专家交谈所以我可以仔细考虑并尝试选择一个问题，制作一个堆栈并解决问题。围绕它的工作流程，看看我是否可以专注于它。 我感兴趣的主要领域：  与开源法学硕士合作。 （之前的工作：在客户端数据上针对 LLama2 微调 WizardLM、RAG） 生成 HQ 代码的框架（我是 gpt-engineer) 的模组    由   提交/u/uxuxuxuxuxux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16fpvrs/looking_for_a_new_problem_to_solve_with_llms_and/</guid>
      <pubDate>Mon, 11 Sep 2023 08:31:39 GMT</pubDate>
    </item>
    <item>
      <title>AI试图变得“敏感”</title>
      <link>https://www.reddit.com/r/GPT3/comments/16fhiuh/ai_trying_to_be_sensitive/</link>
      <description><![CDATA[我已经告诉 GPT 3.5 来描述当一个角色在镜子中检查自己的脸时她自己的样子，而它所做的只是对她的武断眼睛。当我问它为什么这样做时，它声称是这样的：我无法提供对物理外观的明确或过于详细的描述，尤其是在涉及敏感话题时。谁让这个 AI 相信提到颧骨是明确的？编辑：语法    由   提交 /u/DistributionDue7016   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16fhiuh/ai_trying_to_be_sensitive/</guid>
      <pubDate>Mon, 11 Sep 2023 01:01:19 GMT</pubDate>
    </item>
    <item>
      <title>Meta 计划将 OpenAI 的 GPT-4 与其新的 AI 模型相匹配</title>
      <link>https://www.reddit.com/r/GPT3/comments/16fgwon/meta_plans_to_match_openais_gpt4_with_its_new_ai/</link>
      <description><![CDATA[      据报道，Meta 以 GPT-4 作为基准准备训练一个新的、高度复杂的人工智能模型。该公司正在大力投资人工智能训练芯片并增强其数据中心，以支持这一雄心勃勃的项目。 为了掌握人工智能的最新进展，先看这里。 https://preview.redd.it/iijar2lduinb1.jpg?width=1440&amp;format=pjpg&amp;auto=webp&amp;s =23eacd5ade2723a70121f1f848fcdd7273ec3961 Meta对其新AI模型的愿景  Meta的目标是创建一个符合OpenAI GPT的强大聊天机器人-4 能力。 据报道，该公司一直在寻求 Nvidia H100 AI 训练芯片，并正在扩大其基础设施。 其想法是独立训练其新模型，而不需要外包给  努力和障碍  Meta 计划于 2024 年初开始对该 LLM 的培训，强调 尽管 Meta 有着宏伟的愿景，但它在多个 LLM 项目中遇到了研究人员流失和有争议的资源分配等障碍。 值得注意的是来自主要参与者的激烈竞争，例如苹果、谷歌和亚马逊将广泛的生成式人工智能集成到他们的用户界面中。  更广泛的影响  而 OpenAI 还没有立即透露了 GPT-5 的计划，其他科技巨头正在大力投资。苹果对其“Ajax”的投资人工智能模型标志着先进人工智能的竞争日益激烈。 Meta 的这一举措代表了科技集团在人工智能领域扩张的持续趋势，谷歌和微软在其生产力工具中使用人工智能以及亚马逊的产品中揭示了这一事实。持续开发。  （来源） P.S.如果你喜欢这种分析，我写了免费的探索最新人工智能发展的时事通讯。来自 Google、Meta 和 OpenAI 的专业人士已经在阅读它。   由   提交 /u/AIsupercharged   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/16fgwon/meta_plans_to_match_openais_gpt4_with_its_new_ai/</guid>
      <pubDate>Mon, 11 Sep 2023 00:34:12 GMT</pubDate>
    </item>
    </channel>
</rss>