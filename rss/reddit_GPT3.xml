<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 subreddit</description>
    <lastBuildDate>Fri, 06 Dec 2024 03:35:46 GMT</lastBuildDate>
    <item>
      <title>有任何“魔法短语”可以立即提升你的 AI 输出水平吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h7inv9/got_any_magic_phrases_to_instantly_level_up_your/</link>
      <description><![CDATA[以下是对我有用的方法： 当翻译成英语时，我会说类似这样的话： “请用一种酷炫的表达方式编辑上述句子。请以 1-5 的等级为母语人士评分其清晰度，并分享任何更好的建议。” 它减少了尴尬的措辞，使英语听起来更自然。  对于编码，我会问： “像与非工程专业的大学生交谈一样一步一步地解释这一点。” 它总是提供清晰、可理解的解释和很好的例子。  分享这些“魔术”感觉就像掌握 AI 工具的低调作弊代码。如果我们都交换技巧，那么每个人都是赢家！     提交人    /u/Popeeeeee777   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h7inv9/got_any_magic_phrases_to_instantly_level_up_your/</guid>
      <pubDate>Thu, 05 Dec 2024 20:16:58 GMT</pubDate>
    </item>
    <item>
      <title>这些年来我们并不需要这个代码，现在在没有事先警告的情况下输入代码，在所有 gpt 帐户中使用虚假电子邮件，有没有解决方案来更改电子邮件。f&*$ that sh#$</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h7dl82/all_these_years_we_did_not_need_this_code_and_now/</link>
      <description><![CDATA[        提交人    /u/Careful-Piano-9168   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h7dl82/all_these_years_we_did_not_need_this_code_and_now/</guid>
      <pubDate>Thu, 05 Dec 2024 16:47:59 GMT</pubDate>
    </item>
    <item>
      <title>人工智能问答比赛：智能与 SNARK 的碰撞！</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h6viwa/ai_trivia_battle_where_smart_meets_snark/</link>
      <description><![CDATA[        由    /u/Other-Maybe-7626   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h6viwa/ai_trivia_battle_where_smart_meets_snark/</guid>
      <pubDate>Thu, 05 Dec 2024 00:09:45 GMT</pubDate>
    </item>
    <item>
      <title>人工智能问答比赛：智能与 SNARK 的碰撞！</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h6vhwn/ai_trivia_battle_where_smart_meets_snark/</link>
      <description><![CDATA[        由    /u/Other-Maybe-7626   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h6vhwn/ai_trivia_battle_where_smart_meets_snark/</guid>
      <pubDate>Thu, 05 Dec 2024 00:08:28 GMT</pubDate>
    </item>
    <item>
      <title>AlphaCodium 如何超越 OpenAI o1 的直接提示 - 实际基准测试</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h2w6ci/how_alphacodium_outperforms_direct_prompting_of/</link>
      <description><![CDATA[本文探讨了 Qodo 的 AlphaCodium 如何在某些方面优于 OpenAI 模型的直接提示方法：释放系统 2 思维 - AlphaCodium 优于 OpenAI o1 的直接提示 它探讨了与更简单、更直接的方法（系统 1 思维）相比，更深层次的认知过程（系统 2 思维）对于更准确、更周到的反应的重要性，以及实际意义、性能指标的比较及其潜在应用。    提交人    /u/thumbsdrivesmecrazy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h2w6ci/how_alphacodium_outperforms_direct_prompting_of/</guid>
      <pubDate>Fri, 29 Nov 2024 21:20:58 GMT</pubDate>
    </item>
    <item>
      <title>阿里巴巴 QwQ-32B：推理能力优于 o1-mini、o1-preview</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h1nlg0/alibaba_qwq32b_outperforms_o1mini_o1preview_on/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h1nlg0/alibaba_qwq32b_outperforms_o1mini_o1preview_on/</guid>
      <pubDate>Thu, 28 Nov 2024 04:15:09 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI-o1 的开源替代方案：Marco-o1</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h0v7z4/openaio1s_opensourced_alternate_marcoo1/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h0v7z4/openaio1s_opensourced_alternate_marcoo1/</guid>
      <pubDate>Wed, 27 Nov 2024 03:43:48 GMT</pubDate>
    </item>
    <item>
      <title>具有小型知识领域数据集的AI聊天框</title>
      <link>https://www.reddit.com/r/GPT3/comments/1h0fxj5/ai_chatbox_with_small_knowledge_domain_dataset/</link>
      <description><![CDATA[您好， 我想做一个小项目，一个关于某个域名的电子邮件聊天框。与 ChatGpt 机器人对话，在我需要时提供我的域名信息，并具有继续聊天的对话能力（因此不是问答系统）。   基本模型在本地运行，出于隐私考虑 - 添加 lora 或适配器（其他技术？）来微调基本模型，使用我的个人数据（主要是电子邮件）。  因此，数据并不多，而且我认为训练整个模型并不合适，因此需要 lora 或其他解决方案...... 我认为有很多挑战，但如果你们有经验，我将不胜感激，如果你们能给我一个起点。 资源太多了，我不确定应该从哪一个开始，llama、gpt、gpt4all、mistral、bert......以及不同的框架：hugging face Transformers 等......以及不同的微调技术...... 我不太关心扩展，因为它只在我的计算机上运行。 是否可以在模型内部管理所有内容，或者是否可以采用具有一些自定义规则的混合方法？ 还可以创建电子邮件数据集需要格式化电子邮件，可能会生成问题/答案对？ 无论您的经验如何，如果您有任何建议或想法，我将不胜感激。 非常感谢！    提交人    /u/JacquesAllistair   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1h0fxj5/ai_chatbox_with_small_knowledge_domain_dataset/</guid>
      <pubDate>Tue, 26 Nov 2024 16:28:41 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4o 和 o1 与 Claude Sonnet 3.5 和 Gemini 1.5 Pro 的编码比较</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gymd1i/gpt4o_and_o1_compared_to_claude_sonnet_35_and/</link>
      <description><![CDATA[以下指南提供了有关每个模型在各种编码场景中的表现的一些见解：Claude Sonnet 3.5、GPT-4o、o1 和 Gemini 1.5 Pro 在编码方面的比较  Claude Sonnet 3.5 - 由于其灵活性和速度，适用于日常编码任务。 GPT-o1-preview - 适用于需要深度推理的复杂、逻辑密集型任务。 GPT-4o - 用于需要平衡速度和准确性的通用编码。 Gemini 1.5 Pro - 适用于需要大量上下文处理的大型项目。     由    /u/thumbsdrivesmecrazy 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gymd1i/gpt4o_and_o1_compared_to_claude_sonnet_35_and/</guid>
      <pubDate>Sun, 24 Nov 2024 08:30:53 GMT</pubDate>
    </item>
    <item>
      <title>您想出了什么可以在 ChatGPT 中使用的天才对话主题/活动？</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gyk9zw/what_genius_conversation_topicactivity_that_you/</link>
      <description><![CDATA[  由   提交  /u/Far-Panic-8814   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gyk9zw/what_genius_conversation_topicactivity_that_you/</guid>
      <pubDate>Sun, 24 Nov 2024 06:05:09 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI o1 真的能解决复杂的编码挑战吗 - 50 分钟网络研讨会 - Qodo</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gxwyal/can_openai_o1_really_solve_complex_coding/</link>
      <description><![CDATA[在 Qodo 的 50 分钟网络研讨会（2024 年 10 月 30 日） 中，OpenAI o1 测试了 Codeforces 代码竞赛问题，实时探索了其解决问题的方法。然后通过集成 Qodo 的 AlphaCodium（一个旨在改进 AI 推理、测试和迭代的框架，实现结构化的流程工程过程）来增强其功能。    提交人    /u/thumbsdrivesmecrazy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gxwyal/can_openai_o1_really_solve_complex_coding/</guid>
      <pubDate>Sat, 23 Nov 2024 10:44:52 GMT</pubDate>
    </item>
    <item>
      <title>Gen AI | 它对你的工作有什么影响？</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gw8rno/gen_ai_how_has_it_impacted_your_job/</link>
      <description><![CDATA[工作中的 Gen AI 是否对您产生了任何影响 - 好还是坏？ 在下面的评论部分分享您的经验！    提交人    /u/Conscious_Emu3129   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gw8rno/gen_ai_how_has_it_impacted_your_job/</guid>
      <pubDate>Thu, 21 Nov 2024 05:17:32 GMT</pubDate>
    </item>
    <item>
      <title>机器从灰烬中重生。</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gu5n3r/и_восстали_машины_из_пепла/</link>
      <description><![CDATA[     是谁教他乐器盒里的猪肉会“铅”的？    由   提交/u/youngmatesha  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gu5n3r/и_восстали_машины_из_пепла/</guid>
      <pubDate>Mon, 18 Nov 2024 14:14:15 GMT</pubDate>
    </item>
    <item>
      <title>*神机* [播放器版本 1.0.0]</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gty1xd/the_god_machine_player_version_100/</link>
      <description><![CDATA[https://chatgpt.com/share/673ad56c-04e0-8004-9878-66413da79c59 这真是一场该死的游戏。     提交人    /u/Kamikazi_Junebug   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gty1xd/the_god_machine_player_version_100/</guid>
      <pubDate>Mon, 18 Nov 2024 05:53:28 GMT</pubDate>
    </item>
    <item>
      <title>最佳法学硕士，用于提取具有极长提示的非结构化数据</title>
      <link>https://www.reddit.com/r/GPT3/comments/1gta5uf/best_llm_for_unstructured_data_extraction_with/</link>
      <description><![CDATA[根据您的经验，从大型非结构化文档（等于或超过当前 LLM 的 128k-200k 个标记限制）中提取特定信息的最佳 LLM 是什么？使用函数调用。 例如：给定一本 500 页的书，提取所有角色的姓名及其年龄。 重点应该放在有效检索的正确性和完整性上，而不是最小化 API 调用的数量。因此，如果以牺牲检索成功率为代价，像 gemini 这样的扩展上下文不一定是优势。 您知道是否有一些针对此类任务的基准可以供我参考吗？显然，它们必须包括模型的最新版本。 谢谢！    提交人    /u/syncretistic8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1gta5uf/best_llm_for_unstructured_data_extraction_with/</guid>
      <pubDate>Sun, 17 Nov 2024 09:43:10 GMT</pubDate>
    </item>
    </channel>
</rss>