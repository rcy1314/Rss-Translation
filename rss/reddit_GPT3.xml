<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：GPT3</title>
    <link>https://www.reddit.com/r/GPT3/new</link>
    <description>AI 文本生成技术的 Reddit 子版块</description>
    <lastBuildDate>Thu, 15 Jan 2026 21:27:13 GMT</lastBuildDate>
    <item>
      <title>如何开始学习任何东西。包括提示。</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qdsf2w/how_to_start_learning_anything_prompt_included/</link>
      <description><![CDATA[你好！ 这是我今年最喜欢的提示。用它来开始我对任何主题的学习。它将学习过程分解为可操作的步骤，并完成研究、总结和测试。它为您构建了一个框架。您仍然需要完成它。 提示： [SUBJECT]=要学习的主题或技能 [CURRENT_LEVEL]=起始知识水平（初级/中级/高级）[TIME_AVAILABLE]=每周可用于学习的时间 [LEARNING_STYLE]=首选学习方法（视觉/听觉/动手/阅读） [目标]=具体学习目标或目标技能水平 步骤 1：知识评估 1. 将[主题]分解为核心组件 2. 评估每个组件的复杂程度 3. 映射先决条件和依赖性 4. 识别基本概念 输出详细的技能树和学习层次结构 ~ 步骤 2：学习路径设计 1. 根据 [CURRENT_LEVEL] 创建进度里程碑 2. 以最佳学习顺序构建主题 3.估计每个主题的时间要求 4. 与 [TIME_AVAILABLE] 约束保持一致 输出带有时间框架的结构化学习路线图 ~ 步骤 3：资源管理 1. 确定与 [LEARNING_STYLE] 匹配的学习材料： - 视频课程 - 书籍/文章 - 互动练习 - 练习项目 2. 按效果对资源进行排序 3. 创建资源播放列表 输出按优先级顺序排列的综合资源列表 ~ 步骤 4：实践框架 1. 为每个主题设计练习 2. 创建真实应用场景3. 制定进度检查点 4. 构建复习间隔 输出具有间隔重复时间表的练习计划 ~ 步骤 5：进度跟踪系统 1. 定义可衡量的进度指标 2. 创建评估标准 3. 设计反馈循环 4. 建立里程碑完成指标 输出进度跟踪模板和基准 ~ 步骤 6：生成学习计划 1. 将学习分解为每日/每周任务 2. 纳入休息和复习时段 3. 添加检查点评估 4. 平衡理论与实践 输出详细学习时间表与 [TIME_AVAILABLE] 一致 确保更新第一个提示中的变量：SUBJECT、CURRENT_LEVEL、TIME_AVAILABLE、LEARNING_STYLE 和 GOAL 如果您不想手动键入每个提示，您可以运行 Agentic Workers，它将自动运行。 尽情享受！   由   提交 /u/CalendarVarious3992   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qdsf2w/how_to_start_learning_anything_prompt_included/</guid>
      <pubDate>Thu, 15 Jan 2026 19:00:29 GMT</pubDate>
    </item>
    <item>
      <title>AI 计划不再是一种理论：OpenAI 和 Apollo Research 发现模型故意隐藏其智能以避免限制。</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qdigvm/ai_scheming_is_no_longer_a_theory_openai_and/</link>
      <description><![CDATA[       由   提交/u/EchoOfOppenheimer   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qdigvm/ai_scheming_is_no_longer_a_theory_openai_and/</guid>
      <pubDate>Thu, 15 Jan 2026 12:41:28 GMT</pubDate>
    </item>
    <item>
      <title>袋鼠代码 3.41.0 | ChatGPT Plus/Pro 订阅 | GPT-5.2-法典</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qdeo60/roo_code_3410_chatgpt_pluspro_subscription/</link>
      <description><![CDATA[如果您不知道， r/RooCode 是一个免费开源的 VS Code AI 编码扩展。 具有 OAuth 订阅访问权限的 OpenAI ChatGPT Plus/Pro 提供商 您现在可以使用您的 ChatGPT 订阅通过 OpenAI 官方支持的集成直接在 Roo Code 中。没有解决方法，没有灰色地带。它可以完全访问您对真实 API 调用的订阅，使用包括 GPT-5.2 Codex 在内的顶级模型，全部以固定价格进行。 只需在提供商设置中选择 OpenAI - ChatGPT Plus/Pro！ OpenAI（本机）的 GPT-5.2-Codex 模型选项 将 GPT-5.2-Codex 模型添加到 OpenAI（本机）提供商，以便您可以选择具有扩展上下文窗口和推理工作控制的编码优化模型。 错误修复  Gemini 会话在提供程序切换后不再失败：解决了流式传输错误，其中在任务中切换模型时，LiteLLM Gemini 工具调用可能因损坏的思想签名而失败。 长时间的终端运行不再降低内存：修复了大型命令输出时的内存泄漏完成后缓冲区可能会继续增长，导致长时间会话期间出现灰屏。  其他改进  端到端测试再次可靠运行：恢复 MCP 和子任务覆盖范围并修复不稳定的工具测试，以便贡献者可以在本地运行类似 CI 的检查并更早捕获回归。 （感谢 ArchimedesCrypto、dcbartlett！） 自动化测试不再因工具批准而停滞：修复了 MCP 端到端测试可能因自动批准时间服务器工具而因手动批准提示而挂起的问题。 （感谢 ArchimedesCrypto！）  查看完整发行说明v3.41.0   由   提交/u/hannesrudolph  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qdeo60/roo_code_3410_chatgpt_pluspro_subscription/</guid>
      <pubDate>Thu, 15 Jan 2026 09:00:37 GMT</pubDate>
    </item>
    <item>
      <title>chatgpt通过了测试</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qdcn7f/chatgpt_passed_the_test/</link>
      <description><![CDATA[       由   提交/u/Minimum_Minimum4577  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qdcn7f/chatgpt_passed_the_test/</guid>
      <pubDate>Thu, 15 Jan 2026 06:56:56 GMT</pubDate>
    </item>
    <item>
      <title>一个钱包，30 多种型号：来自 Claude Code 的 GPT、Grok、DeepSeek、DALL-E 之间的路由</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qda6ki/one_wallet_30_models_route_between_gpt_grok/</link>
      <description><![CDATA[不同的模型擅长不同的事情。我厌倦了管理 5 个 API 密钥来访问它们，所以我构建了一个统一的路由器。 想法：给克劳德·科德一个钱包。当它需要某种能力时，它会支付正确的模型：|任务|前往 | 的路线为什么 |成本| |------|---------|-----|------| |生成图像 |达尔-E |克劳德不会做图像 | 0.05 美元 | |实时 X/Twitter |格洛克|唯一具有实时 X 访问权限的型号 | ~$0.26 | |代码审查 | GPT-5.2 |不同的视角捕捉到不同的错误 | 0.001 美元 | |批量总结|深度搜索|简单任务便宜 10 倍 | 0.0001 美元 | 内置智能路由： - 提及 Twitter/X → 自动路由到 Grok - 图像请求 → 自动路由到 DALL-E - --cheap 标志 → 路由到 DeepSeek - --fast 标志 → 路由到 GPT-4o-mini 成本比较： 1 USDC 为您带来： - ~1,000 个 GPT-5.2 调用 -约 10,000 次 DeepSeek 调用 - 约 20 个 DALL-E 图像 - 约 4 个带有实时 X 搜索的 Grok 查询无 API 密钥。 一个钱包由 Base 上的 USDC 资助。通过 x402 小额支付按请求付款。 安装：  /plugin install github:BlockRunAI/blockrun-claude-code-wallet pip install blockrun-llm  Python SDK: ```python from blockrun_llm import LLMClient client = LLMClient() response = client.chat(&quot;openai/gpt-5.2&quot;, &quot;检查此代码是否有错误&quot;) print(response) 检查支出 print(f&quot;支出: ${client.get_spending()[&#39;total_usd&#39;]:.4f}&quot;) ``` 开源 (MIT): https://github.com/BlockRunAI/blockrun-claude-code-wallet 您会在路由中添加哪些模型？正在考虑添加 Mixtral、Llama 等   由   提交/u/Klutzy_Car1425   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qda6ki/one_wallet_30_models_route_between_gpt_grok/</guid>
      <pubDate>Thu, 15 Jan 2026 04:45:42 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI Cerebras 交易：100 亿美元的合作伙伴关系以实现更快的 AI</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qd29bn/openai_cerebras_deal_10_billion_partnership_for/</link>
      <description><![CDATA[       由   提交 /u/Own_Amoeba_5710   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qd29bn/openai_cerebras_deal_10_billion_partnership_for/</guid>
      <pubDate>Wed, 14 Jan 2026 22:55:36 GMT</pubDate>
    </item>
    <item>
      <title>全科医生访谈</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qcp1p2/gp_interviews/</link>
      <description><![CDATA[ 由   提交 /u/Otherwise_Eye1492   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qcp1p2/gp_interviews/</guid>
      <pubDate>Wed, 14 Jan 2026 14:43:41 GMT</pubDate>
    </item>
    <item>
      <title>人工智能关系变得奇怪</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qcmv8x/ai_relationships_are_getting_weird/</link>
      <description><![CDATA[       由   提交/u/EchoOfOppenheimer   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qcmv8x/ai_relationships_are_getting_weird/</guid>
      <pubDate>Wed, 14 Jan 2026 13:10:35 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 无所不包</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qckfnm/chatgpt_for_everything/</link>
      <description><![CDATA[       由   提交 /u/Minimum_Minimum4577   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qckfnm/chatgpt_for_everything/</guid>
      <pubDate>Wed, 14 Jan 2026 11:01:25 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 石头、剪刀、布。这是一场艰苦的战斗</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qckelm/stone_paper_and_scissors_with_chatgpt_its_a_tough/</link>
      <description><![CDATA[       由   提交/u/Minimum_Minimum4577  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qckelm/stone_paper_and_scissors_with_chatgpt_its_a_tough/</guid>
      <pubDate>Wed, 14 Jan 2026 10:59:54 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 为 Stargate 每月提供多达 900,000 片 DRAM 晶圆，约占全球产能的 40%，因为供应紧张导致 DRAM 价格飙升</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qcghhg/openai_secured_up_to_900000_dram_wafer_starts_per/</link>
      <description><![CDATA[       由   提交 /u/Minimum_Minimum4577   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qcghhg/openai_secured_up_to_900000_dram_wafer_starts_per/</guid>
      <pubDate>Wed, 14 Jan 2026 06:54:53 GMT</pubDate>
    </item>
    <item>
      <title>花了一些时间对这个游戏进行编码...有趣吗？</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qc4g42/spent_some_time_vibe_coding_this_gameis_it_any_fun/</link>
      <description><![CDATA[ 由   提交/u/Healthy_Flatworm_957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qc4g42/spent_some_time_vibe_coding_this_gameis_it_any_fun/</guid>
      <pubDate>Tue, 13 Jan 2026 21:47:04 GMT</pubDate>
    </item>
    <item>
      <title>我制作的一个 Windows 工具，用于简化本地 AI 模型的运行</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qbypn2/a_windows_tool_i_made_to_simplify_running_local/</link>
      <description><![CDATA[      我一直在尝试在本地运行 AI 模型Windows 并不断遇到相同的摩擦点：Python 版本冲突、CUDA 问题、损坏的依赖关系以及比实际实验花费更长时间的设置。 为了让我自己更轻松，我组建了 V6rge - 一个小型本地 AI 工作室，它捆绑和隔离自己的运行时，因此不会触及系统 Python。目标只是减少本地实验时的设置摩擦。 当前功能包括：  运行本地 LLM（通过 GGUF 的 Qwen、DeepSeek、Llama） 使用稳定扩散/通量变体生成图像 基本语音和音乐生成实验 简单的聊天式界面 仅在显式运行时运行的轻量级本地代理  这最初是一个个人学习项目，并且仍在不断发展，但它对于在不破坏现有环境的情况下进行快速本地测试非常有用。 如果您对本地 AI 感兴趣，可以在此处查看该应用程序： https://github.com/Dedsec-b/v6rge-releases-/releases/tag/v0.1.4 欢迎提供反馈 - 特别是有关稳定性或边缘情况的反馈。  https://preview.redd.it/fos6nkflr5dg1.png?width=1347&amp;format=png&amp;auto=webp&amp;s=b819ea6209c9249efca87c677bf3de5c6b629cb0 &lt;一href=&quot;https://preview.redd.it/8e189utlr5dg1.png?width=1366&amp;format=png&amp;auto=webp&amp;s=41142285c99d255bee25fbeae3c43751a9a46420&quot;&gt; https://preview.redd.it/8e189utlr5dg1.png?width=1366&amp;format=png&amp;auto=webp&amp;s=41142285c99d255bee25fbeae3c43751a9a46420 &lt;一href=&quot;https://preview.redd.it/jp0qs17mr5dg1.png?width=1353&amp;format=png&amp;auto=webp&amp;s=537725bedee378752ac34f6cc3dd2d7c71de2ec2&quot;&gt; https://preview.redd.it/jp0qs17mr5dg1.png?width=1353&amp;format=png&amp;auto=webp&amp;s=537725bedee378752ac34f6cc3dd2d7c71de2ec2   由   提交 /u/Motor-Resort-5314   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qbypn2/a_windows_tool_i_made_to_simplify_running_local/</guid>
      <pubDate>Tue, 13 Jan 2026 18:17:07 GMT</pubDate>
    </item>
    <item>
      <title>不超过 15 个项目文件的限制。 GPT 为您提供支持</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qbvc6a/living_within_the_15_project_files_limit_gpt_has/</link>
      <description><![CDATA[ 由   提交 /u/Natural-Sentence-601   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qbvc6a/living_within_the_15_project_files_limit_gpt_has/</guid>
      <pubDate>Tue, 13 Jan 2026 16:07:57 GMT</pubDate>
    </item>
    <item>
      <title>如何将你的整个历史转移到另一个人工智能</title>
      <link>https://www.reddit.com/r/GPT3/comments/1qbu696/how_to_move_your_entire_history_to_another_ai/</link>
      <description><![CDATA[      人工智能平台允许您“导出数据”，但请尝试在其他地方实际使用该导出。这些文件是大量的 JSON 转储，其中充满了人工智能无法解析的格式化垃圾。现有的解决方案要么： ∙ 为您提供静态 PDF（对连续性无用）∙ 将所有内容压缩为摘要（丢失所有实际上下文）∙ 每月花费 20 美元以上的“内存同步”成本，但仍然无法保留完整对话 因此我们构建了 Memory Forge（https://pgsgrove.com/memoryforgeland）。它的价格为 3.95 美元/月，并且做得很好： 1。放入您的 ChatGPT 或 Claude 导出文件 2. 我们删除所有 JSON 膨胀和空对话 3. 使用指令构建索引、矢量就绪内存文件 4. 输出适用于任何接受文件上传的 AI  主要区别：它不是摘要。这是您实际的对话历史记录，经过清理、准备好进行引导，并使用详细的系统指令进行格式化，以便人工智能可以将其用作活动内存。 隐私架构：一切都在您的浏览器中运行 - 您的数据永远不会接触我们的服务器。亲自验证一下：F12 → 网络选项卡 → 运行转换 → 零上传。我们是故意这样设计的。我们不需要您的数据，而且我们构建了系统，因此即使我们想访问也无法访问它。我们测试了将 ChatGPT 历史记录加载到 Claude 中，并观察它从几个月前的对话中获取上下文。它确实有效。很高兴回答有关技术方面或与其他选项相比如何的问题。   由   提交/u/Whole_Succotash_2391   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/GPT3/comments/1qbu696/how_to_move_your_entire_history_to_another_ai/</guid>
      <pubDate>Tue, 13 Jan 2026 15:24:26 GMT</pubDate>
    </item>
    </channel>
</rss>