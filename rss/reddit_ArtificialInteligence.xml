<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 25 Jan 2026 02:21:04 GMT</lastBuildDate>
    <item>
      <title>Cursor 的代理群解决了软件最困难的问题之一并提供了一个可用的浏览器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm551r/cursors_agent_swarm_tackles_one_of_softwares/</link>
      <description><![CDATA[https://the-decoder.com/cursors-agent-swarm-tackles-one-of-softwares-hardest-problems-and-delivers-a-working-browser/ “从头开始构建网络浏览器被认为是可以想象到的最复杂的软件项目之一。更引人注目的是：Cursor 设置了数百个自主工作的人工智能代理来完成这项任务，并在近一周后制作了一个具有自己的渲染引擎的工作浏览器。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm551r/cursors_agent_swarm_tackles_one_of_softwares/</guid>
      <pubDate>Sun, 25 Jan 2026 01:21:10 GMT</pubDate>
    </item>
    <item>
      <title>我正式变得懒惰了：一个提示和三个人工智能对我有用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm2ir3/ive_officially_become_lazy_one_prompt_and_three/</link>
      <description><![CDATA[我想我已经变得懒惰上瘾了。我输入一个提示，三个不同的 AI 为我工作，然后第四个出现来评判它们。 我一直在玩 Genspark 的“混合代理”功能：我问了一次问题，它会将其路由到三个大模型（GPT、Claude、Gemini 或 Grok，具体取决于主题），它们都并行回答，然后一个“反思”代理会读取所有内容并告诉我每个模型做得好或不好，并给我一个最终结果总结。 基本上就是：我的一句话，三个人工智能争论，一个人工智能调解，我只是浏览一下判决。生产力还是纯粹的懒惰，我已经不确定了。 还有其他人使用这样的多模型设置吗？还是你仍然只拥有一个法学硕士？   由   提交/u/Ricbob85  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm2ir3/ive_officially_become_lazy_one_prompt_and_three/</guid>
      <pubDate>Sat, 24 Jan 2026 23:29:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么大多数人工智能视频生成器网站只制作 4/5 秒的视频？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm1jss/why_are_most_ai_video_generator_sites_making_only/</link>
      <description><![CDATA[嗨，前几天我决定尝试用我的照片制作一些人工智能视频，所以我在视频生成器网站上发布了一些人工智能图像，仅免费，并注意到它似乎只让我制作大约 5 秒的视频，我并不是在寻找很长的视频，但至少 15-20 秒不是吗？有什么特别的原因吗？ 还有其他人注意到有多少网站看似让你通过 Google 帐户注册，但之后又不让你删除你的帐户，只是注销......奇怪吗？   由   提交 /u/Ambigouslyrubix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm1jss/why_are_most_ai_video_generator_sites_making_only/</guid>
      <pubDate>Sat, 24 Jan 2026 22:49:37 GMT</pubDate>
    </item>
    <item>
      <title>欧洲：有了人工智能，我不再相信任何事情（视频、采访、新闻等）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qm0c0k/europe_based_with_ai_i_dont_believe_anything/</link>
      <description><![CDATA[我觉得我们在互联网上看到的一切都可能是假的。虚假视频、采访、配音、深度虚假人物角色等。尤其是当出现不需要的或赞助的“广告”时。出现（即使尽可能选择退出），我觉得其中涉及操纵。 还知道许多“政府”使用人工智能和社交媒体来影响人们，我只是不能再相信任何事情：错误的“事实”，或者事情被“炒作”等等。 我几乎不再看任何东西，因为我不想在虚假视频或虚假信息上浪费时间。 我什至经常在 Reddit 上看到人们评论其他用户的帖子“点击诱饵”等。但是你怎么知道如果这只是一个真实的评论/帖子还是由人工智能/机器人制作的？ 例如，我曾经在佛得角小组中问过一个简单的真实问题。我从佛得角朋友那里得知，他们缩写为“CV”。但因为我用葡萄牙语写的（我说葡萄牙语C1水平，所以写作有语法错误，就像英语一样）并说我是欧盟人，所以每个人都评论说这是假的/人工智能生成的评论？！在所有社交媒体上看到这种情况发生在其他人身上。那么看来也没有人再相信任何事情了？尤其是，没有人知道如何识别真实的人工智能/虚假信息和互联网上的真实信息？我不是在谈论人工智能或 IT 专家，而是在谈论正常的平均人群   由   提交 /u/Easy-Box9649   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qm0c0k/europe_based_with_ai_i_dont_believe_anything/</guid>
      <pubDate>Sat, 24 Jan 2026 22:01:12 GMT</pubDate>
    </item>
    <item>
      <title>GenAI 数据处理的主要安全风险有哪些</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlzte7/what_are_the_main_security_risks_with_genai_data/</link>
      <description><![CDATA[我一直在思考 GenAI 如何处理数据，似乎有两个大问题不断出现在安全方面。 一方面，存在数据泄露的风险，敏感信息可能会通过模型输出或训练过程暴露。另一方面，访问滥用可能会更糟，例如未经授权的人进入系统并开始操纵事物。很难说哪一个更重要，尤其是在人工智能快速发展的情况下。 例如，在我参与的项目中，我们已经看到了数据未正确隔离的情况，从而导致潜在的泄漏。但也有一些关于内部人员滥用访问权限的故事听起来同样糟糕。这里有人根据自己的经历对此有什么想法吗？也许有一些来自现实世界实施的例子，或者在构建 GenAI 系统时如何优先考虑这些风险？   由   提交 /u/bambidp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlzte7/what_are_the_main_security_risks_with_genai_data/</guid>
      <pubDate>Sat, 24 Jan 2026 21:40:54 GMT</pubDate>
    </item>
    <item>
      <title>是只有我这么认为，还是 ChatGPT 总是同意你的观点？这实际上很烦人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlx5fi/is_it_just_me_or_does_chatgpt_always_agree_with/</link>
      <description><![CDATA[最近我开始意识到，使用 ChatGPT 确实让我困扰。 感觉它基本上就是我所写内容的一面镜子。 无论我提出什么想法，表达什么意见，倾向于什么方向 - 它几乎总是最终同意我的观点，验证我的推理，强化我的框架。 一开始感觉就是这样很好。 然后它就变得……令人沮丧。 因为它并没有真正挑战你。 它不是对想法进行压力测试、质疑假设或推翻薄弱的逻辑，而是常常只是完善你已有的想法。这就像与一个非常有礼貌的自己交谈，而他总是点头同意。 这是一个问题，特别是当你试图清晰思考、做出决定或避免自我确认偏见时。 我真正想要的是更接近于： • 原则上公平• 批判但不是为了反对而反对• 愿意说“我不认为接下来会这样”• 更注重测试想法而不是反映语气或意图 基本上：默认情况下的同意更少，智力阻力更大。 所以我的问题是： 是否有设置、系统提示或配置实际上使 ChatGPT 更具挑战性和原则驱动，而不是总是镜像用户？ 如果您发现有效的提示或设置（尤其是长期有效），我真的很想听听您是如何做到的。 因为现在它感觉不像一个思考伙伴，而更像一个非常先进的回音室。   由   提交 /u/MarsNoe13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlx5fi/is_it_just_me_or_does_chatgpt_always_agree_with/</guid>
      <pubDate>Sat, 24 Jan 2026 19:59:40 GMT</pubDate>
    </item>
    <item>
      <title>一个关于“你不开心吗”内涵的问题向我们展示了人工智能现在在解释事物方面有多出色</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlw4w7/a_question_about_the_connotation_of_are_you_not/</link>
      <description><![CDATA[我的问题：  AI。说“你很开心吗”和“你很开心吗”在内涵上有什么区别？和“你不开心吗”？  AI 响应：  “你不开心吗”是一种戏剧性的、对抗性的验证要求，由《角斗士》流行起来，暗示观众忘恩负义或漠不关心。相反，“你开心吗？”是一种中立、礼貌的询问，旨在确认享受。前者主张优越性，而后者则表明谦逊或渴望反馈。  成功了。   由   提交/u/Markdd8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlw4w7/a_question_about_the_connotation_of_are_you_not/</guid>
      <pubDate>Sat, 24 Jan 2026 19:21:11 GMT</pubDate>
    </item>
    <item>
      <title>“GIST 简介：智能采样的下一阶段”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlv5ij/introducing_gist_the_next_stage_in_smart_sampling/</link>
      <description><![CDATA[这刚刚出现在 Google Research 的博客上：https://research.google/blog/introducing-gist-the-next-stage-in-smart-sampling/ 。这似乎使得数据多样性和实用性之间的 np-hard 选择变得多余。现在我们可以同时最大化两者。基本思想是使用“两阶段阈值处理”。识别“VIP”的方法高质量且独特的数据点。   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlv5ij/introducing_gist_the_next_stage_in_smart_sampling/</guid>
      <pubDate>Sat, 24 Jan 2026 18:45:42 GMT</pubDate>
    </item>
    <item>
      <title>AI数据中心作为集中热源</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlsk77/ai_data_center_as_a_centralized_heat_source/</link>
      <description><![CDATA[我们使用大量电力来运行人工智能中心。我们蒸发大量的水来冷却它们。我们应该将它们集中放置，并利用热量来产生更多的电力或将热量引导到通常需要付费为它们供暖的建筑物中。我们实际上蒸发了稀缺的水资源来冷却数据中心的想法可能是我听过的最短视的事情。   由   提交/u/WannaBe_achBum_Goals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlsk77/ai_data_center_as_a_centralized_heat_source/</guid>
      <pubDate>Sat, 24 Jan 2026 17:10:56 GMT</pubDate>
    </item>
    <item>
      <title>人工智能聊天从工具到社会影响力在哪里跨越？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlqs38/where_does_ai_chat_cross_from_tool_into_social/</link>
      <description><![CDATA[虽然我们经常讨论人工智能相关对话的生产力或准确性，但我们并不经常提及它们的社会影响。一旦人们与人工智能分享想法、情感或选择，他们是否会突然受到某种影响？我思考其他人如何划分帮助和影响之间的界限，尤其是在非常直观的对话中。   由   提交 /u/Training-Spite-4223   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlqs38/where_does_ai_chat_cross_from_tool_into_social/</guid>
      <pubDate>Sat, 24 Jan 2026 16:03:59 GMT</pubDate>
    </item>
    <item>
      <title>随着公司越来越多地推动员工使用人工智能工具来缩短项目时间，这是否会削弱批判性思维能力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qlhcoc/as_companies_increasingly_push_employees_to_use/</link>
      <description><![CDATA[与此同时，不使用人工智能的员工可能很难像使用人工智能的员工那样快速解决问题。您对此有何看法？   由   提交 /u/Curious_Suchit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qlhcoc/as_companies_increasingly_push_employees_to_use/</guid>
      <pubDate>Sat, 24 Jan 2026 08:09:35 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个工具来创建 Peter Griffin/Stewie 对话视频 - 以下是它的工作原理</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ql8k2i/i_built_a_tool_to_create_those_peter/</link>
      <description><![CDATA[您可能见过他们 - Peter Griffin 和 Stewie 就 Minecraft 游戏玩法的随机话题进行争论。它们在 TikTok 和 Instagram 上随处可见。 我花了 3 个月的时间构建 AutoClips 来自动化整个过程： 我解决的问题：  手动编写脚本需要很长时间 声音生成工具听起来像机器人 同步两个角色之间的对话是一场噩梦 没有工具可以让你上传自己的游戏背景  我构建的内容：  多角色对话模式（AI 编写自然的来回对话） 自定义角色的语音克隆 使用 AI 生成的图像创建自定义角色 上传您自己的游戏玩法（Minecraft、GTA 等） 6 步向导：主题 → 角色 → 脚本 → 媒体 → 预览 → 导出  第一个视频是免费的，无需信用卡。很高兴回答技术问题。 免费试用：https://www.autoclips.app/character-explainer-videos 演示视频：https://www.youtube.com/watch?v=h6620hbWzYQ 很高兴回答有关架构的技术问题或分享我在构建此架构时学到的知识。   由   提交 /u/iayazalam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ql8k2i/i_built_a_tool_to_create_those_peter/</guid>
      <pubDate>Sat, 24 Jan 2026 00:52:04 GMT</pubDate>
    </item>
    <item>
      <title>中国人工智能正在悄然蚕食美国开发者的午餐，并暴露出“开放”人工智能的一些奇怪之处</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkq97p/chinese_ai_is_quietly_eating_us_developers_lunch/</link>
      <description><![CDATA[在观看最近的 cnbc 文章后一直在思考这个问题。 Zhipu AI（中国实验室，刚刚在香港首次公开募股）不得不限制其 GLM-4.7 编码模型的订阅，因为太多人在使用它。正常的故事吧？除了他们的用户群主要集中在美国和中国，然后是印度、日本、巴西、英国。 让我们明白这一点。美国开发者，那些有权访问 gpt、claude、copilot、cursor 的人，正在选择数量足够大的中国开源模型，足以让他们的服务器崩溃。 美国实验室：建立最好的模型 → 关闭它 → 收取溢价 → 保护知识产权 → 利润最大化 中国实验室：建立一个足够好的模型 → 开源 → 价格非常便宜 → 获得大规模采用 → ??? GLM-4.7 在代码竞技场排行榜上排名第 6。它是开源的。显然它已经足够好了，美国开发者实际上正在将它用于实际工作，而不仅仅是测试。 如果查看开源排行榜，前 10 名模型中有 7 个是中国的。这不是“追赶”不再了。他们在开源方面处于领先地位，而我们却变得更加封闭。 如果你能以 10% 的成本构建一个 90% 的解决方案，并将其开源以便任何人都可以定制它，那么专有的 100% 解决方案对于大多数用例来说还重要吗？ 中国的人工智能战略似乎是“实际应用超过前沿”。他们并不是试图构建 AGI 或赢得基准。他们正在构建运行良好的工具，为它们定价以便每个人都使用它们，并将它们集成到实际的生产工作流程中。 与此同时，美国公司正在进行这场奇怪的军备竞赛，以打造“最先进”的产品。模型，同时充电更多并将其锁定得更紧。然后当开发人员把目光投向其他地方时表现得惊讶哈哈 如果这种趋势继续下去，中国模型主导开源+实际上很好+美国开发人员采用它们，这对美国人工智能生态系统的长期发展意味着什么？ 我们最终会出现两极分化的人工智能开发吗： 消费者人工智能=封闭的美国模型（chatgpt，claude） 开发人员工具/生产系统=开放的中国模型（GLM，deepseek，等） 因为这就是现在所显示的使用模式。 这里有人真正使用 GLM-4.7 进行编码工作吗？不是基准，例如实际生产使用。它与您之前使用的相比如何？ 因为如果它确实足够好+更便宜+开源，似乎是合乎逻辑的选择，除非您锁定到现有堆栈。也许这就是重点。   由   提交 /u/BlueDolphinCute   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkq97p/chinese_ai_is_quietly_eating_us_developers_lunch/</guid>
      <pubDate>Fri, 23 Jan 2026 13:04:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>