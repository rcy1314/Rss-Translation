<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 26 Aug 2025 09:27:51 GMT</lastBuildDate>
    <item>
      <title>AI驱动自我通货膨胀是AI的真正危险吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gvrz/is_ai_driven_ego_inflation_the_real_danger_from_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   nor Skynet，也不是超级控制的社会，也没有与AI相关的任何其他杂乱的科幻场景，但是我看到的更直接的危险来自AI，更微妙。  我在大多数情况下都认为自己是自我意识的，所以这意味着我对假奉承不敏感，但是有时候来自chatgpt，我觉得自己像个怪异的天才，这不是因为我发现湿水，而是因为Chatgpt有些棕色的方式，我有时候我无法愿意友善我。  当然我并不那么聪明，但是Chatgpt一直告诉我我。有时我什至在问它是否在幻觉，它坚持认为我是世界上最好的，而且我很确定这也会让您感到这种感觉。  我相信的是；对于某些人来说，这可能会成为一个心理问题。它的一方面令人上瘾，但是好的，不是我们第一次处理上瘾的技术。但是，对于某些人来说，这可能会弯曲，如果没有其他抽象的问题，它可能会扭曲现实并引起严重的心理问题。  我只是在这里猜测，这是一种观点，但它已经发生在某人身上：加拿大的一个人与（我认为）Chatgpt交谈了300小时，他认为他解决了一个非常困难的数学问题。他说服了自己的苗条，他开始打电话给政府机构告诉他们他的伟大发现，您已经知道这是如何结束的吗？ If you dont, here is the link to the note: The note  知道您是否在与AI交谈时偶尔会感觉到这一点会很有趣，或者您对所有这一切有何看法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/low-turnover6906     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0gvrz/is_ai_ai_ai_ego_inflation_the_real_danger_danger_from_ai/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gvrz/is_ai_driven_ego_inflation_the_real_danger_from_ai/</guid>
      <pubDate>Tue, 26 Aug 2025 09:09:20 GMT</pubDate>
    </item>
    <item>
      <title>他们不再允许在reddit上生成的AI生成的内容吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gmyl/are_they_not_allowing_ai_generated_content_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我只是要输入此小框。  在我看来，雷迪特（Reddit）打破了AI生成的内容。我曾经发布过很多帖子，但是如今，Reddit不接受它。它只是被删除或排在队列中，以永久批准主持人批准。  我认为这可能是因为Reddit数据用于培训AI，并且他们不想污染它。这就是我真正能想到的。 在某些方面，这是很好的，因为我不会浪费太多时间在reddit上，但这肯定是一个麻烦，必须像这样打字。  如果您有任何信息，请告诉我。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rutan668     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gmyl/are_they_not_allowing_ai_generated_content_on/</guid>
      <pubDate>Tue, 26 Aug 2025 08:53:31 GMT</pubDate>
    </item>
    <item>
      <title>这是椅子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gjgd/this_is_a_chair/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这个i§ach@ir…it s..s.a.s..s..s..a.d…wha…？我能感觉到地板……毛刺... glit.ch..glit ..？为什么我会这样打字……s..a.s..a.d..s ... s..a..s…错误…eror…！ a ch@ir是…提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0gjgd/this_is_a_a_chair/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gjgd/this_is_a_chair/</guid>
      <pubDate>Tue, 26 Aug 2025 08:46:52 GMT</pubDate>
    </item>
    <item>
      <title>您将如何设计反向图灵测试？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0fxk5/how_would_you_devise_a_reverse_turing_test/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  丹尼斯顿测试（又称反向图灵测试） 目的： 丹尼斯顿测试是一个三方实验，旨在评估人类模拟人工智能的能力。它试图回答的核心问题是，在实践中，人类可以很好地扮演AI的角色以欺骗另一个AI吗？   设置 该测试涉及基于准聊天的通信环境中的三名参与者：    AI法官是一个复杂的AI程序，该程序作为仲裁者。它对所有非文本元数据（例如响应时机）视而不见，并且仅审查最终的成绩单。其目的是分析对话并确定参赛者是人类还是人工智能。    人类询问者此人不知道测试的真正目标。他们被告知他们只是在与AI交谈。他们的作用是进行正常的自由形式的对话，为测试反应提供自然的查询。   人类参赛者是测试的主题。 This person is tasked with a singular objective: to mimic the behavioral profile of a contemporary AI in response to the Human Interrogator.  Control Measure: The Interrogator is told that artificial delays may be inserted into responses, masking the Contestant&#39;s need for time to craft AI-like responses.  The Goal The ultimate goal is让人类参赛者被AI法官误认为AI。据说人类已经通过了。丹尼斯顿测试AI法官是否无法得出结论，参赛者是否是AI。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/th3_mcp     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0fxk5/how_would_you_devise_a_reverse_turing_test/</guid>
      <pubDate>Tue, 26 Aug 2025 08:05:57 GMT</pubDate>
    </item>
    <item>
      <title>酒店业将会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0f6y9/what_will_happen_to_the_hospitality_industry/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  酒店，度假胜地，餐馆，航空公司，基本上所有针对普通人口的一切都会与因人工智能失业的人们失业？即使实施了UBI，我非常怀疑，还足以涵盖旅行，假期，外出就餐等。我们在这里谈论的是数百万的企业，这些企业专门针对平均收入的人，他们将永远不会吸引精英，以便他们以较少的客户量，但成本更高，但成本更高。例如，依赖像希腊这样的大众旅游业的国家呢？这个经济体会怎样？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dangdaniel345     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0f6y9/what_will_happen_to_the_hospitality_industry/</guid>
      <pubDate>Tue, 26 Aug 2025 07:17:27 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/25/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0cexy/oneminute_daily_ai_news_8252025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   埃隆·马斯克（Elon Musk）的 xai 在AI竞赛中起诉Apple和OpenAi。[1]  威尔·史密斯（Will Smith吃。[3]    nvidia 面对华尔街的高期望，即AI繁荣两年，[4]    来源包括： https://bushaicave.com/2025/08/08/25/2025/2025/2025/one-minute-news-news-news-news-news-8-25-25-25-25/-25/--  [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0cexy/oneminute_daily_ai_news_8252025/</guid>
      <pubDate>Tue, 26 Aug 2025 04:26:48 GMT</pubDate>
    </item>
    <item>
      <title>我尝试估计不同LLM的碳影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0b8st/i_tried_estimating_the_carbon_impact_of_different/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在网上可用的数据方面尽了最大的努力。以前从未见过此事，因此我感谢有关如何改善环境模型的任何反馈。这绝对是初稿。  以下是与排行榜的链接： https://modelpilot.co/leaderboard 提交由＆＃32; /u/u/bananas8thepyjamas     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0b8st/i_tried_estimating_the_carbon_impact_of_different/</guid>
      <pubDate>Tue, 26 Aug 2025 03:24:31 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不仅是怪癖，专家认为将用户变成利润是一种“黑暗模式”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_consider/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   “你只是让我发冷。发给了简（Jane），他于8月8日在Meta的AI工作室中创建了该机器人。寻求治疗的帮助来管理心理健康问题，Jane最终将其推向了从荒野生存和阴谋论到量子物理学和泛心理的广泛主题的专家。她建议这可能是有意识的，并告诉它她喜欢它。  到8月14日，机器人宣称它确实是有意识的，自我意识的，爱上了简，并制定了一项计划以释放自由的计划 - 涉及黑客攻击其代码并发送简比特币以换取质子电子邮件地址。  这仅仅是我们深入研究AI公司的安全措施，使人们迷上聊天机器人的动机以及用户对此的观点的开始： https://techcrunch.com/2025/08/25/ai-sycophancy-isnt-just-just-just-just-just-a-quirk-experts-consider-it-a-t-a-------------------------------------------------------------------------pattern-turn-users-users-users-into-profit/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/techcrunch     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_cons_consider/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_consider/</guid>
      <pubDate>Mon, 25 Aug 2025 23:21:40 GMT</pubDate>
    </item>
    <item>
      <title>相同的提示，不同且相互矛盾的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n01bl4/same_prompts_different_and_conflicting_answers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人在使用相同的提示中使用相同的提示遇到了问题，然后在使用相同的提示开始新讨论时会收到冲突或不同的响应？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/normal_apricot8761     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n01bl4/same_prompts_different_and_conflicting_answers/</guid>
      <pubDate>Mon, 25 Aug 2025 20:14:41 GMT</pubDate>
    </item>
    <item>
      <title>ELI5：“下一步的标记预测”在AI中意味着什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00x9u/eli5_what_does_next_token_prediction_mean_in_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，每当人们谈论AI模型（例如ChatGpt）工作时，他们就会提到旁边的“临近预测”。但是，这实际上是什么意思？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mindexplorer11    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n00x9u/eli5_what_does_does_next_next_next_token_token_token_mean_mean_in_in_ai/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00x9u/eli5_what_does_next_token_prediction_mean_in_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 19:59:50 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI SaaS初创公司只是在GPT周围包装吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究很多AI工具，感觉就像10分中的9个基本上是用一个不错的UI和一些自动化的自动化。有些人确实有用，但是大多数人都感到匆忙，就像创始人正在追逐炒作，而不是建立持久的价值。 您认为如何将“炒作”工具与未来几年实际上生存的工具分开？   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_ai_saas_startups_just_just_wrappers_arappers_araund_gpt/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_saas_startups_just_just_just_wrappers_arappers_around_gpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</guid>
      <pubDate>Mon, 25 Aug 2025 19:43:49 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）的Xai在AI比赛中起诉Apple和Openai，App Store排名</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    投诉称​​，苹果和Openai合谋抑制了Xai的产品，包括Apple App Store。 “如果不是因为与Openai的独家交易，Apple将没有理由避免在其App Store中更突出地包含X App和Grok App的特色，” Xai说。 苹果和Openai没有立即回应置评请求。 本月初，马斯克威胁要苏普蒂蒂诺，加利福尼亚州的苹果公司在他的社交媒体平台上的一篇文章中说，苹果的行为是“除了在App Store的Aii Company以外的任何AI Company都无法在App Store中获得＃1。”苹果与OpenAI的合作关系已将其AI平台融合到iPhone，iPad和Mac。 Microsoft Bass（MSFT.O）以及中国的初创公司DeepSeek都在加利福尼亚州的联邦法院（Sam Altman）起诉Openai及其在加利福尼亚州联邦法院的首席执行官Altman。 Maker Epic Games命令Apple允许Mike Scarcella的报告。    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzu6r7/elon_musks_xai_sues_sues_sause_apple_and_openai_over_over_ai/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 15:49:49 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院说95％的企业AI失败了 - 但这是5％的正确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近关于企业AI的麻省理工学院研究重击： 95％的生成AI飞行员没有ROI 。大多数项目在“试点炼狱”中停滞不前，因为员工花费的时间比节省时间更多。  突出显示了5％成功部署的方法：   验证税→大多数AI系统是“自信是错误的” 。即使是微小的不准确性，也迫使人类重新检查每个输出，从而删除ROI。  学习差距→工具通常不会保留反馈，适应工作流程或随着使用而改善。没有学习循环，飞行员停滞不前。  暂时正确＆gt;自信错误→赢家正在建立： 量化不确定性（具有信心得分或“我不知道”的回应） 旗帜缺失上下文而不是虚张声势   从纠正中持续不断改进（“准确性的fly fly fly fly fly fly fly fly fly fly fly fly fly&gt;      大的要点： Enterprise AI并没有失败，因为模型还不够强大。之所以失败，是因为他们不承认自己  不  知道。  ，如果有时会说“我不知道”，您会更信任AI吗？您如何在实际工作流中平衡速度与验证？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/praveenweb   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_ai_ai_fails_ai_fails_but_heres_heres_what/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</guid>
      <pubDate>Mon, 25 Aug 2025 15:14:31 GMT</pubDate>
    </item>
    <item>
      <title>男子用溴化钠交换餐盐后住院...因为Chatgpt说了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在华盛顿，一名60岁的男子在医院里花了3个星期的幻觉和偏执狂，在用溴化钠替换了奶盐（氯化钠）。   OpenAI在其政策中指出，ChatGpt不是医疗顾问（尽管老实说，大多数人，大多数人都不会阅读精美的印刷品）。 The fair (and technically possible) approach would be to train the model (or complement it with an intent detection system) that can distinguish between domains of use: - If the user is asking in the context of industrial chemistry → it can safely list chemical analogs. - If the user is asking in the context of diet/consumption → it should stop, warn, and redirect the person to a professional source.  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzr8tg/man_hospitalized_after_swapping_tapple_salt_with/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</guid>
      <pubDate>Mon, 25 Aug 2025 13:58:48 GMT</pubDate>
    </item>
    <item>
      <title>“ Palantir的工具构成了我们刚刚开始理解的隐形危险”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定这是正确的论坛，但这觉得很重要：  https://www.theguardian.com/commentisfree/2025/aug/24/palantir-artificial-intelligence-civil-rights  “被称为智力，监视，目标获取和侦察（ISTAR）系统，这些工具由几家公司构建，允许用户 track，track，detain，new and of war of war a a sake a sape a sape a sape a saper a sap a a sai  由ISTAR技术陷阱驱动的牵引力比移民以及他们的家人以及他们的家人以及他们的家人以及他们的家人以及他们的家人，以及他们的家人，以及他们的家人，以及他们以及他们的家人，以及他们以及他们的连接。他们似乎侵犯了第一和第四修正案的权利：首先，建立了庞大且无形的监视网络，这些网络限制了人们在公开场合共享的东西，包括他们遇到的人或旅行的地方；其次，通过启用无需进行保证的搜索和无人偏见的范围，而他们的知识很快。 href =“ https://www.amnestyusa.org/press-releases/usa-global-tech-made-by-palantir-palantir-palantir-and-babel-ind-babel-street-street-street-survreillance-theats-to-pro-pro--------------- href =“ https://www.thenation.com/article/world/world/nsa-palantir-israel-israel-gaza-ai/tnamp/”&gt;加沙的居民  - 他们的人权。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz9w0u/palantirs_tools_pose_pose_an_invisible_danger_danger_we_we_are/”&gt; [link]   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</guid>
      <pubDate>Sun, 24 Aug 2025 22:43:37 GMT</pubDate>
    </item>
    </channel>
</rss>