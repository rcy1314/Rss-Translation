<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 11 Mar 2025 09:24:03 GMT</lastBuildDate>
    <item>
      <title>LLM受正式系统的局限性支配</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mfns/llms_are_governed_by_the_limitations_of_formal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  虽然LLM的表面行为是概率和非轴心的，但其基本机制 - 它运行的代码，数学和机器 - 基于正式系统。因此，它所做的一切最终都受这些系统的局限性的控制。      llms在正式的基材内运行 - 它们是通过确定性程序（例如，使用数学结构（如张量，线性代数，优化算法）在正式系统中描述的       。 （例如，生成一个句子）可能看起来“软”或“紧急”，但是产生它们的过程最终受正式的可计算规则的控制。   因此，该模型生成的任何统计结果均受：A。A. Formor System的构图，该正式系统定义了模型的体系结构和训练过程。 B.教会论文所施加的计算限制（即模型无法超越图灵表现力）。      ，换句话说，查询本身，这些查询本身是有条件的公理概念，在这些套件的上下文中购买结果。 （以这种方式结果是有意义的。） 看起来巨大，流畅和紧急的系统可以通过固定的基于规则的结构从下面界定，以至于它们的“判断”仍然位于公理框架内。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mfns/llms_are_are_governed_by_the_limitations_of_formal/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mfns/llms_are_governed_by_the_limitations_of_formal/</guid>
      <pubDate>Tue, 11 Mar 2025 08:59:36 GMT</pubDate>
    </item>
    <item>
      <title>AI可以帮助学术写作吗？实验结果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mfkf/can_ai_paraphrasing_help_with_academic_writing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近，我进行了一个小实验，以测试AI释义工具在学术写作中的有效性。我采用了AI生成的文章，并采用了不同的释义方法（AI释义与手动重写）。然后，我使用了AI检测工具来检查每个版本的绕过检测程度。 结果非常有趣：   - 原始的AI生成的文本具有 95％的概率被检测为Ai-worting的概率。            - 使用AI释义工具进行处理后，概率降至10％。 您怎么看？ AI是否可以在将来完全替换手动解释，或者人类的改进将永远是必要的？让我们讨论！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mfkf/can_ai_ai_ai_ai_paraphrasing_help_with_academic_writing/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mfkf/can_ai_paraphrasing_help_with_academic_writing/</guid>
      <pubDate>Tue, 11 Mar 2025 08:59:24 GMT</pubDate>
    </item>
    <item>
      <title>有时候，当我在提示中呆滞时，GPT知道我的意思。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mc3a/sometimes_when_i_am_sloppy_in_my_prompts_gpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  换句话说，我可能会在提示中忘记规范，但GPT由于上下文而理解我的意图。这真是令人印象深刻。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mc3a/sometimes_when_i_i_am_sloppy_my_my_my_my_prompts_gpt/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8mc3a/sometimes_when_i_i_sloppy_my_my_my_my_my_prompts_gpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mc3a/sometimes_when_i_am_sloppy_in_my_prompts_gpt/</guid>
      <pubDate>Tue, 11 Mar 2025 08:51:26 GMT</pubDate>
    </item>
    <item>
      <title>“我无法为您生成代码，”光标要求开发人员“学习编码”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mbvw/i_cannot_generate_code_for_you_cursor_asks/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/soul_predator     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8mbvw/i_cannot_generate_code_for_you_cursor_asks/</guid>
      <pubDate>Tue, 11 Mar 2025 08:50:59 GMT</pubDate>
    </item>
    <item>
      <title>Claude 3.7 OCR完全失败/幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8m9nn/claude_37_ocr_completely_failinghallucinating/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在玩耍，以提示克劳德（Claude）根据来自Excel Workbook的数据的屏幕截图生成交互式信息图表。我注意到这在这里和那里造成了阴险的小错误。例如，将151,342读为111,342。   i随后测试了屏幕截图足够清晰，可以看到正确的数字。 拿起带有数字的2x10单元格网格的小屏幕截图，并只是要求克劳德告诉我它看到的数字。这次是正确的，但最完全错误的。例如：将129,443读为72,309。 ，但它并没有完全弥补，因为下一个单元格会正确。 在第二种情况下，屏幕截图也足够清晰，无法阅读。 在这里发生什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nateisgrate     [link]   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8m9nn/claude_37_ocr_completely_failinghallucinating/</guid>
      <pubDate>Tue, 11 Mar 2025 08:45:56 GMT</pubDate>
    </item>
    <item>
      <title>“出现”很愚蠢</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8ll9k/emergence_is_silly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  只是一个想法 - 我没有声称这是正确的，但我想分享一种直觉。认为它类似于罗杰·彭罗斯（Roger Penrose）的无限宇宙理论，这只是一个想法。 “出现”的概念有些误导。当我们谈论大型语言模型（LLMS）中的出现时，我们通常会对意外的能力感到惊讶。但是我相信这种现象超出了LLM，它存在于所有数据中。我们尚未考虑的所有数据集中都有潜在功能，但是它们仍然存在。诸如变形金刚之类的模型有助于发现这些有影响力的隐藏特征，揭示了始终存在但以前没有注意到的模式。 以推理为例。每个连贯的博客文章，故事或评论都包含一定程度的逻辑。如果推理不是我们提供给LLM的数据的固有功能，那么它们的输出就没有意义。这表明“推理”是嵌入语言本身中的隐藏功能。如果我们有提前分析和公开此类功能的工具，那么当模型显示推理能力时，我们不会感到惊讶。 现在，没有这种工具可以系统地探索这种隐藏的功能空间。但是，如果我们要开发一个，我们甚至可以在训练它之前预测模型的完整功能。这也可能使我们更加了解黑匣子的机器学习。 无论如何，只是一个淋浴的想法。这个想法是否承担着任何重量。继续学习并获得乐趣！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/phy2go      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8ll9k/emergence_is_silly/</guid>
      <pubDate>Tue, 11 Mar 2025 07:51:48 GMT</pubDate>
    </item>
    <item>
      <title>如果AI本质上比人类更聪明，我们该如何监视AGI/ASI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j8jdg1/how_can_we_monitor_agiasi_if_the_ai_is_inherently/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经考虑过一段时间了，这是一个严重的问题，我还没有看到任何解决方案。如果我们实现AGI/ASI（即模型超过所有人类智能的点），则似乎不可能监视它以保持对齐方式。根据定义，要么1）即使是最聪明的人也无法完全理解模型的功能，或者2）人类可以认为他们理解模型的功能，但实际上无法确定，因为模型欺骗了它们，因为该模型本质上更聪明。一旦我们达到了人工智能的行动，超出了人类理解的观点，无论是对人类的好事还是坏事，似乎完全取决于偶然。 Yampolskiy在某种程度上写了有关此的文章。我错了吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8jdg1/how_can_we_we_we_monitor_agiasi_agiasi_if_the_ai_is_is_inheryse/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j8jdg1/how_can_we_we_we_monitor_monitor_agiasi_agiasi_if_the_ai_iis_is_inhereyse/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j8jdg1/how_can_we_monitor_agiasi_if_the_ai_is_inherently/</guid>
      <pubDate>Tue, 11 Mar 2025 05:10:19 GMT</pubDate>
    </item>
    <item>
      <title>您是否推荐一部好电影，播客LR采访，以了解AI将如何影响就业市场？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j88mn4/do_you_recommend_a_good_movie_podcast_lr/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对这个主题感兴趣，也必须在我的作业上找到一些有趣的来源，如果您知道一些好的，我很高兴我很高兴听到您的建议！   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/itzzom     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j88mn4/do_you_recommend_a_good_movie_podcast_lr/</guid>
      <pubDate>Mon, 10 Mar 2025 20:33:15 GMT</pubDate>
    </item>
    <item>
      <title>当前的AI模型是真正的推理，还是只是预测下一个令牌？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j878uh/are_current_ai_models_really_reasoning_or_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着围绕AI推理的所有嗡嗡声，当今的大多数模型（包括LLMS）仍然依赖下一步的预测，而不是实际的计划。 ？ 您如何看待，没有计划机制，AI可以真正理由，还是我们坚持不懈地完成自动完成？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j878uh/are_current_ai_models_really_reasoning_or_just/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j878uh/are_current_ai_models_really_reasoning_or_just/</guid>
      <pubDate>Mon, 10 Mar 2025 19:34:39 GMT</pubDate>
    </item>
    <item>
      <title>我们解决了UR的皇家游戏</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j85425/we_have_solved_the_royal_game_of_ur/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，另一个旧的棋盘游戏咬住了灰尘……我们强烈解决了约4500年的皇家游戏。您可能会记得汤姆·斯科特（Tom Scott）与YouTube上的欧文·芬克尔（Irving Finkel）视频，这很受欢迎。 为了解决游戏，我们扩大了对价值迭代的使用来创建一个地图，并有机会从游戏中的每个州获胜。使用它，您只需选择导致获胜机会的最高机会的举动即可。简单的！虽然，我们仍然花了3年的时间才弄清楚这是可能的…… 从更技术上来说，我们计算了游戏的NASH均衡，我们可以使用它使bot毫无疑问地发挥作用。  huggingface for Seloved Maps： https://huggingface.co/sothatsit/royalurmodels      github用于解决游戏： https://github.com/royalur/royalur/royalur-java   这实际上对我来说是很大的事情。但是我很感兴趣，这里的人们如何看待解决这些旧的棋盘游戏？是20年前有趣的好奇心吗？还是这些类型的经典AI方法仍然剩下一些现实世界中的影响？我对他们的表现感到乐观，但我不确定。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/sothatsit     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j85425/we_have_solved_the_royal_game_of_ur/</guid>
      <pubDate>Mon, 10 Mar 2025 18:07:11 GMT</pubDate>
    </item>
    <item>
      <title>决定在我的iPhone上尝试图像操场。为什么苹果的人工智能如此糟糕？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j83t6d/decided_to_try_out_image_playground_on_my_iphone/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我提出的提示是“近距离的映像”，这就是我得到的。我认为整个六个手指的事情现在应该是现在的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aggressive_action      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j83t6d/decided_tro_try_image_image_playground_on_my_iphone/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j83t6d/decided_to_try_out_image_playground_on_my_iphone/</guid>
      <pubDate>Mon, 10 Mar 2025 17:13:47 GMT</pubDate>
    </item>
    <item>
      <title>将大脑外包给AI时的大脑如何变化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j7xjda/how_your_brain_changes_when_you_outsource_it_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为这是一篇非常考虑的文章，总结了很多我一直在仔细考虑我们如何和应该在生活中使用AI和数字工具的事情。长阅读，但是一个好读物：   https：//wwwwwwww.ox.com/future-perfect/403100/403100/ai-brain-brain-brain-brain-brain-brain-brain-brain-fects-technology-mous as we Mous as at we-as at we we we we/we we/p&gt; p&gt; Think＆quot＆quot，Vannevar Bush的1945年论文，但仍然很好）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jacknunn     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j7xjda/how_your_your_your_brain_changes_changes_when_you_you_outsource_it_it_it_it_it_to_ai/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j7xjda/how_your_brain_changes_when_you_outsource_it_to_ai/</guid>
      <pubDate>Mon, 10 Mar 2025 12:33:26 GMT</pubDate>
    </item>
    <item>
      <title>人们非常低估了人工智能。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j7nb8r/people_underestimate_ai_so_much/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在一个每天与很多人互动的环境中工作，它也在技术领域中，所以当然，技术是一个经常讨论的话题。 我一直发现自己对人们如何在这些模型（例如gimmick orse gimmick或不用有用）中感到困惑。我可以提及我如何与AI讨论一些主题，它们会笑或似乎对我从与模型的互动中获得的信息表示怀疑。  我始终回答了我的问题，这些模型扩大了我的知识。我一直发现他们可能会帮助麻烦拍摄，识别或推理问题，并为我提供解决方案。这些模型将在很短的时间内完成5-6个Google搜索和时间滚动以找到正确的文章的事情。我认为，只要询问这些模型，就可以回答和解决他们的日常问题及其日常混乱点。  他们没有这样看到。他们几乎认为这相当于要求机器为您打字。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j7nb8r/people_underestimate_ai_so_so_so_much/”&gt; [link]      [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j7nb8r/people_underestimate_ai_so_much/</guid>
      <pubDate>Mon, 10 Mar 2025 01:30:14 GMT</pubDate>
    </item>
    <item>
      <title>是时候在我们的潜艇中摇晃一切了吗？分享您的想法！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   再次发布，以防万一你们中的某些人在社区中错过了它 - 欢迎所有建议！   嘿，伙计，   我是这里的一个mod，我们知道有时会变得有些沉闷，但是我们计划改变这一点！我们正在寻找有关如何使Reddit的小角落更加出色的想法。 以下是几个想法：   amas with Cool Ai peeps      主题讨论线程         giveawey&gt; g&gt; giveawey  将您的想法放在评论中，让我们让这个子成为闲逛的杀手级！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/beachbunny_07     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6inz4/time_time_to_to_to_to_to_things_up_in_our_our_our_subgot_ideas_share/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</guid>
      <pubDate>Sat, 08 Mar 2025 14:47:17 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>