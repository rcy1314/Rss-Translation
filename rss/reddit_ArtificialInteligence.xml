<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 11 Feb 2026 05:06:50 GMT</lastBuildDate>
    <item>
      <title>我向 AI 描述了我的歌曲，但没有让它听到。这是它与真品的对比。里面投票。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1o2tl/i_described_my_song_to_ai_without_letting_it_hear/</link>
      <description><![CDATA[今晚进行了一个快速实验。 我制作音乐并拍摄了我的一首歌曲并将其描述给 AI。故事、情绪、乐器、声调。但我从来没有让它听到实际的曲目。 所以它必须纯粹根据歌曲的书面想法生成自己的版本。 现在有两个版本。我的和人工智能的解释。 很好奇人们认为哪一个在情感上更人性化。 原创 Spotify https://open.spotify.com/track/3SZ136cvELb9iJ3IkPKa07?si=h87rhwfvTAStk1G8HPKxXg AI版Udio https://www.udio.com/songs/t47L6McB2GTFBmJKAm6XBj 我给出的描述 独立摇滚民谣，讲述一个女人情感上的心碎像石头一样坚硬。找到一张类似美女的照片后，记忆重新浮现，将叙述者拉回过去在曼哈顿从苏荷区到列克星敦的恋情，而她在情感和社交上渐行渐远。 忧郁梦幻的语气。古筝纹理、原声吉他、钢琴、立式贝斯、柔和的鼓、环境键、分层的电吉他营造出情感。亲密脆弱的男声。缓慢摇摆的能量会形成更具戏剧性的东西。温暖一点的低保真制作。 如果有人想放弃自己的歌曲，我也会听并回应。 下面的投票：哪个版本更人性化？ 查看投票   由   提交 /u/SizzleInGreen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1o2tl/i_described_my_song_to_ai_without_letting_it_hear/</guid>
      <pubDate>Wed, 11 Feb 2026 04:51:33 GMT</pubDate>
    </item>
    <item>
      <title>学生对人工智能有很多看法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1nccd/student_has_a_heavy_load_of_opinions_on_ai/</link>
      <description><![CDATA[在对这所人口稠密的通勤学校引入人工智能专业的愤怒中，一名学生发表了这些观点。这是虚伪还是无稽之谈？ 学生发帖：“（我不是人工智能专业，也不会，我只是想分享一个想法。另外，我不同意黑人研究被删除，但我们都知道这是由于 DEI 和美国总统......） 我认为你们看到这个专业被引入并犹豫和反对它，是那些完全赞成把头埋在沙子里的人，允许历史/文化上由人类完成的工作被人工智能的进化所取代。 是的，人工智能“泡沫”将会破裂，但我相信它只会扩展到其免费使用的组件，请参阅：Grok、ChatGPT、Claude 等。我非常怀疑泡沫的破裂会影响人工智能在医疗、政府、天气预报和自然灾害预测，甚至简单的工厂工作中的使用。 这些都是应该存在的工作。永远被人类占据。 你不必忽视人工智能对生态系统或独立创造者的破坏，就像无神论者不必喜欢宗教一样。简而言之，你仍然可以看到它的好处，它永远不会消失，只是我们中的一些人需要改进。能够控制人工智能缰绳的知识.. 此外..大多数反对人工智能纯粹存在的论点都是基于道德论点，如果我们存在于一个光荣的社会中，就永远不会成为问题。 （例如：人们从独立艺术家那里窃取艺术品并将其喂给人工智能，所以现在像ChatGPT这样的法学硕士永远会吐出由于吉卜力风格的艺术家而产生的黄色染色图像） 我觉得将旗杆插在沙子上并宣称“我不仅反对人工智能，而且它不应该完全存在！”完全是好战的，让人想起我们的前几代人是如何意识到他们无法跟上技术的推出，因此他们完全反对它并将其从日常生活中排斥出来。 （彩色电视，PS2、Wii 之外的任何东西） 人工智能有很多用途，我担心 POC 人口如此之多，我们不应该集体完全反对它作为人类/生态系统的论点，相反，至少我们中的一些人应该追求理解 AI/LLMs/Gen AI，不仅可以构建和管理它，而且能够使它们成为道德和不被滥用的工具，就像有一天的锤子一样“   由   提交/u/Independent-Camp-520   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1nccd/student_has_a_heavy_load_of_opinions_on_ai/</guid>
      <pubDate>Wed, 11 Feb 2026 04:14:45 GMT</pubDate>
    </item>
    <item>
      <title>对于大型模型性能来说，委派比智能更重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ln1v/delegation_is_more_important_than_intelligence/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ln1v/delegation_is_more_important_than_intelligence/</guid>
      <pubDate>Wed, 11 Feb 2026 02:55:23 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 在讨论杰弗里·爱泼斯坦时遇到了奇怪的困难</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ksep/chatgpt_is_having_a_weirdly_hard_time_discussing/</link>
      <description><![CDATA[ 由   提交/u/runswithscissors475  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ksep/chatgpt_is_having_a_weirdly_hard_time_discussing/</guid>
      <pubDate>Wed, 11 Feb 2026 02:17:12 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 宣布 GPT-5.3-Codex</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ja9t/openai_announces_gpt53codex/</link>
      <description><![CDATA[ 由   提交 /u/QuantumQuicksilver   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ja9t/openai_announces_gpt53codex/</guid>
      <pubDate>Wed, 11 Feb 2026 01:09:57 GMT</pubDate>
    </item>
    <item>
      <title>有人在 Kubernetes 集群中运行 LLM 吗？好奇人们如何处理安全问题。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ii7l/anyone_running_llms_in_kubernetes_clusters/</link>
      <description><![CDATA[嘿，我在 MetalBear（我们制作镜像）工作，我们一直在深入研究在 Kubernetes 上运行自托管 LLM 的安全方面。 简单来说，k8s 完美地完成了它的工作，调度、隔离、运行状况检查，但它不知道工作负载实际做了什么。当模型从训练数据中泄露凭证或进行提示注入时，pod 看起来可能完全健康。 我们编写了我们认为最重要的模式：提示注入、输出过滤、模型工件的供应链风险以及工具权限。包括模型前面的最小安全网关的参考实现。 很想听听其他人在做什么。您是否在自托管模型前面放置了任何策略层？使用 LiteLLM 或 Kong AI Gateway 之类的东西？或者还不担心这个问题？   由   提交/u/jakepage91  [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ii7l/anyone_running_llms_in_kubernetes_clusters/</guid>
      <pubDate>Wed, 11 Feb 2026 00:35:34 GMT</pubDate>
    </item>
    <item>
      <title>希格斯菲尔德结束了吗？该公司被指控让用户生成次要的 NSFW 内容，现在面临着重大反弹，因为有证据表明，在获得黑色星期五交易后，该公司停止向年度订阅者提供服务。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ic5f/is_higgsfield_over_the_company_accused_of_letting/</link>
      <description><![CDATA[这家被指控让用户生成轻微的 nsfw 内容的公司现在面临着重大反弹，因为有证据表明，在获得黑色星期五优惠后，该公司停止向年度订阅者提供服务。   由   提交/u/raifeller  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ic5f/is_higgsfield_over_the_company_accused_of_letting/</guid>
      <pubDate>Wed, 11 Feb 2026 00:28:26 GMT</pubDate>
    </item>
    <item>
      <title>美国还没有准备好应对人工智能对就业的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1hc42/america_isnt_ready_for_what_ai_will_do_to_jobs/</link>
      <description><![CDATA[长篇评论，让你的心情变得阴暗：https://www.theatlantic.com/magazine/2026/03/ai-economy-labor-market-transformation/685731/    由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1hc42/america_isnt_ready_for_what_ai_will_do_to_jobs/</guid>
      <pubDate>Tue, 10 Feb 2026 23:46:11 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 的“匿名”采访由一位教授使用广泛使用的法学硕士进行了去匿名化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ax4m/anthropics_anonymous_interviews_are_deanonymized/</link>
      <description><![CDATA[12 月，人工智能公司 Anthropic 推出了其最新工具 Interviewer，据新闻稿称，该工具在其初始实施中“帮助了解人们对人工智能的看法”。作为 Interviewer 推出的一部分，Anthropic 公开发布了在该平台上进行的 1,250 次匿名采访。 然而，东北大学的 Tianshi Li 进行的概念验证演示提出了一种使用广泛使用的大语言模型 (LLM) 来对匿名采访进行去匿名化的方法，以便将回答与真实的参与者联系起来。 以下是完整的故事，有兴趣阅读更多内容的人可以阅读：https://news.northeastern.edu/2026/02/10/anthropics-interviewer-deanonymized/   由   提交 /u/NGNResearch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1ax4m/anthropics_anonymous_interviews_are_deanonymized/</guid>
      <pubDate>Tue, 10 Feb 2026 19:44:00 GMT</pubDate>
    </item>
    <item>
      <title>印度时报：人类人工智能安全主管突然辞职，在情感丰富的告别信中发出警报</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r17omn/india_times_anthropic_ai_safety_chief_abruptly/</link>
      <description><![CDATA[ 由   提交 /u/JollyQuiscalus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r17omn/india_times_anthropic_ai_safety_chief_abruptly/</guid>
      <pubDate>Tue, 10 Feb 2026 17:49:28 GMT</pubDate>
    </item>
    <item>
      <title>我刚从中国回来。我们没有赢（史蒂文·拉特纳《纽约时报》客座文章）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0yon7/i_just_returned_from_china_we_are_not_winning_nyt/</link>
      <description><![CDATA[由史蒂文·拉特纳 (Steven Rattner) 撰写，他是一位特约撰稿人，曾担任奥巴马政府财政部长顾问。   由   提交/u/somegetit  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0yon7/i_just_returned_from_china_we_are_not_winning_nyt/</guid>
      <pubDate>Tue, 10 Feb 2026 11:51:38 GMT</pubDate>
    </item>
    <item>
      <title>大型科技公司仍然相信 LLM 会带来 AGI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0tfiz/big_tech_still_believe_llm_will_lead_to_agi/</link>
      <description><![CDATA[大型科技公司在 GPU 和数据中心上投入巨资，目标是培训和部署法学硕士？ 我们在法学硕士的改进方面不是已经趋于稳定了吗？所有这些新的基础设施都会做出任何改进吗？ 编辑：我很好奇人们对这份白皮书的看法https://arxiv.org/pdf/2601.23045 “人工智能在任务上的不连贯性是通过测试时的随机性来衡量的，作为其误差的一部分，该误差源于方差，而不是源于方差在我们测量的所有任务和前沿模型中，模型推理和采取行动的时间越长，它们的失败就越不连贯，而模型规模的变化与实验有关。然而，在某些情况下，规模更大、能力更强的模型比规模更小的模型更不连贯。相反，随着能力更强的人工智能追求更困难的任务，需要更多的连续行动和思考，我们的结果预测失败会伴随着更多的不连贯。这表明未来人工智能有时会导致工业事故（由于不可预测的不当行为），但不太可能表现出对不一致目标的持续追求，这增加了针对奖励黑客或目标错误指定的一致性研究的相对重要性。”   由   提交/u/bubugugu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0tfiz/big_tech_still_believe_llm_will_lead_to_agi/</guid>
      <pubDate>Tue, 10 Feb 2026 06:31:19 GMT</pubDate>
    </item>
    <item>
      <title>OpenClaw、MoltBot 或 Clawdbot，无论本周它叫什么，都是今年人工智能安全领域发生的最好的事情。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0qhq1/openclaw_or_moltbot_or_clawdbot_whatever_its/</link>
      <description><![CDATA[是的，两周内发生的安全事件比一些供应商整个历史上发生的安全事件还要多。那个。 我一直在密切关注安全社区的反应。每个主要供应商都发表了他们的看法。思科称其为一场噩梦。帕洛阿尔托表示，这标志着一场危机。趋势科技警告隐形风险。您可能会认为有人将未打补丁的 Windows XP 机器直接插入互联网。在医院里。运行呼吸机。 大家深呼吸。他们缺少一些东西。 OpenClaw 是开源的。一周内有 200 万访问者，这是 GitHub 历史上增长最快的项目之一。开发人员购买 Mac Mini 是为了在他们的闲置房间里运行它。任何人都不应该针对生产系统或公司电子邮件运行此程序，甚至该项目自己的文档也将其描述为不适合大多数非技术用户的实验。创作者对这是什么很诚实。这在这个行业中几乎是闻所未闻的。 实验正是安全性变得更好的方法。 研究人员发现，单击单个恶意链接可以在几毫秒内劫持 OpenClaw 实例，绕过该项目构建的每个沙箱和安全护栏。这是一个重要的教训：旨在包含即时注入的代理人工智能安全控制无法防止控制平面中的架构漏洞。在开源爱好项目上学习这一点比在企业供应商的代理平台上学习更好。发布到其市场的 400 个恶意技能表明，AI 技能注册中心与传统软件包存储库存在相同的供应链问题，但具有更广泛的执行权限。 云计算的早期看起来正是如此。研究人员研究了 S3 存储桶，发现一切都敞开了，整个行业都失去了理智。一路上确实造成了很多损害。但不知何故，我们幸存下来，建立了适当的控制，并继续前进。 OpenClaw 正在为特工 Al 做同样的事情。每个暴露的网关、每个提示注入链、每个恶意技能都在向安全社区传授代理威胁模型在实践中而不是在框架文档中的实际情况。真正的 CVE、真正的攻击链、针对人们可以实际检查的系统的真正缓解模式，而不是黑盒供应商产品。 每个人都担心这个有 180,000 人审查每个缺陷的开源项目。同时，企业代理平台也存在相同的架构问题。您只是看不到它们。 您的企业代理供应商有一个信任页面和 SOC 2 徽章。 OpenClaw 拥有 180,000 名研究人员，他们正在实际进行突破。您认为哪一个先发现问题？   由   提交 /u/Aislot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0qhq1/openclaw_or_moltbot_or_clawdbot_whatever_its/</guid>
      <pubDate>Tue, 10 Feb 2026 03:59:02 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>