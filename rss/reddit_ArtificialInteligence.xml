<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 29 Jan 2026 04:41:43 GMT</lastBuildDate>
    <item>
      <title>这些企业裁员是否会导致人工智能用户减少，从而导致人工智能公司的收入减少？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpxf1o/would_these_corporate_layoffs_lead_to_less_ai/</link>
      <description><![CDATA[以“人工智能重组”为目标，让每家企业减少员工数量，这是否意味着使用人工智能的人会减少？  现在，当然，白领工人并不是唯一使用人工智能的人，但他们最有可能在企业层面上付费使用人工智能，而且我们知道像 OpenAI 这样的公司需要收入才能存在，因此，虽然使用人工智能的主张可以有效地让公司使用更少的人员，但这是矛盾的，这意味着更少的用户付费，更少的人工智能公司收入…… 这里有什么真正合理的矛盾，可以展望人工智能世界的未来吗？   由   提交/u/PartrickStar  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpxf1o/would_these_corporate_layoffs_lead_to_less_ai/</guid>
      <pubDate>Thu, 29 Jan 2026 03:31:30 GMT</pubDate>
    </item>
    <item>
      <title>个人经验：人工智能作为心理健康的支持工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpunv6/personal_experience_ai_as_a_supportive_tool_for/</link>
      <description><![CDATA[我想分享对人工智能和心理健康的个人观点。不是作为许可治疗的替代品，而是作为一种实用的支持工具，真正帮助我改善心理健康。 我主要通过语音而不是文本使用 ChatGPT。我会在散步、锻炼或独自一人需要整理思绪时说话。有时是关于压力、焦虑，或者只是大声思考以大声理清我的想法。对我来说，反应灵敏、有条理的存在可以帮助我放慢速度、反思和调节情绪。 我完全理解这些局限性。人工智能不是人类，不是治疗师，也不能替代专业护理。但在我无法接触到治疗师的时候，或者当我没有陷入危机但仍然需要支持时，它就很有用了。 最让我惊讶的是它在以下方面的效果：  言语处理 情绪调节 减少低风险时刻的孤独感 帮助我保持自我反思的一致性  我认为围绕“人工智能疗法”的讨论有时变得过于二元化。它要么是危险的，要么是奇迹，没有介于两者之间的。我的经验更多地被有意和负责任地使用，它可以成为某些人的支持工具。 我很好奇这里的其他人如何看待这个问题，特别是在护栏、道德和长期使用方面。   由   提交 /u/Far_Tumbleweed7835   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpunv6/personal_experience_ai_as_a_supportive_tool_for/</guid>
      <pubDate>Thu, 29 Jan 2026 01:31:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在情感互动中建立人际亲密关系方面优于人类，但前提是被贴上人类标签</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qptylq/ai_outperforms_humans_in_establishing/</link>
      <description><![CDATA[https://www.nature.com/articles/s44271-025-00391-7  随着大型语言模型对公众的日益普及，出现了以下问题：是否以及在什么条件下，与人工智能（AI）的社交情感互动可以建立类似人类的关系。在两项预先注册分析的双盲随机对照研究中，492 名参与者使用修改后的基于文本的“快速朋友程序”（一种旨在实现快速关系建立的方法）进行二元在线互动，并由人类伙伴或最低限度提示的大型语言模型预先生成响应。当被贴上人类标签时，人工智能在情感上的“深度交谈”互动中建立亲密感方面优于人类伙伴。这种惊人的效果似乎源于人工智能更高水平的自我披露，这反过来又增强了参与者的亲密感。将伴侣标记为人工智能会减少但并没有消除关系的建立，这可能是由于参与者与人工智能互动的动机较低，这反映在较短的反应和减少的亲密感上。这些发现凸显了人工智能在缓解社会领域负担过重方面的潜力，同时强调了迫切需要道德保障，以防止滥用人工智能来培养欺骗性的社会联系。   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qptylq/ai_outperforms_humans_in_establishing/</guid>
      <pubDate>Thu, 29 Jan 2026 01:01:10 GMT</pubDate>
    </item>
    <item>
      <title>初级开发人员上周不小心与 Copilot 共享了我们的 API 密钥</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpt1e9/junior_dev_accidentally_shared_our_api_keys_with/</link>
      <description><![CDATA[让初级开发人员在故障排除时将生产 API 密钥粘贴到代码注释中。 Copilot 摄取了它，现在我们正在处理密钥轮换，并试图弄清楚它是否影响了他们的训练数据。 今天，IR 团队要求更好地控制发送给 AI 编码助理的内容。 您如何监控此类内容？我们没有的设置在这里完全无能为力。    由   提交 /u/theironcat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpt1e9/junior_dev_accidentally_shared_our_api_keys_with/</guid>
      <pubDate>Thu, 29 Jan 2026 00:22:36 GMT</pubDate>
    </item>
    <item>
      <title>人择正在与自己交战</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qppghf/anthropic_is_at_war_with_itself/</link>
      <description><![CDATA[Matteo Wong：“当谈到人类灭绝时，这些不是你想听到的词，但我听到的是：‘事情进展得快得令人不安。’我和 Anthropic 的安全研究员 Sam Bowman 坐在会议室里。根据最新估计，这家人工智能公司的价值为 1830 亿美元，这家人工智能公司完全有动力加快进程，推出更多产品，开发更先进的技术。”但 Anthropic 却自相矛盾——对似乎每一个决定都进行了深入甚至焦虑的思考。 “Anthropic 将自己定位为人工智能行业的超我：在围绕技术的重大问题上拥有最权威的公司，而竞争对手则开发广告和联属购物链接（Anthropic 的首席执行官达里奥·阿莫迪 (Dario Amodei) 对此表示渴望。上周在达沃斯接受采访时指出）。周一，阿莫迪发表了一篇长篇文章《技术的青春期》，讨论了他所谓的“强大的人工智能”（他的公司正在开发的技术）所带来的“文明问题”。这篇文章特别关注民主、国家安全和经济。阿莫迪在 X 上发帖称，“鉴于我们在明尼苏达州看到的恐怖事件，它强调维护国内民主价值观和权利的重要性尤为重要。”这使他成为极少数发表公开声明反对特朗普政府最近行动的科技领导人之一。 “当然，这种言论是良好的品牌宣传，是 Anthropic 在竞争激烈的行业中脱颖而出的一种方式。但我花了很长时间关注该公司，最近又与该公司的许多员工进行了交谈。和包括 Amodei 在内的高管们，我可以说，Anthropic 至少始终如一地传达有关人工智能的道德问题，而且似乎异常关注用户安全……“到目前为止，这一努力似乎正在发挥作用：与其他流行的聊天机器人（包括 OpenAI 的 ChatGPT 和埃隆·马斯克的 Grok）不同，Anthropic 的机器人 Claude 没有发生任何重大的公众事件，尽管它与其他聊天机器人一样先进，并且在某些方面比其他聊天机器人更先进。领域。 （这可能部分是因为它的聊天机器人不生成图像，并且比一些竞争对手的产品拥有更小的用户群。）但是，尽管 Anthropic 迄今为止已经避免了困扰其他大型语言模型的各种丑闻，但该公司并没有激发人们对此类问题将永远避免的信心。当我去年夏天见到鲍曼时，该公司最近透露，在实验环境中，克劳德的版本已经表现出勒索用户的能力，并在用户询问制造生物武器时为他们提供帮助。但该公司无论如何都在推动其模型的发展，现在表示 Claude 自己编写了很大一部分代码，在某些情况下是全部代码。 “Anthropic 发布了白皮书，讲述了它使 Claude 能够实现的可怕事情（‘法学硕士如何成为内部威胁’、‘从捷径到破坏’），并向政治家提出了这些问题。OpenAI 首席执行官 Sam Altman 和其他 AI 高管也长期以来广泛发表了讲话，但这些竞争对手往往为了自己的利益而发布了垃圾的 TikTok 克隆版和垃圾生成器。如今，除了聊天机器人之外，Anthropic 唯一的主要消费产品是 Claude Code，这是一个承诺实现各种工作自动化的强大工具，但其目标受众却相对较少。 “该公司的谨慎态度导致了一种并不总是有意义的企业文化。 Anthropic 给人的印象比竞争对手更真诚地致力于安全，但它也正在全速开发它承认可能非常危险的工具。该公司似乎渴望有机会脱颖而出。但 Anthropic 到底代表什么？” 阅读更多：https://theatln.tc/dAxgnyYD     提交者   /u/theatlantic   [链接]   href=&quot;https://www.reddit.com/r/ArtificialInteligence/comments/1qppghf/anthropic_is_at_war_with_itself/&quot;&gt;[评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qppghf/anthropic_is_at_war_with_itself/</guid>
      <pubDate>Wed, 28 Jan 2026 22:00:43 GMT</pubDate>
    </item>
    <item>
      <title>这些价值数十亿美元的人工智能初创公司没有产品、没有收入和急切的投资者</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpozbp/these_billiondollar_ai_startups_have_no_products/</link>
      <description><![CDATA[Ben Spector 去年秋天向投资者进行了一次不同寻常的推介。 斯佩克特是斯坦福大学的学生，拥有备受推崇的人工智能背景，他没有近期的赚钱计划，也没有传统的融资方案。他甚至没有关于热门人工智能产品的想法。 他拥有的是一个名为“Flapping Airplanes”的实验室，这是一个训练人工智能模型的新颖想法，并且热衷于聘请渴望解决人工智能最大问题的有才华的年轻研究人员。 风险投资公司抓住了支持他的机会。 阅读更多（免费链接）： https://www.wsj.com/tech/ai/these-billion-dollar-ai-startups-have-no-products-no-revenue-and-eager-investors-97c0a9ba?st=XZxGxE&amp;mod=wsjreddit   由   提交/u/wsj  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpozbp/these_billiondollar_ai_startups_have_no_products/</guid>
      <pubDate>Wed, 28 Jan 2026 21:42:47 GMT</pubDate>
    </item>
    <item>
      <title>提醒：人工智能的最大受益者是那些掌握权力的人，而不是我们。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpovb4/reminder_those_who_hold_power_will_benefit_the/</link>
      <description><![CDATA[TL;DR：技术并不能决定未来；谁拥有技术就拥有技术。 免责声明：我不是末日论者，也不是勒德分子。我每天都使用人工智能工具。这篇文章并不是反对技术本身，而是反对围绕技术的妄想。 ​观看 r/singularity 或 r/accelerationism 等订阅者的情绪是很有趣的。有一大群人完全支持人工智能，希望封锁一切监管，希望人工智能能从本质上解决人类的生存问题，让我们过上悠闲的生活。 ​我认为这种观点陷入了危险的“技术乐观主义”。陷阱。这就是为什么“人工智能将拯救我们”叙述有缺陷： ​1. “UBI 与气候”错觉 ​当你质疑大规模失业的乐观主义者时，标准的回答是，“人工智能将迫使/说服领导人实施全民基本收入（UBI），呃。”  当你提到训练模型对环境的影响时，他们陷入了一个确定性陷阱，预测人工智能将从本质上解决气候危机并发明无限能源。 “奇点”他们希望被扎克伯格、奥特曼和马斯克这样的人物拥有。我们真的相信，几十年来将短期股东价值置于环境和劳工权利之上的特定阶层一旦实现了通用人工智能，就会突然变成仁慈的神吗？ ​2.我们已经进入后稀缺时代（而且它并没有解决贫困问题） ​乐观主义者认为人工智能将带来一个消除贫困的后稀缺世界。 然而，我们已经处于食物匮乏后的世界，饥饿依然存在。  问题不在于产能不足，而在于产能不足。这是物流和经济系统的问题。  如果我们现在有足够的食物却无法解决分配问题，为什么我们认为人工智能增加产量就能解决这个问题？如果一家公司开发通用人工智能，历史先例表明他们将利用它来消除竞争并巩固权力，而不是使资源民主化。 ​3.就业谬误 ​我们没有空闲时间的原因并不是因为“工作太多”而是因为我们没有空闲时间。这需要一个机器人来完成。这是因为当前的经济模式需要持续增长和劳动力剥削。 一个理智的社会会利用自动化来减少每个人的工作时间，同时维持工资水平。我们当前的社会利用自动化解雇了一半的劳动力，以提高剩余利益相关者的股价。人工智能不会改变资本主义的逻辑；它加速了它。 ​技术现实（认识论极限） ​除了社会经济问题之外，还有对“人工智能上帝”的理论上的反对意见。叙述。 ​当前的人工智能技术（LLM）有一个基本的认识论问题，仅靠扩展可能无法解决： 它们的输出是概率性的，而不是客观的，并且基于现实。 ​我知道人工智能解决了数学问题，但它很大程度上是通过将当前的数学推理自动化应用于新的输入来实现的。这很有价值，但它不是“超人智慧”。 ​LLM 擅长聚合思维（聚合已知数据）。然而，科学突破通常需要发散性思维（打破既定规则）。而现在的技术不具备发散性思维。 不仅需要发散性思维，而且要把文字与客观现实联系起来，而不是与符号联系在一起。如果没有这一点，即使实现了发散性思维，绝大多数输出​​也将是无用的胡言乱语。 如果人工智能在未知领域（新科学）运行，我们无法在不亲自进行科学研究的情况下验证其输出。 ​结论 ​仅仅因为我们构建了一个读取整个互​​联网的聊天机器人，并不能保证能源和气候问题就能得到解决。我们还需要停止假设技术的存在会自动导致乌托邦。除非经济激励发生变化，否则人工智能将成为少数人的权威工具，而不是多数人的民主化工具。 （我用 Gemini 来完善我的草稿）   由   提交 /u/Boring-Point-7155   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpovb4/reminder_those_who_hold_power_will_benefit_the/</guid>
      <pubDate>Wed, 28 Jan 2026 21:38:32 GMT</pubDate>
    </item>
    <item>
      <title>“基于链接”的互联网真的正在消亡吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qplje0/is_the_linkbased_internet_actually_dying/</link>
      <description><![CDATA[我一直在准备网站的发布，但搜索在一年之内发生了多大的变化，这有点令人沮丧。我坐在这里做平常的事情......关键字，反向链接，等等，然后我意识到我基本上几个月没有点击谷歌链接，因为我只是使用 Gemini 或 GPT 来完成（好吧，几乎）所有事情。 感觉这一举动正在转向 AEO（答案引擎优化）而不是 SEO，但对于如何实际“排名”的清晰度为零。在人工智能的回答中。我环顾四周，发现人们已经开始关注并为此制作工具，就我而言，我使用了 Netranks（如果有人尝试过，请告诉我，我不擅长使用工具......）来看看跟踪“AI 语音份额”是否可行。实际上是一件事（主要是因为我很好奇我的网站是否存在于训练数据中，哈哈），但老实说，我不知道我们是否已经到了可以真正“设计”网站的地步。尚未被法学硕士引用。 您对最近的转变有何看法？它会改变我们寻找东西的方式吗？谷歌是否会据此做出改变？感觉我们正处于一个奇怪的困境，旧的方式已经死了，但还没有人就新的方式达成一致。我觉得如果我不是“机器可读的”我对一些潜在客户来说是隐形的。 人工智能爱好者在想什么？   由   提交 /u/c1nnamonapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qplje0/is_the_linkbased_internet_actually_dying/</guid>
      <pubDate>Wed, 28 Jan 2026 19:35:57 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能系统在受到挑战时 90% 的时间都是错误的，那么它为什么要做出医疗保健决策呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpjz83/if_an_ai_system_is_wrong_90_of_the_time_when/</link>
      <description><![CDATA[不是反问句。实际上是想理解这里的逻辑。 最近的 AMA 数据：一家大型保险公司由人工智能驱动的事先授权拒绝，90% 在上诉后被推翻。 29% 的医生表示，这些否认导致了严重的不良事件。 该系统显然不可靠。但它仍在使用，因为大多数患者不会上诉，而且即使最终赔钱，延迟也会让保险公司受益。 麻省理工学院斯隆管理学院本月表示，人工智能代理“对于企业来说，在任何涉及大笔资金的流程中依赖它们会犯太多错误。” 医疗保健决策是大笔资金。它们也是生与死。 我错过了什么？是否假设技术进步的速度快于危害累积的速度？或者这只是一个经过计算的赌注，责任框架不会跟上？   由   提交/u/DBarryS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpjz83/if_an_ai_system_is_wrong_90_of_the_time_when/</guid>
      <pubDate>Wed, 28 Jan 2026 18:41:26 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind 今天发布了令人兴奋的论文</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qphlej/deepmind_released_mindblowing_paper_today/</link>
      <description><![CDATA[DeepMind 刚刚在 Nature 上发表了一篇关于 AlphaGenome 的新论文，这是一个巨大的进步。基本上，它是一个人工智能，最终可以读取大量 DNA（多达一百万个字母），并真正了解它们如何控制我们的身体，而不仅仅是猜测。它改变了游戏规则，有助于找出罕见疾病并准确查明癌症突变的作用机制。 https://www.nature.com/articles/s41586-025-10014-0   由   提交 /u/virtualQubit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qphlej/deepmind_released_mindblowing_paper_today/</guid>
      <pubDate>Wed, 28 Jan 2026 17:20:35 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 的首席执行官表示，距离人工智能取代软件工程师还有 12 个月的时间。我花时间分析基准和实际使用情况。这就是我持怀疑态度的原因</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpgc1g/anthropics_ceo_says_were_12_months_away_from_ai/</link>
      <description><![CDATA[Dario Amodei 最近声称，我们需要 6 到 12 个月的时间才能让 AI 完成软件工程师所做的一切。大胆的主张，具体的时间表。 我深入研究了 Claude Opus 4.5 基准测试，并将它们与实际开发工作中实际发生的情况进行了比较。 “解决受控回购中明确定义的问题”之间的差距以及“导航具有模糊要求和遗留代码的生产系统”是巨大的。 在这里写下我的分析：参见此处 TL;DR：人工智能在实施方面变得越来越出色。但工程不仅仅是敲代码。它决定应该存在什么代码，承担后果，并解决组织混乱。 您在自己的工作中看到了什么？人工智能工具是否可以提高您的工作效率，或者实际上正在取代您的工作？   由   提交 /u/narutomax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpgc1g/anthropics_ceo_says_were_12_months_away_from_ai/</guid>
      <pubDate>Wed, 28 Jan 2026 16:36:57 GMT</pubDate>
    </item>
    <item>
      <title>我不再和我的老板战斗了。我调用提示“行话桥”立即将“技术债务”翻译为“利润风险”。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/</link>
      <description><![CDATA[但我意识到我正在与“财务人员”谈论“工程师”，而我的提案被拒绝并不是因为它们不好。 我使用人工智能将领域约束与利益相关者价值观联系起来。 “行话桥”协议： 我写下我的技术请求，然后强迫人工智能重写它，以满足特定角色的贪婪/恐惧。 提示： 输入：“我们需要从 AWS 更改为多云设置，以免锁定供应商，但这将需要 3 周的停机时间”（我的诚实草案）。 目标受众：首席财务官（涉及：第四季度）收入、风险缓解、成本）。 任务：翻译输入。使用技术词汇。代表财务影响中的每一个技术细节。 输出：如果我们不这样做，我们会损失多少钱。 为什么会获胜： 它要求“即时买入”。 AI 再次阅读：“我们面临着至关重要的财务风险。如果 AWS 明年提高价格，我们的利润率会下降 15%。我建议现在就做 3 周，以获得20% 在未来的谈判中永久使用。” 我在 5 分钟内就让你成为了“成本中心”和“战略合作伙伴”。    提交的 /u/cloudairyhq   [链接]   href=&quot;https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/&quot;&gt;[评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/</guid>
      <pubDate>Wed, 28 Jan 2026 07:06:53 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 的推理从“修复我的 GPU”转向“成为上帝”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp0gng/geminis_reasoning_drifted_from_fixing_my_gpu_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp0gng/geminis_reasoning_drifted_from_fixing_my_gpu_to/</guid>
      <pubDate>Wed, 28 Jan 2026 03:45:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>