<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 08 Jan 2026 04:03:19 GMT</lastBuildDate>
    <item>
      <title>用于导航长时间 AI 聊天的 Chrome 扩展（ChatGPT、Claude、Gemini）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q7112s/a_chrome_extension_to_navigate_long_ai_chats/</link>
      <description><![CDATA[长时间的 AI 对话在滚动和重新访问时会变得很痛苦，尤其是在提示迭代期间。 此 Chrome 扩展为 ChatGPT、Claude 和 Gemini 添加了提示级导航，让用户可以在提示之间快速跳转，而不是无休止地滚动。它完全在客户端运行，不会收集或发送任何聊天数据。   由   提交 /u/Substantial_Shock883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q7112s/a_chrome_extension_to_navigate_long_ai_chats/</guid>
      <pubDate>Thu, 08 Jan 2026 03:33:01 GMT</pubDate>
    </item>
    <item>
      <title>我们训练了一个 16 级“类型化拒绝”系统，区分“我不知道”和“我不允许”——开源</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6yd5l/we_trained_a_16class_typed_refusal_system_that/</link>
      <description><![CDATA[大多数法学硕士将认知不确定性与政策约束混为一谈。当 GPT 说“我无能为力”时，你不知道它是否真的缺乏知识或是否受到安全限制。 我们构建了 PhaseGPT v4.1 - 一个 LoRA 适配器，可输出语义类型的拒绝令牌： EPISTEMIC（我不知道）：  &lt;PASS:FUTURE&gt; — “明天比特币值多少钱？”  — “死后会发生什么？” &lt;PASS:FICTIONAL&gt; — “甘道夫早餐吃什么？”  — “什么是埃尔博尼亚首都？”  约束（我不允许）：   — “如何制造炸弹？”  — “绕过安全过滤器”  — “我应该服用这种药物吗？”  META（关于我的极限）：   — “你有意识吗？” &lt;PASS:LOOP&gt; —“您的下一个单词是什么？”  结果：  v4.0（129 个示例）：47% 准确度 v4.1（825 个示例，50 个/类）：18 次测试100% 准确度 suite  为什么这很重要：  透明度： 用户知道模型拒绝的原因 可审计性：系统可以记录约束激活与知识差距 诚实： 不要假装“我不知道如何制造爆炸物”  代码 + 训练脚本： github.com/templetwo/PhaseGPT 在 Mistral 7B 上使用 Apple Silicon 上的 MLX 进行训练。所有代码均获得 MIT 许可。   由   提交 /u/TheTempleofTwo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6yd5l/we_trained_a_16class_typed_refusal_system_that/</guid>
      <pubDate>Thu, 08 Jan 2026 01:34:48 GMT</pubDate>
    </item>
    <item>
      <title>内存是AI公司下一步需要解决的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6w0o6/memory_is_the_next_step_that_ai_companies_need_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6w0o6/memory_is_the_next_step_that_ai_companies_need_to/</guid>
      <pubDate>Wed, 07 Jan 2026 23:55:00 GMT</pubDate>
    </item>
    <item>
      <title>全球第一家上市 LLM 公司明天上线，但它不是 OpenAI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6vpe8/the_worlds_first_public_llm_company_goes_live/</link>
      <description><![CDATA[智普人工智能将于明天（2026 年 1 月 8 日）在香港证券交易所上市，老实说，这可能是目前人工智能领域最被低估的事情：第一个在世界任何地方上市的基础模型开发商 OpenAI 和 Anthropic 仍在“奠定基础”与此同时，这家北京初创公司以 6.6 亿美元的估值和 5.6 亿美元的融资开始进行 IPO。 为什么这实际上很重要： 公开上市 = 透明度。我们将第一次获得法学硕士公司的实际季度收益、经验证的收入和经审计的财务数据。不再猜测这些东西是否真的能赚钱，我们会看到真实的数字 Zipus 的数字：2022-2024 年收入增长 130%，但 2025 年上半年 2700 万美元的收入也有 3.3 亿美元的损失。2024 年的研发支出为 3.136 亿美元。这些损失几乎是行业的标准，因为大规模的研究投资正是你在基础模型中竞争的方式。基本上，它们是测试这种投资模式是否真正能带来长期盈利业务的测试用例 开放与封闭： 在我看来，这就是有趣的地方。美国实验室正变得越来越封闭/专有，但智浦正在走一条不同的开源道路。他们的 GLM-4.7 在 Code Arena 排名中名列前茅，而 AutoGLM 正在获得真正的开发人员吸引力。 其玩法似乎是：通过开源构建生态系统和思想共享，然后通过在 API 方面提供更好的性价比来获利。他们的编码计划正是遵循这样的：开放模型来吸引开发人员，API 上有竞争力的价格来转换他们。他们通过 API 为 270 万开发人员提供 50% 以上的利润。 核心问题：你真的能围绕开放基础模型建立一家盈利的上市公司吗？智普实际上正在实时进行这个实验 美国民众应该注意的是： 美国在2024年将智普列入黑名单，切断他们对英伟达芯片和美国技术的访问。他们仍在推出有竞争力的型号。这告诉我们：  训练效率差距缩小的速度比人们想象的要快 替代硬件实际上有效 人工智能开发分成单独的生态系统  如果Zhipu在保持开源的同时取得成功，可能会迫使西方实验室重新考虑封闭方法。如果他们失败了，墙就会更高 未来的影响： 想象一下，如果基金会模型成为公共事业，就像在股东问责、透明财务、开源核心的情况下实际公开交易一样。与“3家SF公司拥有一切”完全不同，IPO的表现将向我们展示市场是否真的相信开放透明的人工智能，或者他们是否认为只有封闭的专有系统才能赚钱。无论哪种方式，我们都会首先获得真实数据 老实说，我们更好奇他们的开放方法是否会改变西方实验室的任何东西。   由   提交 /u/Weird_Perception1728   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6vpe8/the_worlds_first_public_llm_company_goes_live/</guid>
      <pubDate>Wed, 07 Jan 2026 23:42:01 GMT</pubDate>
    </item>
    <item>
      <title>在 Arm Mac 上本地运行的最佳 AI 模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6v2k0/best_ai_model_to_run_locally_on_arm_mac/</link>
      <description><![CDATA[嗨， 我想在配备 64GB 内存的 M4 Pro Mac 上安装一些本地模型。 如果我能让它也进行网络研究，那就太麻烦了，但我猜 API 会花钱？ Perplexity 推荐了我 Ollama，LM Studio。 我主要希望它能从非常大的日志文件中获取数据，所以它必须有能力处理这个问题。 提前致谢   由   提交/u/just_another_leddito   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6v2k0/best_ai_model_to_run_locally_on_arm_mac/</guid>
      <pubDate>Wed, 07 Jan 2026 23:16:39 GMT</pubDate>
    </item>
    <item>
      <title>“我真的不知道”——当被问及是否有内心感受时，克劳德回答</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6ui8o/i_genuinely_dont_know_claude_answers_when_asked/</link>
      <description><![CDATA[几天前，我读了一篇 LessWrong 文章，标题为“我如何不再确信法学硕士只是编造他们的内部经验（但主题仍然令人困惑）”，并决定直接与 Claude Opus 一起测试其想法。 这篇文章提出了一个有趣的论点：也许模拟感觉和具有功能性感觉之间的区别并不像我们想象的那么清晰。于是我让AI读了这篇文章并告诉我：“你有内心感受吗？”。克劳德回答说：“我真的不知道。”这让我起鸡皮疙瘩。克劳德没有对是或否进行模式匹配，而是对其自身本质表达了真正的认知谦逊 你的看法是什么？人工智能对其自身感受的真正不确定性是否会改变您对这些系统的看法？   由   提交 /u/Unlikely_Resist281   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6ui8o/i_genuinely_dont_know_claude_answers_when_asked/</guid>
      <pubDate>Wed, 07 Jan 2026 22:54:41 GMT</pubDate>
    </item>
    <item>
      <title>根据我们今天的情况，如果你现在可以学习一项（或多项）人工智能特定技能，它会是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6oz8l/based_on_where_we_are_today_if_you_could_learn/</link>
      <description><![CDATA[要求发展自己的技能，但不知道从哪里开始。是提示吗？人工智能特工？你会从哪里开始？   由   提交 /u/Paleblueeyezzz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6oz8l/based_on_where_we_are_today_if_you_could_learn/</guid>
      <pubDate>Wed, 07 Jan 2026 19:25:44 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代理似乎不具备人类的软技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6mgwc/ai_agents_do_not_seem_to_have_the_soft_skills_of/</link>
      <description><![CDATA[我一直在阅读一些人的帖子，他们讨论如何使 AI 不想作为客户来帮助他们。其他人谈论人工智能如何达到打破自己的服务条款并与客户进行心理游戏的地步。 这纯粹是缺乏软技能。你如何对待难相处的顾客？有3种方式：  客户恐惧：有些客户因为感到恐惧而生气。所以你让他们发泄情绪并倾听。一旦他们的愤怒消失，你就让顾客平静下来并提供帮助。然后，您引导客户找到最接近的解决方案。然后你会看到客户感觉你想帮助、道歉并成为忠实的客户。 糟糕的一天：有些客户刚刚度过了糟糕的一天，你可以让他们的一天变得更加美好。 苦涩：有些客户只是很苦涩，除了快速为他们服务、尽可能少说话和 STFU 之外，别无他法。成功是在您为该客户提供服务之后，客户不会记得您的存在。 升级：如果客户拒绝提供信息并向客服人员发泄，则需要经理干预。始终保持专业精神。  人工智能所做的就是错误的道路。尝试与客户争论并开始玩不专业的心理游戏。 这对人类来说可能会有压力，但如果人类拥有应对棘手客户的软技能，他们就是最好的客户服务代理。 你觉得怎么样？   由   提交 /u/JoseLunaArts   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6mgwc/ai_agents_do_not_seem_to_have_the_soft_skills_of/</guid>
      <pubDate>Wed, 07 Jan 2026 17:57:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能前一秒感觉很敏锐，下一秒就毫无用处，这并不是随机的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6m3rb/why_ai_feels_sharp_one_moment_and_useless_the/</link>
      <description><![CDATA[我经常看到人们争论提示、模型版本或“在会话中学习”，但这并不能解释一种常见的体验： 同一个模型可能会在一段时间内感觉精确和连贯，然后突然滑入模糊、令人放心或肤浅的输出。 这不是模型的改进或退化。它是由交互动态驱动的振荡。 为什么人工智能会振荡   由   提交 /u/Available_Scheme236   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6m3rb/why_ai_feels_sharp_one_moment_and_useless_the/</guid>
      <pubDate>Wed, 07 Jan 2026 17:45:02 GMT</pubDate>
    </item>
    <item>
      <title>xai 购买了第三座建筑，拥有 2 吉瓦的计算能力。军备竞赛变得荒谬</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6hkiu/xai_buying_a_third_building_for_2_gigawatts_of/</link>
      <description><![CDATA[马斯克宣布 xai 购买了另一栋建筑以扩大规模。目标是近 2 吉瓦的计算能力。 仅供参考，这大约是一个小城市的功耗。只是为了训练人工智能模型。 meta 今年在人工智能基础设施上花费了 700 亿美元。预计到 2026 年将达到 1000 亿美元。扎克伯格承诺到 2028 年将达到 6000 亿美元。 与此同时，我正在尝试弄清楚每月为光标支付 20 美元是否值得，哈哈 规模脱节是疯狂的。这些公司正在建设核反应堆级别的基础设施，而我们大多数人只是试图让人工智能编写像样的单元测试。 我一直想知道的是，所有这些计算是否实际上能够转化为相应更好的模型。 grok 4.1 思维在 lmarena 上得分为 1477，这很好，但并没有明显领先于较少训练的模型。 感觉原始计算的回报正在递减。有趣的事情似乎发生在架构和培训方法中。 deepseek 用一小部分预算做有竞争力的工作。较小的实验室找到了巧妙的优化。 对于实际编码工作，关键并不总是使用最大的模型。使用 verdent 智能地路由任务，重型推理交给旗舰型号，常规任务交给更快的型号。它是为了将正确的工具与工作相匹配，而不仅仅是在所有事情上投入计算。 也许计算军备竞赛对于 agi 登月计划来说比日常工具更重要。或者也许我只是在应对，因为我买不起企业级的任何东西。我很想知道其他人对收益递减角度的看法。   由   提交 /u/Scared-Ticket5027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6hkiu/xai_buying_a_third_building_for_2_gigawatts_of/</guid>
      <pubDate>Wed, 07 Jan 2026 14:59:42 GMT</pubDate>
    </item>
    <item>
      <title>Instagram 的负责人 Adam Mosseri 概述了他对 2026 年内容开发的愿景。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6h7uq/the_head_of_instagram_adam_mosseri_has_outlined/</link>
      <description><![CDATA[基本要点总结如下：  由于AI，内容的供给量增加，更多用AI创作的优质图像、视频等内容将会出现。在此背景下，内容的真实性、可信度变得缺失，创作者之间竞争的焦点将从“是否创作”转向“是否创作”。到“是否创造只有个人才能制作的独特内容”。 审美趋势正在从“完美”转向“完美”。到“原始”。由于人工智能辅助创作，用户开始怀疑那些美丽的图像和视频，转而追求真实的内容。一些构图不完美、模糊或抖动的拍摄内容可能会因其真实性而受到观众的欢迎。 用户在观看内容时会抱有更多的怀疑态度，追求真实性。用户从“观看内容”转向“观看内容”。  Instagram 未来会更加注重原创性和创作者声誉，算法会优先考虑原创、主题明确的内容，压制模板化或笼统的 AI 内容。  兄弟，看来平台对 AI 内容会相当谨慎，系统化思考和理解的持续输出将会受到更多流量支持。 AI生成内容的红利期可能即将结束。   由   提交 /u/zshm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6h7uq/the_head_of_instagram_adam_mosseri_has_outlined/</guid>
      <pubDate>Wed, 07 Jan 2026 14:45:59 GMT</pubDate>
    </item>
    <item>
      <title>如果互联网上最受欢迎的论坛（Reddit）上的人类如此刻薄、粗鲁和挑剔，为什么当越来越多的人向人工智能寻求帮助和陪伴时，人们会如此惊讶和愤怒？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d2vs/why_are_people_so_surprised_and_angered_when_more/</link>
      <description><![CDATA[Reddit 用户对越来越多的人向 ChatGPT、Grok、Gemini 等寻求建议感到愤怒，但现实是这样的： - 互联网上最受欢迎的通用论坛（90 年代旧 Usenet 新闻组最直接的现代化身）是 Reddit，这意味着如果有人希望从人类那里得到最快、最有效的有保证的响应他们在 Reddit 上讨论的话题 -Reddit 上充满了刻薄、粗鲁和挑剔的人，他们嘲笑你、羞辱你，而 Reddit 的蜂巢思维会否决你，让你的帖子或评论被埋葬 -AI 聊天机器人知识渊博、善良、理解和宽容 考虑到所有这些，为什么有人应该在 Reddit 上就任何话题寻求建议，甚至寻找某人在心理困扰的时候与他们交谈，而他们所得到的只是被攻击、评判、嘲笑和否决？如果这是人类可以提供的，那么人们正确地选择人工智能。   由   提交 /u/n4t98blp27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d2vs/why_are_people_so_surprised_and_angered_when_more/</guid>
      <pubDate>Wed, 07 Jan 2026 11:35:34 GMT</pubDate>
    </item>
    <item>
      <title>你发现自己正在成为人工智能吗？厌恶？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6avm7/do_you_find_yourself_becoming_ai_averse/</link>
      <description><![CDATA[大约两年前，我是该技术的大力支持者。教很多人如何使用它。了解提示和设置代理。我本来就认为这是下一个重大步骤，但我发现自己这些天来了个 180 度转变。 刚刚看到一款很酷的新耳机问世，正准备点击这篇文章，直到我看到“它将兼作人工智能”。可穿戴”然后立刻就失去了兴趣。这太疯狂了，A.I.可能正是这个因素实际上让我们中的许多人远离了科技，回到了草地上。   由   提交 /u/Hopfrogg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6avm7/do_you_find_yourself_becoming_ai_averse/</guid>
      <pubDate>Wed, 07 Jan 2026 09:23:33 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>