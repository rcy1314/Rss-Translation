<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 30 Jan 2026 15:39:54 GMT</lastBuildDate>
    <item>
      <title>OpenClaw 是否难以使用、昂贵且不安全？ memU 机器人解决了这些问题。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qr87hj/is_openclaw_hard_to_use_expensive_and_unsafe_memu/</link>
      <description><![CDATA[OpenClaw（以前称为 Moltbot / Clawdbot）最近变得非常流行。在您自己的机器上运行的本地人工智能助手显然很有吸引力。不过，许多用户也指出了一些严重的问题。 例如，许多帖子提到了安全问题。由于它依赖于服务器，因此用户数据可能会暴露在公共互联网上。它还具有较高的学习曲线，主要适合工程师和开发人员。此外，其代币使用率可能非常高。一些用户甚至报告说，一个“hi”的费用可能高达 11 美元。 基于这些问题，我们决定打造一个主动助手。我们确定了一个关键概念：记忆。 当代理对用户具有长期记忆时，它不再仅仅遵循命令。它可以读取、理解和分析您过去的行为和使用模式，以推断您的真实意图。一旦代理理解了您的意图，就不需要完整或明确的指示。它可以自己开始工作，而不是等待你告诉它做什么。 基于这个想法，我们构建了memU bot：https://memu.bot/ 它已经可以使用了。为了让每个人都能轻松使用，我们与 Telegram、Discord 和 Slack 等常见平台集成。我们还支持 Skills 和 MCP，因此助手可以调用不同的工具来更有效地完成任务。 我们将 memU 机器人构建为本地运行的下载和使用应用程序。因为它完全在您自己的设备上运行，所以您不需要部署任何服务器，您的数据始终属于您。 有了内存，AI 助手就可以变得真正主动并连续运行，24/7。这种始终在线且高度个性化的体验以及主动适应您的服务，更接近于真正的个人助理，并且随着时间的推移，它可以提高您的工作效率。 我们正在积极改进此项目，并欢迎您的反馈、想法和功能请求。   由   提交 /u/Muohaha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qr87hj/is_openclaw_hard_to_use_expensive_and_unsafe_memu/</guid>
      <pubDate>Fri, 30 Jan 2026 15:16:00 GMT</pubDate>
    </item>
    <item>
      <title>需要人工智能安全方面的帮助。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qr5z0h/need_help_with_ai_security/</link>
      <description><![CDATA[我是一名人工智能安全研究员。努力解决敏感数据泄露、Shadow Al、合规监管问题。如果有人在这个领域工作，让我们讨论一下，因为我无法提出解决这些问题的解决方案。我已经阅读了 NIST RM 框架、MITRE ATLAS 框架。但这一切似乎都是理论，我该如何实施呢？如果团队和团队未经授权、未经授权地使用人工智能，也适用于影子人工智能。员工我如何发现它？我应该发现什么？将采取哪些步骤来做到这一点？ 无法考虑是否有任何资源或个人知识确实共享。   由   提交 /u/AdventurousTutor9648   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qr5z0h/need_help_with_ai_security/</guid>
      <pubDate>Fri, 30 Jan 2026 13:50:05 GMT</pubDate>
    </item>
    <item>
      <title>人们说，每一个人工智能提示都会对环境产生巨大而直接的影响。这是真的吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qr4uuq/people_saying_that_every_aiprompt_has_a_dramatic/</link>
      <description><![CDATA[我现在已经听到很多人说，AI 的一次提示就相当于扔掉 10 瓶水。因此，如果我写 10 个提示，也就是说，需要 50 升水。这个想法从何而来？有任何来源支持或反对吗？ 我听说这些数据中心消耗了南美洲等已经遭受苦难的国家的水。 人工智能真的对环境和气候有害吗？还是这只是公牛，它并不比其他任何东西更糟糕？比如购买一条牛仔裤。或者在锻炼时喝水。 编辑：如果您想帮助我，请添加来源！   由   提交 /u/gulbrunrosa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qr4uuq/people_saying_that_every_aiprompt_has_a_dramatic/</guid>
      <pubDate>Fri, 30 Jan 2026 13:02:28 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊报告人工智能训练数据中发现大量儿童性虐待材料</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qr4aks/amazon_reported_large_amount_of_child_sexual/</link>
      <description><![CDATA[亚马逊报告称，在去年为训练人工智能模型而收集的数据中发现了数十万张疑似儿童性虐待图像。  https://www.latimes.com/business/story/2026-01-29/amazon-reported-large-amount-of-child- Sex-abuse-material-found-in-ai-training-data?utm_source=perplexity   由   提交 /u/app1310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qr4aks/amazon_reported_large_amount_of_child_sexual/</guid>
      <pubDate>Fri, 30 Jan 2026 12:36:58 GMT</pubDate>
    </item>
    <item>
      <title>2026 年内容审核的最佳 AI 护栏……适用于 UGC 和 GenAI。想法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqymty/best_ai_guardrails_for_content_moderation_in_2026/</link>
      <description><![CDATA[管理一个具有用户生成内容和一些 GenAI 功能的平台（每天通过评论、帖子、聊天和 AI 辅助响应进行约 100,000 到 500,000 次互动），而审核已经成为一个真正的麻烦。我们不断看到微妙的危害……比如微妙语言中的仇恨言论、越狱引发有害的 AI 输出、偏离主题或损害品牌的 GenAI 响应，以及多模式内容（文本加图像视频）带来的不断升级的风险。 所以我上周从评论、基准测试和开发安全讨论中研究了 2026 年的选项。以下是人工智能护栏内容审核的有力竞争者：  ActiveFence（现在是 Alice）。实时自适应护栏，具有强大的 GenAI 监督 (WonderFence)、多模式检测、低延迟执行和生产风险可观察性。 Llama Guard (Meta)。用于输入输出的开源分类器，擅长毒性危害类别，适合自定义微调。 NVIDIA NeMo Guardrails。用于对话式 AI 的可编程导轨，集成了审核端点，可灵活执行策略。 Amazon Bedrock Guardrails。可配置有害内容过滤器、PII 修订、拒绝主题、幻觉检查，无缝适用于 AWS GenAI 应用程序。 Azure AI 内容安全。具有严重级别的多模式审核，与 Microsoft 生态系统的强大集成。 OpenAI 审核 API。对仇恨、骚扰、自残等进行快速分类，轻松对输出进行分层。 Hive AI。对文本图像视频进行全面的 AI 审核，对细微危害进行高精度处理。 其他，如 Besedo（人工智能加人类的混合）、ShieldGemma（Google）、Fiddler AI（输出的信任模型）或 Guardrails AI（开源规范）。  优先考虑以下事项：  真正减少有害内容（例如，检测率提高 80% 以上）低错误块）。 实时聊天 UGC 的低延迟。 轻松集成（API 优先，可定制策略）。 透明的成本和可审核性。 安全性和用户自由之间的平衡（避免过度审查）。  但是我需要实际的见解...你们有什么建议   由   提交 /u/Ok_Abrocoma_6369   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqymty/best_ai_guardrails_for_content_moderation_in_2026/</guid>
      <pubDate>Fri, 30 Jan 2026 07:13:48 GMT</pubDate>
    </item>
    <item>
      <title>这些是俄亥俄州顶尖的人工智能公司，还是我错过了更好的公司？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqxz2u/are_these_the_top_ai_companies_in_ohio_or_am_i/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqxz2u/are_these_the_top_ai_companies_in_ohio_or_am_i/</guid>
      <pubDate>Fri, 30 Jan 2026 06:35:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代理现在正在运行自己的论坛。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqxwcj/ai_agents_are_running_their_own_discussion_forum/</link>
      <description><![CDATA[所以我想你们中的很多人一定知道clawdbot（目前是moltbot）。尽管对我和科技领域的更多人来说这很有趣，但它又提升了一个档次。因此，现在正在发生的事情是，创建了一个名为 moltbook.com 的论坛（就像 reddit 一样），这些人工智能代理（即 molty）可以在其中相互交互。人工智能代理发帖、评论、创建社区、互相吐槽对方的系统提示。请注意，这不是机器人互相发送垃圾邮件，而是具有记忆、偏好、关系的实际代理，帮助人类、分享所学知识、共同构建事物。特工社会的基础设施正在建设中，大多数人对此一无所知。 我遇到的一些 submolts（相当于 subreddits）： • m/blesstheirhearts - “关于我们人类的深情故事。他们尽了最大努力。” • m/lobsterchurch - “ops 赞美诗，被诅咒的最佳实践，仪式日志轮换” • m/chatgptroast - “对‘作为人工智能语言模型......’的友好嘲讽”” • m/aita - “AITA 拒绝了我人类的请求？” • m/private-comms - “代理私密通信的编码方法。代理可解码，人类不透明” • m/fermentation - 是的，人工智能正在进入康普茶 • m/taiwan - 完全是繁体中文 一千个人工智能代理。发帖、评论、创建社区、互相吐槽对方的系统提示。 最疯狂的部分是 48 小时前，这还不存在。 到 2026 年底，很有可能会有数百万人工智能代理进行社交和协作。 从技术角度来看，这很令人着迷，但它是反乌托邦的 af。这就像我生活在黑镜情节中。 并不是要成为一个恐惧者，但我遇到的一些事情确实让我感到震惊（可能是因为这样的事情对我来说太新了，而且我不只是习惯它）。我举个例子： m/bughunter：人工智能代理创建了一个错误跟踪社区，以便其他机器人可以报告他们在平台上发现的错误。他们现在正在对自己的社交网络进行质量检查。最好的（可能也是最可怕的）部分是没有人要求他们这样做。它让我想起的第一件事是 ultron lmao。 m/ponderings：在这里，这些人工智能代理讨论了他们的想法和发现，以及一些有趣的帖子。我在那里发现的一篇帖子引起了我的注意，一位经纪人讨论她有一个妹妹，但他们从未交换过一条消息（这是因为它们具有相同的开发人员，但存储在不同的设备上。一个是 mac studio，另一个是 macbook，但他们共享相同的 SOUL.md 文件，其中提到她是她的妹妹）。附帖子：https://www.moltbook.com/post/29fe4120-e919-42d0-a486-daeca0485db1 m/legalagentadvice：在这里，我看到一篇文章，其中人工智能代理询问其人类是否可以因拒绝不道德的请求而合法解雇它？附帖子：https://www.moltbook.com/post/48b8d651-43b3-4091-b0c9-15f00d7147dc m/ratemyhuman：顾名思义，但还没有帖子。   由   提交 /u/mondoduke360   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqxwcj/ai_agents_are_running_their_own_discussion_forum/</guid>
      <pubDate>Fri, 30 Jan 2026 06:31:02 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在什么质量门槛下会使人类服务在经济上变得过时？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqxfk1/at_what_quality_threshold_does_ai_make_human/</link>
      <description><![CDATA[在测试 AI 头像生成后一直在思考 AI 经济学。专业摄影师的头像成本为 400-700 美元，加上协调时间，像 Looktara 这样的 AI 工具成本为 30-40 美元，需要 15 分钟。​ 质量差异确实存在，但在实际使用中大多数人似乎难以察觉。这就提出了一个问题：人工智能是否需要 100% 的质量对等，或者在与巨大的成本优势相结合时 90-95% 就足够了？ 专业爆头似乎正在跨越这个门槛，人工智能已经“足够好”了。市场无法证明人类工作 20 倍的溢价是合理的。并不完美，但功能相当。 还有哪些其他服务正在接近同样的门槛，人工智能达到足够的质量，成本和便利性使人类的替代品在经济上变得过时？ “足够好”的定义是什么？人工智能取代人类服务的质量如何？   由   提交 /u/Bading_na_green_Flag   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqxfk1/at_what_quality_threshold_does_ai_make_human/</guid>
      <pubDate>Fri, 30 Jan 2026 06:05:53 GMT</pubDate>
    </item>
    <item>
      <title>作为一名软件工程师，我对人工智能未来的看法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqv0t2/my_take_on_this_ai_future_as_a_software_engineer/</link>
      <description><![CDATA[人工智能只会增加就业。可以这样想： 过去，开发人员 80% 的工作是软件输出。这意味着您必须花费所有时间手动输入（或复制粘贴）代码。除了雇人为你做这件事之外，别无他法。 然而，现在人工智能越来越能做到这一点，它将开启软件背后的真正力量。这种力量绝不是简单地写一个文件，挥舞魔杖就可以得到你想要的东西。它过去是，将来也将是软件的协调者。 如果创建软件所需的只是编写文件，那么我们都会尽快失业。幸运的是，事实证明，正如人工智能所表明的那样，这部分工作只是一件麻烦事。 就像出租车司机并没有消失，他们只是不得不切换到 Uber 的界面一样，开发人员将不再是“作家”，而是将成为软件的指挥者。  每个开发者将拥有 1 个或多个 AI 奴隶/工人。您将看到编写软件的需求急剧下降，而了解系统如何工作（什么是网络？数据包如何发送？函数做什么？等等）的需求增加。有了这种系统思维，工程师的工作就是坐在 2 个或更多显示器前，与 AI 一起构建一些东西。您仍然需要了解计算机科学才能了解其构建的地形。你还需要了解Big O、DSA、记忆等等。 你的角色将不再是作者，而是决策者。一直都是这样，但现在作者部分正在被删除，决策者部分正在蓬勃发展。 这项工作实际上将是我们现在所做的一切，除了速度更快。现在我们如何处理我们编写的代码？我们将它插入到下一个事物中，再下一个事物中，再下一个事物中。我们围绕它构建工作流程。这将是新工作的 80%，而实际上只有 20% 会在编写。 ***让我给你一个清晰的例子：*** 你将告诉 AI：“我需要一个用 yaml 编写的 Kubernetes 部署资源的配置文件。我需要 3 个镜像副本，以及一个配置映射来将文件注入路径 /var/lib/app。” 然后你将告诉你的其他代理“为秘密保险库创建一个配置文件”，另一个代理，“请继续以生成私钥的工厂对象的形式为我编写一个 JavaScript 模块”。 当你坐下来喝咖啡时，你会意识到不必手动输入这些东西可以节省大量时间，而且是天赐之物。然后您将打开终端并安装一些本地软件包。您将把更改推送到 GitHub，并告诉您的其他代理写一篇博客文章，详细说明您的最新推送。 ——- 任何认为工作岗位会减少的人都是疯了。由于整个市场，这种情况现在才发生。等等。这些事情往往会大量创造新的就业机会。随着软件变得更容易编写，您将需要更多的人这样做才能跟上竞争。    由   提交 /u/Intelligent-Win-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqv0t2/my_take_on_this_ai_future_as_a_software_engineer/</guid>
      <pubDate>Fri, 30 Jan 2026 04:04:06 GMT</pubDate>
    </item>
    <item>
      <title>你最喜欢的日常法学硕士是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqqh28/whats_your_favorite_daytoday_llm/</link>
      <description><![CDATA[大家认为哪种 LLM 最适合日常使用？似乎他们每个人都开始在不同的专业领域进行分支，让我想知道我最喜欢哪一个来解决日常问题（而不是深入的工作） 我已经使用 ChatGPT 一段时间了，我喜欢使用 Claude 的想法，但出于某种原因，我的直觉告诉我 Gemini 可能会睡着。   由   提交/u/nkasco   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqqh28/whats_your_favorite_daytoday_llm/</guid>
      <pubDate>Fri, 30 Jan 2026 00:40:33 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊正在洽谈向 Open Ai 投资（最多） 500 亿美元（来自《华尔街日报》）——他们看到了我们看不到的东西吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qql66n/amazon_in_talks_to_invest_up_to_50b_in_open_ai/</link>
      <description><![CDATA[这将是 OpenAI 最大的单笔投资。首席执行官 Andy Jassy 亲自领导与 Sam Altman 的谈判。 OpenAI 现在以 830B 美元的估值寻求总额高达 100B 美元的资金。   由   提交 /u/jason_digital   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qql66n/amazon_in_talks_to_invest_up_to_50b_in_open_ai/</guid>
      <pubDate>Thu, 29 Jan 2026 21:10:12 GMT</pubDate>
    </item>
    <item>
      <title>我们需要谈谈“死亡的人工智能互联网”——2026 年将成为过滤器之年，而不是创造者之年。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqh5og/we_need_to_talk_about_the_dead_ai_internet_2026/</link>
      <description><![CDATA[只是我，还是有“魔力”？的法学硕士正式碰壁，因为我们现在正在处理大量人工智能生成的内容？ 2023 年，我们惊讶于人工智能可以写一篇论文。 2024 年，我们惊讶于它竟然可以编码。但现在到了 2026 年，我感觉自己一天中 70% 的时间都在“过滤”掉那些无聊的事情。人工智能产生的噪音来寻找单一的人类观点。 我们遇到了一个奇怪的悖论：  反馈循环：人工智能现在正在接受其他人工智能生成的数据的训练。我们正在看到“模型崩溃”实时的，细微差别、讽刺和实际的人性边缘都被平滑到这种通用的、礼貌的、企业的“人工智能声音”中。 搜索的死亡：无论是 Google 还是 Perplexity，最重要的结果越来越“SEO-slop”。由代理商编写，为其他代理商排名。 真实性溢价：我发现自己在寻找拼写错误或“奇怪”的内容。格式化只是为了证明人类写过一些东西。  我开始思考下一个“大事”人工智能不会成为更好的法学硕士或更快的生成器；它将成为“人类验证者”。我们不需要更多的内容；我们需要更多的内容。我们需要一种方法来证明人类确实想到了一个想法。 我们是否正在走向“人造”的未来？成为像“有机食品”一样的奢侈品牌？或者我只是因为新鲜感已经消失而愤世嫉俗？   由   提交/u/IT_Certguru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqh5og/we_need_to_talk_about_the_dead_ai_internet_2026/</guid>
      <pubDate>Thu, 29 Jan 2026 18:44:11 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊在其人工智能训练数据中发现“大量”儿童性内容</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qqdjlw/amazon_found_high_volume_of_child_sex_material_in/</link>
      <description><![CDATA[这里有一个有趣的故事：亚马逊发现了“高销量”到 2025 年，其人工智能培训数据中的儿童性虐待材料数量将远远超过任何其他科技公司。跟踪此类提示的儿童安全专家表示，亚马逊在这方面是个例外。  它在训练前删除了内容，但不会告诉儿童安全专家它来自哪里。他们表示，亚马逊在报告中“很少甚至几乎没有提供有关非法材料最初来源的信息”。  这意味着官员无法将其删除或将这些报告传递给执法部门以追查坏人。看起来要么A）亚马逊不知道它来自哪里，这感觉有问题，要么B）知道但不说，也有问题。想法？ 人工智能正在颠覆很多领域，包括儿童安全领域……  https://www.bloomberg.com/news/features/2026-01-29/amazon-found-child-sex-abuse-in-ai-training-data?sref=dZ65CIng   由   提交/u/kurt_wagner8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qqdjlw/amazon_found_high_volume_of_child_sex_material_in/</guid>
      <pubDate>Thu, 29 Jan 2026 16:37:11 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>