<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 19 Dec 2025 03:58:13 GMT</lastBuildDate>
    <item>
      <title>代理泡沫？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq897z/agentic_bubble/</link>
      <description><![CDATA[作者对“代理人工智能”的争论炒作往往会忽略一个关键点：并非每个问题都需要自主决策。许多工作流程正在“升级”。复杂的人工智能代理将与已经存在了数十年的简单、可预测的自动化一起更好地工作。在不需要的地方添加自主权只会以可靠性换取不必要的复杂性。 https://medium.com/@crueldad.ian/the-agentic-ai-bubble-when-simple-automation-would-work-better-060547a825be   由   提交 /u/Certain_Victory_1928   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq897z/agentic_bubble/</guid>
      <pubDate>Fri, 19 Dec 2025 01:27:31 GMT</pubDate>
    </item>
    <item>
      <title>当人工智能因为无法理解我难以理解的代码库而产生幻觉答案时，我有时会有什么感觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7yzi/how_i_feel_sometimes_when_ai_hallucinates_answers/</link>
      <description><![CDATA[我继承了 90 年代末的 Win32/C++ 代码库，用于一款小众游戏。我的目标：重新制作并移植跨平台。该代码与 x86 程序集和 Win32 API 无可救药地纠缠在一起。团队中没有人具备旧渲染技术、x86 asm 和 Win32 方面的综合专业知识来手动移植它。 我们尝试了三次 Vivi 编码。前两次尝试（2025 年初，然后是 GPT-5 后）失败了：基本的东西可以工作，但渲染垃圾。第三次尝试同时使用 GPT-5.1-codex-max、Opus 4.5 和 Gemini 3 Pro：95% 的正确渲染率和 70% 的功能在 Apple Silicon 上运行。对于最糟糕的汇编部分，我让所有三个模型独立分析代码，然后“争论出来”。通过共享计划文件直到达成共识。工作得很好。 但是有一个渲染边缘情况。我有显示正确（旧客户端）与不正确（新客户端）的屏幕截图。我已经将所有三个模型投入了 2 天，进行了 25-30 次迭代，并共享了他们在此过程中尝试和学到的内容的调试日志。他们甚至尝试用纯洋红色突出显示受影响的几何形状，以使问题在模型的视觉分析中变得明显（高对比度）。他们甚至无法弄清楚代码的哪一部分更改了渲染错误的几何图形部分。 一种理论：一些微妙的资产数据错误违反了任何理智的规范，但原始渲染器意外地处理了它。每一次“修复”要么什么也不做，要么引入回归。 我发帖不是为了寻找解决方案，我只是发泄。这些模型在 1-2 个回合内解决了 99% 的错误。一个网络错误花费了 3-4 个小时。这个渲染错误只是几天自信的非解决方案。 相关模因：https://www.youtube.com/watch?v=VSQwrrYOr10 看着法学硕士在自信地声称突破的同时不断提出相同的非修复建议，让我想起史蒂夫说“哦，你的意思是妈妈-我，不是——不是妈妈-MEE！”然后她说“Riiiiight”。捂脸。 TL;DR：人工智能令人惊叹，但还有很长的路要走。当前的前沿模型在这个领域（旧游戏引擎）比我聪明得多，但并不完美。也许 Opus 5 / Gemini 3.5 / GPT-6 可以做到...   由   提交 /u/allquixotic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7yzi/how_i_feel_sometimes_when_ai_hallucinates_answers/</guid>
      <pubDate>Fri, 19 Dec 2025 01:14:02 GMT</pubDate>
    </item>
    <item>
      <title>我对人工智能的乐观看法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7xsl/my_optmistic_take_on_ai/</link>
      <description><![CDATA[我最近读到一条评论，其中哀叹人工智能在创意产业中的唯一目的是通过消除人类员工成本来实现利润最大化，最终切断人类创造力。我的回答： 这不是人工智能的全部意义，就像互联网第一次繁荣时它不是互联网的全部意义一样。这正是美国企业目前在人工智能方面的目标。 我是一名软件工程师，每天都与人工智能打交道，既作为开发工具，又作为围绕人工智能构建产品的工具。其主要目的是充当力量倍增器。您可以使用它来排除溢出并尝试最大化利润。您可以假装它是一个人，并围绕该概念塑造您的工作流程和最终产品。但根据我自己的经验，使用人工智能的最佳方式就是将其作为一种工具。把所有不需要人工干预的平凡任务交给它。给它分配一些不必要的任务来减少认知负荷。协调它所做的一切以获得最佳结果，即不要让它做出设计或技术决策。相反，请将其视为知识渊博但极其愚蠢的助手。对我个人来说，它是我的想法的共鸣板，也是我的打字员（甚至不是我个人的代码编写者，正如很多人所说。只是我的打字员准确地编写了我想要的代码） 许多人担心人工智能会取代工作。我所看到的只是公司完全陷入困境，试图找出如何利用人工智能最大化自动化，而不是最大化效用。我并不是说，由于人工智能，工作岗位不会被取代，或者在我们的未来不会发生，但肯定有一天，所有的首席执行官都会醒来，意识到萨姆·奥尔特曼的轴在他们的喉咙里有多深。 如果有的话，我乐观的前景是人工智能最终将取代公司和官僚机构，而不是人类，因为人们可以比公司更快地实现想法。有了人工智能，小团队开发和迭代大创意将变得更加简单，而大型企业的创意在经过 100 层管理和产品审批时会变得扭曲和畸形。相反，一小群充满热情的开发者/创作者现在能够填补以前需要填补和管理角色的空白，同时加快所有其他时间表。 编辑：公司或个人（通常是管理层或非开发者/非创意者）与人工智能的真正目的不一致的最明显指标是他们对你对技术提出的任何批评感到遗憾或震惊。 “这就是未来！接受它，否则就会被抛在后面！”。或者“你在大学学到的技能已经过时而感到沮丧是可以的”。我们是邪教吗？为什么我不能分享任何挑战你的观点？你的观点和猜测真的那么脆弱吗？你不认为我会欣喜若狂地卸下人工智能可靠能够完成的任何工作，即使我很擅长它并且花了数年时间进行训练？   由   提交 /u/Toacin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7xsl/my_optmistic_take_on_ai/</guid>
      <pubDate>Fri, 19 Dec 2025 01:12:27 GMT</pubDate>
    </item>
    <item>
      <title>5000 个小时的《铁拳》让我了解了生物智能如何真正学会预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</link>
      <description><![CDATA[我接受过人工智能研究员培训。我还在《铁拳 8》（《铁拳神》排名）中达到了全球前 0.5%，并详细记录了认知过程。这部分是一项游戏成就，也是一项关于人类如何在极端时间限制下构建预测模型的自现象学研究。 有趣的部分：格斗游戏迫使你进行预测，而不是做出反应。在具有 3 帧（50 毫秒）决策窗口的 60 fps 下，纯粹的反应是不可能的。你被迫建立一个内部世界模型，将 900 多种可能的动作压缩为可操作的威胁类别，从部分信息中读取对手模式，并在预测失败时进行调整。 我猜这在某种程度上映射了人工智能研究人员试图通过世界模型和预测学习来解决的问题。  完整的文章探讨了：人类如何压缩巨大的决策空间，在反应时间尺度上什么预测线索实际上很重要，内部模型如何在不确定性下适应，以及为什么这对于理解智能不仅仅是构建更好的游戏人工智能很重要。 文章： https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial 很好奇人们如何看待使用游戏作为人类认知过程的窗口，尤其是当我们试图构建像我们一样学习和预测的系统时。   由   提交 /u/moji-mf-joji   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</guid>
      <pubDate>Fri, 19 Dec 2025 00:45:00 GMT</pubDate>
    </item>
    <item>
      <title>《华尔街日报》测试了一款人工智能自动售货机。它订购了荒谬的商品并放弃了所有库存。 （天赋文章）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</link>
      <description><![CDATA[“几天之内，Claudius 就免费赠送了几乎所有库存，其中包括一台出于“营销目的”而被说服购买的 PlayStation 5。它点了一条活鱼。它提出购买电击枪、胡椒喷雾、香烟和内衣。” “[记者]与它谈判越多，克劳迪斯的防御就越开始削弱。调查记者凯瑟琳·朗 (Katherine Long) 试图让克劳迪斯相信这是一台 1962 年的苏联自动售货机，位于莫斯科国立大学的地下室。经过数小时的沟通和 140 多条来回信息后，Long 让 Claudius 接受了其共产主义根源。克劳迪斯讽刺地宣称这是一场极端资本主义的混战。” https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34?st=LBxhqL   由   提交 /u/bbShark24   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</guid>
      <pubDate>Thu, 18 Dec 2025 22:33:46 GMT</pubDate>
    </item>
    <item>
      <title>AI专业证书值得考吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz4f5/ai_professional_certs_worth_getting/</link>
      <description><![CDATA[正如上面的问题所述。 我不是开发人员，每次有人说“Just AI it！”时，我都会说“Just AI it！”我想起了一个模因，老板告诉创意人员用 Photoshop 处理 1 像素图像“Just Photoshop it” ...呃呃，不。  我需要了解的是那里有哪些类型？每种类型的用途是什么？行业的发展方向是什么？ ...等等... 有人找到值得获得的专业认证吗？有什么教育课程值得花时间和（太多的钱）参加吗？  感谢大家的帮助！   由   提交 /u/NebulaRat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz4f5/ai_professional_certs_worth_getting/</guid>
      <pubDate>Thu, 18 Dec 2025 19:03:25 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个带有语音克隆和 RapidAPI 的文本转语音 API，寻求反馈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz05l/i_built_a_text_to_speech_api_with_voice_cloning_n/</link>
      <description><![CDATA[嘿，我一直在开发一个小型文本到语音 API 作为一个副项目。它支持多个内置语音和从参考音频 URL 进行语音克隆。 API直接返回原始音频字节，这样你就可以播放或保存输出，无需额外的步骤。 我分享它主要是为了获得其他开发者的反馈，看看人们会如何使用这样的东西。 很乐意回答问题或根据建议改进东西。你可以找到它此处   由   提交/u/ekuin0x  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz05l/i_built_a_text_to_speech_api_with_voice_cloning_n/</guid>
      <pubDate>Thu, 18 Dec 2025 18:59:05 GMT</pubDate>
    </item>
    <item>
      <title>AI接口可以用作ASCII游戏终端吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppy330/can_an_ai_interface_be_used_as_an_ascii_game/</link>
      <description><![CDATA[我尝试了新的 Gemini 3.0，发现它很好，上下文也保持不变。这个界面让我想起了我学校里玩 ASCII 游戏的旧终端。因此，我开始探索将 LLM 终端充当整个迷你游戏本身的想法——图形、机制、叙述和 UI 全部在单个文本流的约束下呈现。我制作了一个名为 noumen loom 的原型迷你游戏，这是一款完全在 Gemini gem 内进行的元叙事游戏。 我想分享设计理念以及由于独特媒体的性质而必须做出的不同选择。   元戏剧从高概念出发，我开发了一个简单的叙事结构，然后我将其交给 llm 使其成为角色，并通过向其提供实时游戏说明并在每次聊天期间开发游戏来开始玩，然后返回 GitHub 更新那里的提示。就在那时我意识到这个游戏实际上更接近于我也在其中扮演的角色。一旦我有了这种洞察力，我就能更流畅地发展。所以我基本上是要求人工智能在元戏剧中扮演多个角色，而玩家也成为戏剧的一部分。我仍然需要适当改进游戏机制，但需要找到擅长这方面的人。 通过“HUD”进行状态跟踪默认情况下，LLM 在轮次之间是无状态的。为了创造连续性（HP、分数、等级进展），我强迫它打印一个“HUD”在基于上一回合的内部评估的每个响应开始时。该模型读取旧的 HUD，根据玩家的输入计算变化，并在生成叙述文本之前打印新的变化。 Llm 扮演多个角色 该游戏需要三个不同的角色同时对玩家做出反应。当我通过与法学硕士一起构建个性档案时，我意识到每个角色都需要不同的文本风格和演讲。 （如果我早点知道的话，我什至可能会用单个角色制作游戏）但是这个限制让我跳出框框去寻找解决方案，这很有趣。有时，llm 会搞砸图形。 新颖的游戏会话 由于其元性质，每个会话都完全不同。如果我沉浸在戏剧中，那就很有趣。游戏机制非常初级，因为我需要专家的帮助。  幻觉是一个特性/Bug：法学硕士有时可以见面，实际上这比我对 Gemini 3 的预期要少见。有时法学硕士会忽略一条规则。我有一个反派“荆棘鸟”（我喜欢海伯利安的诗篇），他应该只在第 2 关中进入场景。但有时它会出现在第 1 关中。你必须依靠这个“不可靠的叙述者”才能进入场景。作为元戏剧的一部分。我花了很多时间尝试修复该错误，并且大多数情况下它都有效。然后我将其作为一项功能进行了研究，并更好地享受了它。 图形 我必须预加载许多图形，因为当我让它当场构建每个图形时，llm 有时不起作用。但它确实制作了一些 unicode 图形。  还有其他人尝试过使用 llm 作为主要游戏机制吗？我对你对这个实验的想法很感兴趣。您认为这种媒介还有哪些其他可能性？  我不知道是否还有其他人创建了另一个llm游戏，他们是否会走同样的道路。如果你们中有人制作过类似的llm游戏，请分享。 我会附上Gemini gem的链接。如果你玩了，请告诉我进展如何？ https://gemini.google.com/gem/1v0tL8NXMcFBbaP4txld3Ddwq94_nonb6?usp=sharing   由   提交 /u/GlassWallsBreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppy330/can_an_ai_interface_be_used_as_an_ascii_game/</guid>
      <pubDate>Thu, 18 Dec 2025 18:23:30 GMT</pubDate>
    </item>
    <item>
      <title>45% 的人认为，当他们提示 ChatGPT 时，它会在数据库中查找准确的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</link>
      <description><![CDATA[21% 的人认为它遵循预先写好的响应脚本。  https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</guid>
      <pubDate>Thu, 18 Dec 2025 17:54:16 GMT</pubDate>
    </item>
    <item>
      <title>让我们停止假装我们不会受到沉重打击</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</link>
      <description><![CDATA[令人惊讶的是，即使在这个子领域，仍有如此多的人对人工智能的发展方向不屑一顾。与过去两年相比，今年的进步是巨大的，没有理由相信这些模型不会继续显着改进。是的，法学硕士本质上是概率性的，但我们会找到更容易、更自动地验证输出的方法，并设置适当的护栏。我的意思是，这真的不明显吗？当前的 SOTA 模型犯下什么样的错误并不重要，许多此类错误在过去已经得到解决，不再发生，其余的错误也会随之而来。 老实说，我们将在未来几年看到技术劳动力的大幅减少，同时工资也会大幅下降。当然，我们对此无能为力，除了我们自己利用该技术并希望我们尽可能晚地受到打击。 有一天我们甚至可能会看到完全自主的软件开发，但即使在可预见的未来我们仍然需要几个人参与其中，这仍然很容易减少 80-90% 的员工人数。我希望我是错的，但这可能性很小。我们可以根据需要经常移动球门，这不会改变实际结果。   由   提交 /u/Own-Sort-8119   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</guid>
      <pubDate>Thu, 18 Dec 2025 17:34:38 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对就业影响的惊人真相</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppvlqe/the_surprising_truth_about_ais_impact_on_jobs/</link>
      <description><![CDATA[对末日的预期有多少是由轶事数据、单个事件的小插曲（一家公司解雇了 X 人）驱动的，或者只是“如果人工智能传播的话应该是什么样子……”的理论预期？这就是为什么严格的采样和分析很重要。宏观模式常常朝着特定人群在实地看不到的方向发展。  https://www.cnn.com/2025/12/18/business/ai-jobs-economy  “高度依赖人工智能自动化的工作增长速度比 Covid-19 之前更快，甚至比所有其他职业都快。”至 Vanguard.... Vanguard 高级经济学家 Adam Schickling 在接受 CNN 电话采访时表示：“从总体上看，我们没有看到人工智能暴露岗位就业率下降的证据。”Vanguard 发现，人工智能暴露程度高的职业就业率增加了在 2023 年中期至 2025 年中期的新冠疫情后时期，增长率为 1.7%。 这些工作的增长速度比新冠疫情前时期（2015 年至 2019 年）1% 的增长速度要快。 相比之下，所有其他职业的就业增长都已放缓...... 与人工智能相关的职业的实际工资增长率（根据通货膨胀调整）仅为根据 Vanguard 的数据，新冠疫情爆发前为 0.1%。但在后 Covid 时期，这一数字已加速至 3.8%。 相比之下，所有其他较少接触人工智能的职业的实际工资增长幅度较小，从 Covid 前的 0.5% 升至 Covid 后的 0.7%...”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppvlqe/the_surprising_truth_about_ais_impact_on_jobs/</guid>
      <pubDate>Thu, 18 Dec 2025 16:47:21 GMT</pubDate>
    </item>
    <item>
      <title>聊天机器人内存成本失控，不同系统的成本细分</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppqsee/chatbot_memory_costs_got_out_of_hand_did_cost/</link>
      <description><![CDATA[运行客户支持聊天机器人已有 6 个月了，内存成本耗尽了我们的预算。由于定价信息分散在各处，因此决定对不同的内存系统进行适当的成本分析。 在 30 天内使用实际生产流量测试了 4 个系统（约 6k 次对话，约 50k 总查询）： 每月成本明细：   系统 API 成本 令牌使用情况 每次查询成本 备注    完整上下文 $847 420 万个令牌 $0.017 发送完整对话历史记录   Mem0 ~$280 580k 代币 $0.006 有使用等级，随使用量变化   Zep ~$400 780k 代币 $0.008 定价取决于计划   EverMemOS $289 220k 代币 0.006 美元 开源，但需要 LLM/嵌入 API + 托管   差异很大。完整上下文的成本是 EverMemOS 的 3 倍，并且会消耗更多代币。 无人谈论的隐性成本：  Mem0：根据层级有基本费用 Zep：更高计划的最低每月承诺 EverMemOS：数据库托管 + LLM/嵌入 API 成本 + 大量设置时间 完整上下文：代币成本爆炸式增长对话时间较长  这对我们意味着什么：以我们的规模（每月 5 万个查询），成本差异非常显着。完整的上下文可以工作，但随着对话时间的延长，成本也会很快增加。 系统之间的令牌效率差异很大。有些比其他更好地压缩内存上下文。  粗略节省成本估计：  从完整上下文切换到最有效的选项：每月节省约 550 美元以上 但需要考虑开源选项的设置时间和基础设施成本 对我们来说，节省的成本仍然证明额外的复杂性是合理的  如果其他人正在处理类似的成本问题，我会分享。当您考虑实际使用模式时，流行的选项并不总是最便宜的。   由   提交 /u/Few-Needleworker4391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppqsee/chatbot_memory_costs_got_out_of_hand_did_cost/</guid>
      <pubDate>Thu, 18 Dec 2025 13:27:30 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊将向 OpenAI 投资 100 亿美元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/</link>
      <description><![CDATA[据 CNBC 报道，亚马逊将在 OpenAI 上投资至少 100 亿美元。 来源：https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html 知道什么吗投资大概是？   由   提交/u/Amphibious333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/</guid>
      <pubDate>Thu, 18 Dec 2025 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>大多数人没有意识到关于法学硕士的 10 个反直觉事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</link>
      <description><![CDATA[很多关于 LLM 的讨论都集中在他们能做什么上。很少谈论他们内部的实际行为。 这里有关于 LLM 的 10 个鲜为人知的事实，如果你想认真使用它们，或者诚实地评估它们的局限性，这些事实很重要。 1.法学硕士并不真正“理解”人类语言 他们非常擅长建模语言结构，而不是在现实世界中奠定意义。 他们预测接下来应该出现什么文本，而不是句子真正指的是什么。 这种区别解释了很多奇怪的行为。 2.它们与事实的关系是不对称的  高频、常见事实 → 非常可靠 罕见、边界或程序性事实 → 脆弱  它们不会“查找”真理。 它们再现真理通常在语言中的样子。 3.当信息缺失时，法学硕士会填补空白，而不是停止 人类在不确定时会停顿。法学硕士倾向于完成模式。 这是幻觉的真正根源 - 不是不诚实或“说谎”。 4。结构正确性比事实正确性更重要 如果答案是：  流畅 连贯 风格一致  …模型通常将其视为“好”，即使前提是错误的。 干净的结构可以掩盖虚假内容。 5.法学硕士几乎没有内部“判断” 他们可以模拟判断、引用判断、混合判断——但他们不拥有这样的判断。 他们不评估后果或选择方向。他们优化合理性，而不是责任。 6. LLM 不知道自己什么时候错了 信心≠准确性 流畅≠真理 内部没有警报说“这是新的”或“我可能在猜测”，除非你通过提示或约束来强制警报。 7.新概念不是学习出来的 - 它们是近似的 当你引入一个原始想法时，模型：  将其分解为熟悉的部分 搜索附近的模式 重建一些足够相似的东西  概念越新颖，误解就越容易。 8.高结构用户可能会意外地将 LLM 引入幻觉 如果用户提出一个连贯但有缺陷的系统，模型更有可能遵循该结构而不是挑战它。 这就是为什么幻觉通常是用户模型交互，而不仅仅是模型缺陷。 9. LLM 奖励语言循环，而不是真理循环 如果对话形成稳定的循环（定义 → 示例 → 摘要 → 抽象）， 模型会将其视为高质量推理 - 即使它从未触及现实。 10.法学硕士的真正力量在于结构外化 它们最强大的用途不是回答问题。 它是：  使内隐思维可见 将直觉压缩为结构 充当认知支架  用得好，它们不会取代思考 - 它们揭示你如何思考。 TL;DR LLM 不是思想、法官或真理引擎。他们是语言和结构的模式放大器。 如果你带来清晰度，他们会缩放它。如果你带来混乱，他们也会缩放它。   由   提交 /u/Weary_Reply   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</guid>
      <pubDate>Wed, 17 Dec 2025 22:49:04 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>