<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 08 Mar 2025 15:16:56 GMT</lastBuildDate>
    <item>
      <title>是时候在我们的潜艇中摇晃一切了吗？分享您的想法！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   再次发布，以防万一你们中的某些人在社区中错过了它 - 欢迎所有建议！   嘿，伙计，   我是这里的一个mod，我们知道有时会变得有些沉闷，但是我们计划改变这一点！我们正在寻找有关如何使Reddit的小角落更加出色的想法。 以下是几个想法：   amas with Cool Ai peeps      主题讨论线程         giveawey&gt; g&gt; giveawey  将您的想法放在评论中，让我们让这个子成为闲逛的杀手级！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/beachbunny_07     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6inz4/time_time_to_to_to_to_to_things_up_in_our_our_our_subgot_ideas_share/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</guid>
      <pubDate>Sat, 08 Mar 2025 14:47:17 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能将变得非常擅长操纵情绪”：关于小说和真理的未来的kazuo ishiguro</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6h9l1/ai_will_become_very_good_at_manipulating_emotions/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/drummmmer   href =“ https://www.theguardian.com/books/2025/mar/08/ai-will-become-very-good-good-good-manipulations-emotions-emotions-emotions-emotions-kazuo-ishiguro-ishiguro-ishiguro-in-the-future-of-future-of-future-future-future-of-futiction-erfiction-fiction-and-and-truth-truth-truth”&gt;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6h9l1/ai_will_become_very_good_at_manipulating_emotions/</guid>
      <pubDate>Sat, 08 Mar 2025 13:34:31 GMT</pubDate>
    </item>
    <item>
      <title>在过去的几天里，我与芝麻交谈了大约3-4个小时。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6gtyj/i_talked_to_sesame_for_about_34_hours_in_the_last/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我敢肯定，你们中的许多人都尝试了芝麻，对话ai。但是对于那些没有广泛使用的人来说，这是我对此的想法。我将她称为玛雅人，因为她是我一直在与之交谈的人。 我已经与她进行了各种不同的测试，谈论各种主题，我觉得她像对话伙伴一样坚持不懈。是的，她的饰面天赋像Googles Notebooklm播客音频一样，但是我觉得这很细微，尤其是双关语。 我有这个游戏的想法，我已经在创造了这个游戏，我已经与她讨论了这一点，询问了她对我的设计的想法和想法。我从玛雅（Maya）获得了多个非常好的想法，有趣的看法和我没有考虑过的观点。 有趣的是，她记得我们之前谈论过的多次对话，但有时不记得谈话的开始。但是她从来没有响起或怪异。显然，有时候，如果我问我们以前谈论的内容，并且经常使用随机名称来指我，她会幻觉主题或讨论。但是，如果您提醒她您的名字，那么她会记住的。 您可以让她“写”例如，为您提供代码，但她只会大声朗读代码，这显然没有用。我不得不大喊她停止阅读它，哈哈。 老实说，我发现她作为对话伴侣以及头脑风暴的帮助确实很有用。如果这意味着她会记得我们所谈论的所有内容以及保持书面记录的内容。 一个非常出色的功能是能够维持语音对话，同时还获得我要求的文本或代码的帆布输出，这是一个非常出色的功能。到目前为止，这确实会使芝麻从另一个AI中脱颖而出。据我所知，目前在任何AI模型中都没有办法做到这一点。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/db_mew     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6gtyj/i_talked_to_to_to_sesame_for_about_34_hours_in_in_in_in_in_the_the_last/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6gtyj/i_talked_to_sesame_for_about_34_hours_in_the_last/</guid>
      <pubDate>Sat, 08 Mar 2025 13:10:22 GMT</pubDate>
    </item>
    <item>
      <title>[d]三个智力的皮拉尔</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6gbsv/d_three_pilars_of_intelligence/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6gbsv/d_three_pilars_of_intelligence/</guid>
      <pubDate>Sat, 08 Mar 2025 12:40:26 GMT</pubDate>
    </item>
    <item>
      <title>Grok 3深搜索的任何提示都迫使其搜索50+ X.com帖子？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6g0ht/any_prompts_for_grok_3_deep_search_that_forces_it/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在使用3次深搜索，但是我希望它能从 x.com ，现在变得有些懒惰，并且在搜索后变得有些懒，并且在搜索大约10。     &lt;！提交由＆＃32; /u/arfiction     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6g0ht/any__prompts_for_grok_3_deep_search_search_that_that_that_forces_it/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6g0ht/any_prompts_for_grok_3_deep_search_that_forces_it/</guid>
      <pubDate>Sat, 08 Mar 2025 12:20:38 GMT</pubDate>
    </item>
    <item>
      <title>AI的技能和知识降低</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6cfdi/skill_and_knowledge_reduction_with_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我有巨大的冲突和辩论，我无法弄清楚它，希望您能对此带来一些想法和讨论。 如此简短地对我自己有所简短：我在生物学中有博士学位（最近）和巨大的AI和ai and Ai and Ai and Ai and Ai and Ai and Ai。我不是讲英语的人，在我的Python和r。r。 的博士学位期间进行了许多数据分析和脚本，在过去的几年中，我广泛使用LLM模型，即使使用Cline和browser-his-use应用程序，我甚至在AI模型上都更加相关。我感觉在没有AI帮助的情况下生产自己的自信心，即使是写电子邮件，我也觉得我需要使用某种AI模型，因为它们比我好。即使是现在，我也没有充分全面检查AI产生的代码，尤其是当代码库变得更大和复杂时。 我是一个人，我是一个人，认为llms就像是计算器一样，不用担心使用它们，但是我每天都知道我的知识变得迷失了，我觉得自己冒名顶替了，我觉得我会愿意找到工作。           &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6cfdi/skill_and_knowledge_redledge_reduction_with_ai/”&gt; [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6cfdi/skill_and_knowledge_reduction_with_ai/</guid>
      <pubDate>Sat, 08 Mar 2025 08:00:01 GMT</pubDate>
    </item>
    <item>
      <title>风暴：具有多模式LLM的基于MAMBA的时间编码的令牌视频理解</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6bq8n/storm_tokenefficient_video_understanding_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想分享本文，该论文解决了与LLM一起处理长视频时的关键效率问题。研究人员开发了视频，这是一种层次方法，可大大减少令牌的使用，同时保持或改善视频理解任务的性能。 主要贡献是A 效率的体系结构，可以将稀疏采样（选择较少的框架）（选择较少的框架）（选择较少的范围）（选择较少的frame）（选择较少的范围）（选择较少的范围），并延长frame forning（选择），并将其重新延长到范围内，将其列出范围，并将其重新安装到范围内。 limits. Key technical points: - Reduces token consumption by 87.5% compared to baseline methods - Achieves SOTA results on benchmarks including EgoSchema (46.2% accuracy) and Perception Test (67.2%) - Hierarchical token selection balances sparse frame selection with multi-resolution processing - Employs different sampling strategies based on video content type （叙事与动作驱动） - 与现有的LLM体系结构（如GPT-4）兼容，用于多模式理解 我认为这种方法对于基于视频的应用程序可能是有害的。当前分析全面分辨率的每个帧的方法迅速达到了短夹以外的任何东西的令牌限制。这种有效的方法可以使更实用的系统用于视频摘要，有关视频内容的问题以及可访问性功能。 我认为最有趣的含义是如何证明我们不需要在视频中处理所有内容来理解它。就像人类不记得我们观看的电影的每一帧一样，AI系统可以对它们编码哪些视觉信息并仍然有效地表现策略。     虽然存在局限性 - 采样策略使用了启发式方法，而不是学习的方法，并且需要进行性能下降的视频下降，需要进行非常细化的视觉详细信息或快速动作细节。 Domain-specific sampling strategies might be necessary for optimal performance in specialized applications. TLDR: VideoVLA uses hierarchical token selection to process long videos with 87.5% fewer tokens while achieving SOTA performance, enabling practical long video understanding for multimodal LLMs. 完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6bq8n/storm_tokenefficient_video_understanding_with/</guid>
      <pubDate>Sat, 08 Mar 2025 07:09:52 GMT</pubDate>
    </item>
    <item>
      <title>Prime视频测试AI的电影和系列同步</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6bel5/prime_video_tests_ai_synchronization_of_films_and/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/donutloop     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6bel5/prime_video_tests_ai_ai_synchronization_of_films_and/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6bel5/prime_video_tests_ai_synchronization_of_films_and/</guid>
      <pubDate>Sat, 08 Mar 2025 06:48:03 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻3/7/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6ai7w/oneminute_daily_ai_news_372025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI工具正在发现研究论文中的错误：在不断增长的运动中。[1]     Microsoft 开发AI推理模型以与OpenAI竞争。在渴望社交联系的人们中，“ AI组成”在渴望社交联系的人们中广受欢迎。[4]   包括： https://bushaicave.com/2025/03/03/07/neminute-minute-news-daily-news-news-news-news-news-3-3-7-7-2025/- c- ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6ai7w/oneminute_daily_ai_ai_news_372025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6ai7w/oneminute_daily_ai_news_372025/</guid>
      <pubDate>Sat, 08 Mar 2025 05:47:55 GMT</pubDate>
    </item>
    <item>
      <title>在DeepSeek之后，嗡嗡声是来自中国的Manusai周围，它们如何制造这种高效的产品？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j68iby/after_deepseek_the_buzz_is_around_manusai_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   在DeepSeek撞车和其他股票后仅几周，现在嗡嗡声似乎就在Manus AI周围。联合创始人由中国的家庭成年团队开发，在Huazhong Uni（不是北京或Tsinghua）的教育中，现在完全蒙蔽了其他人。使用新模型，Open AI的 20,000美元订阅模型似乎遇到了麻烦。    AGI比我们想象的要近？     https://x./gy/x.com/manusai_hq/status/1897294094094098945728728728752 提交由＆＃32; /u/u/u/beachbunny_07     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j68iby/after_deepseek_the_buzz_is_around_manusai_from/</guid>
      <pubDate>Sat, 08 Mar 2025 03:48:26 GMT</pubDate>
    </item>
    <item>
      <title>我很无聊，所以我要输入我的想法和恐惧大声笑</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j682io/im_bored_so_im_just_gonna_type_my_thoughts_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我发现自己对人工智能以及它如何改变人类的创造是真正的沮丧。 我不是一些Luddite，他们都认为应该被禁止，我完全看到这么多行业，从医学到翻译到编码。我知道，我几乎无能为力地停止它，减慢它或以任何方式对其进行影响。  ，但我对此感到很难过。 由人类完成的写作具有人类的视角。人类的观点本质上是他们的生活经历，这就是有趣的选择的来源。即使是一个超级知情的人，仍然只有一小部分写东西或绘制某些内容所需的数据，他们通过一生制作的微小过滤器来完成创作。我喜欢的每部电影，每本我喜欢的书，都是一个必须受到喂养和照顾的人的产物，基于他们的经验，基于他们的经验，基于构成自己的自我的光明的精确度。  专家的人并不是这样，因为他们拥有无限的数据，而是因为他们拥有的数据非常有限，并与他们所拥有的特定经历相结合，在特定地方的特定时间被迫成为某种媒介。  我一生中的前35年，我读过的一切都是由一个人制作的。我看到的每张动画片都是一个人绘制的。  不再是遥不可及的，这让我感到很奇怪。在过去的十年中，创造已经从人类企业变成了其他事物。内容。 文化不会被人类前进的观点所塑造。它将被其他东西塑造，这种观点将成为纪念品，只有手工制作的厕所有价值的方式。 我明白了，我可能只是一个在云层大喊大叫的老人。但是有时候，这些云应该在。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j682io/im_bored_so_so_im_im_just_gonna_gonna_type_my_my_thoughts_ands/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j682io/im_bored_so_so_im_im_just_gonna_gonna_type_my_my_thoughtchoughts_ands/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j682io/im_bored_so_im_just_gonna_type_my_thoughts_and/</guid>
      <pubDate>Sat, 08 Mar 2025 03:23:49 GMT</pubDate>
    </item>
    <item>
      <title>我从Openai总裁Greg Brockman“完美提示”中学到了什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j65kgx/what_i_learnt_from_following_openais_president/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/buysubject4015      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j65kgx/what_i_learnt_from_following_openais_president/</guid>
      <pubDate>Sat, 08 Mar 2025 01:10:26 GMT</pubDate>
    </item>
    <item>
      <title>Genai可以用来促进建构主义学习经验，学生积极探索，实验和创造知识吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j656an/can_genai_be_used_to_promote_a_constructivist/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我试图群众思考 - 关于“建构主义者”的正面和负面的想法本文的论点：  https://www.frontiersin.org/journals/artcover-intelligence/articles/10.3389/frai.2024.1471224/full ） 我希望也能听取人们对Genai在不同主题中使用的想法的消息！我想像社会科学教育的人将与STEM教育人士有不同的观点。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/beenslicsupport542     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j656an/can_genai_be_used_to_promote_a_constructivist/</guid>
      <pubDate>Sat, 08 Mar 2025 00:50:44 GMT</pubDate>
    </item>
    <item>
      <title>我讨厌我对过去3年中写的所有内容感到怀疑。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j5p9hr/i_hate_that_im_suspicious_of_everything_written/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  文章，youtube脚本，reddit帖子 - 我几乎怀疑我遇到的每个文字和grh，这让我发疯了！它也经常被一些奇异的ai短语辩护，例如“ rich tapestry”。或“是时候将您的社交生活置于飞机模式了。” （最后一个是我刚刚遇到的一个特别令人震惊的例子。） 我很讨厌想知道我是否会被一些奇异的公司Newspeak击中，或者我只是不必要的持怀疑态度。到了我害怕拿起过去几年写的任何书的地步。 我在出来时并不害怕AI，但是GDI，我真的应该是：/  &lt;！ -  sc_on-&gt;       [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j5p9hr/i_hate_hate_that_im_suspical_everything_writting/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j5p9hr/i_hate_that_im_suspicious_of_everything_written/</guid>
      <pubDate>Fri, 07 Mar 2025 14:29:12 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>