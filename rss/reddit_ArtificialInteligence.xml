<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 07 Nov 2025 21:18:10 GMT</lastBuildDate>
    <item>
      <title>有没有办法阻止“人工智能”破坏互联网？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or5x24/will_there_ever_be_a_way_to_stop_ai_from_ruining/</link>
      <description><![CDATA[人工智能泡沫仍然巨大，前景也总是巨大的。不可否认的一件事是，人工智能在互联网上完全是负面的。 YouTube 和 TikTok 等媒体网站/服务充斥着垃圾人工智能内容，这些内容的存在就是为了浪费人们的时间。像 Reddit 这样的论坛也受到了非常严重的打击，因为任何主要的 Reddit 子版块都充满了人工智能编写的垃圾农场视图。有些甚至只是为了在有争议的话题上制造混乱而存在。这里甚至有人让 chatgpt 出于某种原因写帖子和评论，这很可悲。人工智能加速了死亡互联网理论几乎成为现实。这没有什么好处。 让这些垃圾毁掉互联网真的值得吗？   由   提交 /u/chipkeymouse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or5x24/will_there_ever_be_a_way_to_stop_ai_from_ruining/</guid>
      <pubDate>Fri, 07 Nov 2025 20:51:37 GMT</pubDate>
    </item>
    <item>
      <title>涉嫌聊天机器人用户自杀的新统计</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or5jud/new_count_of_alleged_chatbot_user_selfunalives/</link>
      <description><![CDATA[随着新一批法庭案件的审理，涉嫌聊天机器人用户自杀的新人数（或人数）目前为 4 名青少年和 3 名成人。 您可以在 Reddit 上找到所有人工智能法庭案件和裁决的列表： https://www.reddit.com/r/ArtificialInteligence/comments/1onlut8 P.S.：我为愚蠢的委婉说法表示歉意，但为了避免 Reddit 的后杀手机器人过滤器，这是必要的。   由   提交 /u/Appressive_Sky1950   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or5jud/new_count_of_alleged_chatbot_user_selfunalives/</guid>
      <pubDate>Fri, 07 Nov 2025 20:37:08 GMT</pubDate>
    </item>
    <item>
      <title>涉嫌聊天机器人用户自杀的新统计</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or56a3/new_count_of_alleged_chatbot_user_suicides/</link>
      <description><![CDATA[随着新一批法庭案件的审理，涉嫌聊天机器人用户自杀的新人数（或死亡人数）目前为 4 名青少年和 3 名成人。 您可以在 Reddit 上找到所有人工智能法庭案件和裁决的列表： https://www.reddit.com/r/ArtificialInteligence/comments/1onlut8   由   提交 /u/Appressive_Sky1950   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or56a3/new_count_of_alleged_chatbot_user_suicides/</guid>
      <pubDate>Fri, 07 Nov 2025 20:22:12 GMT</pubDate>
    </item>
    <item>
      <title>人工智能真的会抢走工作岗位吗……还是这些裁员背后还有更深层的原因？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or4a0w/is_artificial_intelligence_really_stealing_jobs/</link>
      <description><![CDATA[https://www.youtube.com/watch?v=8g5img1hTes CNBC 刚刚进行了深入探讨，实际上让您停下来思考。事实证明，很多裁员根本不只是与人工智能有关......有些是关于重组、公司战略，甚至是简单的成本削减举措。 这是一个视频，它改变了你对当前工作世界中正在发生的事情的看法。   由   提交/u/North_Way8298   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or4a0w/is_artificial_intelligence_really_stealing_jobs/</guid>
      <pubDate>Fri, 07 Nov 2025 19:47:59 GMT</pubDate>
    </item>
    <item>
      <title>黑匣子护栏逆向工程攻击</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or3o5u/blackbox_guardrail_reverseengineering_attack/</link>
      <description><![CDATA[研究人员刚刚发现，即使在黑盒设置中，也可以从外部对大型语言模型中的护栏进行逆向工程。该论文介绍了护栏逆向工程攻击（GRA），这是一种基于强化学习的框架，它使用遗传算法驱动的数据增强来近似受害者护栏的决策策略。通过迭代收集输入输出对，关注分歧情况，并应用有针对性的突变和交叉，该方法逐渐收敛到护栏的高保真替代品。他们在三个广泛部署的商业系统（即 ChatGPT、DeepSeek 和 Qwen3）上评估了 GRA，结果显示规则匹配率超过 0.92，同时将 API 成本保持在 85 美元以下。这些研究结果表明，护栏提取不仅可行而且实用，引发了对当前 LLM 安全机制的真正安全担忧。 研究人员发现，该攻击可以在不探测内部结构的情况下揭示可观察的决策模式，这表明当前的护栏可能会泄漏足够的信号以供外部代理模仿。他们还表明，相对较小的预算和智能数据选择可以击败高级防护罩，至少对于测试的平台而言是如此。这项工作强调了迫切需要更强大的防御措施，这些防御措施不会通过可观察的输出泄露其政策指纹，并且暗示了更广泛的风险：更具弹性的护栏可能会变得更加复杂，并且在不引入新的故障模式的情况下更难以调整。 完整细分： https://www.thepromptindex.com/unique-title-guardrails-under-scrutiny-how-black-box-attacks-learn-llm-safety-boundaries-and-what-it-means-for-defenders.html 原始论文：https://arxiv.org/abs/2511.04215   由   提交 /u/ThePromptIndex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or3o5u/blackbox_guardrail_reverseengineering_attack/</guid>
      <pubDate>Fri, 07 Nov 2025 19:24:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 MCP 服务器实现动态代码执行 - 一些有趣的发现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or3dc0/implemented_dynamic_code_execution_with_mcp/</link>
      <description><![CDATA[我一直在尝试使用 MCP（模型上下文协议）服务器和代码执行作为直接工具调用的替代方案。构建了一个动态实现，可以完全避免生成文件。以下是一些观察结果： 关于使用 MCP 执行代码的 Anthropic 博客文章令人大开眼界。它们展示了如何为每个工具生成 TypeScript 文件，从而避免预先加载所有定义，从而减少令牌的使用。但大规模维护这些文件似乎很痛苦 - 当工具架构更改时，您需要重新生成所有内容、处理复杂类型以及管理数百个工具的版本冲突。 我的方法使用纯运行时注入。我没有文件，而是有两个发现工具：一个用于列出可用的 MCP 工具，另一个用于按需获取详细信息。片段以字符串形式存储在聊天数据中，执行时，callMCPTool 函数会直接注入到环境中。没有文件系统，没有导入，只是直接 mcpManager.tools 调用。 我发现真正有趣的是，片段还可以访问 callLLM 函数，这解锁了一些强大的元编程可能性。代理可以通过自定义系统提示以编程方式创建和执行专门的子代理，智能处理 MCP 工具输出而无需淹没上下文，并构建自适应多阶段工作流程。这就像让代理能够动态设计自己的推理策略。 优点：由于您调用实时连接，工具始终保持同步。没有构建步骤，没有再生。与基于文件的方法相同的渐进式发现和上下文效率，加上这些元编程功能。 MCP 协议本身的一个缺点：它不强制执行输出模式，因此链接工具调用需要防御性编码。该模型不知道工具输出的预期结构。也就是说，一些 MCP 工具确实提供了可选的输出模式，代理可以访问这些模式来帮助解决此问题。 实现使用 Vercel AI SDK 对运行时基础设施的 MCP 支持。 有兴趣了解其他人大规模使用 MCP 的经验。是否有更好的模式来处理模式不确定性？您如何管理工具版本控制？有人探索过具有类似 callLLM 功能的类似元编程方法吗？ 如果有人想查看实现，请访问 github.com/pranftw/aiter-app 的 GitHub 链接。   由   提交/u/psauxer  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or3dc0/implemented_dynamic_code_execution_with_mcp/</guid>
      <pubDate>Fri, 07 Nov 2025 19:12:55 GMT</pubDate>
    </item>
    <item>
      <title>关于具有开放权重模型的人工智能聊天机器人替代品的想法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or0hr4/thoughts_on_ai_chatbot_alternatives_with_open/</link>
      <description><![CDATA[最近一直在测试不同的对话式 AI 平台，我很好奇人们对转向更开放的方法与经过严格过滤的主流选项的看法有何不同。 像大多数人一样，我从角色 AI 开始，但对破坏沉浸感的内容限制感到沮丧。尝试了其他几个，最终选择了 Dippy AI，它使用合并的开源模型。对话质量的差异是显而易见的，特别是对于不完全符合公司安全类别的创造性或细致入微的讨论。 这项技术也很有趣。他们正在 Bittensor 上专注于角色扮演法学硕士。似乎确实在推动优先考虑用户体验而不是过度安全的模型。 社区对此有何看法？我们是否会看到经过过滤的企业人工智能和更开放的替代方案之间出现更多的碎片化，或者主流平台最终会放松吗？   由   提交/u/segsy13bhai  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or0hr4/thoughts_on_ai_chatbot_alternatives_with_open/</guid>
      <pubDate>Fri, 07 Nov 2025 17:24:54 GMT</pubDate>
    </item>
    <item>
      <title>没那么快：人工智能编码工具实际上会降低生产力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or0gs0/not_so_fast_ai_coding_tools_can_actually_reduce/</link>
      <description><![CDATA[我们听到很多人说非程序员可以对整个应用程序进行振动编码等。 这似乎是对最近一项研究的平衡看法，该研究表明即使是经验丰富的开发人员也大大高估了人工智能编码的收益。 你们都怎么看？对我来说，某些情况下它似乎提高了速度，或者至少感觉速度更快，但其他情况下，它确实减慢了我的速度。 链接：https://secondthoughts.ai/p/ai-coding-slowdown   由   提交/u/ethsmither  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or0gs0/not_so_fast_ai_coding_tools_can_actually_reduce/</guid>
      <pubDate>Fri, 07 Nov 2025 17:23:51 GMT</pubDate>
    </item>
    <item>
      <title>寻找人工智能泡沫的经济基础</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1or0ad9/in_search_of_the_ai_bubbles_economic_fundamentals/</link>
      <description><![CDATA[生成式人工智能的兴起引发了一场全球竞赛，旨在建设半导体工厂和数据中心，以满足大型语言模型的巨大能源需求。但随着投资激增和估值飙升，越来越多的证据表明金融投机的速度超过了生产率的提高。  https://www.project-syndicate.org/onpoint/will-ai-bubble-burst-trigger-financial-crisis-by-william-h-janeway-2025-11   由   提交 /u/Gloomy_Register_2341   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1or0ad9/in_search_of_the_ai_bubbles_economic_fundamentals/</guid>
      <pubDate>Fri, 07 Nov 2025 17:17:13 GMT</pubDate>
    </item>
    <item>
      <title>每个算法都有一个设计者，每个设计者都有一个老板。股东是人工智能的真正威胁。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oqykpg/every_algorithm_has_a_designer_and_every_designer/</link>
      <description><![CDATA[最危险的人工智能是执行公司议程的超能力算法，以不人道的方式专注于利润或市场份额等单一目标进行优化。  人工智能力量集中在少数大型企业手中才是真正的生存威胁。   由   提交 /u/SystematicApproach   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oqykpg/every_algorithm_has_a_designer_and_every_designer/</guid>
      <pubDate>Fri, 07 Nov 2025 16:12:59 GMT</pubDate>
    </item>
    <item>
      <title>随着人工智能的发展，人类如何在不迷失自我的情况下跟上人工智能的发展？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oqyj4n/as_ai_evolves_how_do_humans_keep_up_without/</link>
      <description><![CDATA[随着人工智能的快速发展，许多专家和思想领袖强调人类在不失去本质的情况下适应的重要性。根据世界经济论坛 2025 年的一份报告，随着人工智能的进步，保持同理心、批判性思维和创造力将是人类保持重要地位的基本技能。心理学家和未来学家都警告说，虽然人工智能可以实现任务自动化，但它无法取代情商和道德判断等人类独特的品质。 《哈佛商业评论》强调，培养持续学习文化和以人为本的领导力的组织更有能力在人工智能时代蓬勃发展。因此，当我们拥抱人工智能的能力时，传达的信息是明确的：将人性置于核心不仅是可取的，而且是成功驾驭未来的必要条件。  如何在人工智能日益塑造的世界中保持脚踏实地并不断成长？   由   提交 /u/Forward-Skirt-5710   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oqyj4n/as_ai_evolves_how_do_humans_keep_up_without/</guid>
      <pubDate>Fri, 07 Nov 2025 16:11:24 GMT</pubDate>
    </item>
    <item>
      <title>英伟达首席执行官警告“中国将赢得人工智能竞赛”：报告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oqwevg/nvidia_ceo_warns_china_is_going_to_win_the_ai/</link>
      <description><![CDATA[ https://www.foxbusiness.com/fox-news-tech/nvidia-ceo-jensen-huang-warns-china-going-win-ai-race-against-america-report   由   提交 /u/rinel521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oqwevg/nvidia_ceo_warns_china_is_going_to_win_the_ai/</guid>
      <pubDate>Fri, 07 Nov 2025 14:51:02 GMT</pubDate>
    </item>
    <item>
      <title>Square Enix 的目标是到 2027 年底让 AI 完成 70% 的 QA 工作，如果不解雇大部分 QA 员工，这一目标似乎很难实现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oqs4ko/square_enix_aims_to_have_ai_doing_70_of_its_qa/</link>
      <description><![CDATA[ https://www.pcgamer.com/gaming-industry/square-enix-aims-to-have-ai-doing-70-percent-of-its-qa-work-by-the-end-of-2027-which-seems-like-itd-be-hard-to-achieve-without-laying-off-most-of-your-qa-workers/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oqs4ko/square_enix_aims_to_have_ai_doing_70_of_its_qa/</guid>
      <pubDate>Fri, 07 Nov 2025 11:38:59 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft 于 2025 年 11 月 3 日开始使用您的 LinkedIn 数据进行 AI 培训</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oqqff0/microsoft_started_using_your_linkedin_data_for_ai/</link>
      <description><![CDATA[默认情况下您已选择加入。 如果您不想与 Microsoft 共享您的私人数据，请按以下步骤将其关闭：转至帐户 -&gt; 设置和隐私 -&gt; 数据隐私 -&gt; 关闭此功能。用于生成人工智能改进的数据。   由   提交 /u/Random-Number-1144   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oqqff0/microsoft_started_using_your_linkedin_data_for_ai/</guid>
      <pubDate>Fri, 07 Nov 2025 09:59:18 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>