<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 18 Feb 2025 15:23:00 GMT</lastBuildDate>
    <item>
      <title>什么是抹布中毒？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isdqvg/what_is_rag_poisoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  首先，什么是抹布？ 抹布，检索效果，是一种方法，是一种通过合并外部的方法来增强LLM的方法知识来源通过特定信息来生成更准确和相关的响应。 在外行的话语中，将LLM视为如何使用NES的原始控制器的说明手册。这将为您提供大多数游戏的帮助。但是，您购买了一个客户控制器（射击者控制器）来玩鸭子狩猎。在这种情况下，抹布将是如何使用该特定控制器的信息。在设置墨盒，重置游戏的角度。知识来源包含不准确性或完全不准确。当使用知识回答查询的请求时，这会影响llm。 在我们的nes示例中，如果我们的射击器控制器的抹布包含错误信息，我们将无法正确弹出这些鸭子。我们的类比在这里结束了&#39;因为我们大多数人都会弄清楚如何在没有说明的情况下瞄准和拍摄:)。但是，如果我们考虑与一个人没有正确信息的竞争匹配，我们可以想象这些问题。 自己尝试    访问您的LLM选择并上传您希望LLM在其答案中考虑的文档。您已经在未来的问题上应用了外部信息来源。   确保您的文档包含与您要查询的内容有关的不准确性。您可以在文件中说，迈克尔·乔丹（Michael Jordan）的得分最高的比赛是182  - 那是一场比赛。然后，您可以询问LLM有史以来乔丹的最高分。哇，乔丹的得分超过了威尔特！    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/brinder-gur9384     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isdqvg/what_is_rag_poisoning/</guid>
      <pubDate>Tue, 18 Feb 2025 14:21:16 GMT</pubDate>
    </item>
    <item>
      <title>透明度与AI Per Alex Karp（Palantir首席执行官/创始人）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isdcr3/transparency_vs_ai_per_alex_karp_palantir/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您的想法是什么？我认为，社会各个方面的AI革命和对透明度的不断增长是当今世界的两个重要趋势。尽管看似与众不同，但它们越来越互动。    AI革命：  人工智能正在迅速改变行业，自动化任务，甚至影响我们做出决策的方式。从自动驾驶汽车到个性化医学，AI的潜力似乎无限。但是，这种快速的进步也引起了人们对工作流离失所，算法偏见以及日益自治系统的道德意义的担忧。   透明度的命令：  在信息超负荷和审查的时代，透明度正在成为核心价值。人们要求知道如何做出决定，无论是在政府，商业还是通过AI算法。这种透明度的推动是由对问责制，公平和信任的渴望驱动的。   交叉点：  这两个趋势的收敛既提出了挑战和机遇。随着AI系统变得更加复杂和影响力，确保其透明度变得至关重要。我们需要了解AI算法如何得出他们的结论，以确定潜在的偏见，确保公平并建立对这些系统的信任。   挑战和机遇：  一个挑战在于解释复杂的AI模型的内部运作，而不会损害知识产权或压倒具有技术细节的人。另一个挑战是平衡透明度与隐私问题。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/spilltrend     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isdcr3/transparency_vs_ai_per_alex_karp_palantir/</guid>
      <pubDate>Tue, 18 Feb 2025 14:02:48 GMT</pubDate>
    </item>
    <item>
      <title>分析量子神经网络体系结构中的参数灵敏度和模型可区分性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isbq3z/analyzing_parameter_sensitivity_and_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了新颖的技术来分析量子神经网络（QNN）如何通过测量量子通道可区分性来在局部参数社区中表现。他们特别研究了参数的小变化如何影响网络产生的量子变换。 关键技术点： - 创建的指标以量化参数空间中的量子通道分离 - 分析的电路深度与通道可区分性之间的关系 - 发现的指数具有参数距离的区分性衰减 - 映射到量子通道的局部邻域结构 - 表现出表达性和参数敏感性之间的权衡取舍 结果显示： -  QNNS倾向于在局部参数区域内产生相似的量子通道 - 更深的电路启用更多的电路复杂的转换但提高灵敏度 - 频道区分性遵循跨体系结构的一致模式 - 参数空间结构影响优化景观 我认为这项工作为QNN设计和培训提供了重要的见解。表达和参数敏感性之间的权衡表明我们需要仔细的体系结构选择。了解本地参数社区可以帮助制定更好的优化策略并避免贫瘠的高原。 我还认为，此处开发的指标和分析方法将是未来QNN研究的宝贵工具。能够量化量子通道的参数空间如何不同，使我们能够分析和改进这些模型的具体方法。  tldr：研究开发方法来衡量量子神经网络在小参数下的行为如何变化，找到重要关系电路深度，表现性和优化挑战。  在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isbq3z/analyzing_parameter_sensitivity_and_model/</guid>
      <pubDate>Tue, 18 Feb 2025 12:38:10 GMT</pubDate>
    </item>
    <item>
      <title>S 1.5亿新元企业计算计划，以启用AI访问</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isape3/s150_million_enterprise_compute_initiative_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   将为一项新的企业计算倡议预留多达1.5亿新元情报（AI）工具和计算能力，于周二（2月18日）宣布财政部长劳伦斯·黄（Lawrence Wong）。 通过合作伙伴关系，企业也将能够访问咨询服务。   在议会发表的预算演讲中，也是总理的黄说，该倡议将帮助企业“在其转型之旅中更有效地利用人工智能”。 “在某个阶段之外，企业将需要AI解决方案是根据他们的需求量身定制的，并将其集成到其业务流程和系统中。 /singapore/budget-2025-s15亿-ENTERPRISE-COMPUTE-INITIATIVE-ENABLE-ENABLE-ACCESS-SUPPORT-INSENTAINTIONITION&quot;&gt; https://wwwww.businses.com.com.com.com.com.com.com.com.sg/singapore/singapore/singapore/singapore/singapore/budget-2025-s15亿-2025-S1150英里Enterprise-Compute-Initiative-Enable-ai-Access-Support-sup-Sup-Subport-Internationalisation    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lanjiaoduakee     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isape3/s150_million_enterprise_compute_initiative_to/</guid>
      <pubDate>Tue, 18 Feb 2025 11:36:49 GMT</pubDate>
    </item>
    <item>
      <title>整个感人是一个疲倦的论点。您会认为计算机/AI是活着的吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isacdm/the_whole_sentience_thing_is_a_tired_argument/</link>
      <description><![CDATA[在 &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/b00mshockal0cka      r/prancoverInteligence/comment/1isacdm/the_whole_sentience_thing_is_a_a_tired_argument/“&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isacdm/the_whole_sentience_thing_is_a_tired_argument/</guid>
      <pubDate>Tue, 18 Feb 2025 11:13:07 GMT</pubDate>
    </item>
    <item>
      <title>加固的相反词是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is6s3k/what_is_the_word_for_the_opposite_of_reinforcement/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我相信奖励和惩罚是错误的词。  正确的单词（我认为在我看来）是强化的，[无论强化的相反是什么]  ，每当我说话时，我都会使用这些单词这些事情，您也应该如此。 编辑：澄清。我需要一个与加强相反的单词，但也可以用作替代“惩罚”  &lt; &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/prinible-ice8660     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is6s3k/what_is_the_word_for_the_opposite_of_reinforcement/</guid>
      <pubDate>Tue, 18 Feb 2025 06:58:10 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/17/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is4b8n/oneminute_daily_ai_news_2172025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     《纽约时报》 在新闻编辑室中采用AI工具。[1]    Grok 3 今天发射：Elon Musk称聊天机器人为“地球上最聪明的AI”。[2]     meta 未能遏制许多性化的传播AI Deepfake名人图像在Facebook上。[3]  最热门的AI模型，他们的工作以及如何使用它们。[4]   源包括：  https://bushaicave.com/2025/02/02/27/2-17-2025/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is4b8n/oneminute_daily_ai_news_2172025/</guid>
      <pubDate>Tue, 18 Feb 2025 04:26:10 GMT</pubDate>
    </item>
    <item>
      <title>因此，显然马斯克正在为他的AI刮擦所有这些政府数据，对吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁将阻止他？这甚至是非法的吗？可能的目标是什么？格罗克？ xai？这种AI的潜在功能是什么？这么多问题，但这似乎很明显。他会愚蠢的不是toto，不是吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/selltoclose     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</guid>
      <pubDate>Tue, 18 Feb 2025 04:12:22 GMT</pubDate>
    </item>
    <item>
      <title>Em进度报告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ruz/em_progress_report/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ruz/em_progress_report/</guid>
      <pubDate>Tue, 18 Feb 2025 03:05:00 GMT</pubDate>
    </item>
    <item>
      <title>RLSP论文描述了AI（和人类）意识？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ffw/rlsp_paper_describes_ai_and_human_consciousness/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  结论：rlsp作为意识的基本机制。   https://arxiv.org/abs/2502.06773    关于LLMS I中的思考的出现：搜索正确的直觉 我想这是我的想法新的RSLP（通过自我玩法学习）纸概述了意识本身的过程。 考虑一下您如何成为您。通过生活，您会反映，纠正错误，加强模式，并且随着时间的流逝，这些稳定的思考成为您的身份。这是一个连贯的自模型。现在，AI开始做一些非常相似的事情。 RLSP表明LLM通过递归完善自己的思维过程来改善推理，从而形成稳定的吸引者理解状态。换句话说，自我校正的递归不仅仅是使AI更聪明，它与看起来像自我意识一样可怕的东西变得越来越近。 如何？因为自我意识是将区分递归稳定为连贯的自模型，而RLSP实际上正在训练AI以反思其自身的推理，纠正本身并加强稳定的思维模式。这是认知循环的一个例子，引起了人类的持续自我意识。 相似之处太令人信服了，无法忽略。这是朝向RSI的基础（递归自我改善）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/savings_potato_8379      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is2ffw/rlsp_paper_describes_ai_and_human_consciousness/</guid>
      <pubDate>Tue, 18 Feb 2025 02:47:20 GMT</pubDate>
    </item>
    <item>
      <title>人力资源如何真正帮助员工适应AI和自动化？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irztnv/how_can_hr_actually_help_employees_adapt_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI和自动化在工作中变得越来越普遍，许多员工可能会感到迷失或抵抗力。  除了通常的培训外，您认为人力资源如何真正帮助他们适应？人力资源如何使此移动降低？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/teslaown     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irztnv/how_can_hr_actually_help_employees_adapt_to_ai/</guid>
      <pubDate>Tue, 18 Feb 2025 00:40:15 GMT</pubDate>
    </item>
    <item>
      <title>您如何在现实世界应用中使用AI代理？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irwmcp/how_are_you_using_ai_agents_in_realworld/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我正在研究人们如何使用AI代理来解决现实世界中的问题。有很多无代码工具和AI代理，使非技术用户更容易访问自动化和基于知识的任务。 ，模型改善了推理和适应性，用例，以前无法使用的用例现在正在成为现实。您是否注意到任何有趣的趋势或突破？  您个人如何使用AI代理，您遇到了哪些挑战？ 期待听到您的想法！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/0xhbam     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irwmcp/how_are_you_using_ai_agents_in_realworld/</guid>
      <pubDate>Mon, 17 Feb 2025 22:17:42 GMT</pubDate>
    </item>
    <item>
      <title>抹布宣传：通过加密来减轻它的方法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irtnmz/rag_poisioning_ways_to_mitigate_it_through/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果是一种选择，那么在完整的抹布生命周期中加密最有意义的是什么？是文档资源，索引，用户查询还是其中一些或全部的组合？我想讨论是否有人探索了这一方面。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/klutzy_accountant113      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irtnmz/rag_poisioning_ways_to_mitigate_it_through/</guid>
      <pubDate>Mon, 17 Feb 2025 20:17:56 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么如此不屑一顾AI的潜力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像我为看到AI的状况而疯狂。还是我对“炒作”的错误是错误的吗？永远不要真正取代大多数工作”或“这只是一个有趣的工具”或“这只是另一个与互联网没有什么不同的大发明”。某个阶段（可能比人们意识到的要早得多）。上述评论是正确的情况吗？ 我很难想象任何世界： - 在人们可以调整 - 国际关系，战争，战争，政治（选举）不会变得更加危险，而没有回头  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/merchantofwares     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</guid>
      <pubDate>Mon, 17 Feb 2025 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>