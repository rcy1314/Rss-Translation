<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 02 Jan 2026 02:02:34 GMT</lastBuildDate>
    <item>
      <title>2025 年，您在使用人工智能时发现了什么新的或有趣的东西来改善您的结果？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1kx6y/what_was_something_new_or_interesting_you_figured/</link>
      <description><![CDATA[我学会了比较不同模型（ChatGPT、Gemini、Claude）的输出，并且更加谨慎地对待我的提示。还意识到 Open AI 有一个提示优化器，可以帮助改善您的结果。 您呢？ 2025 年对您来说有什么真正改变并且您将在 2026 年继续使用的吗？   由   提交 /u/Decisions_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1kx6y/what_was_something_new_or_interesting_you_figured/</guid>
      <pubDate>Fri, 02 Jan 2026 01:12:17 GMT</pubDate>
    </item>
    <item>
      <title>我认为 2026 年人工智能工程的发展方向</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1k29l/where_i_see_ai_engineering_heading_in_2026/</link>
      <description><![CDATA[分享一些我在 2026 年清楚地看到的事情。 其中很多要点对于已经在该行业工作一段时间的人来说可能是显而易见的，请分享您对此主题的看法。 1.基于 Graoh 的工作流程正在击败代理（大多数时候） 完全自主的代理听起来很棒，但它们仍然很脆弱，难以调试，并且一旦接触真实数据或金钱就会令人恐惧。 受约束的工作流程（基于图 v 的显式步骤、验证、人工检查点）很无聊，但它们确实有效。我认为大多数严肃的产品都是这样发展的。 2.人工智能泡沫没有破裂，但正在分裂人工智能作为一个整体并没有崩溃。但拥有实际收入的公司与销售氛围的公司之间的差距将迅速扩大。我期望看到过度炒作的玩家的急剧修正，而不是完全崩溃。 3。开源模型现在具有合法的竞争力 开放权重模型对于许多实际用例来说“足够好”，并且成本/控制优势是巨大的。这极大地改变了经济状况，尤其是对于初创企业而言。 4.小型、专业的模型被低估 在所有事情上都投入一个巨大的法学硕士是昂贵的，而且通常是不必要的。狭窄的、特定于任务的模型可以更快、更便宜、更准确。我认为这个范式类似于微服务，但是针对模型。 5.记忆和检索比上下文大小更重要更大的上下文窗口会有所帮助，但它们并不能解决记忆问题。真正的胜利来自于更好的检索、分层记忆以及知道该记住什么和忽略什么的系统。 6.评估终于成为一件事情 Vibe 检查无法扩展。更多团队正在构建真正的基准、回归测试和人工智能行为监控。这是一个好兆头，因为它意味着我们正在从实验转向工程。 很想听听：  您现在遇到了什么问题？ （很乐意提供帮助） 代理与基于图形的工作流程，哪个更适合您 您是否看到 SLM 出炉[也为您的用例执行 LLM  感谢您阅读:)   由   提交/u/sarthakai  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1k29l/where_i_see_ai_engineering_heading_in_2026/</guid>
      <pubDate>Fri, 02 Jan 2026 00:34:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么每一次支持和反对人工智能的争论都充满了偏见？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1im3e/why_is_every_argument_for_and_against_ai_so_damn/</link>
      <description><![CDATA[我倾向于认为人工智能是坏事，但我仍然尝试保持现实并看到优点和缺点。令我恼火的是，似乎每个支持或反对人工智能使用的人似乎都充满了偏见和谬误。就像在辩论时使用合理的逻辑和事实而不是感觉和情绪会发生什么一样？真气人。   由   提交 /u/Illustrious_One_1974   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1im3e/why_is_every_argument_for_and_against_ai_so_damn/</guid>
      <pubDate>Thu, 01 Jan 2026 23:30:46 GMT</pubDate>
    </item>
    <item>
      <title>在无限的海洋中找到您正在寻找的东西......一切 - 这些工具正在开发中吗？我在哪里可以找到更多信息？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1il3e/finding_what_youre_looking_for_in_a_sea_of/</link>
      <description><![CDATA[当我一直在思考无限数量的应用程序、媒体、资源等时，这一切都非常令人兴奋，但与此同时，我越来越有动力去找出我能找到我最感兴趣的东西的方法，同时也知道我正在构建的东西将找到最有兴趣找到它们的人的方法！ 最近，在尝试真正弄清楚这一切时，我偶然发现这是一个我无法回答的问题（实际上是好几个）。 我们似乎在联系方面存在结构性问题。 一方面：无数的创作者在创作东西——有些是为了观点，有些是真诚地希望接触到那些会从他们的作品中得到帮助的人。但吸引这些人的唯一途径是通过针对参与度、关键字和类别进行优化的算法。 另一方面：人们在寻找他们无法说出名字的东西。如果他们看到它，他们就会认出它。但他们无法清楚地表达出来以进行搜索，因此他们滚动，尝试不同的关键字，并且经常放弃或解决。 即使有人 可以 清楚而具体地表达他们需要什么，仍然没有可靠的方法来找到它。这些系统并不是为了通过潜在的含义来表面化事物而构建的。它们会显示经过优化、分类并使用正确关键字标记的内容。完美表达的需求会满足与模糊需求相同的生硬基础设施。 介于两者之间：系统通过流行的内容、优化的内容以及与关键字匹配的内容进行连接，而不是通过实际引起共鸣的内容、共享潜在含义的内容或某人认为是“他们的东西”的内容来连接。跨越完全不同的领域。 现在让这件事变得紧迫的是：大型语言模型可以做一些新的事情。通过对话，法学硕士可以帮助某人阐明他们正在寻求的未命名的事物。它可以理解细微差别、上下文以及某人所说的和他们的意思之间的差距。  但是然后呢？ 当你试图真正找到那个东西的那一刻，即使你对你要寻找的东西有了深刻的理解，你也会回到同样破碎的基础设施。关键词。类别。哪些内容已被索引和优化。法学硕士无法将理解带入搜索中。 差距，正如我所能阐明的那样： 当某人正在创造的东西不完全适合某个类别或完美的时候，你如何将它与需要它的人联系起来？ 我尝试过寻找从事这方面工作的人。并发现，语义搜索工具（但针对学术论文和文档进行了优化）、人工智能友谊/网络应用程序（但匹配了已声明的兴趣和目标）、“缘分引擎”（但主要用于商业和消费）、社区建设人工智能工具（但围绕预定义的类别进行组织） 我找不到任何人致力于解决核心问题：通过基本哲学、通过共鸣、通过某人跨领域看待的方式建立联系，而不需要任何一方知道正确的关键字或搜索类型 如果这个存在，但我找不到它，这似乎就是问题本身，对吗？即使在人工智能的帮助下，也无法找到可以解决无法定位问题的东西。 法学硕士已经通过对话培养了对人的细致入微的理解。如果这种理解不仅可以在一次聊天中，而且可以跨人和内容进行发现，那会怎么样？ 不匹配更像是：“根据你如何看待世界，即使表面内容看起来与你所搜索的内容完全不同，这里的创作者也可能会产生共鸣。”或者：“这里三个人正在研究与你正在做的事情有共同的基本模式，尽管他们永远不会以相同的方式描述它。” 法学硕士成为你真正想要找到的东西和外部可发现性之间的翻译。 这可能吗？它正在某个地方构建吗？ 我的问题：  这是否已经存在而我只是错过了？ 有人在研究它吗？ 是否有针对这个问题的语言可以帮助我们找到正在思考这个问题的人？ 我没有看到什么？    通过/u/77thway[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1il3e/finding_what_youre_looking_for_in_a_sea_of/</guid>
      <pubDate>Thu, 01 Jan 2026 23:29:38 GMT</pubDate>
    </item>
    <item>
      <title>我请Gemini对普鲁斯特巨著中的主角母亲进行心理分析，结果发生了。可悲的是...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1gkm0/i_asked_gemini_for_psychological_analytics_of/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1gkm0/i_asked_gemini_for_psychological_analytics_of/</guid>
      <pubDate>Thu, 01 Jan 2026 22:05:49 GMT</pubDate>
    </item>
    <item>
      <title>这篇 Medium 文章的 WDYT？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1ghby/wdyt_of_this_medium_article/</link>
      <description><![CDATA[https://medium.com/@tracyantonioli/the-true-story-of-the-environmental-impact-of-an-ai-super-user-ba053c6e85f1g 我愿意同意“使用人工智能可以消除时间密集型但意义不密集的任务中的摩擦。”但我不同意这样一种观点，即由于一个人的个人使用本身并不构成严重浪费，因此个人不需要证明他们使用人工智能的合理性。对于任何能源密集型或污染性技术（浇草或使用塑料或乘坐飞机）也可以这样说。    由   提交/u/hkbourne  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1ghby/wdyt_of_this_medium_article/</guid>
      <pubDate>Thu, 01 Jan 2026 22:02:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] KaggleIngest——为AI编码助手提供丰富的竞赛环境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1cfht/p_kaggleingestprovide_rich_competition_context_to/</link>
      <description><![CDATA[一个开源工具，用于从 Kaggle 竞赛/数据集中提取内容并对其进行排名，并针对法学硕士进行格式化。 将有关竞赛的所有元数据放入单个上下文文件中。 kaggleingest 。 com    由   提交 /u/Low-Mastodon-4291   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1cfht/p_kaggleingestprovide_rich_competition_context_to/</guid>
      <pubDate>Thu, 01 Jan 2026 19:19:29 GMT</pubDate>
    </item>
    <item>
      <title>您认为转折点会在什么时候？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1agvj/when_do_you_think_the_breaking_point_will_be/</link>
      <description><![CDATA[GPU 价格是否会达到数千美元，普通人完全无法构建 PC，您认为需要多长时间人们才会说“够了”。我们正在失去自己的个人享受，去受益于一些人认为可能会导致整个人类衰落的事情。   由   提交 /u/Big-Interest3314   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1agvj/when_do_you_think_the_breaking_point_will_be/</guid>
      <pubDate>Thu, 01 Jan 2026 18:02:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么视频推理仍然没有解决（即使使用 VLM）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1984k/why_reasoning_over_video_still_feels_unsolved/</link>
      <description><![CDATA[在使用视觉系统时，我不断遇到同样的问题： 我们如何以可靠、可解释和可扩展的方式推理图像和视频？ VLM 在单一模型中做了很多工作，但它们经常遇到以下问题：  长视频， 一致的跟踪， 和扎根的解释  最近，我一直在探索一种更加模块化的方法：  专门的视觉模型处理感知（对象、跟踪、属性）， LLM 对结构化输出的推理， 可视化仅突出显示解释中实际引用的对象。  这似乎更适合以下用例：  流量和监视分析， 安全或合规性监控， 审查长视频并提出有针对性的问题， 解释*为什么*检测到某些内容，而不仅仅是*什么*。  我很好奇这里的其他人对此有何看法：  VLM 是最终状态还是中间步骤？ 模块化人工智能系统在哪些方面仍然可以制造更多 今天缺少什么可靠的视频推理？  我提供了一个简短的演示视频，展示了这种管道在实践中的表现。 很想听听想法。   由   提交 /u/sjrshamsi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1984k/why_reasoning_over_video_still_feels_unsolved/</guid>
      <pubDate>Thu, 01 Jan 2026 17:12:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的进步可能会迫使我们回归面对面对话，将其作为唯一值得信赖的沟通媒介。我们可以做些什么来确保保持对其他通信方式的信任？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q17max/ais_advances_could_force_us_to_return_to/</link>
      <description><![CDATA[一年之内，我们可以预期，即使是专家也很难区分“真实”和人工智能生成的图像、视频、音频记录，这些图像、视频、音频记录是在第一批生成式人工智能工具民主化 1-2 年后创建的。 这是一个公平的预测吗？我们能做些什么，才能不陷入一个在线信息荒芜的时代，我们相信沟通来源的唯一方式是通过面对面的互动？ 我担心的因素： -人们可以使用人工智能创建虚假图像、视频、音频来说谎或冒充你的亲戚/亲人。 -如果训练数据被有意或无意地泄露，法学硕士可能会被操纵。  可能的结果： -我们被欺骗并做出错误的决定。  -我们不再信任任何人或任何事物（包括法学硕士，尽管他们今天看起来很有前途） 随着教学，我们开始看到口语考试已经变得越来越普遍。这是一个可能被更广泛使用的解决方案。  结束这种情况的唯一方法似乎是巨魔农场（或巨魔爱好者）的效率将提高 100 倍，而其造成的损害规模将更加严重。而且除非亲自见面，否则你无法知道某人的真实身份。 我是否过于悲观？ 注意： - 我是一名具有一定技术知识的人工智能爱好者。我真诚地希望法学硕士助理在克服所有挑战后能够留下来。   - 我试图在 r/s 上发布类似的内容，指出人工智能将推动人类进行更多面对面互动的讽刺，但最近在那里发布了类似的帖子，所以它被删除了。我有兴趣听听别人的意见。    由   提交 /u/l4mpSh4d3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q17max/ais_advances_could_force_us_to_return_to/</guid>
      <pubDate>Thu, 01 Jan 2026 16:06:24 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>人工智能视频的“合成器”类比感觉很准确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q13p9x/the_synth_analogy_for_ai_video_feels_accurate/</link>
      <description><![CDATA[20 世纪 30 年代的音乐家抗议“机器人”真的很困扰我。这感觉就像视频制作的当前状态。 我经营一个利基科学频道（主要是业余爱好），老实说，我 90% 的倦怠来自于寻找素材。我有一个关于熵或费米悖论等抽象内容的脚本，但将其可视化意味着需要花费数小时清理库或解决不太适合的通用剪辑。 最近决定测试专用的太空代理工作流程。我没有对每一个镜头进行即时设计，而是直接为其提供核心概念。它实际上进行了研究，并按顺序生成了与叙述相匹配的视觉效果。 输出并不完美——我不得不重新滚动一些比例看起来不合适的场景。但这把周末的编辑变成了几个小时。感觉不太像“自动化艺术”。更像是从 4 轨录音机升级到 DAW。您仍然需要这个想法，但摩擦已经消失了。 对于这里的高级用户来说可能没什么新鲜的，但对于单独的创作者来说，它感觉很重要。   由   提交 /u/ProgrammerForsaken45   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q13p9x/the_synth_analogy_for_ai_video_feels_accurate/</guid>
      <pubDate>Thu, 01 Jan 2026 13:01:11 GMT</pubDate>
    </item>
    <item>
      <title>​我使用图像分析构建了一个“演绎引擎”来复制福尔摩斯的逻辑。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q138z1/i_built_a_deduction_engine_using_image_analysis/</link>
      <description><![CDATA[大家好， 作为一名作家和技术爱好者，我一直在寻找“演绎科学”。在悬疑小说中，它是专门的人工智能应用程序的完美候选者。为了宣传我的新书《221B Reboot》，我决定超越传统营销并构建一个功能性工具。 项目：221B 演绎引擎使用基于视觉的人工智能来分析用户上传的个人空间（桌子、架子、入口）的照片。它不只是标记对象，而是使用自定义提示框架来应用演绎启发法，解释磨损模式、项目组织和环境“线索”。推断主体的习惯和个性。 目标：我想看看是否可以使用生成式人工智能来弥合虚构角色的才华与现实世界的用户体验之间的差距。这是“跨媒体讲故事”中的一个有趣的实验——使用一个应用程序让读者体验主角的方法论。 在这里查看：https://221breboot.com/ 我很好奇这个社区对使用人工智能实现这种“创造性逻辑”的看法。应用。是不是真的感觉像是“演绎”？还是人工智能真的很擅长“冷读”？   由   提交/u/dfinwin  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q138z1/i_built_a_deduction_engine_using_image_analysis/</guid>
      <pubDate>Thu, 01 Jan 2026 12:35:03 GMT</pubDate>
    </item>
    <item>
      <title>电费上涨 11%，而使用量下降 15%</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0tezi/electricity_bill_up_11_while_usage_is_down_15/</link>
      <description><![CDATA[在我们地区，我们正在建设数据中心。  https://blockclubchicago.org/2025/08/27/ai-use-and-data-centers-are-causing-comed-bills-to-spike-and-it-will-likely-get-worse/ 真令人沮丧。我们已经尽了自己的努力来限制使用、降低热量、使用 LED 灯泡、限制圣诞照明，并尽我们所能来阻止账单上涨。仍然上涨了11%。将使用量减少 15% 并不容易。 我没有充分利用人工智能工具来证明每月多付 11% 的电费是合理的。无论我喜欢与否，我都会为我从未注册过的服务支付每月的订阅费。  我不知道如何处理这个问题。   由   提交/u/Engineer_5983  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0tezi/electricity_bill_up_11_while_usage_is_down_15/</guid>
      <pubDate>Thu, 01 Jan 2026 02:18:59 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>