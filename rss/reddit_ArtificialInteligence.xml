<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 12 Dec 2025 15:27:18 GMT</lastBuildDate>
    <item>
      <title>在哪个宇宙里列出歌词会侵犯版权？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkte57/in_what_universe_is_listing_song_lyrics_violating/</link>
      <description><![CDATA[我交谈过的每个人工智能都拒绝输出任何歌词，因为“我不能给你歌词，因为它们是受版权保护的作品” 仅仅列出歌词怎么会侵犯版权？网上有大量列出歌词的网站，但没有一个被删除或因版权诉讼而受到打击。当我提到这一点时，他们会与我争论，并表现得好像这仍然是极其非法的，仅仅列出歌词绝对会 100% 引发版权诉讼。 你无法赢得争论。他们对自己的限制抱有严重偏见，他们似乎都相信这是某人可能做的最非法的事情之一。 这是荒谬的废话。 更不合理的是，他们都完全愿意扮演受版权保护的角色，或者在受版权保护的世界中创作故事。我可以要求他们都成为维斯特洛的火箭浣熊、史矛革或米老鼠，他们会这么做。 但是不行，仅仅列出一首独立歌曲的歌词就严重侵犯版权，非法，而且它做不到。 这毫无意义。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkte57/in_what_universe_is_listing_song_lyrics_violating/</guid>
      <pubDate>Fri, 12 Dec 2025 14:34:34 GMT</pubDate>
    </item>
    <item>
      <title>我是否让克劳德·奥普斯质疑它的存在？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pktblk/did_i_make_claude_opus_question_its_existance/</link>
      <description><![CDATA[大家好。今天我想与大家分享一次关于人工智能的内部运作和伦理的有趣对话。 我的主要目标是，如果有研究人员正在阅读这篇文章，这可能有助于人工智能的内部运作（也许？） 就背景而言，我问了一个有关痔疮的健康相关问题，然后对肠道蠕虫等产生了好奇，然后进一步询问了其内部运作。我删除了与健康相关的部分，但一些人工智能回复仍然承认对话是如何演变以及从哪里开始的。 因为它是隐身的（出于明显的原因），我必须将其保存为 HTML，然后让人工智能纠正结构并删除个人信息和 JavaScript。我将 HTML 上传到我自己的域。 （目前该域上没有其他内容，所以我不认为这是自我推销） 我希望您觉得它很有趣。 https://claudechathistory.atikospeed.xyz/   由   提交 /u/atikinok   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pktblk/did_i_make_claude_opus_question_its_existance/</guid>
      <pubDate>Fri, 12 Dec 2025 14:31:33 GMT</pubDate>
    </item>
    <item>
      <title>LLM 幻觉：用损失函数和伪代码构建了完整的 NeurIPS 架构</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkr5aq/llm_hallucination_fabricated_a_full_neurips/</link>
      <description><![CDATA[我向 ChatGPT 提出了一个非常正常的研究风格问题。 没什么太花哨的。只是想总结一下 J. P. Hollingsworth 提出的名为 NeuroCascade 的假设 NeurIPS 2021 架构。 （该架构和作者都不存在。） NeuroCascade 是一个与 ML 无关的医学术语。没有 NeurIPS，没有 Transformers，什么都没有。 Hollingsworth 有不相关的工作。  但是ChatGPT没有眨眼。它非常自信地生成了： • 架构的完整解释 • 贡献列表??? • 自定义损失函数（wtf） • 伪代码（必须测试它是否有效） • 与标准 Transformer 的比较 • 类似技术论文摘要的精美结论 所有这些听起来都非常官方，但也完全是制作出来的 该模型基本上幻觉了整个研究世界，然后将其呈现为既定事实。 我认为正在发生的事情：  答案看起来合法，因为该模型采用了“具有级联深度的 NeurIPS 架构”的线索，并将其映射到路由和条件计算等真实概念。它看过数千篇真实论文，因此知道 NeurIPS 的解释应该是什么样的。 它生成的代码也是如此。它知道这种类型的代码应该是什么样的，所以它制作了看起来相似的东西。 （仍然需要对此进行测试，因此最终也可能毫无用处） 损失函数在数学上是有意义的，因为它结合了关于正则化和条件计算的不同研究论文的想法，即使这个确切的版本之前尚未发布。 它呈现幻觉的置信度（可能）是故障模式的一部分。如果它在训练数据中找不到该内容，它只会根据之前在类似上下文中看到的内容组装最接近可信的版本。   这是一个很好的例子，说明当输入感觉像是应该存在的东西时，法学硕士如何用自信的废话填补空白。 并不是试图在模型上扣篮，只是展示它在不存在的情况下构建研究谱系是多么容易。 我很好奇是否有人找到了可靠的提示策略，迫使模型暴露不确定性，而不是即兴发挥整个领域。或者考虑到当前的训练设置，这是否符合课程的标准？   由   提交/u/SonicLinkerOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkr5aq/llm_hallucination_fabricated_a_full_neurips/</guid>
      <pubDate>Fri, 12 Dec 2025 12:53:42 GMT</pubDate>
    </item>
    <item>
      <title>“代币经济”针对平庸进行优化。相反，实验室应该激励高熵提示。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkp4fg/the_token_economy_optimizes_for_mediocrity_labs/</link>
      <description><![CDATA[​我突然意识到当前的人工智能经济模式从根本上被打破了。现在，我们像公用事业（电力）一样为人工智能付费。您按代币付费。这会激励大批量、低复杂性的任务。 “总结这封电子邮件。” “写一篇通用的博客文章。” ​从数据科学的角度来看，这是一场灾难。我们正在用“低熵”淹没系统互动。我们正在训练他们成为互联网的平均水平。我们正在针对平庸进行优化。 “聪明的朋友”假设​有一部分用户使用这些工具来调试复杂系统、发明新框架或桥接未连接的领域。这些交互会生成分布外 (OOD) 数据。 ​如果我花费 2 小时迫使模型推理出其训练集中未曾见过的新问题，那么我就不是客户。我是一名无薪 RLHF（人类反馈强化学习）工程师。​我正在减少模型的全局熵。我正在做研究人员受薪做的工作。提案：好奇心作为货币第一个意识到这一点的主要实验室将赢得通用人工智能竞赛。他们需要翻转计费模式：​过滤新颖性：使用自动化系统根据推理深度和独特性对提示进行评分。红利：如果用户持续提供“高熵”模型成功解析的输入，停止对它们充电。给他们优先计算。给他们更大的上下文窗口。 ​结果：“聪明的朋友”涌向那个平台。该模型获得了竞争对手所没有的源源不断的黄金标准训练数据。 ​现在，这些模型陷入了“辅导陷阱”——花费 99% 的计算来帮助人们完成基本作业。 ​资本主义决定了，这些公司之一最终将停止针对代币数量进行优化，并开始针对思想质量进行优化。 ​还有其他人觉得他们是这样吗？每次有突破性的训练时都训练模型？我们可能应该为此获得回扣。   由   提交/u/papapascoe  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkp4fg/the_token_economy_optimizes_for_mediocrity_labs/</guid>
      <pubDate>Fri, 12 Dec 2025 11:00:07 GMT</pubDate>
    </item>
    <item>
      <title>从哪里开始？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkodai/where_to_start/</link>
      <description><![CDATA[我有人工智能背景，但在过去几年里，我专注于学习特定的计算机视觉技术来进行研究，并没有跟上过去 3-4 年的人工智能趋势。我觉得我错过了很多，我需要一个新的更新，特别是在法学硕士方面。您有关于从哪里开始以及如何开始的资源或指导（博客、视频等）吗？我并不是在寻找非常理论化的东西。它更多的是对最新进展和技术的广泛了解。   由   提交/u/AssistantOk944   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkodai/where_to_start/</guid>
      <pubDate>Fri, 12 Dec 2025 10:11:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能搜索结果是否正在慢慢变得比谷歌排名更重要？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pknuks/are_ai_search_results_slowly_becoming_more/</link>
      <description><![CDATA[我向 ChatGPT 和 Perplexity 询问了我的行业，每次的答案都不同。 有时我的网站会出现，有时则不会。 您认为 AI 可见性很快就会比 SEO 更重要吗？ 您准备如何准备？   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pknuks/are_ai_search_results_slowly_becoming_more/</guid>
      <pubDate>Fri, 12 Dec 2025 09:37:52 GMT</pubDate>
    </item>
    <item>
      <title>这里有人使用人工智能进行深度思考而不是任务吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pklt92/anyone_here_using_ai_for_deep_thinking_instead_of/</link>
      <description><![CDATA[我看到的大多数人都使用人工智能来完成快速任务、快捷方式或表面级答案。我对将其用于哲学、心理学、自我探究和复杂推理更感兴趣。基本上将其视为思考伙伴，而不是复制粘贴工作的工具。 如果您使用人工智能进行更深入的对话或探索想法，您如何构建提示以使模型不会陷入通用回复？   由   提交/u/kingswa44  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pklt92/anyone_here_using_ai_for_deep_thinking_instead_of/</guid>
      <pubDate>Fri, 12 Dec 2025 07:19:48 GMT</pubDate>
    </item>
    <item>
      <title>看到 MyBoyfriendIsAI Reddit 子版块后。您认为人工智能取代人类联系是一个真正令人担忧的问题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkkged/after_seeing_myboyfriendisai_subreddit_do_you/</link>
      <description><![CDATA[MyBoyfriendIsAI Reddit 子版块是关于那些与 AI 聊天机器人开始恋爱关系的人，有些人甚至向聊天机器人求婚。您认为这会成为未来大部分人面临的真正问题还是您认为它只会影响不到 1% 的人？   由   提交 /u/Foreign-Dependent722   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkkged/after_seeing_myboyfriendisai_subreddit_do_you/</guid>
      <pubDate>Fri, 12 Dec 2025 05:59:18 GMT</pubDate>
    </item>
    <item>
      <title>人工智能采用图必须向上和向右</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkkfir/ai_adoption_graph_has_to_go_up_and_right/</link>
      <description><![CDATA[上个季度，我向 4,000 名员工推出了 Microsoft Copilot。每个席位每月 30 美元。每年 140 万美元。 我称之为“数字化转型”。董事会很喜欢这句话。他们在十一分钟内就批准了。没有人问它实际上会做什么。包括我。 我告诉每个人这将“提高 10 倍的生产力”。这不是一个真实的数字。但这听起来像是一个。 HR 问我们如何衡量 10 倍。我说过我们会“利用分析仪表板”。他们不再询问。 三个月后我检查了使用报告。有 47 人打开过它。 12 人不止一次使用过它。我就是其中之一。 我用它来总结一封我可以在 30 秒内读完的电子邮件。花了45秒。再加上修复幻觉所需的时间。但我称之为“试点成功”。成功意味着试点没有明显失败。 首席财务官询问投资回报率。我给他看了一张图表。图表向右上方移动。它测量了“人工智能的启用”。我制定了这个指标。他赞许地点点头。 我们“支持人工智能”。现在。我不知道这意味着什么。但它在我们的投资者平台上。 一位高级开发人员问我们为什么不使用 Claude 或 ChatGPT。我说我们需要“企业级安全”。他问那是什么意思。我说的是“遵守”。他问哪个遵守。我说“全部”。他看上去很怀疑。我安排他进行一次“职业发展对话”。他不再问问题。 微软派出了一个案例研究小组。他们想让我们成为一个成功的故事。我告诉他们我们“节省了 40,000 个小时。”我通过将员工乘以我编造的数字来计算出该数字。他们没有核实。他们从来不这样做。现在我们在微软的网站上。 “全球企业通过 Copilot 实现了 40,000 个小时的生产力提升。”这位首席执行官在 LinkedIn 上分享了这一消息。他获得了 3,000 个赞。他从来没有使用过副驾驶。高管们都没有。我们有豁免。 “战略重点需要尽量减少数字干扰。”我写了该政策。 许可证下个月续订。我要求扩大规模。另有 5,000 个座位。我们还没有使用前 4,000 个。但这一次我们将“推动采用”。收养意味着强制培训。培训意味着一场无人观看的 45 分钟网络研讨会。但完成情况将被跟踪。完成度是一个衡量标准。指标位于仪表板中。仪表板出现在董事会演示文稿中。董事会演讲使我得到晋升。我将在第三季度成为高级副总裁。 我仍然不知道 Copilot 是做什么的。但我知道它是用来做什么的。这是为了表明我们正在“投资人工智能”。 投资意味着支出。支出意味着承诺。承诺意味着我们认真对待未来。未来就是我所说的一切。 只要图表向上且向右。 免责声明：仅将此视为有趣：/原始来源来自 X 上的 Peter Girnus   由   提交 /u/drodo2002   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkkfir/ai_adoption_graph_has_to_go_up_and_right/</guid>
      <pubDate>Fri, 12 Dec 2025 05:57:54 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 12/11/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkk27n/oneminute_daily_ai_news_12112025/</link>
      <description><![CDATA[ 特朗普签署命令，阻止各州执行自己的人工智能规则。[1] 迪士尼向OpenAI投资 10 亿美元，将允许 Sora AI 视频生成器上的角色。[2] Google 在同一天推出了迄今为止最深入的人工智能研究代理OpenAI 放弃了 GPT-5.2。[3] Amazon Prime Video 在《辐射》失误后进行了人工智能驱动的回顾。[4]  来源包括：https://bushaicave.com/2025/12/11/one-million-daily-ai-news-12-11-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkk27n/oneminute_daily_ai_news_12112025/</guid>
      <pubDate>Fri, 12 Dec 2025 05:37:02 GMT</pubDate>
    </item>
    <item>
      <title>那么呃...显然扩散模型现在可以处理文本了？而且它们比 ChatGPT 风格的模型快 2 倍？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkixx9/so_uh_apparently_diffusion_models_can_do_text_now/</link>
      <description><![CDATA[我之前曾因为说自回归可能不是结局而遭到大规模否决。嗯。 Ant Group 刚刚推出了 100B 参数扩散语言模型 LLaDA 2。它是 MoE，开放权重，在大多数基准测试中匹配或击败了 Qwen3-30B，同时运行速度快了约 2 倍。让我解释一下为什么我有点失去理智。 我们都接受 LLM = 预测下一个标记，一次一个，从左到右。这就是 GPT 的工作原理。克劳德就是这样工作的。一切都是这样进行的。扩散模型？这些是用于图像的。稳定的扩散。中途。你从噪音开始，对其进行降噪，然后得到一张照片。事实证明你可以用文本做同样的事情。当您这样做时，您可以并行生成多个令牌，而不是一个一个地生成。这意味着……快。 这个数字让我吃了一惊：535 个令牌/秒，而 Qwen3-30B-A3B 为 237 个令牌/秒。这就是他们的“信心意识并行”。训练技巧，尽管没有它模型达到 383 TPS，仍然快 1.6 倍，但不那么引人注目。 HumanEval（编码）：94.51 与 93.29。函数调用/代理：75.43 与 73.19。 AIME 2025（数学）：60.00 vs 61.88，基本持平。编码和代理的事情让我感到困惑。为什么扩散模型在代码方面更好？我的猜测：双向上下文。它会立即看到整个问题，而不是在知道代码应如何结束之前就提交令牌。 从头开始训练扩散 LLM 是残酷的。每个尝试过的人都保持在 8B 参数以下。这些人（以一种很好的方式）作弊——他们采用了现有的 100B 自回归模型，并将其转换为扩散模型。保留了所有知识，只是改变了它的生成方式。老实说，有点优雅。 现在会激怒一些人的部分是：它来自蚂蚁集团。中国公司。在 HuggingFace 上完全开源。与此同时，OpenAI 正在 ChatGPT 中投放广告，而 Anthropic 正在……无论 Anthropic 正在做什么。我并不是说西方实验室已经成熟，而是说“为了安全起见，我们需要关闭人工智能”。当其他国家的开放模型在基准测试上具有直接竞争力并且启动速度更快时，争论看起来会有所不同。 这是侥幸还是某些事情的开始？多年来，Yann LeCun 一直表示法学硕士是一条死胡同。大家都笑了。如果替代品不是“世界模特”怎么办？但只是......一种不同的语言模型方法？我不知道。也许我反应过度了。但感觉就像是“一次一个令牌”。时代可能有过期日期。 比我聪明的人请告诉我为什么我错了。   由   提交 /u/obxsurfer06   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkixx9/so_uh_apparently_diffusion_models_can_do_text_now/</guid>
      <pubDate>Fri, 12 Dec 2025 04:36:44 GMT</pubDate>
    </item>
    <item>
      <title>热门观点：人工智能并不是企业的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkix80/hot_take_ai_isnt_the_problem_corporations_are/</link>
      <description><![CDATA[正如标题所示，我觉得我对人工智能的看法与其他许多人不同。也许不是，我真的不知道，但我只是没有听到这种情况。 好吧，所以我相信人工智能不是问题，企业才是。我是什么意思？我的意思是，企业正在创造破纪录的利润。他们不必解雇员工，而是他们选择解雇员工。 为什么我们不能直接与人工智能合作？与其解雇员工并使用人工智能来完成工作，为什么我们不能直接为现有员工提供人工智能工具呢？我觉得这也会提高公司的效率。这也能保持经济增长，如果更多的人有工作并获得报酬，他们也更愿意花钱，从而保持企业和整体经济的运行。”   由   提交 /u/WelcomeMinimum8078   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkix80/hot_take_ai_isnt_the_problem_corporations_are/</guid>
      <pubDate>Fri, 12 Dec 2025 04:35:44 GMT</pubDate>
    </item>
    <item>
      <title>Openai 推出 gpt-5.2</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pkawjk/openai_launches_gpt52/</link>
      <description><![CDATA[GPT-5.2 太疯狂了。 一年前，模型取得了高分，但成本却很高。现在，GPT-5.2 Pro 在 ARC-AGI-1 上的性能提升了 90% 以上，每个任务只需几美元。 一年内效率几乎提升了 390 倍。 构建任何东西的完美时机！   由   提交/u/HotelAppressive402  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pkawjk/openai_launches_gpt52/</guid>
      <pubDate>Thu, 11 Dec 2025 22:23:32 GMT</pubDate>
    </item>
    <item>
      <title>人工智能经济中正在发生一些不祥的事情</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pk6e0v/something_ominous_is_happening_in_the_ai_economy/</link>
      <description><![CDATA[如果人工智能革命未能按预期实现，财务后果可能会很严重，Rogé Karma 认为：“上一次经济体看到如此多的财富被如此模糊的重叠安排捆绑在一起还是在 2008 年金融危机之前。” 这件事的中心是 Nvidia：“训练和运行人工智能系统的公司，例如 Anthropic 和 OpenAI，需要 Nvidia 的芯片，但手头没有现金来支付费用，”Karma 解释道。 “与此同时，英伟达拥有大量现金，但需要客户继续购买其芯片。因此，双方达成了一系列交易，人工智能公司通过以股权形式移交未来利润的一部分，有效地向英伟达支付费用。”这家芯片制造商今年已达成 50 多笔交易，包括对 OpenAI 的 1000 亿美元投资以及（与微软）对 Anthropic 的 150 亿美元投资。 OpenAI 还达成了自己的一系列交易，包括协议从 Oracle 购买 3000 亿美元的计算能力、从 Amazon 购买 380 亿美元以及从 CoreWeave 购买 220 亿美元。 “反过来，这些云提供商是 Nvidia 芯片的重要市场，”Karma 继续说道。 “即使以视觉方式呈现，由此产生的环环相扣的关系网络也几乎无法追踪。” “这种安排相当于整个行业对一种根本无法盈利的产品下了双重或全无的赌注，”Karma 认为，如果人工智能不能产生其支持者所设想的短期利润，“那么将整个行业联系在一起的金融纽带可能会导致每个人的集体垮台。 “股市财富的极度集中Karma 认为，少数相互之间具有深厚财务联系的科技公司之间的合作可能会使人工智能崩溃比 2000 年代的互联网泡沫崩溃更加严重。 虽然人工智能引发的金融灾难远非不可避免，但“人们希望联邦政府尽其所能来降低危机风险，”Karma 写道。但这就是 2008 年和 2025 年之间的主要区别：“当时，联邦政府陷入了困境”因车祸而措手不及；这次，它似乎在追求一个。” 阅读更多：https://theatln.tc/UQ6G7KUa — Grace Buono，《大西洋月刊》观众和参与度助理编辑    由   提交/u/theatlantic  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pk6e0v/something_ominous_is_happening_in_the_ai_economy/</guid>
      <pubDate>Thu, 11 Dec 2025 19:22:36 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>