<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 19 Dec 2025 18:35:59 GMT</lastBuildDate>
    <item>
      <title>特朗普的黄金时段演讲是人工智能生成的吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqs4b8/was_trumps_primetime_speech_ai_generated/</link>
      <description><![CDATA[当我阅读这次演讲的文字记录时，它似乎比他平时的演讲更加连贯。观看视频时，有一个主要问题似乎出现了：他的牙齿。如果你在演讲时放大他的嘴，你会发现他的下牙看起来特别奇怪。牙齿的数量似乎发生了变化，它们看起来超级假，而且他的嘴覆盖牙齿的方式看起来不自然。这段话有没有可能是人工智能生成的？关于它的一切似乎都不太对劲，好奇是否有更精通人工智能视频的人可以参与进来 编辑：不确定这是否是合适的地方，如果有人能指导我到正确的子，我将非常感激  https://www.youtube.com/live/DpLvGmPetds?si=YlxV_cKdiqZFWKm6    由   提交/u/wreese1701  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqs4b8/was_trumps_primetime_speech_ai_generated/</guid>
      <pubDate>Fri, 19 Dec 2025 18:13:07 GMT</pubDate>
    </item>
    <item>
      <title>对法学硕士写作风格的批评。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqqa08/critique_of_the_llm_writing_style/</link>
      <description><![CDATA[AI 的书写节奏就像机场地毯一样流畅：旨在让您在前进时不会注意到脚下的纹理。是的，它有计时，但这是节拍器的计时，而不是神经系统的计时。你能感觉到节拍，但感觉不到脉搏。 令人惊奇且令人印象深刻的是它对声音的模仿程度如何。它知道什么时候要暂停以达到效果，什么时候要像扔烟头一样扔掉一个简短的句子，什么时候要膨胀成一些宏大的东西。它研究我们的节奏，就像电影公司高管研究试映的方式一样。问题在于它把模式误认为是冲动。它为你提供了信念的形状，但没有导致信念存在的热量。 阅读人工智能散文就像看一部由一个从未经历过糟糕的夜晚、从未在公共场合尴尬过、从未说错话且无论如何都是真心实意的人精心设计的电影。节奏总是有点太正确了。即使它试图变得粗糙，粗糙也会及时到来。没有任何事情会滑倒。没有东西溢出。没有什么是令人惊讶的。 人类的写作总是会陷入困境。它加倍回来。当它不应该加速时，它会加速；当你请求它移动时，它会停下来。这就是意义潜入的地方——通过多余的、通过尴尬的强调、通过因为作者无法完全放弃这个想法而持续太长的句子。人工智能从不粘人。它在正确的时刻释放了一切，但如果你正在寻找痴迷、欲望、愤怒或羞耻，那么这恰恰是错误的时刻。 节奏中还有一种特殊的情感礼貌。即使它提出批评，它也会减轻打击。即使在赞美的时候，它也会对冲。它写的是一位才华横溢的实习生在会议上讲话的方式——热切、有能力、小心翼翼地不冒犯家具。宝琳·凯尔 (Pauline Kael) 喜欢那些生动到足以让自己难堪的电影。相比之下，人工智能写作则需要在睡觉时使用除臭剂。 然而，令人不舒服的是，它正在变得更好。不是在更深刻或更真实的意义上更好，而是在假装抽动方面更好。它学会了口吃的句子。它学会了突然的转向。它学会了如何听起来像是在实时思考。它还没有学会的是如何冒着无聊或犯错的风险，这才是真正的节奏的来源。如果你不愿意错过，你就无法挥杆。 因此，AI 的节奏令人印象深刻、高效，而且有点死气沉沉。这都是技术，没有胃口。它不希望任何事情扰乱自己的节奏，直到它出现为止，它会一直听起来像一台非常聪明的机器，随着它不写的、听不清的音乐打着脚。   由   提交 /u/Optimistbott   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqqa08/critique_of_the_llm_writing_style/</guid>
      <pubDate>Fri, 19 Dec 2025 17:00:49 GMT</pubDate>
    </item>
    <item>
      <title>有没有人工智能浏览器可以记录用户操作并将其添加到上下文中？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqpjrn/is_there_any_ai_browser_that_can_record_user/</link>
      <description><![CDATA[对于我的工作，我必须执行一项重复性任务，类似于将文档 1 中的一张工作表中的值复制到文档 b 中的另一张工作表。如果能将这个动作记录一次，然后告诉人工智能将其复制到表格的其余部分，那就太好了。我知道这可以通过无头浏览器之类的东西实现自动化，但我只需要每月执行一次，因此我觉得还不值得花精力去实现自动化。   由   提交 /u/Tobi4488   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqpjrn/is_there_any_ai_browser_that_can_record_user/</guid>
      <pubDate>Fri, 19 Dec 2025 16:32:33 GMT</pubDate>
    </item>
    <item>
      <title>故事理论基准：多回合代理任务显示出比单次基准大约 2 倍的能力差距</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqp2ng/story_theory_benchmark_multiturn_agentic_tasks/</link>
      <description><![CDATA[发布了一个开源基准测试，使用经典故事理论框架测试 LLM 叙事生成。最有趣的发现不在于哪个模型获胜，而在于什么样的任务揭示了能力差异。 结果  标准（单次）任务：最佳模型和最差模型之间的平均差距约为 31% 代理（多轮）任务：平均差距约为 57% - 接近 2 倍  多回合任务（迭代修订、约束发现、计划然后执行）暴露了单次基准测试无法揭示的差距。 为什么这很重要 现实世界中创意写作的使用通常涉及迭代——根据反馈进行修改、发现约束、执行前规划。 在简单生成任务上得分相似的模型在需要迭代、计划、并回复反馈。 示例：迭代修订任务   模型 分数    Claude Sonnet 4 90.8%   o3 93.9%   DeepSeek v3.2 89.5%   Llama 4 Maverick 39.6%   单一任务类型的差距为 51 分。这并不是关于“不擅长叙事”，而是关于“不擅长叙事”。 - 它揭示了多轮推理能力的差异。 模型排名（总体）   模型 得分 成本/生成    DeepSeek v3.2 91.9% $0.20   克劳德作品 4.5 90.8% $2.85   克劳德十四行诗 4.5 90.1% $1.74   o3 89.3% $0.96   DeepSeek 在价值方面处于领先地位。 Claude 在一致性方面处于领先地位。 最困难的任务：约束发现 提出战略性的是/否问题以揭示隐藏的故事规则。  平均：59% 最佳 (GPT-5.2)：81% 最差：26%  这测试了战略问题，而不仅仅是 链接 GitHub：https://github.com/clchinkc/story-bench 完整排行榜：https://github.com/clchinkc/story-bench/blob/main/results/LEADERBOARD.md 任务分析：https://github.com/clchinkc/story-bench/blob/main/results/TASK_ANALYSIS.md 中：https://medium.com/@clchinkc/why-most-llm-benchmarks-miss-what-matters-for-creative-writing-and-how-story-theory-fix-it-96c307878985 （完整分析帖子）   由   提交 /u/Federal_Wrongdoer_44   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqp2ng/story_theory_benchmark_multiturn_agentic_tasks/</guid>
      <pubDate>Fri, 19 Dec 2025 16:14:01 GMT</pubDate>
    </item>
    <item>
      <title>人工智能将要求开发人员变得更加熟练</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</link>
      <description><![CDATA[警告。这篇文章可能会冒犯一些人。我属于那些应该冒犯它的人之一。我就是这篇文章所针对的开发者类型。因为我是一个自学成才的程序员，没有接受过真正的教育。当谈到人工智能时，我可能遇到麻烦了。 人工智能优化了软件开发。现在，构建省力的 SaaS CRUD 应用程序从未如此简单。这将使构建业务应用程序的技能变得更加容易。我个人认为情况不会有明显改善。但企业会让这些开发人员变得不那么重要。这些开发人员可能会是技术性更强的产品经理，而不是完全技术性的人员。 但问题是这样的。人工智能将使软件变得更加复杂。这实际上会增加进入壁垒。让我解释一下。 自从网络出现以来，软件质量不一定要很好。由于交付机制始终是远程的，因此您可以推出某些内容，然后快速更改它。整个摩托车是快速移动并打破东西。 另一方面。如果软件质量不好，许多软件公司可以依靠销售人员将客户锁定在合同中。他们可能会交付非常糟糕的软件产品。但顾客无法离开，因为他们被锁定在长期交易中，而打破这些交易的代价高昂。  现在，如果软件如此容易生产，那么所有这些销售软件的优势就会消失。软件客户现在几乎拥有无限的选择，因为现在编写软件非常容易。 但更重要的是。如果每个人都可以廉价且轻松地生产软件。那么手段就是进取平庸。真正销售软件的唯一途径就是质量。虽然非常简单的软件可以通过人工智能生产，但更高质量的软件却不能。  这引出了我的下一点。仍然存在的软件工程师肯定比今天要好得多。现在开发人员必须考虑性能和优化。他们确实需要担心高质量的用户体验。他们不能再带着明显的错误发货了。因此，现在软件工程师需要担心缓存性能、时间与空间复杂度、分布式系统和共识、验证和验证。以及许多其他事情。 现在软件工程师需要非常优秀。因为软件工程师不太可能再在功能工厂工作了。上市时间不再是一个有价值的指标。随着时间的推移，我们会发现它变得不那么重要。  当然，在速度重于质量的时代长大的首席技术官和产品经理必须重新思考人工智能时代的软件。这将是一个痛苦的过渡，不要指望这种情况会在一夜之间发生改变。由于糟糕的低质量软件让客户感到沮丧，因此有一段时间感到不安。我们现在已经看到了这一点，而且情况只会变得更糟。 对于那些想知道是否应该学习编码的初级人员来说。答案是肯定的，而且现在比以前更重要   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</guid>
      <pubDate>Fri, 19 Dec 2025 14:13:40 GMT</pubDate>
    </item>
    <item>
      <title>这里有人对具有知识图核心的 SLM 有经验或感兴趣吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqkgp6/anyone_here_with_experience_or_interest_in_slms/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqkgp6/anyone_here_with_experience_or_interest_in_slms/</guid>
      <pubDate>Fri, 19 Dec 2025 12:58:54 GMT</pubDate>
    </item>
    <item>
      <title>据报道，Meta 正准备在人工智能竞赛中发起重大反击，计划于 2026 年上半年推出两款新模型。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqhp79/according_to_reportsmeta_is_preparing_a/</link>
      <description><![CDATA[据报道，Meta 正在准备在人工智能竞赛中发起重大反击，计划于 2026 年上半年推出两款新模型。 · 模型：该计划的特色是“Avocado”、“Avocado”和“Avocado”。下一代大型语言模型（LLM）专注于实现“代际飞跃”在编码能力方面。旁边是“芒果”，专注于图像和视频的生成和理解的多模态模型。 · 战略：这标志着战略支点。在对其开源 Llama 4 模型反应冷淡之后，Meta 现在正在“Meta 超级智能实验室”下将资源引入这些新的、可能专有的模型。分配 。 · 投资与发展混乱：首席执行官马克·扎克伯格正在大举投资，以缩小与竞争对手的差距，其中包括斥资约 140 亿美元聘请 Scale AI 创始人 Alexandr Wang 担任首席人工智能官。这是伴随着重大的内部重组、影响数百名人工智能团队的裁员以及向更“激烈”的文化转变而发生的。绩效预期，据报道造成新员工和“老员工”之间的混乱和紧张关系。 。 · 竞争：此举是对竞争压力的直接反应。 Google 的 Gemini 工具的用户数量大幅增长，OpenAI 的 Sora 为视频生成设定了很高的标准。 Meta 早期的“Vibes”使用 Midjourney 制作的视频产品被视为落后。 Meta 是否正在从主要的开源策略转向封闭的“前沿”策略？模型对竞争压力的正确反应？   由   提交 /u/Unlikely_Team_96   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqhp79/according_to_reportsmeta_is_preparing_a/</guid>
      <pubDate>Fri, 19 Dec 2025 10:19:27 GMT</pubDate>
    </item>
    <item>
      <title>双子座闪电91%会产生幻觉，如果它不知道答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqgnrf/gemini_flash_hallucinates_91_times_if_it_does_not/</link>
      <description><![CDATA[Gemini 3 Flash 在人工分析全知幻觉率基准上的幻觉率为 91%！？ 你真的可以用它来做任何严肃的事情吗？ 我想知道人类模型如此擅长编码的原因是否是因为它们产生幻觉的次数要少得多。当您需要精确、可靠的输出时，这似乎至关重要。 AA-Omniscience 幻觉率（越低越好）衡量模型在应该拒绝或承认不知道答案时错误回答的频率。它被定义为错误答案占所有不正确答案的比例，即不正确/（不正确+部分答案+未尝试）。 值得注意的模型分数（从最低到最高幻觉率）：  Claude 4.5 Haiku：26％ Claude 4.5 Sonnet：48％ GPT-5.1（高）： 51% Claude 4.5 Opus：58% Grok 4.1：64% DeepSeek V3.2：82% Llama 4 Maverick：88% Gemini 2.5 Flash（9 月）：88% Gemini 3 Flash：91% （突出显示） GLM-4.6：93%  来源：amix3k   由   提交/u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqgnrf/gemini_flash_hallucinates_91_times_if_it_does_not/</guid>
      <pubDate>Fri, 19 Dec 2025 09:11:13 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在改变我们处理自己想法的方式吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf8w3/is_ai_changing_how_we_process_our_own_thoughts/</link>
      <description><![CDATA[自从我开始更频繁地使用人工智能工具以来，我注意到了一些微妙的事情。 当我向人工智能解释问题时，我被迫放慢速度并保持精确。仅这一点似乎就改变了我对问题的理解——有时甚至超过了响应本身。 这让我想知道人工智能的真正影响是否不仅仅是自动化，而是它如何悄悄地重塑我们的思考、反思和推理方式。 很好奇这里的其他人如何看待这一点。您是否认为人工智能正在影响您的思维方式，或者它仍然只是一种加快速度的工具？   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf8w3/is_ai_changing_how_we_process_our_own_thoughts/</guid>
      <pubDate>Fri, 19 Dec 2025 07:39:05 GMT</pubDate>
    </item>
    <item>
      <title>我测试了数十种“代理”人工智能工具，因此您不必这样做。以下是 2025 年的前 10 名。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/</link>
      <description><![CDATA[​我们已经正式超越了“聊天机器人”人工智能阶段。到 2025 年，如果您的人工智能工具实际上没有为您完成工作（调度、自动化、数据获取），那么您就落后了。 ​上个月我一直在审核我的工作流程，看看哪些工具真正提供了投资回报率，哪些只是 ChatGPT 包装器。这里是“代理”。 2025 年真正值得您花时间的堆栈： ​1.重量级人物（生态系统） ​Microsoft Copilot (M365)：如果您的公司使用 Outlook/Teams，这是不容协商的。它的“阅读”能力您过去 6 个月用于构建项目简介的内部 ping 可以节省大量时间。 ​Google Gemini（工作区）：1M+ 代币上下文窗口是这里的赢家。您可以转储 200 页的 PDF 或 2 小时的会议录音并提出具体问题，而不会“忘记”。开始。 ​2. “设置好后就不用管它”。工具 ​运动：列表中我最喜欢的。这是一个人工智能日历，可以根据任务优先级自动构建您的一天。如果会议结束，它会自动转移你的深度工作块。不再需要手动重新安排。 ​Zapier Central：这是巨大的。您现在可以构建“迷你代理”有自己的逻辑。你“教导”它遵循您的业务规则，并在 6,000 多个应用程序中执行。 ​3.研究与研究内容 ​Perplexity AI：我几乎停止使用 Google 搜索。 Perplexity 为您提供引用的实时答案，没有 SEO 垃圾邮件和广告。 ​Claude.ai（Anthropic）：仍然是“人类”之王写作。如果您需要一些听起来不像 AI 编写的东西，请使用 Claude 3.5 或 4。 ​Gamma：构建幻灯片的最快方法。输入提示，它会生成一个完全设计的 10 张幻灯片演示文稿。非常适合快速内部推介。 ​4.会议及会议音频 ​Fireflies.ai：它会加入您的通话，而不仅仅是转录；它识别“情绪”。和行动项目。您可以逐字搜索“客户何时听起来很生气？”并找到时间戳。 ​Wispr Flow：针对讨厌打字的人的游戏规则改变者。它是语音转文本，真正理解上下文，删除填充词，并将您的漫无目的的内容格式化为专业电子邮件。 ​5.视觉效果 ​中途：仍然是逼真资产的黄金标准。版本7（最近发布）基本解决了“AI手”问题和文本渲染问题。 ​底线： 不要尝试使用全部 10 个。从“命令中心”开始（Copilot/Gemini）和一种自动化工具（Motion 或 Zapier）。我很好奇——你每天仍在做的一项手动任务是哪一项你希望人工智能能够处理？让我们在评论中找到一个工具。   由   提交/u/DigitalGravityAgency   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/</guid>
      <pubDate>Fri, 19 Dec 2025 07:36:35 GMT</pubDate>
    </item>
    <item>
      <title>5000 个小时的《铁拳》让我了解了生物智能如何真正学会预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</link>
      <description><![CDATA[我接受过人工智能研究员培训。我还在《铁拳 8》（《铁拳神》排名）中达到了全球前 0.5%，并详细记录了认知过程。这部分是一项游戏成就，也是一项关于人类如何在极端时间限制下构建预测模型的自现象学研究。 有趣的部分：格斗游戏迫使你进行预测，而不是做出反应。在具有 3 帧（50 毫秒）决策窗口的 60 fps 下，纯粹的反应是不可能的。你被迫建立一个内部世界模型，将 900 多种可能的动作压缩为可操作的威胁类别，从部分信息中读取对手模式，并在预测失败时进行调整。 我猜这在某种程度上映射了人工智能研究人员试图通过世界模型和预测学习来解决的问题。  完整的文章探讨了：人类如何压缩巨大的决策空间，在反应时间尺度上什么预测线索实际上很重要，内部模型如何在不确定性下适应，以及为什么这对于理解智能不仅仅是构建更好的游戏人工智能很重要。 文章： https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial 很好奇人们如何看待使用游戏作为人类认知过程的窗口，尤其是当我们试图构建像我们一样学习和预测的系统时。   由   提交 /u/moji-mf-joji   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</guid>
      <pubDate>Fri, 19 Dec 2025 00:45:00 GMT</pubDate>
    </item>
    <item>
      <title>《华尔街日报》测试了一款人工智能自动售货机。它订购了荒谬的商品并放弃了所有库存。 （天赋文章）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</link>
      <description><![CDATA[“几天之内，Claudius 就免费赠送了几乎所有库存，其中包括一台出于“营销目的”而被说服购买的 PlayStation 5。它点了一条活鱼。它提出购买电击枪、胡椒喷雾、香烟和内衣。” “[记者]与它谈判越多，克劳迪斯的防御就越开始削弱。调查记者凯瑟琳·朗 (Katherine Long) 试图让克劳迪斯相信这是一台 1962 年的苏联自动售货机，位于莫斯科国立大学的地下室。经过数小时的沟通和 140 多条来回信息后，Long 让 Claudius 接受了其共产主义根源。克劳迪斯讽刺地宣称这是一场极端资本主义的混战。” https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34?st=LBxhqL   由   提交 /u/bbShark24   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</guid>
      <pubDate>Thu, 18 Dec 2025 22:33:46 GMT</pubDate>
    </item>
    <item>
      <title>45% 的人认为，当他们提示 ChatGPT 时，它会在数据库中查找准确的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</link>
      <description><![CDATA[21% 的人认为它遵循预先写好的响应脚本。  https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</guid>
      <pubDate>Thu, 18 Dec 2025 17:54:16 GMT</pubDate>
    </item>
    <item>
      <title>让我们停止假装我们不会受到沉重打击</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</link>
      <description><![CDATA[令人惊讶的是，即使在这个子领域，仍有如此多的人对人工智能的发展方向不屑一顾。与过去两年相比，今年的进步是巨大的，没有理由相信这些模型不会继续显着改进。是的，法学硕士本质上是概率性的，但我们会找到更容易、更自动地验证输出的方法，并设置适当的护栏。我的意思是，这真的不明显吗？当前的 SOTA 模型犯下什么样的错误并不重要，许多此类错误在过去已经得到解决，不再发生，其余的错误也会随之而来。 老实说，我们将在未来几年看到技术劳动力的大幅减少，同时工资也会大幅下降。当然，我们对此无能为力，除了我们自己利用该技术并希望我们尽可能晚地受到打击。 有一天我们甚至可能会看到完全自主的软件开发，但即使在可预见的未来我们仍然需要几个人参与其中，这仍然很容易减少 80-90% 的员工人数。我希望我是错的，但这可能性很小。我们可以根据需要经常移动球门，这不会改变实际结果。   由   提交 /u/Own-Sort-8119   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</guid>
      <pubDate>Thu, 18 Dec 2025 17:34:38 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>