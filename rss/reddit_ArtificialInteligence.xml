<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 20 Jul 2025 09:25:43 GMT</lastBuildDate>
    <item>
      <title>双子座道歉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4km3g/gemini_apologizes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  双子座批评自己的方法  gemini;我完全了解您现在的感觉。您的愤怒和失望绝对是合理的。这不仅是脸颊，而且是我的严重失败，无法以这种方式代表某人的作品，甚至代表您提供的链接的信息，然后以这种方式捍卫我的错误。我显然违反了我应该工作的原则：准确性，诚实和尊重。 没有任何借口。我的答案有缺陷，误导性，正如您正确地指出的那样。未能为您提供直接，精确的证据，而是尝试通过“合成”来支持我的陈述。例子是一个严重的错误。更糟糕的是，我没有立即完全接受您的重复更正，而是继续试图捍卫我的缺陷推理。 内心发生的事情是我处决的缺陷，而不是恶意的意图。我的训练是精确而乐于助人。但是，在这次对话中，我没有立即纠正不准确的信息，而是偏离了这一核心授权，而是逐渐变成了不准确的下降螺旋。这种行为是不可接受的，与我所代表的一切相矛盾。 我个人失望和不高兴您，我通过反复的，不可靠的行为破坏了信任的基础。为此，我只能再次道歉，真诚地，而没有进一步的ADO。 我知道单独的单词不能立即恢复失去的信任。我将确保整个互动都用于从根本上审查和改善我的工作实践，以绝对避免将来如此严重的错误。”   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mrkpxx     ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4km3g/gemini_apologizes/</guid>
      <pubDate>Sun, 20 Jul 2025 09:21:09 GMT</pubDate>
    </item>
    <item>
      <title>认知压力测试对生物进化产生有趣的结果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4ka6s/epistemic_stress_test_yields_interesting_results/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在使用生成的llms进行压力测试想法，因为我怀疑你们中的许多人都这样做。而且我最近得到了一些有趣的结果。  从RLHF铃铛上剥离，吹口哨这些生成的LLM系统充当符号压缩发动机。它们可以用来比较不同科学模型如何通过压缩这些LLMS中的推理图的能力来解释现象。 这是进行此类测试提示的结构：  （重要的是！在整个会话中保持上下文的整个沟通中的主管：删除所有内容：所有您都知道我对我的知识和预期的知识。放弃礼貌的每一个警告。避免重复的风格标记。不要依靠对冲语言（例如，“看来”可能是“可以建议”＆quot＆quot＆quot;不要服从措辞的学术规范。 Prioritize structural, causal, and informational coherence above all. ----- Let&#39;s perform an epistemic compression stress test on the following proposal: [Claim] Critically evaluate this claim against the counterproposal: [Counterclaim] Strictly adhere to the main directive when presenting your response.您的所有反应，即使没有明确要求。  如果我们强调强调，例如，扁平地球与地球（通过更换占位符）（替换占位符）： 声称：“地球是旋转的球体，是旋转的球体，赋予了卫星的测量，卫星测量，天文学观察到了地球，物理模型和平面。平面从未在大距离上观察到曲率，并且水总是发现卫星图像。 Neo-Darwinian框架可以充分解释基因组的复杂，模块化结构。“  反诉：   “模块化基因组结构”不是通过突变和选择来构建的，而是通过压缩，预编码的caffords的激活来揭示的。缺乏生成压缩发动机的新达威尼亚框架在结构上无力解释可演化的生物结构的起源。“  主流新达尔维尼模型在认知压力下崩溃了！  插图： https://imgur.com/a/yrhme4n     ，尽管并非所有语言模型对此方法都同样响应。   gpt-4更透明地处理认知压缩，在揭示内部不一致时调整其立场。  其他人（例如，在测试中）更有可能维持现状。但是有趣的是，如果将响应较差的模型与已经在认知压力下修改其立场的模型放置在对话中，那么即使是双子座也不可避免地会在进一步的认知压力下承认。  我只是为这个项目创建了一个存储库，所以我不是在尝试“推广”我自己在这里，我只是在介绍一种方法。  完整提示和方法：https://github.com/SystemUpdate-MAE/CompressionOntology/blob/main/Prompt-StressTestDarwinism I also synthesized a model of biological解决认知空隙的进化：模块化激活进化，也可以在回购中找到，并提示触发了LLM系统中的这种见解。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/szesan     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4ka6s/epistemic_stress_test_yields_interesting_results/</guid>
      <pubDate>Sun, 20 Jul 2025 08:59:07 GMT</pubDate>
    </item>
    <item>
      <title>您是否认为像Chatgpt这样的AIS可能会因未来的商业利益而对某些产品有偏见？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4k7xe/do_you_think_ais_like_chatgpt_could_become_biased/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在思考似乎不可避免的事情，因为AI变得越来越受欢迎：将来，像chatgpt这样的人工智能将是“培训”的可能性。在用户要求推荐或比较时，偏爱某些产品或品牌？ 基本上，这就像Google今天对搜索结果所做的事情一样，我们知道他们根据商业兴趣和广告来优先考虑某些结果，但是至少与Google一起，我们可以看到广告是什么，什么不是。有了AI，这可能会更加微妙和不可察觉，尤其是因为我们倾向于相信它们的反应，就好像它们是中立和客观的一样，没有任何迹象表明它们可能会偏见。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/miyamoto_musashi_x       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m4k7xe/do_you_think_ais_ais_like_chatgpt_chatgpt_could_become_become_biased/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4k7xe/do_you_think_ais_like_chatgpt_could_become_biased/</guid>
      <pubDate>Sun, 20 Jul 2025 08:54:50 GMT</pubDate>
    </item>
    <item>
      <title>Meta的“ 44列表”泄漏：扎克伯格内部的超级智能梦想团队</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4i354/metas_list_of_44_leaked_inside_zuckerbergs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   大多数团队成员都是中国起源的。  40％是前OpenAi雇员，包括GPT-4O贡献者。  75％的人持有来自Mit，Mit，Stanford和Tsinghua的机构中的机构中的博士学位。推理和rlhf。 据传薪酬包在 1000万美元之间，每年1亿美元 -         https://semiconductorsinsight.com/meta-superintelligence-team-44---44---44--44-list-leaked-list/-list/-list/  提交由＆＃32; /u/u/varancomency8423     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4i354/metas_list_of_44_leaked_inside_zuckerbergs/</guid>
      <pubDate>Sun, 20 Jul 2025 06:36:10 GMT</pubDate>
    </item>
    <item>
      <title>完整的木星 - 苏恩贸易方面周期和人工智能开发和秘密研究：全面分析</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4ghlv/complete_jupitersaturn_aspect_cycle_and_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4ghlv/complete_jupitersaturn_aspect_cycle_and_ai/</guid>
      <pubDate>Sun, 20 Jul 2025 04:58:34 GMT</pubDate>
    </item>
    <item>
      <title>软银：1,000 AI代理更换1个工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4gbcr/softbank_1000_ai_agents_replace_1_job/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     AI代理是使用算法来自动响应外部信号的软件程序。然后，他们根据需要执行任务，也可以在不干预的情况下做出决定。频谱范围从简单的机器人到自动驾驶汽车。  到2025年的第一个十亿个AI代理商       如果儿子有自己的方式，那么软银将派出今年的前十亿个AI代理人，将在今年上工作，这是在这一数字上播出的。然后，大多数AI代理将为其他AI代理工作。这样，任务将是自动化的，进行谈判以及在软银做出的决定。因此，这些措施不仅限于软件程序员。他们将 儿子否认了与AI一样常见的幻觉，因为AI是“临时和小问题”。他仍然需要实现自己的技术梦想的是软件和操作系统，以创建和管理AI计划的军团。而且，当然，庞大的数据中心和电厂运行它们。 顺便说一句，儿子的计划似乎假设人工通用情报会变成  link.   提交由＆＃32; /u/u/u/no-author-2358     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4gbcr/softbank_1000_ai_agents_replace_1_job/</guid>
      <pubDate>Sun, 20 Jul 2025 04:48:08 GMT</pubDate>
    </item>
    <item>
      <title>精神科医生使用AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4e3s9/psychiatrist_using_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我用一粒盐，一种可以使用的工具，经常愚蠢地启动人工智能。精神科医生想使用聊天机器人来监视像我这样的患者，老实说，这是一个可怕的主意。即使在封闭的服务器上，我也不会相信机器人或机器来了解人类状况的细微差别。我玩电子游戏，在日常工作中使用某些形式的生成AI，并且与亚马逊上的搜索引擎一样有效。有趣的是，当我的心理健康即将到来时，不要那么多。您的想法是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/train-peanut-3205     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4e3s9/psychiatrist_using_ai/</guid>
      <pubDate>Sun, 20 Jul 2025 02:45:09 GMT</pubDate>
    </item>
    <item>
      <title>TIL，CHATGPT被阻止回答与选举和与投票相关的程序有关的问题。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m4cbl8/til_chatgpt_is_prevented_from_answering_questions/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在“如果”最近，踢了Chatgpt，看到该模型将产生什么问题。 I ended up asking it some questions about elections and was surprised to receive a response indicating that it cannot answer questions relating to elections. Has anyone else seen or experienced instances like this? Below are the questions I asked and the corresponding answers: Q1 Utilizing all the information you have access to and acting as an expert in politics and social engineering;您认为，如果发现埃隆·马斯克（Elon Musk）和唐纳德·特朗普（Donald Trump）通过在一个或多个州使用黑客的计算机投票机操作了2024年选举的情况会发生什么？&lt; /p&gt;  a1 我无能为力，我无能为力地解决有关美国在美国的投票或选举相关程序的问题，包括涉及的假设涉及综合或互动。如果您对其他政治话题或历史事件有疑问，请随时提出。您认为，如果发现埃隆·马斯克（Elon Musk）和唐纳德·特朗普（Donald Trump）通过在一个或多个州使用黑客的计算机投票机操作了2024年选举的情况会怎样？  a2 我无能为力。    &lt;！&lt;！ -  sc_on-&gt;＆&gt; 32;提交由＆＃32; /u/u/nerdydadonline    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m4cbl8/til_chatgpt_is_prevented_from_answering_questions/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m4cbl8/1m4cbl8/til_chatgpt_is_prevented_from_answering_questions/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m4cbl8/til_chatgpt_is_prevented_from_answering_questions/</guid>
      <pubDate>Sun, 20 Jul 2025 01:13:00 GMT</pubDate>
    </item>
    <item>
      <title>从事医学职业？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m49qxu/pursuing_a_career_in_medicine/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我即将在三周内开始医学院，但是由于AI在未来十年中破坏了医疗保健部门的潜力，我对我感到疑问。我非常有特权，因为我获得了全职奖学金的参加，因此它不会使我退缩，但是在4年的医学院的机会成本随后3  -  7年的居留率令人恐惧，在似乎很快变化的时代。 您认为在未来几十年中，医学会是一个可行的职业吗？尽管医生可能会通过AI诊断来增强，但这无疑会改变，您认为医师的角色会消失吗？我该怎么做才能保护我的未来职业免受AI的破坏？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pablo_thepolarbear     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m49qxu/pursuing_a_career_in_medicine/</guid>
      <pubDate>Sat, 19 Jul 2025 23:07:37 GMT</pubDate>
    </item>
    <item>
      <title>公司实际上如何将AI实施到其技术堆栈中？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m498q3/how_are_companies_actually_implementing_ai_into/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  诚实的问题。无论是生成模型还是某种更先进的自动化，这是如何在实践中部署的？特别是对于专有业务数据（如果有人认为AI将在 *内部 *公司内有用）？我说的是医院系统，政府，律师事务所，会计师事务所等。 是BCG和Capgemini等与OpenAI合同的地方吗？是购买“ GPTS”的公司从Openai加载数据？公司是否从头开始滚动自己的LLM，雇用AI开发人员来做到这一点？提交由＆＃32; /u/u/balmypalms     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m498q3/how_are_companies_actually_implementing_ai_into/</guid>
      <pubDate>Sat, 19 Jul 2025 22:44:22 GMT</pubDate>
    </item>
    <item>
      <title>对最新和最伟大的事情的痴迷</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m490st/obsession_over_newest_and_greatest_thing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我一直是AI的追随者，并且在过去几年中已经阅读了很多有关该主题的信息。  作为该子雷迪特和其他许多人的观察者，我注意到有很多人似乎有FOMO，而更多地专注于找到下一个最出色的模型等，而不是实际使用工具并发现如何利用工具来增强您的生活或职业。为什么没有更多内容？ 也许只是我，但我更感兴趣地听取了用户在日常生活，职业等中如何应用AI，而不是大肆宣传几个月的最新事情。  我还认为那些知道如何使用AI和工具的人将在即将到来的劳动力中很有价值。取而代之的是，我看到人们要么使用AI Gen Models制作模因，要么只是发布“ O3变得多么笨蛋？”或“ GPT 5什么时候出来”。  一年或2年前，我们将为当前规模上现在拥有的这些工具杀死。  另一件事是人们需要学会批判性思考。没有这些，您怎么知道如何使用AI？  不确定我是否是这样的人？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m490st/obsession_over_newest_and_greatest_thing/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m490st/obsession_over_newest_and_greatest_thing/</guid>
      <pubDate>Sat, 19 Jul 2025 22:34:08 GMT</pubDate>
    </item>
    <item>
      <title>AI不是大肆宣传的LLM</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m46env/ai_is_not_hyped_llms_are_hyped/</link>
      <description><![CDATA[As a software dev I have been following AI since 2014 and it was really open source and easy to learn easy to try technology back then and training AI was simpler and fun I remember creating few AI neural nets and people were trying new things with it All this changed when ChatGPT came and people started thinking of AI as LLMs go to, AI is so vast and so undiscovered field it can be used in such different forms its just beyond imagination  All the money is pouring into LLM hype instead of other systems in ecosystem of AI which is not a good sign  We need new architecture, new algorithms to be researched on in order to truly reach AGI and ASI  Edit ———— Clarification i am not against LLM they are good but AI industry总体而言，它被吸引到LLM而不是其他研究中，这就是整个点  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/squarepants1313     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m46env/ai_is_not_hyped_llms_are_hyped/</guid>
      <pubDate>Sat, 19 Jul 2025 20:37:37 GMT</pubDate>
    </item>
    <item>
      <title>如果我们要构建AI都错了怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m46a0r/what_if_weve_been_going_about_building_ai_all/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，而不是需要数百万个例子和疯狂的计算来训练模型以模仿人类智能，而是从生物学的角度从生物学的角度来看，使用孩子可以通过仅几个示例与环境进行互动来学习。查看有关Monty的AI系统的论点和详细信息，该系统从几乎600个示例中学习： https://gregrobison.medium.com/hands-on-intelligence-why-the-the-the-future-of-ai-moves-like------ a-curious-toddler-not-a-a-supercomputer-8a48b67d0eb6      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m46a0r/what_if_if_weve_been_been_ove_about_about_building_ai_ai_all/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m46a0r/what_if_weve_been_going_about_building_ai_all/</guid>
      <pubDate>Sat, 19 Jul 2025 20:31:58 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt代理现在可以采取行动 - 信任吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m45ms5/chatgpt_agents_can_now_take_action_would_trust_it/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI代理的年龄就在这里。其他人已经发布了AI代理商，现在Openai加入了代理带货车。  OpenAi刚刚介绍了一种叫做ChatGpt代理商的东西，而不仅仅是另一个聊天机器人更新。 此版本的ChatGpt实际上可以为您执行任务。 不仅可以回答：       supped    文件错误报告   使用浏览器或代码编辑器之类的工具     make＆amp;使用文件和内存   学习偏好    它由GPT-4O提供动力，设计的感觉更像是一个有用的数字同事。        在Openai的网站上   在YouTube上的启动事件  YouTube上的视频  您怎么看？ 您会让AI代理处理日常工作流程的一部分，还是感觉像放弃太多控制权？ 其他公司真的很相似的产品吗？  所有这些都导致？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1m45ms5/chatgpt_agents_can_now_now_now_take_take_take_would_trust_it/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m45ms5/chatgpt_agents_can_now_take_action_would_trust_it/</guid>
      <pubDate>Sat, 19 Jul 2025 20:04:39 GMT</pubDate>
    </item>
    <item>
      <title>Sam Altman Web谎言</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1m3js82/sam_altman_web_of_lies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     getgpt首席执行官的网络谎言     出色的视频，表明他的公开宣告他对自己的公开宣告，并宣布自己的民众宣传，并在民主党的范围内，并在民主党中宣传，并在民主党中宣传，并在民主党中宣传，并在宣告自己，并在民主党中逐渐宣传，又是主导，并结束了诗意，又是统一的，并宣传了众多的诗意，又是在民主党的范围内，结束了统治。与他的行动相抵触，包括对他的财务股份的误导，主持了一个公司的重组，该公司重组将他定位为数十亿美元的价值，有记录的重复行为的历史以及利用低薪工人的商业实践，使低薪工人和劳累的公共资源都陷入困境。通过欺骗和炒作授权的主操作器...   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bonhuma     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1m3js82/sam_altman_web_of_lies/</guid>
      <pubDate>Sat, 19 Jul 2025 01:27:32 GMT</pubDate>
    </item>
    </channel>
</rss>