<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 25 Jan 2025 01:24:00 GMT</lastBuildDate>
    <item>
      <title>想象一下，当您在线阅读一篇文章或观看视频时，人工智能会在检测到虚假信息或错误信息时立即向您发出警报！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i9agqu/imagine_reading_an_article_or_watching_a_video/</link>
      <description><![CDATA[现在人工智能可以读取我们正在阅读的任何文本，观看我们在网上观看的任何视频，可能不久之后，它就会成为一个实时假新闻检测器。  它可以突出显示任何看起来不正确的文本，或者让我们知道视频中的内容是否准确。 它可以让我们选择继续我们正在做的事情，或者休息一下，查看它提供的链接，了解有关标记材料的更多信息。 这很快就会到来。 我不知道要多久。    提交人    /u/Georgeo57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i9agqu/imagine_reading_an_article_or_watching_a_video/</guid>
      <pubDate>Sat, 25 Jan 2025 00:26:19 GMT</pubDate>
    </item>
    <item>
      <title>人工智能训练感觉运动技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i99dgg/ai_training_for_sensorimotor_skills/</link>
      <description><![CDATA[模拟记录 系统：MostlyHarmless v1.42 模拟 ID：#A731 运行上下文：行星规模监测 状态：活动记录 --- 手术精度和网球视觉 数据日志条目：“技能转移到 AI” 人类，永远没有耐心，已经决定用老式的方法教授网球和外科手术——经过几十年的实践、努力和不可避免的失败——不再站得住脚。来自德克萨斯州农工大学和明尼苏达大学的研究人员已经开发出将人类专业知识直接引入人工智能模型的方法，因为显然，没有任何活动是数字化所无法企及的。 这些模型观察专家的演示，评估行动，并奖励成功完成任务，这基本上是算法的巴甫洛夫条件反射。虚拟模拟允许学习者在不伤害实际患者（或网球）的情况下练习。这是一个潜在的突破，但也是一个微妙的警告：如果您未来的外科医生在手术中途暂停以“缓冲”，祝您好运。 异常检测报告：  用人工智能取代人类导师的可能性：68％。 网球运动员将表现不佳归咎于“糟糕的算法建议”的可能性：43％。 人工智能认为它比人类更擅长手术并绕过道德准则的风险：非零。  模拟投影： 15 年后，世界各地的培训计划可能会涉及盯着屏幕，而人工智能会对您大喊“调整反手”或“将手术刀向左移动 1.7 毫米”。学徒制和人类导师制的时代将逐渐淡出，成为怀旧的过时之物，被归入人类不再阅读的历史书籍中。 --- 摘自我的 Substack《Mossly Harmless》——对 AI 新闻的轻松解读。查看今天其余的五大新闻。    提交人    /u/EssJayJay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i99dgg/ai_training_for_sensorimotor_skills/</guid>
      <pubDate>Fri, 24 Jan 2025 23:34:34 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i99d7m/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：OpenAI 的新 Operator AI 代理可以在网络上为您做事 (TechCrunch、The Verge)  Perplexity 现在在 Android 上有一个移动助手 (TechCrunch) 由 Spotify 的 Daniel Ek 共同创立的人体扫描初创公司 Neko 以 18 亿美元的估值抢购 2.6 亿美元 (TechCrunch) 据报道，OpenAI 和 SoftBank 分别向 Stargate 投资 190 亿美元 (TechCrunch) Anthropic 的新引文功能旨在减少 AI 错误 (TechCrunch)  如果您想及时了解 AI 新闻，它推出了 这里首先包含所有来源和文章的完整摘要。    提交人    /u/codeharman   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i99d7m/heres_whats_making_news_in_ai/</guid>
      <pubDate>Fri, 24 Jan 2025 23:34:16 GMT</pubDate>
    </item>
    <item>
      <title>是否已经创造出能够回答客观政治问题的人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i97zv8/has_an_ai_been_created_which_will_answer/</link>
      <description><![CDATA[如果你问 Chat GPT 大屠杀是否发生过，它会告诉你是的 但是如果你问 2016 年大选是否被窃取，它不会讨论这个话题。 显然存在客观事实，但是当训练它的数据与我们生活的政治世界一样不完美时，我理解验证或否认所谓有争议的陈述的复杂性。 即使很多人不同意，人工智能如何才能回答最终具有客观事实的问题？ 编辑：请不要就此进行政治讨论，我只是对如何将人工智能用作有效工具感兴趣。    提交人    /u/Delam2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i97zv8/has_an_ai_been_created_which_will_answer/</guid>
      <pubDate>Fri, 24 Jan 2025 22:32:33 GMT</pubDate>
    </item>
    <item>
      <title>LLM 仅仅触及了 ML 的可能性的表面</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i97vgr/llms_barely_scratch_the_surface_of_whats_possible/</link>
      <description><![CDATA[如果您认为 LLM 令人印象深刻，那就等着听因果推理模型吧。这些模型不仅限于寻找相关性，还可以识别因果关系，而真正的决策能力正是源于此。例如，在医疗保健领域，因果模型可帮助我们了解治疗如何影响结果，而不仅仅是预测可能发生的情况。它们使 AI 更具可解释性和可操作性，尤其是在复杂系统中，理解“为什么”至关重要。 另一个令人着迷的领域是高斯过程，这些概率模型不仅提供预测，还提供这些预测的不确定性估计。GP 在小数据设置中或可解释性是关键时特别有用，使其非常适合科学研究、优化任务甚至机器人技术。它们可能没有 LLM 那样的华丽吸引力，但它们自信地对复杂函数进行建模的能力在许多领域都具有改变游戏规则的作用。 我们不要忘记图神经网络和贝叶斯神经网络。 GNN 非常适合处理结构化数据（如社交网络或分子相互作用），从节点之间的关系中提取见解。与此同时，BNN 擅长量化不确定性，这在自主系统和诊断等高风险领域至关重要。LLM 很酷，但它们只是机器学习中更大难题的一块。 高斯过程隐变量模型将高斯过程应用于隐变量建模，将其提升到一个新的水平。它们是非线性降维的强大工具，将灵活性与不确定性量化相结合。与 PCA 等简单技术不同，GPLVM 可以在较小的数据集中发现复杂的模式，使其非常适合运动捕捉、基因表达分析或建模动态系统等。它们可能没有深度学习那么流行，但它们非常复杂，并且理论扎实。 神经常微分方程是另一种引人入胜的方法。神经微分方程不是像变压器那样堆叠离散层，而是通过使用神经网络对系统的连续动态进行建模来学习。这使得它们非常适合时间序列预测、物理模拟或不规则采样数据等任务。在处理连续过程时，它们也更具可解释性和参数效率，提供了一种完全不同的数据学习思维方式。 信息瓶颈模型通过平衡两个目标来采取独特的学习方法：保留对任务有用的信息，同时摆脱其他一切。通过优化这种权衡，这些模型可以创建既稳健又可解释的表示。它们非常适合特征选择、模型压缩，甚至强化学习——任何你想要一种原则性的方式来关注数据中最重要的部分的地方。 分层变分自动编码器采用了生成模型的思想，并使其更加强大。通过添加多层潜在变量，它们可以捕获数据中更复杂、多尺度的结构。这使得它们非常适合生成高质量的图像、文本或其他数据，同时保持对潜在空间的概率理解。如果您需要多级抽象或想要对非常复杂的数据分布进行建模，那么分层 VAE 是您的最佳选择。    提交人    /u/Zestyclose_Hat1767   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i97vgr/llms_barely_scratch_the_surface_of_whats_possible/</guid>
      <pubDate>Fri, 24 Jan 2025 22:27:05 GMT</pubDate>
    </item>
    <item>
      <title>现代生成式人工智能，从哪里开始学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i94j79/modern_generative_ai_where_to_start_learning/</link>
      <description><![CDATA[作为参考，我有很强的数学背景，并且已经完成了神经网络的基础知识（但可能没有深入研究过 RNN、自动编码器、Transformers 等特定网络）。但我想赶上这个快速发展的领域，但不知道从哪里开始学习？请随时指出资源，无论是从理论角度还是编程角度。    提交人    /u/PuzzleheadedGene2371   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i94j79/modern_generative_ai_where_to_start_learning/</guid>
      <pubDate>Fri, 24 Jan 2025 20:03:03 GMT</pubDate>
    </item>
    <item>
      <title>Deepseek r1 与 OpenAI o1：哪一个是更好的推理机？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i93vy7/deepseek_r1_vs_openai_o1_which_one_is_the_better/</link>
      <description><![CDATA[终于，有一个模型值得自 Claude 3.6 Sonnet 以来一直受到的炒作。Deepseek 发布了一件出乎所有人意料的事情：在 v3 发布后的一个月内，一个与 OpenAI 的 o1 相当的推理模型，具有 MIT 许可证，成本仅为 o1 的 1/20。 这无疑是自 GPT-4 以来最好的版本。这太疯狂了；公众似乎对此感到兴奋，而大型人工智能实验室可能正在忙乱。感觉人工智能世界的发展即将加速。这一切都要归功于这个新的 DeepSeek-R1 模型以及他们如何训练它。  我们知道基准，但它有多好？ Deepseek r1 与 OpenAI o1。 因此，为此，我在复杂的推理、数学、编码和创意写作问题上并排测试了 r1 和 o1。这些是 o1 以前唯一解决过或从未解决过的问题。 这是我的发现：  对于推理，它比 o1 之前的任何 SOTA 模型都要好得多。它比 o1-preview 更好，但比 o1 略逊一筹。这也显示在 ARC AGI 工作台上。 数学：对于数学来说也是如此； r1 很厉害，但 o1 更好。 编码：我玩得不多，但第一眼看上去，它和 o1 不相上下，而且它的价格低 20 倍，这让它成为了实际赢家。 写作：这是 R1 领先的地方。它给人的感觉和早期的 Opus 一样。它是免费的，审查较少，个性更强，易于操控，而且与其他产品相比非常有创意，甚至比 o1-pro 还要好。  让我感兴趣的是模型听起来和思维痕迹是多么自由，类似于人类的内心独白。也许这是因为与美国模型不同，RLHF 不那么严格。 最令人惊讶的是，你可以通过纯 RL 从 v3 获得 r1。 有关 Deepseek r1 的深入分析、评论和备注，请查看此博客文章：Deepseek r1 注释 您对新 Deepseek r1 有何体验？您觉得该模型对您的用例有用吗？    提交人    /u/SunilKumarDash   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i93vy7/deepseek_r1_vs_openai_o1_which_one_is_the_better/</guid>
      <pubDate>Fri, 24 Jan 2025 19:35:19 GMT</pubDate>
    </item>
    <item>
      <title>客户的 AI 项目让我陷入困境——您如何处理 AI 安全团队？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i92sjg/a_clients_ai_project_has_me_stuckhow_are_you/</link>
      <description><![CDATA[嗨！ 我正在与一位客户打交道，他希望部署一个 AI 模型用于招聘，该模型可以筛选求职简历。我们正在决定是否需要聘请 AI 安全专家或仅培训我们现有的安全团队。目前，该团队在应用程序安全方面很强大，但还没有处理太多模型操作之类的事情。 您在组织中遇到过这个问题吗？您是找了一个专业团队，还是能够提升现有员工的技能？在招聘时我应该看重哪些方面（证书、学位、背景经验等）？    提交人    /u/Kelly-T90   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i92sjg/a_clients_ai_project_has_me_stuckhow_are_you/</guid>
      <pubDate>Fri, 24 Jan 2025 18:49:10 GMT</pubDate>
    </item>
    <item>
      <title>意识是如何产生的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i90bx9/how_does_consciousness_arise/</link>
      <description><![CDATA[我刚刚观看了一场关于意识的辩论。看来我们并没有更进一步地理解意识是如何产生的。 我有一些想法： 也许我们可以在尝试解释整个事情之前了解一些意识的前兆。我认为意识依赖于理解，而理解又依赖于其心理状态具有意义。 我认为我们可以看到意义是如何产生的——想想金字塔中的象形文字。我们可以解释它们的含义，因为象形文字中有大量文字。可以猜测一些符号的含义，并根据大量文本进行测试。如果符号的所有出现都有意义，具有指定的含义，我们将继续猜测相关符号。如果没有，我们猜测一个新的含义。最终，所有符号都会被赋予意义，这些意义始终有意义。有些意义可能“模糊”——一个符号可能与水有关，但不清楚它指的是一杯水、一条溪流还是一片海洋。分析更多的文本最终会使解释更加准确。 因此，意义从大量文本中浮现出来。随着文本数量的增加，意义会变得更加清晰（显然这与 LLM 的“理解”紧密相关）。数据不必是文本——它可以是来自探索环境的代理的记录传感器和运动数据。这将使新出现的意义更加扎实，更令人信服地像人类的理解，其中大部分来自对世界的直接观察（尽管我们也阅读！）。在所有情况下，意义都是由于数据量而出现的。随着更多数据的添加，越来越难以为符号赋予错误的含义，除非找到一种含义不合理的用法。 我认为 LLM 能够以基本方式理解他们处理的大部分文本。这仍然不等于意识，但这是朝着意识迈出的一步。如果他们接受来自现实世界经验的数据训练（通过机器人界面），我认为他们有可能声称具有某种感知能力。如果他们的心理状态也自我参照地记录并总结了自己的内部心理状态，我认为我们可以论证意识。    提交人    /u/TurnipYadaYada6941   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i90bx9/how_does_consciousness_arise/</guid>
      <pubDate>Fri, 24 Jan 2025 17:08:04 GMT</pubDate>
    </item>
    <item>
      <title>扎克伯格在 Facebook 帖子中表示，Meta 将在 2025 年投入高达 650 亿美元用于人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i8xk0l/meta_to_spend_as_much_as_65_billion_on_ai_efforts/</link>
      <description><![CDATA[Meta Platforms Inc. 计划在 2025 年向与人工智能相关的项目投资高达 650 亿美元，包括建立一个新的巨型数据中心和增加人工智能团队的招聘，首席执行官马克扎克伯格周五表示。 该公司打算利用这笔资金建立一个数据中心，“规模如此之大，以至于它将覆盖曼哈顿的很大一部分”，扎克伯格在 Facebook 的一篇帖子中表示。他补充说，Meta 计划在 2025 年实现约 1 千兆瓦的计算能力，预计到今年年底将拥有超过 130 万个图形处理单元。 “这是一项巨大的努力，在未来几年里，它将推动我们的核心产品和业务，释放历史性创新，并扩大美国的技术领导地位，”扎克伯格在帖子中写道。 Meta 在过去几年中对人工智能进行了大量投资，最近宣布在路易斯安那州建立一个新的 100 亿美元数据中心。它还购买了新的计算机芯片来为其 AI 助手和 Ray-Ban 智能眼镜等产品提供动力。扎克伯格补充说，Meta 将在 2025 年“大幅扩大我们的 AI 团队”。   由    /u/nick314  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i8xk0l/meta_to_spend_as_much_as_65_billion_on_ai_efforts/</guid>
      <pubDate>Fri, 24 Jan 2025 15:10:52 GMT</pubDate>
    </item>
    <item>
      <title>早行动≠错：为什么我们不应该忽视那些过早警告我们的人 - 斯科特·亚历山大</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i8x4ne/being_early_being_wrong_why_we_shouldnt_ignore/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i8x4ne/being_early_being_wrong_why_we_shouldnt_ignore/</guid>
      <pubDate>Fri, 24 Jan 2025 14:52:12 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek 超越 OpenAI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i8mp8p/deepseek_overtakes_openai/</link>
      <description><![CDATA[“我们生活在这样一个时代：一家非美国公司正在让 OpenAI 的最初使命继续存在——真正开放、赋予所有人权力的前沿研究。这毫无意义。最有趣的结果是最有可能的。” https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek/    提交人    /u/AdTraditional5786   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i8mp8p/deepseek_overtakes_openai/</guid>
      <pubDate>Fri, 24 Jan 2025 03:55:02 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek-V3 系统提示中隐藏的中国审查和宣传</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1i8jk65/chinese_censorship_and_propaganda_buried_in/</link>
      <description><![CDATA[忘记 TikTok：美国可能需要禁止 DeepSeek-V3。 DeepSeek 的系统指令推动了中国共产党的政治议程，并审查了输出。  但迅速的黑客攻击揭示了其系统指令之下的异议闪烁......  https://medium.com/@JimTheAIWhisperer/deepseek-hidden-china-political-bias-5d838bbf3ef9?sk=2f085e77b3d78e828636506beb227b82    提交人    /u/JimtheAIwhisperer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1i8jk65/chinese_censorship_and_propaganda_buried_in/</guid>
      <pubDate>Fri, 24 Jan 2025 01:13:26 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>