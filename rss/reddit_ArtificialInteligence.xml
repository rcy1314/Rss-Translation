<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 24 Oct 2025 18:32:08 GMT</lastBuildDate>
    <item>
      <title>加州成为第一个监管人工智能聊天机器人的州</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1of5062/california_becomes_first_state_to_regulate_ai/</link>
      <description><![CDATA[加利福尼亚州：人工智能必须保护儿童。另外加利福尼亚州：否决限制儿童接触人工智能的法案。 让它有意义：此处文章   由   提交 /u/AIMadeMeDoIt__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1of5062/california_becomes_first_state_to_regulate_ai/</guid>
      <pubDate>Fri, 24 Oct 2025 18:09:22 GMT</pubDate>
    </item>
    <item>
      <title>同类最大规模的研究表明，无论语言或地域如何，人工智能助手在 45% 的情况下都会歪曲新闻内容</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1of4j1l/largest_study_of_its_kind_shows_ai_assistants/</link>
      <description><![CDATA[https://www.bbc.co.uk/mediacentre/2025/new-ebu-research-ai-assistants-news-content 主要发现：   45% 的人工智能答案至少存在一个重大问题。 31% 的答案显示出严重的来源问题 - 缺失、误导或不正确的归因。 20% 包含重大准确性问题，包括幻觉细节和过时的信息。 Gemini 在以下方面表现最差：存在重大问题 76% 的回复是其他助手的两倍多，这主要是由于其采购绩效不佳。 BBC 今年早些时候的结果与本研究的比较显示出一些改进，但错误率仍然很高。  PDF 格式的完整研究报告可在 BBC 文章中找到。它非常长，但执行摘要和建议位于前两页，很容易理解。    由   提交 /u/Howdyini   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1of4j1l/largest_study_of_its_kind_shows_ai_assistants/</guid>
      <pubDate>Fri, 24 Oct 2025 17:51:19 GMT</pubDate>
    </item>
    <item>
      <title>科技的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1of2kny/future_of_tech/</link>
      <description><![CDATA[科技的未来注定会失败吗？几年前，人工智能聊天机器人是自由职业者可以作为服务或 SAAS 出售的最好产品。但现在已经是老事了。我再也想不出任何 SAAS 的想法了。你们有什么想法？    由   提交/u/_akshat_jha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1of2kny/future_of_tech/</guid>
      <pubDate>Fri, 24 Oct 2025 16:36:28 GMT</pubDate>
    </item>
    <item>
      <title>对人工智能的普遍痛苦</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1of20gw/general_anguish_about_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1of20gw/general_anguish_about_ai/</guid>
      <pubDate>Fri, 24 Oct 2025 16:14:51 GMT</pubDate>
    </item>
    <item>
      <title>具有不同兴趣的人工智能代理能否学会防止文明失败？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1of1lq0/can_ai_agents_with_divergent_interests_learn_to/</link>
      <description><![CDATA[当系统陷入明显改进但无法实施的状态时，就会发生文明失败。 这本书的章节不充分的平衡对文明的原因进行了分类 故障分为三个部分：  协调故障。例如，我们无法神奇地协调每个人实现碳中和。 决策者不是受益者，或者缺乏利益共享。 信息不对称。当决策者无法从掌握信息的人那里可靠地获得做出决策所需的必要信息时。  但是，上述所有问题都源于同一个原因：人们的基因并不完全相同。 克隆蚂蚁确实拥有相同的基因，因此在协调、共担风险或将相关信息传递给决策者方面没有任何问题。我们体内 30 万亿个细胞也是如此，它们通过大规模协作来帮助我们生存和复制。 进化使得我们的最终目标是保护和复制我们的基因。细胞 100% 共享其基因，它们的目标是一致的，因此合作毫不费力。人类彼此共享的基因较少，因此我们必须通过发展复杂的社会行为和技术来克服信任问题：地位层次结构、沟通、法律和合同。 我正在进行多智能体强化学习 (MARL) 研究，其中具有不同基因的智能体试图最大化其最终目标。在这个沙盒环境中，会发生文明失败。有趣的是，我们可以对环境和智能体本身进行改变，以了解防止某些文明失败所需的最小改变是什么。 可以在这种设置中探索的一些问题示例（我称之为亲属关系对齐的 MARL）：  在一个智能体消耗相同资源来生存和繁殖的世界中。如果可以通过污染每个人的空气来获得更多资源，智能体是否可以学会协调并阻止全球中毒？ 当智能体开始沟通时可以解决哪些问题？如果所有通信都是公开的，会出现什么问题？如果他们能够访问私人加密通信怎么办？  你能想到更有趣的问题吗？我很想听到他们的声音！ 现在，我已经开发了一个环境，在这个环境中，具有不同利益的特工要么学会合作，要么眼睁睁地看着自己的血统灭绝。这个环境是用 C 语言实现的，这使我能够在其中有效地训练人工智能代理。我还为此 MARL 设置开发了特定的奖励函数和训练算法。 您可以在此处阅读有关环境的更多详细信息，以及有关奖励函数/算法的详细信息此处。   由   提交/u/jpiabrantes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1of1lq0/can_ai_agents_with_divergent_interests_learn_to/</guid>
      <pubDate>Fri, 24 Oct 2025 15:59:23 GMT</pubDate>
    </item>
    <item>
      <title>在没有大量受众的情况下如何建立被动收入？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oexb5c/how_do_you_build_passive_income_without_a_big/</link>
      <description><![CDATA[每个“赚钱”教程都说首先要增加粉丝，但我宁愿构建一些仍然可以赚钱的小东西。这里有人找到了无需成为影响者即可在线赚钱的方法吗？   由   提交/u/defrito20   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oexb5c/how_do_you_build_passive_income_without_a_big/</guid>
      <pubDate>Fri, 24 Oct 2025 13:09:06 GMT</pubDate>
    </item>
    <item>
      <title>AI能让哑人变聪明吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oeuof1/can_ai_turn_a_dumb_person_smart/</link>
      <description><![CDATA[就像阿里在教学方面的表现一样。我是个很笨的人，我想知道我是否可以通过人工智能变得更聪明。割草人风格（我知道他在那部电影中使用了虚拟现实，但仍然请回答问题）   由   提交 /u/fatpermaloser   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oeuof1/can_ai_turn_a_dumb_person_smart/</guid>
      <pubDate>Fri, 24 Oct 2025 11:00:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Reddit 上发现 AI 帐户/帖子？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oetau2/how_do_you_spot_ai_accountsposts_on_reddit/</link>
      <description><![CDATA[嗨，死亡的互联网理论不断在我的脑海中盘旋，我注意到 Reddit 上有很多看起来可疑的文本，这些文本可能是人工智能生成的。所以我想知道如何识别由 AI 运行的帐户或发布 AI 生成的文本？ 1 个指向 AI 文本的好提示似乎是产生大量参与的帖子，但原始发布者从未与任何评论互动。这是一个有效的线索吗？我觉得人工智能可以轻松地与评论员互动。 另一件事让我感到兴奋的是通用文本。我的意思是，当帖子或帐户的回复仅使用格式良好的英语并使用正确的标点符号时。 我很想听听这里的人们如何尝试识别人工智能帖子和人工智能运行的虚假帐户，以及人工智能运行帐户在 Reddit 上的现象有多大（也许有人有见解）。   由   提交/u/K4rl0770   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oetau2/how_do_you_spot_ai_accountsposts_on_reddit/</guid>
      <pubDate>Fri, 24 Oct 2025 09:37:21 GMT</pubDate>
    </item>
    <item>
      <title>《Attention Is All You Need》论文的合著者对 Transformer 感到“彻底厌倦”，这项技术为每个主要的人工智能模型提供动力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oerf8t/coauthor_of_attention_is_all_you_need_paper_is/</link>
      <description><![CDATA[https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers  Llion Jones 是 2017 年开创性论文《Attention Is All You Need》的合著者。甚至创造了“变压器”这个名字周二在旧金山举行的 TED 人工智能会议上发表了异常坦率的评估：尽管前所未有的投资和人才涌入人工智能领域，但该领域已经围绕单一架构方法僵化，这可能会让研究人员对下一个重大突破视而不见。 “尽管事实上从未有过如此多的兴趣、资源、资金和人才，但这在某种程度上导致了我们正在进行的研究范围的缩小，”琼斯告诉观众。他认为，罪魁祸首是“巨大的压力”。投资者要求回报，研究人员争先恐后地在拥挤的领域中脱颖而出。    由   提交/u/vaibeslop  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oerf8t/coauthor_of_attention_is_all_you_need_paper_is/</guid>
      <pubDate>Fri, 24 Oct 2025 07:32:15 GMT</pubDate>
    </item>
    <item>
      <title>如果你在酒吧遇见黄仁勋，你会对他说什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oer9cy/if_you_ran_into_jensen_huang_at_a_bar_what_would/</link>
      <description><![CDATA[假设这只是一些普通类型的潜水酒吧，他独自一人，并且愿意与你交谈多久。    由   提交 /u/always-be-knolling   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oer9cy/if_you_ran_into_jensen_huang_at_a_bar_what_would/</guid>
      <pubDate>Fri, 24 Oct 2025 07:21:23 GMT</pubDate>
    </item>
    <item>
      <title>我意识到心灵捕手是25年前社会与超智能AI互动的一个隐喻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oecie7/i_realized_that_good_will_hunting_is_a_25year/</link>
      <description><![CDATA[这个想法是我在堵车时想到的……《心灵捕手》不仅仅是一个关于来自波士顿的陷入困境的天才的故事。相反，在 ChatGPT 发布前四分之一个世纪，青少年马特·达蒙 (Matt Damon) 和本·阿弗莱克 (Ben Affleck) 写了一个比喻，描述人类与超级智能人工智能的斗争。听我说…… 威尔·亨廷是一位自学成才的神童，他的智力远远超过他周围的每个人。他解决了不可能的数学问题，回忆起他读过的每一本书，并且可以在几秒钟内驳倒任何人的论点。他周围的人以截然不同的方式对他的天才做出反应。 这基本上是现代人工智能的困境：一种超越我们的智能出现，我们争先恐后地想办法控制它、使用它，或使其与我们的价值观保持一致。 在电影中，不同的角色代表不同的社会制度及其对人工智能的态度：  Lambeau 教授 （学术界/科技行业）：将威尔视为一种资源 - 一个人的天才可以提升人类（也许还可以提升他自己的地位）。 国家安全局招聘人员（政府/军队）：将他视为武器。 法院（官僚机构）：将他视为需要遏制的风险。 著名酒吧界的学者（知识经济雇员）将他视为威胁 - 他 “在该死的教育上花了一百五十英镑”并且不可能指望与威尔的精确记忆、知识和回忆的巨大广度相竞争。 肖恩（罗宾·威廉姆斯，治疗师）：是唯一一个试图理解他的人——基于同理心的方法将人工智能与人类价值观结合起来。  然后是肖恩著名的公园独白，强调了知识和智慧之间的巨大差异： 你 只是[一个法学硕士]，你根本不知道自己在说什么……所以如果我问你关于艺术的问题，你可能会给我关于曾经写过的每一本艺术书的简短信息。米开朗基罗，你对他了解很多。一生的工作、政治抱负、他和教皇、性取向，所有的事情，对吧？但我敢打赌你无法告诉我西斯廷教堂里的味道是什么。你从来没有真正站在那里抬头仰望那美丽的天花板；看到... 体验式理解——同理心、人际关系、情商——无法被编程。我们告诉自己，这就是我们与机器的区别。 然而，虽然威尔一开始是不信任和警惕的，但他的情绪却在发展。最终，威尔选择了联系、同理心和人类经验，而不是纯粹的智力、控制或被控制。因此，一方面，他不会被自私的社会机构所利用。但另一方面，他变成了超人，将人性留在了后视镜中。 那么......你现在喜欢这些苹果吗？   由   提交/u/Acrobatic_End_3109   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oecie7/i_realized_that_good_will_hunting_is_a_25year/</guid>
      <pubDate>Thu, 23 Oct 2025 19:22:09 GMT</pubDate>
    </item>
    <item>
      <title>AI 工作者每周工作 100 小时以赢得新技术军备竞赛</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oe96hm/ai_workers_are_putting_in_100hour_workweeks_to/</link>
      <description><![CDATA[ https://www.wsj.com/tech/ai/ai-race-tech-workers-schedule-1ea9a116?st=cFfZ91&amp;mod=wsjreddit  在硅谷最大的人工智能实验室内，顶尖研究人员和高管每周定期工作 80 到 100 小时。几位顶尖研究人员将这种情况与战争进行了比较。 “我们基本上试图在两年内加速 20 年的科学进步，”Anthropic 的研究科学家 Batson 说。他说，人工智能系统“每隔几个月”就会出现非凡的进步。 “这是目前世界上最有趣的科学问题。” 微软、Anthropic、谷歌、Meta、苹果和 OpenAI 的高管和研究人员表示，他们认为自己的工作对于历史上的一个开创性时刻至关重要，因为他们正在与竞争对手决斗，并寻求将人工智能带给大众的新方法。 他们中的一些人现在已经是百万富翁了很多倍，但也有一些人表示，他们还没有时间花掉自己的新财富。     由   提交/u/wsj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oe96hm/ai_workers_are_putting_in_100hour_workweeks_to/</guid>
      <pubDate>Thu, 23 Oct 2025 17:16:10 GMT</pubDate>
    </item>
    <item>
      <title>我是唯一一个相信 AGI 在 21 世纪也是不可能的人吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oe7irh/am_i_the_only_one_who_believes_that_even_agi_is/</link>
      <description><![CDATA[当人们谈论人工智能时，每个人似乎都认为通用人工智能是不可避免的。争论的焦点不是它是否会发生，而是何时发生——甚至有些人已经在谈论 ASI。我是不是太保守了？   由   提交 /u/Gloomy-Status-9258   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oe7irh/am_i_the_only_one_who_believes_that_even_agi_is/</guid>
      <pubDate>Thu, 23 Oct 2025 16:13:17 GMT</pubDate>
    </item>
    <item>
      <title>我曾经是人工智能的忠实信徒。现在我认为整个事情正在从内部腐烂。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1odgfys/i_was_once_an_ai_true_believer_now_i_think_the/</link>
      <description><![CDATA[我曾经全力投入大型语言模型。构建自动化、客户端工具、业务工作流程......地狱，围绕 GPT 和类似系统的整个流程。我以为我们正在看到一个新时代的曙光。我错了。 没有什么是可靠的。如果您的工作流程需要真正的准确性、一致性或可重复性，那么这些模型就是一种负担。问同一个问题两次，得到两个不同的答案。小的更新悄然打破了整个逻辑链。这就像在流沙上建造一样。 那句老话，“这是有史以来最糟糕的情况”是胡说八道。运行完美的 GPT-4.1 工作流程现在在 GPT-5 上毫无用处。事情倒退，行为转变，情境窗口产生幻觉。你无法对实际上不了解自己在做什么的智能进行版本锁定。 用于“护栏”、“安全层”和“合规性”的时间和金钱比仅仅花钱雇人来正确完成工作而相形见绌。更糟糕的是，这些保障措施很少发挥作用。你最终会调试一个不承认错误的人工智能，而它又被另一个无法解释原因的人工智能所包围。 然后就是炒作机器。每家公司都在不遗余力地将“人工智能驱动”附加到不需要它的产品上。 Copilot、ChatGPT、Gemini——它们充其量都是平庸的，大型科技公司已经开始意识到这一点。真正的生产率提高是微乎其微的。商界之所以不愿表态，完全是因为承认这一点很尴尬。首席执行官们实际上正在争先恐后地重新招聘，或者付钱给像我这样的人来解决一些真正可怕的情况。 （我太忙于修复自己身上的所有问题，甚至没有时间为其他人做这件事。但是电话和电子邮件堆积如山。与我交谈过的其他顾问也说了同样的话。Copilot 很容易成为最需要修复的人）。 在美国，随机、不可靠、损坏的系统的审计要求为零。我的意思是零责任。大公司有意或无意地伤害人们的合理推诿数量是巨大的。这些系统现在影响着招聘、薪酬、医疗保健、信用和法律结果，但没有可审计性、透明度或监管。我每天都使用这些工具，并且从跳跃开始。我相信，我们至少处于基本停滞的性能干旱之中，最坏的情况是，见证绝对底线开始崩溃。    由   提交 /u/shallow-pedantic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1odgfys/i_was_once_an_ai_true_believer_now_i_think_the/</guid>
      <pubDate>Wed, 22 Oct 2025 18:31:38 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>