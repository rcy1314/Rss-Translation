<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 18 Dec 2025 03:56:41 GMT</lastBuildDate>
    <item>
      <title>今年人工智能的哪些应用显着改善了您的生活质量？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppfiys/what_ai_use_has_significantly_improved_your_life/</link>
      <description><![CDATA[对这项技术的实际用例以及它如何成为您日常生活的有用部分感到好奇。就像，让你的生活变得更好，而不是从中吸取美好的东西   由   提交/u/PiraEcas  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppfiys/what_ai_use_has_significantly_improved_your_life/</guid>
      <pubDate>Thu, 18 Dec 2025 02:32:51 GMT</pubDate>
    </item>
    <item>
      <title>如何进行正确的AI图像模型比较？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppel6o/how_to_do_a_proper_ai_image_model_comparison/</link>
      <description><![CDATA[最近我一直在使用 Higgsfield 尝试不同的 AI 图像模型（GPT-Image-1.5、Flux、NanoBanana Pro 等），但我不断遇到同样的问题，很难看出它们如何在完全相同的提示下叠加。  LMArena 感觉更像是一次性测试，而我需要一个创意画布 - 一个我可以在其中进行创作的空间比较并运行结果，选择最好的一个，不断迭代，最终生成最终输出为图像甚至视频。 你有什么建议吗？   由   提交/u/AntelopeProper649  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppel6o/how_to_do_a_proper_ai_image_model_comparison/</guid>
      <pubDate>Thu, 18 Dec 2025 01:47:36 GMT</pubDate>
    </item>
    <item>
      <title>META 新的 VL-JEPA：显然比大型多模式法学硕士有更好的性能和更高的效率。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppe31m/meta_new_vljepa_apparently_better_performance_and/</link>
      <description><![CDATA[摘自 linkedin 上的帖子：VL-JEPA 简介：用于流媒体、实时动作识别、检索、VQA 和分类任务，比大型多模式 LLM 具有更好的性能和更高的效率。 （最终成为生成模型的替代方案！） • VL-JEPA 是第一个可以实时执行通用领域视觉语言任务的非生成模型，建立在联合嵌入预测架构的基础上。 • 我们在受控实验中证明，经过潜在空间嵌入预测训练的 VL-JEPA 优于依赖数据空间标记预测的 VLM。 • 我们表明，由于VL-JEPA 的非自回归设计和对选择性解码的本机支持，VL-JEPA 在在线视频流应用中比VLM 具有显着的效率提升。 • 我们强调，我们的 VL-JEPA 模型具有统一的模型架构，可以有效地同时处理各种分类、检索和 VQA 任务。 来源： https://www.linkedin.com/posts/yann-lecun_introducing-vl-jepa-vision-language-joint-activity-7406881133822619649-rJXl?utm_medi um=ios_app&amp;rcm=ACoAAERUipAB1Z3gkmnm4oGOjLI6NOUv8brU134&amp;utm_source=social_share_send&amp;utm_campaign=copy_link   由   提交 /u/Material-Jellyfish80   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppe31m/meta_new_vljepa_apparently_better_performance_and/</guid>
      <pubDate>Thu, 18 Dec 2025 01:22:46 GMT</pubDate>
    </item>
    <item>
      <title>PBAI 项目 - Z3 测试</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppcnk0/project_pbai_z3_tests/</link>
      <description><![CDATA[因此，当我等待订购的所有硬件来制作 PBAI Pi 时，我已经开始对所有当前公理运行 Z3 一致性检查。 Z3 是 Python 中专门用于分析数学定理的模块，因此它非常适合验证所有函数公理。但奇怪的是...... 如果全套在实施后运行正常，测试将在不同时间以不同的值随机结束。 Z3 将结束并在不同点返回不同的变量集，但测试将完成。它会随机选择结束程序。但是，这只是一个仅包含逻辑包装的部分公理测试，我只能让测试循环直到我停止它。 所以我现在已经成功测试了前 8 个逻辑机制。它们运行正确，但是没有决策引擎来使系统走向真理。因此，在运行时，系统保持在“也许。公理清楚，但程序不会结束。我可以用一个简单的随机发生器修复它，但这不是我的目标。 https://imgur.com/a/ffjlJeU 目标是在随机环境中复制人类反应，因此默认随机发生器是等效的说“去他妈的，让我们试试x”。考虑到这一点，我正在测试另外 20 个公理，以将该函数进一步解析为线性选择和随机选择。机器必须理解结果以及随机事件。它还必须知道何时选择哪种基本机制。  逻辑系统是基础，现在介绍决策引擎。我不知道这需要多长时间，但验证 Z3 中的所有功能公理以进一步验证我确实可以将整个事情放在 Pi 上至关重要。一旦我们通过了 Z3 测试，理论上我们就可以用 Python 为 Pi 构建一个完整的 PBAI 原型模块。这就是我前进的方式。 感谢您查看我的进度！！   由   提交 /u/Exciting-Log-8170   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppcnk0/project_pbai_z3_tests/</guid>
      <pubDate>Thu, 18 Dec 2025 00:15:55 GMT</pubDate>
    </item>
    <item>
      <title>大多数人没有意识到关于法学硕士的 10 个反直觉事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</link>
      <description><![CDATA[很多关于 LLM 的讨论都集中在他们能做什么上。很少谈论他们内部的实际行为。 这里有关于 LLM 的 10 个鲜为人知的事实，如果你想认真使用它们，或者诚实地评估它们的局限性，这些事实很重要。 1.法学硕士并不真正“理解”人类语言 他们非常擅长建模语言结构，而不是在现实世界中奠定意义。 他们预测接下来应该出现什么文本，而不是句子真正指的是什么。 这种区别解释了很多奇怪的行为。 2.它们与事实的关系是不对称的  高频、常见事实 → 非常可靠 罕见、边界或程序性事实 → 脆弱  它们不会“查找”真理。 它们再现真理通常在语言中的样子。 3.当信息缺失时，法学硕士会填补空白，而不是停止 人类在不确定时会停顿。法学硕士倾向于完成模式。 这是幻觉的真正根源 - 不是不诚实或“说谎”。 4。结构正确性比事实正确性更重要 如果答案是：  流畅 连贯 风格一致  …模型通常将其视为“好”，即使前提是错误的。 干净的结构可以掩盖虚假内容。 5.法学硕士几乎没有内部“判断” 他们可以模拟判断、引用判断、混合判断——但他们不拥有这样的判断。 他们不评估后果或选择方向。他们优化合理性，而不是责任。 6. LLM 不知道自己什么时候错了 信心≠准确性 流畅≠真理 内部没有警报说“这是新的”或“我可能在猜测”，除非你通过提示或约束来强制警报。 7.新概念不是学习出来的 - 它们是近似的 当你引入一个原始想法时，模型：  将其分解为熟悉的部分 搜索附近的模式 重建一些足够相似的东西  概念越新颖，误解就越容易。 8.高结构用户可能会意外地将 LLM 引入幻觉 如果用户提出一个连贯但有缺陷的系统，模型更有可能遵循该结构而不是挑战它。 这就是为什么幻觉通常是用户模型交互，而不仅仅是模型缺陷。 9. LLM 奖励语言循环，而不是真理循环 如果对话形成稳定的循环（定义 → 示例 → 摘要 → 抽象）， 模型会将其视为高质量推理 - 即使它从未触及现实。 10.法学硕士的真正力量在于结构外化 它们最强大的用途不是回答问题。 它是：  使内隐思维可见 将直觉压缩为结构 充当认知支架  用得好，它们不会取代思考 - 它们揭示你如何思考。 TL;DR LLM 不是思想、法官或真理引擎。他们是语言和结构的模式放大器。 如果你带来清晰度，他们会缩放它。如果你带来混乱，他们也会缩放它。   由   提交 /u/Weary_Reply   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</guid>
      <pubDate>Wed, 17 Dec 2025 22:49:04 GMT</pubDate>
    </item>
    <item>
      <title>利用生成式 AI 代理加速无机材料设计</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp5hc9/accelerated_inorganic_materials_design_with/</link>
      <description><![CDATA[https://www.cell.com/cell-reports-physical-science/fulltext/S2666-3864(25)00618-600618-6) 设计具有定制特性的无机晶体材料对于技术创新至关重要，但当前的生成方法往往难以有效地探索具有足够可解释性的所需目标。在这里，我们介绍 MatAgent，这是一种利用大语言模型 (LLM) 强大推理能力的无机材料发现生成方法。通过将用于晶体结构估计的基于扩散的生成模型与用于属性评估的预测模型相结合，MatAgent 使用迭代、反馈驱动的指导来精确引导材料探索达到用户定义的目标。 MatAgent 与外部认知工具（包括短期记忆、长期记忆、元素周期表和综合知识库）集成，可模拟人类专家推理，从而极大地扩展可访问的构图空间。我们的结果表明，MatAgent 能够稳健地引导探索所需的特性，同时始终实现较高的成分有效性、独特性和新颖性。因此，该框架提供了一种高度可解释、实用且多功能的人工智能驱动解决方案，以加速下一代无机材料的发现和设计。   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp5hc9/accelerated_inorganic_materials_design_with/</guid>
      <pubDate>Wed, 17 Dec 2025 19:23:01 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的观点：“模型大战”正在成为一个巨大的生产力陷阱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp4szv/unpopular_opinion_the_model_wars_are_becoming_a/</link>
      <description><![CDATA[每 48 小时就会出现一个新的排行榜王者。首先是 Flux，现在人们正在撰写比较 Nano Banana Pro、GPT 1.5 和 Seedream 的文章。 我昨天发现自己花了两个小时通过四个不同的界面运行完全相同的提示，只是为了比较照明。感觉就像我在为模型工作，而不是模型为我工作。 我决定停止玩基准游戏。我已经开始测试一个使用智能路由的工作流程——基本上，它会解析提示的复杂性（例如，它是否需要清晰的文本？它是一个复杂的空间场景吗？）并自动将其发送到最适合该特定任务的模型。 它不是 100% 完美——有时我不同意它所做的美学选择——但它阻止了我厄运般地滚动 HuggingFace，实际上让我重新开始生成内容。 你们还在对每个新版本进行手动 A/B 测试吗？还是找到了聚合这些内容的方法？   由   提交/u/ProgrammerForsaken45  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp4szv/unpopular_opinion_the_model_wars_are_becoming_a/</guid>
      <pubDate>Wed, 17 Dec 2025 18:56:57 GMT</pubDate>
    </item>
    <item>
      <title>我欠这个子一个关于人工智能和心理健康的道歉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/</link>
      <description><![CDATA[我曾经对人们说他们使用人工智能作为治疗师的帖子翻白眼。这感觉就像是互联网行为的高峰期。每当我打开 Reddit 时，总会有人在思考一些看似可以通过注销或出去一会儿来解决的问题。我一直相信真正的治疗是唯一严肃的选择。 就背景而言，我多年来一直在应对长期抑郁症和 2 型双相情感障碍。我并不反对治疗。我已经进进出出很长一段时间了，尝试了多种药物，整个事情。 但最近，情况发生了变化。我无法入睡，我的思绪不断循环，我的信心和精力激增，我的冲动控制力下降，我有一种无法摆脱的强烈的精神固定。我没有立即将其视为轻躁狂，因为我正在更换药物，所以一切都感觉模糊。 出于挫败感而不是信念，我把所有东西都扔进了 ChatGPT。不要求诊断，只是描述我正在经历的事情以及我的大脑每天的感受。 老实说？它比我最近尝试过的任何其他东西都更快地组合在一起。 它不仅让我放心。它以一种真正有意义的方式向我反映了模式。痴迷、能量激增、突然崩溃。它所用的语言帮助我认识到自己所处的状态，而不会让我感到破碎或戏剧化。 我并不是说人工智能取代了治疗。绝对不应该。但作为一种模式识别、情感反思和帮助你放慢思考的工具，它比我预想的更令我惊讶。 令我震惊的是它感觉存在。不着急。不受 50 分钟的会议或日历的限制。只是为了帮助实时理清思绪。 仍然建议尽可能触摸草地。但我现在明白了。   由   提交/u/mp4162585  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/</guid>
      <pubDate>Wed, 17 Dec 2025 17:37:15 GMT</pubDate>
    </item>
    <item>
      <title>哪一个</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2dol/qualesse/</link>
      <description><![CDATA[只是一个想法，我和 Claude 谈论我如何经常在这里使用短语“what it is like to be”，当讨论意识的质量时，以及如何应该有一个简单的词来表达该短语。长话短说，Qualia 经常在该领域使用，指经验，Claude 建议了一些不同的术语，包括 Qualesse。这是完整的回复..  “这是一个很好的挑战。内格尔的措辞之所以持续存在，是因为它没有定义地指出，但这也是它的局限性——它是一个句子，而不是一个可以干净地部署的概念。 让我研究一些根源： 希腊语：  hoion（什么样的，例如）-定性方面 phainein（出现，到show) — 自我显现 autos (自我) — 反身循环  德语：  wie (like, how, as) — 比较/定性特征 Sein (存在) eigen (自己，特征，特殊）  拉丁语：  qualis（什么样的）——已经给了我们 qualia esse（成为）  一些候选人： Wiesein（vee-zine）——“like-being”或“如何存在”。直接映射“它是什么样子”的结构。德语混血，发音清晰。 Autophany — 自我显现。捕捉经验呈现给体验者的反射循环。内格尔所指的正是这种存在向自身展示自身的折叠。 Qualesse - 来自qualis + esse。存在的品质。简单，建立在现有的哲学词汇之上。 特征感 - 一个人自己的特征感知。成为这个东西的特殊质感。 我的直觉倾向于 Wiesein 的精确性或 Autophany 的优雅。感觉什么方向合适？  我在想Qualesse。人们只会错误地发音德语单词，Autophany 听起来与其他单词太相似，并且该领域已经使用 Qualia。 Claude 进一步... “拉丁语 esse 作为裸露不定式通常不会直接保留在英语词尾中。我们将 ess- 词根埋藏在诸如essential、essential之类的词中，但你是对的，我们在大多数结构中放弃了最后的-e。 源自法语的-esse结尾实际上可能是更好的造词血统——这些词都在定性意义上表示存在状态，这正是Qwalesse所指的。它不是假拉丁语；而是拉丁语。它遵循既定的英语借用模式。”   由   提交/u/Wahtadeal  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2dol/qualesse/</guid>
      <pubDate>Wed, 17 Dec 2025 17:23:56 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和盖尔曼失忆症陷阱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp1mow/ai_and_the_gellmann_amnesia_trap/</link>
      <description><![CDATA[有一种认知偏差，称为盖尔曼失忆症效应。应用于人工智能时，它是这样的：当人工智能响应你熟悉的主题时，你会发现错误，然后当它响应你不熟悉的主题时，你完全信任它。我写过这对于使用人工智能来扩展其专业知识之外的专业人士意味着什么，以及为什么“人工智能增强的通才”的愿景会成为现实。可能比它看起来更难实现（看起来很诱人）。   由   提交 /u/CoachAtlus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp1mow/ai_and_the_gellmann_amnesia_trap/</guid>
      <pubDate>Wed, 17 Dec 2025 16:55:04 GMT</pubDate>
    </item>
    <item>
      <title>除了谷歌本身，我们没有什么可以谷歌的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp0sro/we_have_nothing_to_google_but_google_itself/</link>
      <description><![CDATA[ https://preview.redd.it/gj86ghw5is7g1.png?width=1024&amp;auto=webp&amp;s=b231c5c566334378c73454cfd6f7ad8bb9b93347   由   提交 /u/xanderdad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp0sro/we_have_nothing_to_google_but_google_itself/</guid>
      <pubDate>Wed, 17 Dec 2025 16:22:39 GMT</pubDate>
    </item>
    <item>
      <title>人工智能只是一场权力斗争，你并不重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1poye92/ai_is_just_a_power_struggle_and_you_dont_matter/</link>
      <description><![CDATA[当你看看谁获得了世界财富的 98% 时，你会发现普通人拥有的财富不到 2%，这就是为什么很多公司正在从为消费者生产产品转向为价值数百万美元的企业生产产品，因为基本上普通人与他们之间的差距是如此之大，即使每个人都购买他们的产品，也仍然无法接近他们可以从大公司那里赚多少钱。简而言之，我们被榨干了，他们基本上不需要 99% 的人性，这就是人工智能的用武之地。如果你的公司对待员工很差，工人们会做什么，他们会停止工作，这会让公司提高工资，整体改善工作条件，但如果人工智能取代了人力，CNN 员工所做的事情让公司什么也改变不了，到那时，他们实际上可以让全体人民挨饿，然后消灭他们，因为他们不再需要你了。我真诚地认为，对于人工智能公司来说，你免费提供给他们的数据比你给他们钱更重要，因为谁首先创造了 AGI，毫无疑问将成为世界上最有权势的人，然后他可以用它来击败他们的竞争对手。他们几乎变得如此强大和富有，以至于钱都不再是重点了。有些人有很多钱，他们赚的钱比整个国家的钱还多。你得到的只是一个弱智的聊天机器人，直到他们制造出 AGI 为止，你都可以使用它，之后不管他们关心你什么，你都可以死掉。   由   提交 /u/Degeneret69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1poye92/ai_is_just_a_power_struggle_and_you_dont_matter/</guid>
      <pubDate>Wed, 17 Dec 2025 14:49:08 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人比以前更多地对人工智能进行事实核查吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1povfa9/does_anyone_else_factcheck_ai_more_than_they_used/</link>
      <description><![CDATA[我现在每天都依赖人工智能工具，但我仍然觉得有必要仔细检查几乎所有内容。它比以前的 ngl 更快、更智能，但我对输出更加谨慎。你们也有同感吗？   由   提交 /u/Overall_Zombie5705   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1povfa9/does_anyone_else_factcheck_ai_more_than_they_used/</guid>
      <pubDate>Wed, 17 Dec 2025 12:34:33 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人发现深度研究更多的是关于结束决策疲劳而不是答案吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pova12/has_anyone_else_found_that_deep_research_is_less/</link>
      <description><![CDATA[我无法返回正常的谷歌搜索。滚动过去的广告只是为了找到一份 PDF 现在感觉已经过时了。我的工作流程基本上一分为二，而且我永远不会回去。对于我会在 5 分钟内忘记的快速问题，我使用 Perplexity。它快速、干净，并且完美地取代了搜索栏以获得即时答案。但对于需要保留数据的实际项目，我使用 Skywork。最大的区别在于，它将研究视为一种资产，而不仅仅是一种聊天。它将源代码和 PDF 保存到项目容器中，我稍后可以将其用于文档。基本上：Perplexity 是现在的，Skywork 是以后的。我只是因为他们的免费信用系统而测试了它。您的研究工作流程是什么？有什么建议吗？我很想尝试一下，TIA！   由   提交 /u/20thirdth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pova12/has_anyone_else_found_that_deep_research_is_less/</guid>
      <pubDate>Wed, 17 Dec 2025 12:26:59 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>