<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 10 Feb 2026 19:12:13 GMT</lastBuildDate>
    <item>
      <title>印度时报：人类人工智能安全主管突然辞职，在情感丰富的告别信中发出警报</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r17omn/india_times_anthropic_ai_safety_chief_abruptly/</link>
      <description><![CDATA[ 由   提交 /u/JollyQuiscalus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r17omn/india_times_anthropic_ai_safety_chief_abruptly/</guid>
      <pubDate>Tue, 10 Feb 2026 17:49:28 GMT</pubDate>
    </item>
    <item>
      <title>寻找 AI 工具推荐 - 这些问题是普遍的还是特定于工具的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r178wm/looking_for_ai_tool_recommendations_are_these/</link>
      <description><![CDATA[我为我的小型企业（钩针图案设计/博客）使用 Claude 和 ChatGPT（开放式 AI 中的所有版本）已有大约 2 个月了。它一开始令人惊叹，但已经完全退化到让我的工作变得更加困难而不是更容易的地步。在我不断地用头撞墙之前，我需要知道：这些问题是所有人工智能工具都普遍存在的，还是 Claude 和 ChatGPT 特有的？ 我的主要问题： 写作质量下降  开始用我的品牌声音完美地写作，现在默认使用通用的企业人工智能语言 只是回收我的确切内容回复我的短语而不是生成原始内容 我必须“敢于”在它正确写入之前多次尝试或挑战它 即使上传了详细的语音文档，它也会忽略所有内容，听起来就像一个机器人  内存/上下文被破坏  向我询问关于我们已经讨论了15次以上的事情的相同问题 即使我给出了确切的聊天标题，也无法找到过去的对话 忘记了关键细节我已经多次提到过（比如我尚未创建的特定内容） 同一对话中的自相矛盾 聊天会话之间的零一致性  工具/技术问题  搜索工具无法找到我在界面中确实可以看到的对话 告诉我单击屏幕截图中不存在的按钮 推荐“免费”需要付费升级的工具 反复将我带到软件界面中的错误位置 在提出建议之前无法验证信息  工作流程中断  当我注意力高度集中时（我患有多动症），不断建议我停止工作中的任务 不断询问“准备好在 X 上工作了吗？”或“下一步是什么？”当我告诉它停止管理我的工作流程时 用不必要的建议打断我的流程 不尊重我规定的工作模式  矛盾的建议  说一件事，然后立即自相矛盾 在一次对话中提供关于同一主题的相互矛盾的信息 无法保持逻辑一致性 弥补实际文件中没有的详细信息  拒绝模式  前几周的性能非常出色 在添加自定义指令和上传文档后性能显着下降 错误率现在超过了正确响应 无法再信任它进行业务运营  基本错误  获取星期几错误 无法读取屏幕截图中可见的日历约会 混淆不同的分析指标 猜测而不是承认自己不知道某些事情 与我争论屏幕截图中清晰可见的内容  沟通问题  Gaslights我关于屏幕截图内容 纠正时具有防御性 让我不断地重复自己 浪费时间做无用功的循环响应 不遵循直接指示  我的问题：  这些问题在人工智能工具中是否普遍存在？或者是这是克劳德特有的吗？ 您在业务任务中使用什么人工智能工具（文案、规划、研究等）？ 随着时间的推移，无论您使用什么工具，您是否都经历过类似的退化？ 您会推荐什么作为替代方案？我需要一些能够： 以特定品牌声音编写营销文案 记住上下文跨对话 始终如一地遵循说明 真正提供帮助，而不是创造更多工作   如果这意味着我可以再次真正信任它，我愿意花钱购买更好的工具。现在，我花在与人工智能战斗上的时间比我自己做工作的时间还要多。 TL;DR： Claude 和 ChatGPT 工作得很好，然后就完全崩溃了。这对于人工智能工具来说是正常现象还是我应该更换？您使用的是什么实际上始终有效？   由   提交 /u/Pug1607   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r178wm/looking_for_ai_tool_recommendations_are_these/</guid>
      <pubDate>Tue, 10 Feb 2026 17:33:45 GMT</pubDate>
    </item>
    <item>
      <title>你是否曾经告诉过人工智能一些你不会告诉人类的事情？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r16aek/have_you_ever_told_ai_something_that_you_wouldnt/</link>
      <description><![CDATA[我刚刚读到，52.13% 的人告诉人工智能一些他们不会告诉人类的事情。 （来源） 当 73% 的调查受访者担心他们的提示被公开时，这很疯狂。 由于我不需要登录，所以我在隐身状态下在 Google 的 AI 模式下问了一些问题。 您最有可能与哪个 AI 分享秘密？ 编辑：措辞   由   提交/u/kpness  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r16aek/have_you_ever_told_ai_something_that_you_wouldnt/</guid>
      <pubDate>Tue, 10 Feb 2026 16:59:28 GMT</pubDate>
    </item>
    <item>
      <title>是否存在大多数人工智能产品最终在经济上不可行的情况？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1364f/is_there_a_scenario_where_most_ai_stuff_ends_up/</link>
      <description><![CDATA[换句话说，Chatbot 邻近的东西到处都在变得更好，但操作起来不一定更便宜。所有的风险投资都慢慢减少，我们被留在了一个令人难以置信的令人印象深刻的技术领域，但在大多数用例中成本太高，实际上不值得。我不可能是唯一一个愿意每月支付 20 美元购买这些东西，但永远不会每月支付 150 美元或其他什么的人。 这是一个现实的结果，还是有理由认为随着时间的推移，一切都会变得更便宜、更高效？ 显然，人工智能有实际用途，与加密货币不同，但观看所有人工智能超级碗广告让我想起了 2022 年（我认为？）超级碗，里面充斥着所有加密狗屎，我想，嗯，也许这不会像这些公司想象的那样改变现状。 再说一次，它有真正的用途，所以我不认为它会消失，但也许会变得更加昂贵、利基的东西？   由   提交 /u/FleetBroadbill   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1364f/is_there_a_scenario_where_most_ai_stuff_ends_up/</guid>
      <pubDate>Tue, 10 Feb 2026 15:05:31 GMT</pubDate>
    </item>
    <item>
      <title>关于人工智能的讨论是否变得过于黑白分明？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r121qd/is_the_discourse_around_ai_getting_too/</link>
      <description><![CDATA[继上周 Facebook 上的 AI 漫画风潮之后，关于 AI 的危言耸听、非黑即白的讨论似乎无处不在。是的，人工智能有缺陷，但恐慌或抵制并没有多大帮助。人工智能不会去任何地方——牙膏已经从管子里出来了。我将它用作一种创造性工具，而不是作为人类的替代品。对我来说，价值来自意图，而不是来自锤子、机器或工具本身。我很好奇这里的其他人如何看待这个问题：我们如何摆脱恐慌，真正专注于最大程度地减少伤害、保护生计并负责任地使用技术，而不是假装我们可以让它消失？   由   提交/u/HulaHoop444  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r121qd/is_the_discourse_around_ai_getting_too/</guid>
      <pubDate>Tue, 10 Feb 2026 14:22:12 GMT</pubDate>
    </item>
    <item>
      <title>开源 llm (glm 4.7) 在编码基准上匹配封闭模型。通过 api 在实际项目上进行测试。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1065y/open_source_llm_glm_47_matching_closed_models_on/</link>
      <description><![CDATA[我对开放与封闭模型差距的发展很感兴趣，去年 12 月发布的 glm 4.7 的 swe-bench 验证率为 73.8%，相当于 claude sonnet 的 77% 左右，gpt-5.1 的验证率为 76% 左右。在实际编码工作中针对十四行诗进行了 3 周的测试 背景：356b 参数 moe 模型（32b 活动），开源架构，由 zhipu ai 训练。 Benchmark 声称 swe-bench 已验证 73.8%，终端 bench 2.0 41%，多语言 swe-bench 66.7% 现实世界测试：后端调试、重构、自动化脚本 与 Sonnet 竞争的地方：多文件重构准确地跟踪跨代码库的导入。调试以相似的速度确定了根本原因。 Bash 自动化实际上比十四行诗更好，语法错误更少。当第一个解决方案失败时，迭代问题解决调整方法 十四行诗的未来：架构设计解释系统模式和权衡。最近的科技十四行诗以 2025 年数据为基础进行训练，glm 截止日期为 2024 年中/后期。教学分解“为什么”有趣的是，开放模型在专门领域（编码）上达到了具有竞争力的质量，而 API 定价约为封闭模型的 1/5。人工智能辅助发展的成本障碍显着下降。 观察到的局限性：一般知识弱于前沿模型。解释质量较低，做的比教的好。训练数据新近度差距落后 6-12 个月 成本分析：sonnet api 每月大约 70 美元，我的使用量每月大约 70 美元，glm api 每月大约 15 美元，相同的使用量每月节省大约 55 美元 更广泛的问题是，我们是否看到专业化成为竞争性开放模型的途径？对特定领域数据（例如代码和数学）的培训是否可以让开放模型在利基市场中竞争？当多个专门的开放模型以具有竞争力的质量覆盖不同领域时会发生什么？ 使用 3 周：处理我之前使用 sonnet 的 60-70% 的任务。节省了大约 45 美元的 API 成本。质量差异明显，但对于实施工作来说并没有破坏性 并不是说开放模型总体上赶上了，而是在特定领域（例如编码和终端自动化差距快速缩小）   由   提交/u/Technical_Fee4829  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1065y/open_source_llm_glm_47_matching_closed_models_on/</guid>
      <pubDate>Tue, 10 Feb 2026 13:04:04 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 在 ChatGPT 中投放广告，哈佛大学研究发现人工智能让你工作更多而不是更少 + 40 个以上的人工智能故事（2026 年 2 月 10 日回顾）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0zggt/openai_puts_ads_in_chatgpt_harvard_study_finds_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0zggt/openai_puts_ads_in_chatgpt_harvard_study_finds_ai/</guid>
      <pubDate>Tue, 10 Feb 2026 12:30:55 GMT</pubDate>
    </item>
    <item>
      <title>我刚从中国回来。我们没有赢（史蒂文·拉特纳《纽约时报》客座文章）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0yon7/i_just_returned_from_china_we_are_not_winning_nyt/</link>
      <description><![CDATA[由史蒂文·拉特纳 (Steven Rattner) 撰写，他是一位特约撰稿人，曾担任奥巴马政府财政部长顾问。   由   提交/u/somegetit  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0yon7/i_just_returned_from_china_we_are_not_winning_nyt/</guid>
      <pubDate>Tue, 10 Feb 2026 11:51:38 GMT</pubDate>
    </item>
    <item>
      <title>您认识我们成功为企业提供人工智能服务的人吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0xwbc/do_you_know_anyone_that_us_successfully_offering/</link>
      <description><![CDATA[我看到了很多人工智能服务，但我们谈论的是一些订阅或小型项目，每月最高提供 250 美元的价格。 但是，您知道有哪些人成功地以每月 1K 美元以上的价格提供产品/服务/程序？例如，他们提供什么？  提前谢谢您！   由   提交 /u/ThatsFantasy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0xwbc/do_you_know_anyone_that_us_successfully_offering/</guid>
      <pubDate>Tue, 10 Feb 2026 11:07:30 GMT</pubDate>
    </item>
    <item>
      <title>阿里巴巴刚刚放弃了 Qwen-Image-2.0</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0w53t/alibaba_just_dropped_qwenimage20/</link>
      <description><![CDATA[Qwen 团队刚刚推出了 Qwen-Image-2.0，它实际上非常有趣。这是一种 7B 模型，将生成和编辑结合到一个管道中，而不是为每个模型提供单独的模型。 对我来说最突出的是：  原生 2K 分辨率 (2048×2048)，纹理看起来非常逼真，皮肤、织物、建筑等 根据提示进行文本渲染，最多 1K 标记。海报、信息图表、PPT 幻灯片、中国书法。这基本上是每个扩散模型的一个痛点，他们似乎很认真地对待它 您可以在同一模型中生成和编辑。添加文本叠加、组合图像、重新设计样式、无需管道切换 多面板漫画（4×6），具有一致的角色和对齐的对话气泡，这对于 7B 来说是疯狂的  值得注意的是，它们从 v1 中的 20B 降到了这里的 7B，因此推理应该更快。目前，API 在阿里云上仅受邀请，但如果您想了解一下，Qwen Chat 上有免费演示。 当每个人都专注于 LLM 竞赛时，中国实验室一直在悄悄推出强大的视觉模型。   由   提交/u/RIPT1D3_Z   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0w53t/alibaba_just_dropped_qwenimage20/</guid>
      <pubDate>Tue, 10 Feb 2026 09:20:19 GMT</pubDate>
    </item>
    <item>
      <title>大型科技公司仍然相信 LLM 会带来 AGI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0tfiz/big_tech_still_believe_llm_will_lead_to_agi/</link>
      <description><![CDATA[大型科技公司在 GPU 和数据中心上投入巨资，目标是培训和部署法学硕士？ 我们在法学硕士的改进方面不是已经趋于稳定了吗？所有这些新的基础设施都会做出任何改进吗？ 编辑：我很好奇人们对这份白皮书的看法https://arxiv.org/pdf/2601.23045 “人工智能在任务上的不连贯性是通过测试时的随机性来衡量的，作为其误差的一部分，该误差源于方差，而不是源于方差在我们测量的所有任务和前沿模型中，模型推理和采取行动的时间越长，它们的失败就越不连贯，而模型规模的变化与实验有关。然而，在某些情况下，规模更大、能力更强的模型比规模更小的模型更不连贯。相反，随着能力更强的人工智能追求更困难的任务，需要更多的连续行动和思考，我们的结果预测失败会伴随着更多的不连贯。这表明未来人工智能有时会导致工业事故（由于不可预测的不当行为），但不太可能表现出对不一致目标的持续追求，这增加了针对奖励黑客或目标错误指定的一致性研究的相对重要性。”   由   提交/u/bubugugu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0tfiz/big_tech_still_believe_llm_will_lead_to_agi/</guid>
      <pubDate>Tue, 10 Feb 2026 06:31:19 GMT</pubDate>
    </item>
    <item>
      <title>OpenClaw、MoltBot 或 Clawdbot，无论本周它叫什么，都是今年人工智能安全领域发生的最好的事情。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0qhq1/openclaw_or_moltbot_or_clawdbot_whatever_its/</link>
      <description><![CDATA[是的，两周内发生的安全事件比一些供应商整个历史上发生的安全事件还要多。那个。 我一直在密切关注安全社区的反应。每个主要供应商都发表了他们的看法。思科称其为一场噩梦。帕洛阿尔托表示，这标志着一场危机。趋势科技警告隐形风险。您可能会认为有人将未打补丁的 Windows XP 机器直接插入互联网。在医院里。运行呼吸机。 大家深呼吸。他们缺少一些东西。 OpenClaw 是开源的。一周内有 200 万访问者，这是 GitHub 历史上增长最快的项目之一。开发人员购买 Mac Mini 是为了在他们的闲置房间里运行它。任何人都不应该针对生产系统或公司电子邮件运行此程序，甚至该项目自己的文档也将其描述为不适合大多数非技术用户的实验。创作者对这是什么很诚实。这在这个行业中几乎是闻所未闻的。 实验正是安全性变得更好的方法。 研究人员发现，单击单个恶意链接可以在几毫秒内劫持 OpenClaw 实例，绕过该项目构建的每个沙箱和安全护栏。这是一个重要的教训：旨在包含即时注入的代理人工智能安全控制无法防止控制平面中的架构漏洞。在开源爱好项目上学习这一点比在企业供应商的代理平台上学习更好。发布到其市场的 400 个恶意技能表明，AI 技能注册中心与传统软件包存储库存在相同的供应链问题，但具有更广泛的执行权限。 云计算的早期看起来正是如此。研究人员研究了 S3 存储桶，发现一切都敞开了，整个行业都失去了理智。一路上确实造成了很多损害。但不知何故，我们幸存下来，建立了适当的控制，并继续前进。 OpenClaw 正在为特工 Al 做同样的事情。每个暴露的网关、每个提示注入链、每个恶意技能都在向安全社区传授代理威胁模型在实践中而不是在框架文档中的实际情况。真正的 CVE、真正的攻击链、针对人们可以实际检查的系统的真正缓解模式，而不是黑盒供应商产品。 每个人都担心这个有 180,000 人审查每个缺陷的开源项目。同时，企业代理平台也存在相同的架构问题。您只是看不到它们。 您的企业代理供应商有一个信任页面和 SOC 2 徽章。 OpenClaw 拥有 180,000 名研究人员，他们正在实际进行突破。您认为哪一个先发现问题？   由   提交 /u/Aislot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0qhq1/openclaw_or_moltbot_or_clawdbot_whatever_its/</guid>
      <pubDate>Tue, 10 Feb 2026 03:59:02 GMT</pubDate>
    </item>
    <item>
      <title>你会说“请”和“谢谢”吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r0pf25/do_you_say_please_and_thank_you/</link>
      <description><![CDATA[我不知道它是什么，但每次我要求 AI 做某事（很少发生）时，我总是说“请”和“谢谢”。这可能是担心人工智能将来会因为行为不端而让我陷入困境，或者我非常友善之类的事情。我发布此内容是因为我想看看有人与此相关。 （你可能不知道）   由   提交 /u/Crazgamrboi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r0pf25/do_you_say_please_and_thank_you/</guid>
      <pubDate>Tue, 10 Feb 2026 03:09:51 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>