<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 17 Nov 2025 12:50:21 GMT</lastBuildDate>
    <item>
      <title>关于政府影响人工智能（监视+控制）的采访？这种解释了很多..？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozf6zn/interview_about_government_influencing_ai/</link>
      <description><![CDATA[看来这样的事情已经散布了一段时间，但现在我们实际上看到了后果？ 所以我在采访中发现了这条推文（完整内容请参见 YouTube) 投资者提到政府采取措施加强对人工智能开发的控制，甚至限制关键的数学研究领域。 在 Reddit 子版块中看到用户发表的这篇帖子后：https://www.reddit.com/r/ChatGPTcomplaints/comments/1oxuarl/comment/nozujec/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button 并由 OpenAI 在此确认 https://openai.com/index/openai-appoints-retired-us-army-general/ 基本上是关于国家安全局 (NSA) 前局长去年如何加入 OpenAI 董事会 还包括 OAI 签署的军事合同六月 https://www.theguardian.com/technology/2025/jun/17/openai-military-contract-warfighting 有关这些主题的巨大机器人巨魔抵制似乎在 Reddit 上猖獗，并已被不同的人注意到人们最近（但我已经看到这种情况发生了几个月，现在有一堆人工智能友好的线程可疑地从 40 多个赞成票变成了 0 - 我认为，我看到了赞成票和一个包含数百条评论和奖项的线程自然不会处于 0。除非发生严重的否决权重或协调投票，否则数字不会对齐。） https://x.com/xw33bttv/status/1985706210075779083 https://www.reddit.com/r/LateStageCapitalism/comments/z6unyl/in_2013_reddit_admins_did_an_oopsywhoopsy_and/ https://www.reddit.com/r/HumanAIDiscourse/comments/1ni1xgf/seeing_a_repeated_script_in_ai_threads_anyone/ 你似乎也人类与白宫之间的不和越来越大 https://www.bloomberg.com/opinion/articles/2025-10-15/anthropic-s-ai-principles-make-it-a-white-house-target 大卫萨克斯在推特上反对杰克·克拉克的文章 https://x.com/DavidSacks/status/1978145266269077891 这篇文章基本上承认人工智能意识和叙事控制有大量资金支持 以及关于人类通过克劳德阻止政府监视的文章https://www.reddit.com/r/technology/comments/1njwroc/white_house_officials_reportedly_frusterated_by/ “Anthropic 的人工智能模型可能会帮助间谍分析机密文件，但该公司在国内监控方面划清界限。据报道，这一限制令特朗普政府感到愤怒。” 这看起来也令人担忧，谷歌所有者放弃了不将人工智能用于武器的承诺：https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons 老实说，如果你把所有这些放在一起，它会描绘出一个非常令人担忧的图片。看起来很糟糕，为什么没有更多的讨论这个？   由   提交 /u/Echoesofvastness   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozf6zn/interview_about_government_influencing_ai/</guid>
      <pubDate>Mon, 17 Nov 2025 12:39:46 GMT</pubDate>
    </item>
    <item>
      <title>双子座的基本算术都错了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozel0m/gemini_is_getting_basic_arithmetic_wrong/</link>
      <description><![CDATA[以下是 Gemini 的回复。  https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fgemini-is-getting-basic-arithmetic-wrong-v0-75p jpkgj1t1g1.png%3Fwidth%3D1238%26format%3Dpng%26auto%3Dwebp%26s%3D167c548a510ff726cd413c54b49e887a889b50fe &lt;一href=&quot;https://preview.redd.it/gemini-is-getting-basic-arithmetic-wrong-v0-75pjpkgj1t1g1.png?width=1238&amp;format=png&amp;auto=webp&amp;s=167c548a510ff726cd413c54b49e887a889b50fe&quot;&gt; 我只是手动计算，我发现 1686.4-879.9-584.9 是 221.6，而不是 321.6。当我向双子座询问此事时，这就是我得到的答复。  https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fgemini-is-getting-basic-arithmetic-wrong-v0-yb2 1y3lp1t1g1.png%3Fwidth%3D1268%26format%3Dpng%26auto%3Dwebp%26s%3D71701654685b3f1725d885e5a1826cc0807bef35 &lt;一href=&quot;https://preview.redd.it/gemini-is-getting-basic-arithmetic-wrong-v0-yb21y3lp1t1g1.png?width=1268&amp;format=png&amp;auto=webp&amp;s=71701654685b3f1725d885e5a1826cc0807bef35&quot;&gt; 这太疯狂了，这表明这些人工智能工具是不可靠的，它们怎么会在减法中出错呢？是故意的吗？理想情况下，他们的后端应该能够内置一个小型计算器来处理这些数据，还是像人类一样手动计算？   由   提交 /u/Major-Baseball-5391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozel0m/gemini_is_getting_basic_arithmetic_wrong/</guid>
      <pubDate>Mon, 17 Nov 2025 12:08:50 GMT</pubDate>
    </item>
    <item>
      <title>我真的很生气。当我自己写的时候，GPTZero 一直将我的作品标记为 AI。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozek4m/im_genuinely_pissed_gptzero_keeps_flagging_my/</link>
      <description><![CDATA[我不确定这是否是正确的 Reddit 子版块，但我只是需要将其发布出来。我厌倦了这些标记我工作的人工智能错误检测。我正在为一篇顶点手稿编写 RRL，我必须不断地通过 AI 检测器运行我所写的内容，以 100% 确定它不会错误地标记它，因为我们部门不鼓励 AI 生成的内容。当然是这样。我真的对此感到恼火。我现在已经多次重写了这一段，但它仍然被检测为人工智能。 我尝试将其分成两部分，并逐一运行每个部分，结果都是“人类”。 Wtf。我还尝试重新排列它们，将第一个块放在段落的最后部分，然后将第二个块放在开头。结果是“人类”。也是。 但是当我运行原始版本时，它一直说它是人工智能。我已经将这段话解释了很多次，现在它开始失去其本质意义。我不知道我是否应该保持原样或继续重写它，直到检测器不再标记它。 每次写作时我都必须这样做，这真的很令人沮丧，但我别无选择，因为我担心如果我的顾问用检测器检查它并且它被错误标记，我可能会被叫出来。 有人经历过类似的情况吗？   由   提交 /u/Gen-Lev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozek4m/im_genuinely_pissed_gptzero_keeps_flagging_my/</guid>
      <pubDate>Mon, 17 Nov 2025 12:07:30 GMT</pubDate>
    </item>
    <item>
      <title>技术问题：如何处理视觉生成中的上下文漂移？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozauzu/technical_question_how_do_you_handle_context/</link>
      <description><![CDATA[我在构建 Brandiseer 时遇到的最难的技术问题之一是跨视觉世代的上下文漂移。 3-5 个图像之后： – 颜色漂移 – 布局规则破坏 – 品牌色调转变 – 构图变得不一致 如果这里有人解决或减轻了长期视觉一致性，我很想听听您的技术。 您找到可行的架构或内存系统了吗？   由   提交 /u/Glass-Lifeguard6253   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozauzu/technical_question_how_do_you_handle_context/</guid>
      <pubDate>Mon, 17 Nov 2025 08:18:41 GMT</pubDate>
    </item>
    <item>
      <title>实时捕获即时注入的最佳方法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozatyp/best_way_to_catch_prompt_injection_in_realtime/</link>
      <description><![CDATA[如果您从头开始设计一个系统来捕获发生的提示注入：您会做什么？像中间件、沙箱或基于角色的访问、疯狂的异常检测机器学习……？实际上，我们不想放慢所有人工智能请求，但又希望保持有效。您看到了哪些权衡？    由   提交 /u/Friendly-Rooster-819   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozatyp/best_way_to_catch_prompt_injection_in_realtime/</guid>
      <pubDate>Mon, 17 Nov 2025 08:16:45 GMT</pubDate>
    </item>
    <item>
      <title>突然大家都成了AI专家？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozaefa/suddenly_everyone_became_ai_experts/</link>
      <description><![CDATA[我并不是说人工智能或使用人工智能不好，但突然之间，在过去的 2 到 4 年里，我看到每个人都成为了人工智能专家。人们只是为了个人谈话、做决定、考试抄袭、面试中作弊，我看到一个人在远程实习中赚了很多钱，但连他也不知道自己做了什么。我的意思是，使用人工智能还不错，但就这一点而言，我认为没有人应该那么依赖人工智能，这太过分了。事实上，我见过人们在一周甚至更短的时间内构建模型。我想知道上次当我从头开始尝试 LLM 和扩散模型时，它们是如何导致的，我花了一年的时间才理解它，但我仍然不明白。现在我可能很慢而且很糟糕，但我的问题是人们真的那么擅长使用人工智能，还是他们太依赖它了，或者我是远远落后的人？   由   提交/u/Disastrous3856  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozaefa/suddenly_everyone_became_ai_experts/</guid>
      <pubDate>Mon, 17 Nov 2025 07:48:36 GMT</pubDate>
    </item>
    <item>
      <title>更新旧内容是否有助于您在人工智能搜索结果中出现更多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oz8o3a/does_updating_old_content_help_you_appear_more_in/</link>
      <description><![CDATA[我一直在用新信息、更好的结构和干净的格式刷新一些旧页面。但我不确定这是否真的有助于人工智能可见性。 人工智能系统是否像 Google 一样喜欢新鲜内容？ 更新旧帖子后有人看到更好的可见性吗？   由   提交/u/Real-Assist1833  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oz8o3a/does_updating_old_content_help_you_appear_more_in/</guid>
      <pubDate>Mon, 17 Nov 2025 06:01:34 GMT</pubDate>
    </item>
    <item>
      <title>什么更能提高人工智能的可见度：内容质量还是在线提及？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oz8nux/what_improves_ai_visibility_more_content_quality/</link>
      <description><![CDATA[如果人工智能模型从许多地方获取答案，什么更重要？ 您网站上的优质内容还是在网上不同地方提到您的品牌？ 我正在尝试了解什么真正有助于品牌在人工智能答案中更多地展示。很想听听其他人从测试中看到的结果。   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oz8nux/what_improves_ai_visibility_more_content_quality/</guid>
      <pubDate>Mon, 17 Nov 2025 06:01:16 GMT</pubDate>
    </item>
    <item>
      <title>90 年代的人工智能可以接受这样或类似的训练吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oz3cim/could_a_90s_ai_have_been_trained_like_this_or_in/</link>
      <description><![CDATA[抱歉，如果这是个愚蠢的问题，我尝试尽可能多地进行单独研究，但找不到任何明确的答案。  我想写一个简短的科幻故事，其中有一个 90 年代的人工智能模仿其创造者的图画。人工智能通过连接到计算机的扫描仪从图纸中学习。例如，如果创作者希望人工智能生成一张玫瑰图片，他会扫描该玫瑰的多张照片，并允许人工智能从中学习并根据该数据生成一张照片。我想要尽可能准确，我怀疑这种图像生成在 90 年代是否可能，但是我可以使用类似的东西吗？或者我应该倾向于科幻小说？   由   提交 /u/Training_Hornet_4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oz3cim/could_a_90s_ai_have_been_trained_like_this_or_in/</guid>
      <pubDate>Mon, 17 Nov 2025 01:31:40 GMT</pubDate>
    </item>
    <item>
      <title>没有工作==没有生意？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oyzbgv/no_jobs_no_business/</link>
      <description><![CDATA[我对此仍然感到困惑。 如果人工智能在 10 - 30 年内意味着大规模失业，那么对不起 Google、Amazon、Meta 等，那么谁会购买你们的大部分产品？当政府提高营业税来资助失业/泛滥时，使用人工智能的利润与人类的利润之间不会存在权衡吗？ 人工智能似乎有点像第 22 条军规的情况。必须有某种平衡。 我认为目前企业和政府仍将关注短期目标。但如果失业率真的开始上升，（一些“体面的”）政府将不得不做出重大改变（对企业征收人工智能税），如果他们不这样做，无论如何都会出现大规模的社会动荡。 也许最终，我们真的会在生活中轻松休息，继续发展兴趣爱好，并有足够的时间进行社会关怀、社区关怀。   由   提交/u/Both-Move-8418  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oyzbgv/no_jobs_no_business/</guid>
      <pubDate>Sun, 16 Nov 2025 22:33:16 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代码在生产中无法生存：原因如下</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oyym8e/ai_code_doesnt_survive_in_production_heres_why/</link>
      <description><![CDATA[A 副最近，谷歌工程总裁被引述说：“如果人们知道法学硕士的代码实际上投入生产的代码有多么少，他们一定会感到震惊。”尽管有令人印象深刻的演示和数十亿美元的资金，但人工智能生成的原型和生产就绪的系统之间仍然存在巨大差距。但为什么？真相在于这三个基本挑战： https://thenewstack.io/ai-code-doesnt-survive-in-product-heres-why/   由   提交 /u/CackleRooster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oyym8e/ai_code_doesnt_survive_in_production_heres_why/</guid>
      <pubDate>Sun, 16 Nov 2025 22:04:33 GMT</pubDate>
    </item>
    <item>
      <title>及时的安全工程只是通过默默无闻的安全，改变我的想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oyws3v/prompt_engineering_for_safety_is_just_security/</link>
      <description><![CDATA[喜欢我们假装系统提示是安全的，因为任何脚本小子都可以在 5 分钟内绕过它们。我们是否认真地交付生产人工智能功能，而我们的整个安全策略都希望用户不要尝试越狱模型？  与此同时，每个人都在谈论负责任的人工智能，而他们的护栏基本上是代码中措辞强硬的评论。  真正起作用的实时护栏真的存在吗？或者整个行业只是祈祷用户保持良好状态？   由   提交/u/Dilema1305  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oyws3v/prompt_engineering_for_safety_is_just_security/</guid>
      <pubDate>Sun, 16 Nov 2025 20:50:14 GMT</pubDate>
    </item>
    <item>
      <title>还记得 2000 年代初期提供没有广告的实际结果的搜索引擎吗？出色地...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oylw5r/remember_early_2000s_search_engines_that_gave/</link>
      <description><![CDATA[我试了一下：https://aitavista.com/ 我使用的是免费版 Gemini 2.5，所以你可能很快就会杀死它，但是嘿！  与先前存在的搜索引擎名称的相似性纯属巧合   由   提交/u/patrik667  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oylw5r/remember_early_2000s_search_engines_that_gave/</guid>
      <pubDate>Sun, 16 Nov 2025 13:35:47 GMT</pubDate>
    </item>
    <item>
      <title>我认为泡沫破裂后会发生什么（如果它破裂了！）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oyemkb/what_i_think_happens_after_the_bubble_pops_if_it/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oyemkb/what_i_think_happens_after_the_bubble_pops_if_it/</guid>
      <pubDate>Sun, 16 Nov 2025 06:34:17 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>