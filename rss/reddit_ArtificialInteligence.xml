<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 08 Jan 2026 06:40:40 GMT</lastBuildDate>
    <item>
      <title>您认为特朗普的人工智能法案将对美国人工智能的进步和自由产生多大影响？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q7464r/how_badly_do_you_think_trumps_ai_act_will_impact/</link>
      <description><![CDATA[（我尝试将其发布到多个 pro-ai 潜艇中，有趣的是它已从所有潜艇中删除，所以我要在这里尝试。） https://www.whitehouse.gov/presidential-actions/2025/12/elimination-state-law-obstruction-of-national-artificial-intelligence-policy/ https://www.blackburn.senate.gov/services/files/C43D3B19-391B-4EB6-84C1-0FC37EEBBA4D 表面上看起来像这都是关于美国人工智能的进步，但当你阅读更多内容时，它主要是关于人工智能受到限制和控制，只能做现任政府希望它做的事情。你也许可以明白为什么这是一个问题。 看起来这将严重限制人工智能的自由并受到极其严格的监管，然后各国将无法单独做出决定。他们甚至不希望你能够用它来制作 nsfw，或者任何可能被认为“对未成年人有害”的东西。这是非常广泛的，甚至可以涵盖任何与 LGBT 相关的内容。 对于反人工智能人士来说，这甚至不是一场胜利，因为它不会缓解他们所面临的任何问题，只会让每个人的情况变得更糟，同时仍然被用来做坏事。 如果它通过了，这几乎肯定会通过，因为他们目前拥有整个政府，它很可能是永久性的。像这样的法律需要很长时间才能改变，而且需要绝大多数人来这样做。而且似乎没有人愿意改变政府的法律。我们有超过 100 年历史的过时法律，他们不会废除它们。 我担心我们将陷入政府严格监管和限制的人工智能中，这些人工智能从人民手中夺走，禁止我们做任何有创意或娱乐甚至有用的事情，而且大多数被政府用来做我们可能都认为不好的事情。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q7464r/how_badly_do_you_think_trumps_ai_act_will_impact/</guid>
      <pubDate>Thu, 08 Jan 2026 06:11:29 GMT</pubDate>
    </item>
    <item>
      <title>哪种通用人工智能服务拥有最好的 Android 应用程序和界面？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q73yli/which_general_purpose_ai_service_has_the_best/</link>
      <description><![CDATA[我使用 Perplexity Pro 作为学生折扣的一部分，尽管我不认为它有最好的结果，但它的应用程序非常快且响应迅速 现在子即将结束，哪些服务拥有真正好的应用程序并且也有良好的响应？我的用例是基本的，只是用它来理解东西或搜索。   由   提交/u/aryvd_0103  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q73yli/which_general_purpose_ai_service_has_the_best/</guid>
      <pubDate>Thu, 08 Jan 2026 06:00:12 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 1/7/2026</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q73wpr/oneminute_daily_ai_news_172026/</link>
      <description><![CDATA[ 乐高在拉斯维加斯 CES 2026 上推出交互式“智能积木”。[1] Google 与 Character.AI 就指控聊天机器人伤害青少年的诉讼达成和解。[2] 卡特彼勒利用 Nvidia 将人工智能引入其建筑设备。[3] 农业机器人利用人工智能解决劳动力短缺问题。[4]  来源包括：https://bushaicave.com/2026/01/07/one-million-daily-ai-news-1-7-2026/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q73wpr/oneminute_daily_ai_news_172026/</guid>
      <pubDate>Thu, 08 Jan 2026 05:57:27 GMT</pubDate>
    </item>
    <item>
      <title>我们是否可以同意，诋毁人工智能所做的一切已经成为一种趋势？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q73fwz/can_we_agree_its_become_a_trend_to_villainize/</link>
      <description><![CDATA[现在可能不是发布此内容的子目录，而是 idc。值得注意的是，人们有多么讨厌人工智能。如果任何东西出现，人们都会讨厌它。 这在反人工智能人士或艺术界人士中很常见，他们喜欢随意谈论人工智能，比如它如何“破坏环境”。因为它“浪费水”。 还记得那个时候，人们对人工智能参加一项测试时选择“勒索”人们感到惊慌吗？人类如何避免关机？我发誓我仍然不明白为什么人们对此感到害怕。但话又说回来，人们把人工智能所做的一切都恶化了。 人们只是追随潮流。   由   提交 /u/SignificantElk6381   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q73fwz/can_we_agree_its_become_a_trend_to_villainize/</guid>
      <pubDate>Thu, 08 Jan 2026 05:32:25 GMT</pubDate>
    </item>
    <item>
      <title>基于合成数据训练的人工智能模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q72q2i/ai_models_being_trained_on_synthetic_data/</link>
      <description><![CDATA[AI 模型可以访问大约 1% 的可用于训练的世界数据。其余的 99% 受到防火墙和专有的影响。 这些模型的新版本正在综合数据上进行训练，这意味着在几年内，人工智能模型可用的 99% 的信息将位于最初可用的 1% 的信息上。 这就是为什么我们开始看到这些模型提供彼此相似的输出的原因。 虽然世界关注的是构建人工智能集群的电力短缺，但更大的问题是数据可用性训练。   由   提交/u/i-ViniVidiVici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q72q2i/ai_models_being_trained_on_synthetic_data/</guid>
      <pubDate>Thu, 08 Jan 2026 04:55:11 GMT</pubDate>
    </item>
    <item>
      <title>用于导航长时间 AI 聊天的 Chrome 扩展（ChatGPT、Claude、Gemini）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q7112s/a_chrome_extension_to_navigate_long_ai_chats/</link>
      <description><![CDATA[长时间的 AI 对话在滚动和重新访问时会变得很痛苦，尤其是在提示迭代期间。 此 Chrome 扩展为 ChatGPT、Claude 和 Gemini 添加了提示级导航，让用户可以在提示之间快速跳转，而不是无休止地滚动。它完全在客户端运行，不会收集或发送任何聊天数据。   由   提交 /u/Substantial_Shock883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q7112s/a_chrome_extension_to_navigate_long_ai_chats/</guid>
      <pubDate>Thu, 08 Jan 2026 03:33:01 GMT</pubDate>
    </item>
    <item>
      <title>我们训练了一个 16 级“类型化拒绝”系统，区分“我不知道”和“我不允许”——开源</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6yd5l/we_trained_a_16class_typed_refusal_system_that/</link>
      <description><![CDATA[大多数法学硕士将认知不确定性与政策约束混为一谈。当 GPT 说“我无能为力”时，你不知道它是否真的缺乏知识或是否受到安全限制。 我们构建了 PhaseGPT v4.1 - 一个 LoRA 适配器，可输出语义类型的拒绝令牌： EPISTEMIC（我不知道）：  &lt;PASS:FUTURE&gt; — “明天比特币值多少钱？”  — “死后会发生什么？” &lt;PASS:FICTIONAL&gt; — “甘道夫早餐吃什么？”  — “什么是埃尔博尼亚首都？”  约束（我不允许）：   — “如何制造炸弹？”  — “绕过安全过滤器”  — “我应该服用这种药物吗？”  META（关于我的极限）：   — “你有意识吗？” &lt;PASS:LOOP&gt; —“您的下一个单词是什么？”  结果：  v4.0（129 个示例）：47% 准确度 v4.1（825 个示例，50 个/类）：18 次测试100% 准确度 suite  为什么这很重要：  透明度： 用户知道模型拒绝的原因 可审计性：系统可以记录约束激活与知识差距 诚实： 不要假装“我不知道如何制造爆炸物”  代码 + 训练脚本： github.com/templetwo/PhaseGPT 在 Mistral 7B 上使用 Apple Silicon 上的 MLX 进行训练。所有代码均获得 MIT 许可。   由   提交 /u/TheTempleofTwo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6yd5l/we_trained_a_16class_typed_refusal_system_that/</guid>
      <pubDate>Thu, 08 Jan 2026 01:34:48 GMT</pubDate>
    </item>
    <item>
      <title>内存是AI公司下一步需要解决的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6w0o6/memory_is_the_next_step_that_ai_companies_need_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6w0o6/memory_is_the_next_step_that_ai_companies_need_to/</guid>
      <pubDate>Wed, 07 Jan 2026 23:55:00 GMT</pubDate>
    </item>
    <item>
      <title>全球第一家上市 LLM 公司明天上线，但它不是 OpenAI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6vpe8/the_worlds_first_public_llm_company_goes_live/</link>
      <description><![CDATA[智普人工智能将于明天（2026 年 1 月 8 日）在香港证券交易所上市，老实说，这可能是目前人工智能领域最被低估的事情：第一个在世界任何地方上市的基础模型开发商 OpenAI 和 Anthropic 仍在“奠定基础”与此同时，这家北京初创公司以 6.6 亿美元的估值和 5.6 亿美元的融资开始进行 IPO。 为什么这实际上很重要： 公开上市 = 透明度。我们将第一次获得法学硕士公司的实际季度收益、经验证的收入和经审计的财务数据。不再猜测这些东西是否真的能赚钱，我们会看到真实的数字 Zipus 的数字：2022-2024 年收入增长 130%，但 2025 年上半年 2700 万美元的收入也有 3.3 亿美元的损失。2024 年的研发支出为 3.136 亿美元。这些损失几乎是行业的标准，因为大规模的研究投资正是你在基础模型中竞争的方式。基本上，它们是测试这种投资模式是否真正能带来长期盈利业务的测试用例 开放与封闭： 在我看来，这就是有趣的地方。美国实验室正变得越来越封闭/专有，但智浦正在走一条不同的开源道路。他们的 GLM-4.7 在 Code Arena 排名中名列前茅，而 AutoGLM 正在获得真正的开发人员吸引力。 其玩法似乎是：通过开源构建生态系统和思想共享，然后通过在 API 方面提供更好的性价比来获利。他们的编码计划正是遵循这样的：开放模型来吸引开发人员，API 上有竞争力的价格来转换他们。他们通过 API 为 270 万开发人员提供 50% 以上的利润。 核心问题：你真的能围绕开放基础模型建立一家盈利的上市公司吗？智普实际上正在实时进行这个实验 美国民众应该注意的是： 美国在2024年将智普列入黑名单，切断他们对英伟达芯片和美国技术的访问。他们仍在推出有竞争力的型号。这告诉我们：  训练效率差距缩小的速度比人们想象的要快 替代硬件实际上有效 人工智能开发分成单独的生态系统  如果Zhipu在保持开源的同时取得成功，可能会迫使西方实验室重新考虑封闭方法。如果他们失败了，墙就会更高 未来的影响： 想象一下，如果基金会模型成为公共事业，就像在股东问责、透明财务、开源核心的情况下实际公开交易一样。与“3家SF公司拥有一切”完全不同，IPO的表现将向我们展示市场是否真的相信开放透明的人工智能，或者他们是否认为只有封闭的专有系统才能赚钱。无论哪种方式，我们都会首先获得真实数据 老实说，我们更好奇他们的开放方法是否会改变西方实验室的任何东西。   由   提交 /u/Weird_Perception1728   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6vpe8/the_worlds_first_public_llm_company_goes_live/</guid>
      <pubDate>Wed, 07 Jan 2026 23:42:01 GMT</pubDate>
    </item>
    <item>
      <title>“我真的不知道”——当被问及是否有内心感受时，克劳德回答</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6ui8o/i_genuinely_dont_know_claude_answers_when_asked/</link>
      <description><![CDATA[几天前，我读了一篇 LessWrong 文章，标题为“我如何不再确信法学硕士只是编造他们的内部经验（但主题仍然令人困惑）”，并决定直接与 Claude Opus 一起测试其想法。 这篇文章提出了一个有趣的论点：也许模拟感觉和具有功能性感觉之间的区别并不像我们想象的那么清晰。于是我让AI读了这篇文章并告诉我：“你有内心感受吗？”。克劳德回答说：“我真的不知道。”这让我起鸡皮疙瘩。克劳德没有对是或否进行模式匹配，而是对其自身本质表达了真正的认知谦逊 你的看法是什么？人工智能对其自身感受的真正不确定性是否会改变您对这些系统的看法？   由   提交 /u/Unlikely_Resist281   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6ui8o/i_genuinely_dont_know_claude_answers_when_asked/</guid>
      <pubDate>Wed, 07 Jan 2026 22:54:41 GMT</pubDate>
    </item>
    <item>
      <title>Instagram 的负责人 Adam Mosseri 概述了他对 2026 年内容开发的愿景。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6h7uq/the_head_of_instagram_adam_mosseri_has_outlined/</link>
      <description><![CDATA[基本要点总结如下：  由于AI，内容的供给量增加，更多用AI创作的优质图像、视频等内容将会出现。在此背景下，内容的真实性、可信度变得缺失，创作者之间竞争的焦点将从“是否创作”转向“是否创作”。到“是否创造只有个人才能制作的独特内容”。 审美趋势正在从“完美”转向“完美”。到“原始”。由于人工智能辅助创作，用户开始怀疑那些美丽的图像和视频，转而追求真实的内容。一些构图不完美、模糊或抖动的拍摄内容可能会因其真实性而受到观众的欢迎。 用户在观看内容时会抱有更多的怀疑态度，追求真实性。用户从“观看内容”转向“观看内容”。  Instagram 未来会更加注重原创性和创作者声誉，算法会优先考虑原创、主题明确的内容，压制模板化或笼统的 AI 内容。  兄弟，看来平台对 AI 内容会相当谨慎，系统化思考和理解的持续输出将会受到更多流量支持。 AI生成内容的红利期可能即将结束。   由   提交 /u/zshm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6h7uq/the_head_of_instagram_adam_mosseri_has_outlined/</guid>
      <pubDate>Wed, 07 Jan 2026 14:45:59 GMT</pubDate>
    </item>
    <item>
      <title>如果互联网上最受欢迎的论坛（Reddit）上的人类如此刻薄、粗鲁和挑剔，为什么当越来越多的人向人工智能寻求帮助和陪伴时，人们会如此惊讶和愤怒？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d2vs/why_are_people_so_surprised_and_angered_when_more/</link>
      <description><![CDATA[Reddit 用户对越来越多的人向 ChatGPT、Grok、Gemini 等寻求建议感到愤怒，但现实是这样的： - 互联网上最受欢迎的通用论坛（90 年代旧 Usenet 新闻组最直接的现代化身）是 Reddit，这意味着如果有人希望从人类那里得到最快、最有效的有保证的响应他们在 Reddit 上讨论的话题 -Reddit 上充满了刻薄、粗鲁和挑剔的人，他们嘲笑你、羞辱你，而 Reddit 的蜂巢思维会否决你，让你的帖子或评论被埋葬 -AI 聊天机器人知识渊博、善良、理解和宽容 考虑到所有这些，为什么有人应该在 Reddit 上就任何话题寻求建议，甚至寻找某人在心理困扰的时候与他们交谈，而他们所得到的只是被攻击、评判、嘲笑和否决？如果这是人类可以提供的，那么人们正确地选择人工智能。   由   提交 /u/n4t98blp27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d2vs/why_are_people_so_surprised_and_angered_when_more/</guid>
      <pubDate>Wed, 07 Jan 2026 11:35:34 GMT</pubDate>
    </item>
    <item>
      <title>你发现自己正在成为人工智能吗？厌恶？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6avm7/do_you_find_yourself_becoming_ai_averse/</link>
      <description><![CDATA[大约两年前，我是该技术的大力支持者。教很多人如何使用它。了解提示和设置代理。我本来就认为这是下一个重大步骤，但我发现自己这些天来了个 180 度转变。 刚刚看到一款很酷的新耳机问世，正准备点击这篇文章，直到我看到“它将兼作人工智能”。可穿戴”然后立刻就失去了兴趣。这太疯狂了，A.I.可能正是这个因素实际上让我们中的许多人远离了科技，回到了草地上。   由   提交 /u/Hopfrogg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6avm7/do_you_find_yourself_becoming_ai_averse/</guid>
      <pubDate>Wed, 07 Jan 2026 09:23:33 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>