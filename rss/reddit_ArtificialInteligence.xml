<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 06 Feb 2026 15:45:00 GMT</lastBuildDate>
    <item>
      <title>您实际使用 Claude 做的最酷的事情是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxkq9k/what_is_the_coolest_thing_you_actually_use_claude/</link>
      <description><![CDATA[我一直听说 Claude 有多出色，但我在网上找到的大多数示例都感觉​​太技术性或太复杂，让我无法理解。我正在寻找人们在现实世界中使用它的一些方式，这些方式一开始可能并不明显。 如果您有一个特定的用例，实际上使您的生活变得更轻松，或者只是一种有趣的交互方式，请分享。我对不仅仅是“写电子邮件”之外的事情特别感兴趣。或“修复此代码”因为我想看看当你发挥创造力时，这个东西到底能做什么。 你最喜欢的使用方式是什么？   由   提交 /u/funnycallsw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxkq9k/what_is_the_coolest_thing_you_actually_use_claude/</guid>
      <pubDate>Fri, 06 Feb 2026 15:31:33 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 挖苦 OpenAI/ChatGPT 的广告，这已经让很多人感到不安</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxiydn/anthropic_takes_a_dig_at_openaichatgpt_for_ads/</link>
      <description><![CDATA[Anthropic 凭借敏锐的超级碗定位举措击败了 OpenAI。 Sam Altman 反应很快，这放大了它。 发生了什么 Anthropic 投放了 4 个超级碗广告，模仿人工智能聊天机器人在对话中推送广告。例如，聊天机器人提供建议，然后宣传约会网站或鞋垫。 每个广告都使用“背叛”等戏剧性词语，并以以下结尾： “广告将投放到 AI 中，但不会投放到 Claude 中。” Anthropic 在每个广告位上花费了大约 1000 万美元，将 Claude 定位为无广告、值得信赖的替代品。 Altman 在几小时内就在 X 上做出了回应。他称这些广告很有趣，但“不诚实”，指责 Anthropic 说三道四，并批评 Claude 价格昂贵且限制性强。 OpenAI 的首席营销官补充道：“真正的背叛不是广告。而是控制。” 战略现实 Altman 在商业机制上的方向是正确的，但 Anthropic 赢得了叙述。 事实： ChatGPT 拥有 3 亿多用户，其中大部分是免费用户。 广告是补贴免费访问的合理方式。 Anthropic 目前更多地依赖于企业、API 和订阅。 但定位战胜了事实。 Anthropic 将问题从经济学重新定义为伦理学。 不是“不同的商业模式”。相反：“广告=背叛信任。” 这将竞争从功能转向价值。 为什么 Anthropic 的举动是教科书式定位  他们将 OpenAI 强行纳入他们的框架  最有力的定位举措是让竞争对手使用你的语言来保护自己。 Anthropic 框架广告是有害的。 Altman 的回应是解释 OpenAI 的广告方法。 结果：OpenAI 无意中验证了前提。  他们将基础设施变成了意识形态  广告通常是中立的基础设施。人择使它们成为一个道德问题。基于价值观的定位比功能比较更难对抗。  他们战略性地利用矛盾  花费数百万美元在广告上说“我们不相信广告”会造成认知摩擦。这种悖论产生了记忆。奢侈品牌也采用同样的策略。  他们的目标是大众市场，而不是人工智能内部人士  超级碗观众包括数百万不熟悉人工智能竞争的人。 Anthropic 建立了一个简单的关联：Claude = 值得信赖、无广告的人工智能 这种规模的第一印象非常持久。 OpenAI 的失误之处 Altman 的回应存在三个战略弱点：他立即参与，放大了 Anthropic 的信息。他争论细节而不是重新叙述叙述。他含蓄地接受了 Anthropic 的前提。 更好的回应：  “很棒的广告。我们的重点是让人工智能惠及数十亿人。”  这将广告重新定义为民主化，而不是背叛。 更深层次的战略教训 这不是广告。这是类别框架。 顺序：  人择定义了框架：广告 = 糟糕。 OpenAI 在该框架内做出响应。 人择无需进一步努力即可获胜。  一旦竞争对手捍卫自己，他们就会失去定位优势。 底部 Anthropic 同时取得了三个成果： 大幅提升了 Claude 的品牌知名度 对 OpenAI 进行防御性定位 定义了围绕 AI 货币化的道德叙事 这是精英级的定位执行。 他们不仅仅是推销产品。他们重新定义了围绕人工智能信任的对话。   由   提交/u/ranaji55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxiydn/anthropic_takes_a_dig_at_openaichatgpt_for_ads/</guid>
      <pubDate>Fri, 06 Feb 2026 14:23:42 GMT</pubDate>
    </item>
    <item>
      <title>本地人工智能模型：更私密，但它们实际上更值得信赖吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxicmh/local_ai_models_more_private_but_are_they/</link>
      <description><![CDATA[我一直在尝试在本地运行 AI 模型，而不是依赖云 API。一方面，自托管可以完全控制数据和日志 - 您可以审核输出、安全存储结果，并避免将敏感信息发送到外部服务器。但问题是：即使一切都在您自己的机器上运行，模型决策背后的“原因”仍然大部分是不透明的。您可以记录和检查输入和输出，但模型本身的推理仍然是一个黑匣子。所以我很好奇：对于那些在本地运行法学硕士的人来说，自托管是否真的可以提高信任度，或者它主要提供隐私，但无法解决可解释性问题？我很想听听其他人的意见：他们如何确保输出的可审核性信任边界与自托管设置中的便利性在本地运行高性能模型的实际限制。   由   提交 /u/NeoLogic_Dev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxicmh/local_ai_models_more_private_but_are_they/</guid>
      <pubDate>Fri, 06 Feb 2026 13:59:13 GMT</pubDate>
    </item>
    <item>
      <title>Opus 4.6 是一个不同的野兽。它只是在我观看时处理了我的整个国际化逻辑</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxfuhv/opus_46_is_a_different_beast_it_just_handled_my/</link>
      <description><![CDATA[刚刚体验了新的 Opus 4.6（在 Cursor 中运行）。 我需要向我的 MVP 添加完整的国际化支持（英语、法语、西班牙语）和全球定位基础设施。通常，这是与人工智能进行乏味的“一步一步”舞蹈。 但这一次呢？我向它提出了高级要求，它就……接管了。  它切换到了计划模式。 编写了架构。 安装了必要的软件包。 实现了逻辑并翻译了整个网站。  我一次都没有握住它的手。是只有我一个人这么认为，还是从 4.​​5 到 4.6 的跳跃在主体自主性方面是巨大的？很好奇是否其他人感受到了这种“飞跃”，或者我是否幸运地得到了完美的提示。   由   提交 /u/Tzipi_builds   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxfuhv/opus_46_is_a_different_beast_it_just_handled_my/</guid>
      <pubDate>Fri, 06 Feb 2026 12:06:29 GMT</pubDate>
    </item>
    <item>
      <title>到 2026 年，人工智能医疗抄写员可能会被如何评估</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxeyyi/how_ai_medical_scribes_will_likely_be_evaluated/</link>
      <description><![CDATA[几年后，我认为人工智能抄写员的评判标准不会是它能否转录。 这将是基线，真正的区别是：它能适应你的书写方式吗？它在访问之前、期间和之后有帮助吗？它真的减轻了精神负担吗？   由   提交/u/MianHasnainShah  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxeyyi/how_ai_medical_scribes_will_likely_be_evaluated/</guid>
      <pubDate>Fri, 06 Feb 2026 11:19:27 GMT</pubDate>
    </item>
    <item>
      <title>高盛正在利用 Anthropic 的人工智能模型来实现会计、合规角色的自动化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxebd4/goldman_sachs_is_tapping_anthropics_ai_model_to/</link>
      <description><![CDATA[嵌入式 Anthropic 工程师在高盛花了六个月的时间构建自主系统，用于时间密集型、大批量的后台工作。该银行期望提高效率，而不是短期裁员，利用人工智能来加快流程并限制未来员工数量的增长。编码之外的成功让高管们感到惊讶，这强化了人工智能可以处理复杂的、基于规则的工作，比如会计和合规性。 https://www.cnbc.com/2026/02/06/anthropic-goldman-sachs-ai-model-accounting.html   由   提交 /u/app1310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxebd4/goldman_sachs_is_tapping_anthropics_ai_model_to/</guid>
      <pubDate>Fri, 06 Feb 2026 10:42:11 GMT</pubDate>
    </item>
    <item>
      <title>借助 AI，下载文件夹将成为您最重要的资产中心</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxcpjv/with_ai_the_download_folder_becomes_your_most/</link>
      <description><![CDATA[自从大量使用 AI 工具（我主要使用 Claude、ChatGPT 和 Perplexity）以来，我是唯一一个更频繁地使用下载文件夹的人吗？  感觉就像是一个巨大的“垃圾场”，里面堆满了旧草稿、资产和各种文物。  这可能只是人工智能工作流程的临时状态，但现在看到下载文件夹内容成倍增加有点烦人……。    由   提交 /u/Late-Masterpiece-452   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxcpjv/with_ai_the_download_folder_becomes_your_most/</guid>
      <pubDate>Fri, 06 Feb 2026 09:02:02 GMT</pubDate>
    </item>
    <item>
      <title>人工智能作为职业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxcnp8/ai_as_career/</link>
      <description><![CDATA[对第一年 Btech 的建议。 CSE 学生将从事人工智能和数据科学职业。  建议课程和资源。 此外，建议在人工智能领域找到工作的途径   由   提交 /u/Beginning-Budget-361   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxcnp8/ai_as_career/</guid>
      <pubDate>Fri, 06 Feb 2026 08:59:01 GMT</pubDate>
    </item>
    <item>
      <title>我对新的 QWEN3 TTS 模型太过分了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxcnns/i_went_too_far_with_the_new_qwen3_tts_model/</link>
      <description><![CDATA[所以我一直在摆弄这个模型，并且进行了很多有趣的声音采样，但是由于某种原因，今天我发现了几个月前去世的父亲的视频，并认为尝试采样他的声音是个好主意。  我和我的兄弟们坐在一起，让他说出我们认为他会说的话，过了一会儿，我们都哭了，那是一个悲伤的时刻，现实被悬置了，感觉他就在我们身边，然后意识到他不再和我们在一起了，感到空虚。  这就像再次失去他一样。外出时保持安全，珍惜与所爱之人在身边时分享的时刻。有些东西技术永远无法真正取代。   由   提交 /u/Zempire   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxcnns/i_went_too_far_with_the_new_qwen3_tts_model/</guid>
      <pubDate>Fri, 06 Feb 2026 08:58:56 GMT</pubDate>
    </item>
    <item>
      <title>Claude Opus 4.6 更智能，但它仍然在欺骗你——现在只是更流畅了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxb0f3/claude_opus_46_is_smarter_but_it_still_lies_to/</link>
      <description><![CDATA[热门观点：Opus 4.6 的幻觉并没有减少。它产生幻觉更好。 自推出以来我一直在观看r/ClaudeAI。我一直看到的模式是，旧的 Opus 版本会自信地编造垃圾——错误的公式、虚假的引用，以及满怀信心地发表的胡言乱语。 4.6 仍然这样做，但它用更细致的语言包装它，因此您不太可能注意到。   由   提交 /u/vijayeesam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxb0f3/claude_opus_46_is_smarter_but_it_still_lies_to/</guid>
      <pubDate>Fri, 06 Feb 2026 07:17:01 GMT</pubDate>
    </item>
    <item>
      <title>我是一名初级开发人员，说实话，到 2026 年，人工智能将在我的工作流程中无处不在。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qx6dce/im_a_junior_developer_and_to_be_honest_in_2026_ai/</link>
      <description><![CDATA[我是一名初级开发人员，说实话，到 2026 年，人工智能将在我的工作流程中无处不在。 大多数时候，我不会完全从头开始编写代码。我使用人工智能工具来生成代码、修复错误、重构逻辑，甚至向我解释事情。有时感觉人工智能比我自己编写的代码更干净、更“正确”。 甚至业内的高级工程师和大人物也公开表示他们现在使用人工智能。 Linux 的创建者 Linus Torvalds 谈到了使用 AI 来完成编码任务，但与此同时，他警告说，如果您不了解代码在做什么，那么盲目信任 AI 来完成严肃的长期项目可能是一个非常糟糕的主意。 这就是我的困惑开始的地方。 一方面： AI 帮助我快速前进 我快速学习新的语法、模式和库 我可以交付我无法单独构建的东西 另一方面： 我担心我正在跳过基础知识 有时我在没有完全理解人工智能代码的情况下接受它 我担心从长远来看，这可能会损害我作为一名工程师的成长 我读过一些研究，称人工智能可以提高生产力，但如果你过度依赖它，就会减少深度学习。我还看到报告称，如果不仔细审查，许多人工智能生成的代码都包含细微的错误或安全问题。与此同时，我周围几乎每个人都在使用人工智能——所以完全避免它感觉不现实。 我真正的问题是： 作为初级开发人员，如何使用人工智能而不依赖它？你如何确保你仍然在培养有一天成为高级工程师所需的技能——比如系统设计、调试和解决问题——而不是仅仅擅长促进人工智能？ 我一点也不反对人工智能。我认为这是一个令人难以置信的工具。我只是不想让它成为限制我长期成长的拐杖。 很想听听前辈、领导或其他正在思考这个问题的人的意见。   由   提交 /u/Beginning-Scholar105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qx6dce/im_a_junior_developer_and_to_be_honest_in_2026_ai/</guid>
      <pubDate>Fri, 06 Feb 2026 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>Grok 的情况引发了一个更大的问题：未经同意在真人身上训练人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qx2y4b/the_grok_situation_raises_a_bigger_question_about/</link>
      <description><![CDATA[Grok 的情况提出了一个更大的问题，即如何在未经同意的情况下对真人进行人工智能训练。这不仅仅是关于一种模式或一家公司。它将人类身份（面孔、声音、相似度）视为默认训练数据，即使这些数据属于未成年人。  一旦这些内容被吸收，无论后来如何进行审核或删除，其危害都不会是假设的，也不会轻易消除。如果身份可以在未经许可的情况下以这种方式使用，那么很难说它受到了有意义的保护。 其他人对此有什么想法吗？   由   提交/u/WeirAI_Gary  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qx2y4b/the_grok_situation_raises_a_bigger_question_about/</guid>
      <pubDate>Fri, 06 Feb 2026 00:39:58 GMT</pubDate>
    </item>
    <item>
      <title>每个人工智能公司都希望将数据中心送上太空的明显原因</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qwzik8/the_obvious_reason_why_every_ai_company_wants_to/</link>
      <description><![CDATA[它们无法被饥饿、失业的暴民袭击和摧毁。真的就这么简单。 值得赞扬的是：他们已经做好了功课，并意识到，一旦他们导致经济崩溃，人们就会挨饿并且非常愤怒！解决方案？建造巨大的末日掩体，并将底层基础设施发送到无法被摧毁的地方。纯粹邪恶的一击；在某种意义上是值得尊敬的。   由   提交 /u/Nissepelle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qwzik8/the_obvious_reason_why_every_ai_company_wants_to/</guid>
      <pubDate>Thu, 05 Feb 2026 22:16:49 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>