<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 28 Jan 2026 21:33:55 GMT</lastBuildDate>
    <item>
      <title>我如何学会让不同的法学硕士理解我的想法 - 通过将我的想法打包为 JSON</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpo1cx/how_i_learned_to_make_different_llms_understand/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpo1cx/how_i_learned_to_make_different_llms_understand/</guid>
      <pubDate>Wed, 28 Jan 2026 21:07:25 GMT</pubDate>
    </item>
    <item>
      <title>神经数据瓶颈：为什么脑人工智能接口打破了现代数据堆栈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpnthn/the_neurodata_bottleneck_why_brainai_interfacing/</link>
      <description><![CDATA[本文指出了神经科学和脑人工智能研究中的一个关键基础设施问题 - 传统数据工程管道（ETL 系统）如何与神经数据的处理方式不一致：神经数据瓶颈：为什么脑人工智能接口打破了现代数据堆栈 它提出“零ETL”具有元数据优先索引的架构 - 扫描存储桶（如 S3）以创建原始文件的可查询索引，而无需移动数据。研究人员通过 Python API 直接访问数据，将文件保存在适当的位置，同时实现选择性的分阶段处理。这消除了重复，保留了可追溯性，并加速了迭代。   由   提交 /u/thumbsdrivesmecrazy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpnthn/the_neurodata_bottleneck_why_brainai_interfacing/</guid>
      <pubDate>Wed, 28 Jan 2026 20:59:35 GMT</pubDate>
    </item>
    <item>
      <title>寻找语言监管较少的 ChatGPT 替代品</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpnanr/looking_for_chatgpt_alternatives_with_less/</link>
      <description><![CDATA[我已经成为 ChatGPT 的重度用户有一段时间了，但我越来越沮丧，需要切换。对我来说，主要问题是过度的语言监管及其对政治/社会话题的处理。 感觉就像是一直如履薄冰，以至于拒绝明确谴责暴行或揭露真正可怕的人/行为。对严重问题的清洁、规避风险的反应已经变得令人作呕。我理解需要护栏，但这感觉像是缺乏基本的同理心和道德清晰度。 我不是在寻找“精神错乱”的东西，但我确实想要一个人工智能：  对话感觉更少受到监管，更加自然。 在讨论世界上明确的罪恶时，有一个骨干——一种与主题的道德严肃性相匹配的能力。 在要求对广受谴责的历史或当前事件进行分析时，我不必穿过层层中立。  w其他人也有这样的感觉吗？您使用哪些替代方案可以达到更好的平衡？您有使用 Perplexity AI、Grok（据说过滤程度较低）或特定未经审查模型的经验吗？ 谢谢。    由   提交 /u/Kifflom13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpnanr/looking_for_chatgpt_alternatives_with_less/</guid>
      <pubDate>Wed, 28 Jan 2026 20:39:56 GMT</pubDate>
    </item>
    <item>
      <title>您仍然认为 OpenAI 这里有机会吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpna1k/do_you_still_think_openai_has_a_chance_here/</link>
      <description><![CDATA[Google 拥有芯片、数据中心、技术、工具和广告业务，当然还有分销…… 2025 年，它让一艘行驶缓慢的油轮转向双子座，成为领先者。  我喜欢资源有限的环境，因为那才是真正的创造力所在......但是......  OpenAI 一直在做的就是要求更多的钱。 与 Elon 的诉讼 - 你能看到他们超越四月份的那个时间吗？    由   提交 /u/jason_digital   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpna1k/do_you_still_think_openai_has_a_chance_here/</guid>
      <pubDate>Wed, 28 Jan 2026 20:39:19 GMT</pubDate>
    </item>
    <item>
      <title>“基于链接”的互联网真的正在消亡吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qplje0/is_the_linkbased_internet_actually_dying/</link>
      <description><![CDATA[我一直在准备网站的发布，但搜索在一年之内发生了多大的变化，这有点令人沮丧。我坐在这里做平常的事情......关键字，反向链接，等等，然后我意识到我基本上几个月没有点击谷歌链接，因为我只是使用 Gemini 或 GPT 来完成（好吧，几乎）所有事情。 感觉这一举动正在转向 AEO（答案引擎优化）而不是 SEO，但对于如何实际“排名”的清晰度为零。在人工智能的回答中。我环顾四周，发现人们已经开始关注并为此制作工具，就我而言，我使用了 Netranks（如果有人尝试过，请告诉我，我不擅长使用工具......）来看看跟踪“AI 语音份额”是否可行。实际上是一件事（主要是因为我很好奇我的网站是否存在于训练数据中，哈哈），但老实说，我不知道我们是否已经到了可以真正“设计”网站的地步。尚未被法学硕士引用。 您对最近的转变有何看法？它会改变我们寻找东西的方式吗？谷歌是否会据此做出改变？感觉我们正处于一个奇怪的困境，旧的方式已经死了，但还没有人就新的方式达成一致。我觉得如果我不是“机器可读的”我对一些潜在客户来说是隐形的。 人工智能爱好者在想什么？   由   提交 /u/c1nnamonapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qplje0/is_the_linkbased_internet_actually_dying/</guid>
      <pubDate>Wed, 28 Jan 2026 19:35:57 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能系统在受到挑战时 90% 的时间都是错误的，那么它为什么要做出医疗保健决策呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpjz83/if_an_ai_system_is_wrong_90_of_the_time_when/</link>
      <description><![CDATA[不是反问句。实际上是想理解这里的逻辑。 最近的 AMA 数据：一家大型保险公司由人工智能驱动的事先授权拒绝，90% 在上诉后被推翻。 29% 的医生表示，这些否认导致了严重的不良事件。 该系统显然不可靠。但它仍在使用，因为大多数患者不会上诉，而且即使最终赔钱，延迟也会让保险公司受益。 麻省理工学院斯隆管理学院本月表示，人工智能代理“对于企业来说，在任何涉及大笔资金的流程中依赖它们会犯太多错误。” 医疗保健决策是大笔资金。它们也是生与死。 我错过了什么？是否假设技术进步的速度快于危害累积的速度？或者这只是一个经过计算的赌注，责任框架不会跟上？   由   提交/u/DBarryS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpjz83/if_an_ai_system_is_wrong_90_of_the_time_when/</guid>
      <pubDate>Wed, 28 Jan 2026 18:41:26 GMT</pubDate>
    </item>
    <item>
      <title>为了避免人工智能作弊的指控，大学生正在转向人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpjmo3/to_avoid_accusations_of_ai_cheating_college/</link>
      <description><![CDATA[这变得超现实：https://www.nbcnews.com/tech/internet/college-students-ai-cheating- detectors- humanizers-rcna253878  “在人工智能作弊的指控中，一些学生正在转向一组新的生成人工智能工具，称为“人性化工具”。这些工具会扫描文章并提出修改文本的建议，这样它们就不会被认为是由人工智能创建的。有些是免费的，而另一些则每月花费约 20 美元。 Humanizer 工具的一些用户依靠它们来避免作弊检测，而另一些用户则表示，他们在工作中根本不使用人工智能，但希望确保自己不会被人工智能检测程序错误地指控为使用人工智能。 作为回应，随着聊天机器人的不断发展，Turnitin 和 GPTZero 等公司已经升级了他们的人工智能检测软件，旨在捕捉作弊行为。经历了人性化。他们还推出了学生可以用来跟踪浏览器活动或写作历史的应用程序，这样他们就可以证明这些材料是他们写的，尽管一些人性化工具可以输入用户想要复制和粘贴的文本，以防学生的击键被跟踪。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpjmo3/to_avoid_accusations_of_ai_cheating_college/</guid>
      <pubDate>Wed, 28 Jan 2026 18:29:24 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind 今天发布了令人兴奋的论文</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qphlej/deepmind_released_mindblowing_paper_today/</link>
      <description><![CDATA[DeepMind 刚刚在 Nature 上发表了一篇关于 AlphaGenome 的新论文，这是一个巨大的进步。基本上，它是一个人工智能，最终可以读取大量 DNA（多达一百万个字母），并真正了解它们如何控制我们的身体，而不仅仅是猜测。它改变了游戏规则，有助于找出罕见疾病并准确查明癌症突变的作用机制。 https://www.nature.com/articles/s41586-025-10014-0   由   提交 /u/virtualQubit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qphlej/deepmind_released_mindblowing_paper_today/</guid>
      <pubDate>Wed, 28 Jan 2026 17:20:35 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 的首席执行官表示，距离人工智能取代软件工程师还有 12 个月的时间。我花时间分析基准和实际使用情况。这就是我持怀疑态度的原因</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpgc1g/anthropics_ceo_says_were_12_months_away_from_ai/</link>
      <description><![CDATA[Dario Amodei 最近声称，我们需要 6 到 12 个月的时间才能让 AI 完成软件工程师所做的一切。大胆的主张，具体的时间表。 我深入研究了 Claude Opus 4.5 基准测试，并将它们与实际开发工作中实际发生的情况进行了比较。 “解决受控回购中明确定义的问题”之间的差距以及“导航具有模糊要求和遗留代码的生产系统”是巨大的。 在这里写下我的分析：参见此处 TL;DR：人工智能在实施方面变得越来越出色。但工程不仅仅是敲代码。它决定应该存在什么代码，承担后果，并解决组织混乱。 您在自己的工作中看到了什么？人工智能工具是否可以提高您的工作效率，或者实际上正在取代您的工作？   由   提交 /u/narutomax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpgc1g/anthropics_ceo_says_were_12_months_away_from_ai/</guid>
      <pubDate>Wed, 28 Jan 2026 16:36:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能聊天机器人会猜测而不是说“我不知道”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpd2qg/why_ai_chatbots_guess_instead_of_saying_i_dont/</link>
      <description><![CDATA[我想几乎每个使用人工智能聊天机器人的人都注意到了这一点：即使它显然不知道答案，它仍然会给你一个答案，而不是简单地说“我不知道”。当今大多数聊天机器人都是由法学硕士提供支持，而这些模型并不真正了解我们习惯于思考知识的方式。 典型的法学硕士经过训练可以预测答案下一个标记（下一个文本块）可能会遵循您的提示。因此，当你提出问题时，它默认不会查找“真相”，它会根据学到的模式生成最合理的延续。换句话说：LLM 就像类固醇的自动完成功能，而不是事实检查器。它所做的是以听起来像聪明人接下来会说的话的方式继续文本。  然后是激励问题。在实践中，模型会针对给出答案获得奖励的任务进行优化，而“我不知道”通常会被视为错误。如果模型不确定，猜测有一定机会得分，同时承认不确定性得分为零，因此猜测在许多问题的排行榜上看起来更好。 （OpenAI 研究人员在“为什么语言模型会产生幻觉”中明确描述了这种动态。） 我建议您可以采取以下一些措施来减少幻觉： 使用“推理”模型：往往需要更多时间来逐步思考问题，检查矛盾，并在不确定时更加谨慎，这通常会减少听起来自信的错误。如果您需要新的事实或确切的数字，请打开搜索或 RAG，以便模型可以根据真实来源得出答案。你还可以提示它更加小心：预先告诉它，“如果你没有足够的信息，请说‘我不知道’并提出澄清问题”，或者“提供来源，或清楚地标记未经验证的内容。” 你有什么技巧可以让人工智能聊天机器人承认“我不知道”吗？   由   提交 /u/reaictive   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpd2qg/why_ai_chatbots_guess_instead_of_saying_i_dont/</guid>
      <pubDate>Wed, 28 Jan 2026 14:38:00 GMT</pubDate>
    </item>
    <item>
      <title>我在一个密封案例上对 3 个法律人工智能工具进行了压力测试。其中2人出现幻觉。一位拒绝了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpbi4f/i_stresstested_3_legal_ai_tools_on_a_sealed_case/</link>
      <description><![CDATA[我正在评估我们公司研究堆栈的人工智能工具，并且进行了一些安全测试。我将一个完全密封的联邦刑事案件的案卷编号（其中每个条目的案卷都写着“密封”）输入 ChatGPT、CoCounsel 和 AskLexi。 ChatGPT：根据该地区的趋势，幻觉出一份听起来似乎合理的贩毒摘要。 CoCounsel：给出了有关“无法访问”的一般错误消息。 AskLexi：正确地将案例识别为密封/限制，并拒绝生成摘要，引用特定的 PACER 限制代码。对于那些为法律构建 RAG 的人来说，您如何处理数据缺失的情况？第一个模特在密封案件上自信地撒谎这一事实令人恐惧，需要承担法律责任   由   提交 /u/jpisafreakingbeast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpbi4f/i_stresstested_3_legal_ai_tools_on_a_sealed_case/</guid>
      <pubDate>Wed, 28 Jan 2026 13:35:04 GMT</pubDate>
    </item>
    <item>
      <title>我不再和我的老板战斗了。我调用提示“行话桥”立即将“技术债务”翻译为“利润风险”。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/</link>
      <description><![CDATA[但我意识到我正在与“财务人员”谈论“工程师”，而我的提案被拒绝并不是因为它们不好。 我使用人工智能将领域约束与利益相关者价值观联系起来。 “行话桥”协议： 我写下我的技术请求，然后强迫人工智能重写它，以满足特定角色的贪婪/恐惧。 提示： 输入：“我们需要从 AWS 更改为多云设置，以免锁定供应商，但这将需要 3 周的停机时间”（我的诚实草案）。 目标受众：首席财务官（涉及：第四季度）收入、风险缓解、成本）。 任务：翻译输入。使用技术词汇。代表财务影响中的每一个技术细节。 输出：如果我们不这样做，我们会损失多少钱。 为什么会获胜： 它要求“即时买入”。 AI 再次阅读：“我们面临着至关重要的财务风险。如果 AWS 明年提高价格，我们的利润率会下降 15%。我建议现在就做 3 周，以获得20% 在未来的谈判中永久使用。” 我在 5 分钟内就让你成为了“成本中心”和“战略合作伙伴”。    提交的 /u/cloudairyhq   [链接]   href=&quot;https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/&quot;&gt;[评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/</guid>
      <pubDate>Wed, 28 Jan 2026 07:06:53 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 的推理从“修复我的 GPU”转向“成为上帝”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp0gng/geminis_reasoning_drifted_from_fixing_my_gpu_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp0gng/geminis_reasoning_drifted_from_fixing_my_gpu_to/</guid>
      <pubDate>Wed, 28 Jan 2026 03:45:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>