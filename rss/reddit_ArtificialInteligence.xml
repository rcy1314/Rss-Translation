<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 27 Dec 2025 09:25:22 GMT</lastBuildDate>
    <item>
      <title>您的燃气/电费因数据中心需求而增加了多少？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwrz83/how_much_has_your_gaselectric_bill_increased_from/</link>
      <description><![CDATA[不确定所有这些没人要求的随机 AI 扩展是否值得我每月支付 500 美元来将恒温器保持在 60 度   由   提交 /u/STOP0000000X7B   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwrz83/how_much_has_your_gaselectric_bill_increased_from/</guid>
      <pubDate>Sat, 27 Dec 2025 07:33:22 GMT</pubDate>
    </item>
    <item>
      <title>反AI讽刺书</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwrti9/anti_ai_satire_book/</link>
      <description><![CDATA[我终于走出了困境，出版了我的讽刺儿童书，宣传 AI Slop 艺术的创作。这本书的标题是“婴儿的第一个人工智能故事”。我很好奇这个 Reddit 子版块中的人们如何看待人工智能以这种方式使用，特别是取笑它。 我把它放在 Kindle Unlimited 上只是因为我希望人们阅读它并评论它。希望这不算是自我推销。 目标受众是科技人员，或者作为给准父母和小孩父母的恶作剧礼物。 我这样做主要是为了我自己，但我希望人们看看。只有35页。请告诉我您的想法！ https://www.amazon.com/Babys-First-AI-Slop-Story-ebook/dp/B0GC4V457Z   由   提交/u/kazerman55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwrti9/anti_ai_satire_book/</guid>
      <pubDate>Sat, 27 Dec 2025 07:23:26 GMT</pubDate>
    </item>
    <item>
      <title>我发布了创建 llm 的原始说明</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwr7rj/i_released_the_original_instructions_to_create/</link>
      <description><![CDATA[呃。我无法发布图片。我无法发布链接。我如何证明我是谁。 https://x.com/i/status/2004796317525324023 Quora.com/robert_stork   由   提交 /u/Spiritual_Bottle1799   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwr7rj/i_released_the_original_instructions_to_create/</guid>
      <pubDate>Sat, 27 Dec 2025 06:47:24 GMT</pubDate>
    </item>
    <item>
      <title>人工智能 - 一年之后，一年之后</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwqhj1/ai_year_later_year_ahead/</link>
      <description><![CDATA[AI 有了一个良好的开端，但这仅仅是一个开始。如果你问我，我们只跑完了全程人工智能马拉松比赛的第一英里。而且它受到资金和电力等基础设施问题的严重制约。权力是房间里的大象（以及未来的杰克卡斯）的责任，即政府。中国很早就解决了这个问题，但由于计算能力的获取而受到阻碍，这给了美国人工智能堆栈喘息的空间。但不会太久。  一场类似于冷战时代的竞赛将有助于更快地达到 AGI，而且很可能美国堆栈会排在第一位，但现在它由山姆大叔安全地守护着。他们进展缓慢，直到 DeepSeek 出现，他们被迫在轨道上跑步，而不是漫步。 其结果是一系列模型的推出。最初，包括微软、Meta 等在内的所有人都在加快步伐，但它似乎正在融入 ChatGPT 和 Gemini 之间的两人竞赛。直到范式转变发生。 ”由   提交/u/i-ViniVidiVici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwqhj1/ai_year_later_year_ahead/</guid>
      <pubDate>Sat, 27 Dec 2025 06:04:42 GMT</pubDate>
    </item>
    <item>
      <title>我需要一个试点客户，但很难找到人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwnsc6/i_need_a_pilot_client_and_its_really_hard_to_find/</link>
      <description><![CDATA[我正在为我在海外的兄弟姐妹（我住在美国）建立一个网站，并致力于其 SEO 和 AI 可见性，我做了一项研究，发现了解 AI 以及它如何“看待”某家公司内容的需求正在远远超过供应量。所以我想出了一个想法来提高这种可见性。我构建了所谓的“AIVO Engine”人工智能可见性优化引擎，我在它上面花费了 500 多个小时，我在软件和站点可靠性工程方面拥有深厚的背景，我使用人工智能来帮助快速编码，我构建了架构和这个引擎以及一个营销网站、visibilitylens.com 和一个引擎的子域，人们可以在其中运行测试分析、创建帐户、登录......等。 aivoengine.visibilitylens.com  以下是该引擎简单明了的功能： 它抓取一个网站，提取所有页面，然后按 4 个不同类别（感知、意图覆盖、语义覆盖和实体信号）对每个页面进行分析，分析是使用 Claude Sonnet 4 API 完成的。 （我不想透露核心工作原理的细节） 我在我兄弟的网站上使用了它，两周后它开始被 chatgpt 列为第一服务。  底线，我知道我构建的东西非常好，但我不知道营销它的最佳方式是什么。我正在尝试一些社交媒体，并试图与人们建立联系……等等，但我真的需要一个可以提升我水平的试点客户端（除了我兄弟的网站） 我欢迎任何与上述相关的评论以及关于如何营销的任何建议（根据我迄今为止的经验，人工智能并不是最好的营销理念）   由   提交 /u/bhannik-itiswatitis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwnsc6/i_need_a_pilot_client_and_its_really_hard_to_find/</guid>
      <pubDate>Sat, 27 Dec 2025 03:43:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么对人工智能泡沫破灭的预期没有导致它已经破灭？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwnal3/why_doesnt_anticipation_of_the_ai_bubble_bursting/</link>
      <description><![CDATA[我到处都有文章不断谈论我们现在正处于人工智能泡沫之中，而且泡沫即将破裂。但如果情况确实如此，而且人们真的相信这一点，那么是什么阻止它已经破裂呢？为什么对人工智能泡沫的恐惧不会引起大规模恐慌并导致先发制人的破裂？  上次我检查时，OpenAI 仍然需要数十亿美元的资金，而且他们最近才转向营利性商业模式，所以我不知道他们是否已经开始赚钱了。与微软一样，他们似乎在人工智能的采用方面举步维艰。 是什么让一切保持在一起？    由   提交 /u/frenetic_alien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwnal3/why_doesnt_anticipation_of_the_ai_bubble_bursting/</guid>
      <pubDate>Sat, 27 Dec 2025 03:19:09 GMT</pubDate>
    </item>
    <item>
      <title>训练模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwn7z0/training_models/</link>
      <description><![CDATA[是否可以根据电影风格训练模型/Lora？例如，如果你拍摄一部经典的迪士尼电影并将其输入人工智能（完整的或逐帧的），它是否能够准确地重新创建动画的复杂性？我一直在与双子座尝试这一点，但收效甚微。我发现，如果你告诉它“制作一个自然的延续帧”，它会专注于二维动画中描绘的传统简约运动，但每个图像都会变得更加像素化。对此事有什么想法或想法吗？我知道迪士尼与索拉达成协议，因此它将能够使用受版权保护的角色，但这能够捕捉到魔法吗？我认为绝对不是，但作为一个不会画画但喜欢写作的人，有一个工具可以看看一部心爱的童年电影的续集如果很好的话会是什么样子，而不是像他们推出的直接 DVD 续集。   由   提交/u/KaminariDenki24  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwn7z0/training_models/</guid>
      <pubDate>Sat, 27 Dec 2025 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>我可能不会构建下一个大型人工智能产品，所以我一直在研究一些小而奇怪的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwkx5y/im_probably_not_going_to_build_the_next_big_ai/</link>
      <description><![CDATA[我不是在研究前沿模型，我也不期望在人工智能方面取得任何重大突破。因此，我一直把时间花在一些小型的、稍微奇怪的实验上，试图回答关于神经网络实际上能做什么和不能做什么的狭隘问题。 这是一项非常基本的技能：数字相加。 我想要理解的是......当神经网络添加数字时，它实际上是在学习加法的过程，还是主要通过示例进行模式匹配？ 这听起来很微不足道，但一旦你关心它，就会发现它非常微妙。关于这样的事情：  携带数字 在正确的时间停止 处理比训练期间看到的任何数字都长的数字  我将数字表示为我称之为“肢体”的块，而不是十进制数字。每个分支存储一个 0-99 之间的值（大约两位小数）。数字只是肢体的列表，从最不重要的开始。两个数字被打包到一个列表中，如下所示：[A 四肢] | [分隔符] | [B肢体] 每个肢体都是一个令牌。短数字会被填充，以便所有内容都对齐。这使得缩放变得容易，大约 100 个十进制数字 ≈ 50 个肢体。 模型做了两个不同的事情： 1) 一旦 Transformer 读取两个数字的整个肢体列表并为每个位置生成一个向量，就读取所有内容。您可以将其视为创建一堆带标签的槽，例如“A 数字 3”或“B 数字 7”。 2) 一次遍历一个数字，然后从最低有效数字开始，一个小循环遍历这些槽。 每一步，它都会从 A 中拉出一个肢体，从 B 中拉出一个肢体，保留内部“进位”存储器，输出下一个结果数字，并决定是否完成。因此，它被迫表现得更像长加法，而不是一次性猜测整个答案。 一种无聊的失败模式是进位不会经常发生，因此模型只能学习“进位基本上总是零”。 为了避免这种情况，我故意偏置大量训练示例，因此进位频繁发生，并且我仅在实际需要进位的步骤上跟踪准确性。如果它不能正确完成这些，那么它还没有真正学会加法。 我不只是检查训练的准确性。我进行了一些健全性检查。  精确匹配：它得到的整数是否正确？ 进行消融：如果我在测试时将进位内存清零，性能会崩溃吗？ 较长的数字：训练较短的数字，然后测试从未见过的更长的数字  如果它仍然适用于较长的数字，这至少是它学习通用程序的一些证据记住模式。 我不认为这会带来什么大的结果。但是，探究这些微小的、受控的问题感觉像是一种探索神经网络的局限性和故障模式的好方法，而不需要大量的计算或广泛的声明。 如果不出意外的话，这提醒我们，一旦你询问模型实际上是如何做到这一点的，即使是加法这样的“简单”事情仍然隐藏着许多有趣的行为。 我不能说我已经取得了很好的结果..在当前的排列中，当在 16 条腿上进行训练时，它的准确度为32条腿只占~64%。但这是我可以在一台笔记本电脑上玩的东西，它让我探索一些有趣的（至少对我来说）角度..例如将较小的模型与插槽内存和迭代相结合，而不是仅仅尝试变大。  无论如何，我想要理解的是为什么潜在插槽内存似乎会随着使用量的增加而降低。在多达 16 条腿（它所训练的腿）上，它的准确率几乎达到 100%。当模型中有正确的数字要相加时，处理加法的部分可以以 100% 的准确度执行。随着问题规模的增加，性能似乎会稳步下降。   由   提交 /u/IWantAGI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwkx5y/im_probably_not_going_to_build_the_next_big_ai/</guid>
      <pubDate>Sat, 27 Dec 2025 01:25:59 GMT</pubDate>
    </item>
    <item>
      <title>AGI 如何可能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwew9l/how_is_agi_even_possible/</link>
      <description><![CDATA[去年对于人工智能来说是伟大的一年，我确信明年会在长期记忆、潜在思维、世界模型、持续学习等方面带来一些重大进展 但从一段时间以来，我脑海中一直有一个挥之不去的问题：AGI 现在如何成为可能。在我看来，当前的模型在很多方面落后于人类大脑  架构 人类大脑肯定有某种专门的分形架构，经过数百万年的综合进化搜索而达到。至少可以说，当前的模型架构非常简单  学习算法 我们不知道大脑使用什么学习算法，但它们绝对比我们的要优越得多。无论是在样本效率还是泛化方面。我毫不怀疑它是某种元学习来决定使用哪种算法来执行哪个任务。但我们离这样的系统还很遥远  可塑性 这很难建模。将神经网络作为密集矩阵的运算具有极大的限制性，我认为在这种限制下不可能实现最佳架构搜索  计算 这对我来说是最明显和最大的危险信号。据估计，我们的大脑有大约 400-500 万亿个突触，每个突触并不能转化为单一的重量。使用神经网络复制单个突触输出的实验需要具有 1000 个参数的 MLP。但即使保守估计，Gemini 3 Pro 的容量也比人脑小 100,000 倍左右（与我们拥有的兆瓦型号相比，其运行功率为 20 瓦）。我们如何开始缩小这个巨大的差距？   这甚至不包括我确信有很多未知的未知因素。我对那些认为 AGI 即将到来或几年后就出现的人感到非常困惑。我缺少什么？是不是认为大脑的大部分区域不参与思考或对智力没有贡献？或者硅是一种更有效、更自然的智能基质，这些限制并不重要？   由   提交 /u/pyrolid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwew9l/how_is_agi_even_possible/</guid>
      <pubDate>Fri, 26 Dec 2025 21:00:37 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在改变初学者学习编码的方式吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwettn/is_ai_changing_how_beginners_learn_to_code/</link>
      <description><![CDATA[我的表弟开始学习编码，看着他的过程让我思考了很多关于当今初学者如何学习的问题 他从 Python 开始，很快就表示他想进入 ML 和数据相关的领域。让我惊讶的是，他的学习从一开始就依赖人工智能。 每当有东西不起作用时，他就问人工智能，每当他看到错误时，他就问人工智能，即使事情正常，他仍然要求人工智能重写或解释代码 表面上看起来很棒，他动作很快，快速构建小东西，几乎不会长时间卡住 但就我个人而言，我认为这可能是一个问题:/ 感觉好像缺少很多批判性思维部分，就像在学习时，我花了几天时间为 bug 绞尽脑汁，阅读文档，尝试失败的事情，并慢慢理解为什么某些事情有效或无效，这种斗争是痛苦的，但它迫使我思考和推理！ 和他一起，我有时觉得答案来得太快 像 BlackBox、Claude 和 Cursor ha 这样的工具确实很酷而且很有用，但我并不总是确定他理解背后的推理 我并不是说人工智能不好，它显然很强大而且很有帮助但我确实想知道，过早依赖它的初学者是否可能会失去一些过去自然发展的解决问题的能力 人工智能是否正在改变初学者以健康的方式学习编码的方式？或者我们是否正在用深刻的理解和批判性思维来换取速度和便利？   由   提交/u/PishingWedding   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwettn/is_ai_changing_how_beginners_learn_to_code/</guid>
      <pubDate>Fri, 26 Dec 2025 20:57:51 GMT</pubDate>
    </item>
    <item>
      <title>我们是否训练人工智能听起来很自信，而不是注意它何时可能是错误的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwdll8/are_we_training_ai_to_sound_confident_instead_of/</link>
      <description><![CDATA[最近感觉大多数人工智能进步都是关于更流畅的答案和更好的语气即使底层信号不稳定，模型也会快速、干净、自信地响应 但在实际工作中，最困难的部分不是得到答案，而是意识到有些事情不成立，或者问题本身是错误的 人类会犹豫、自相矛盾、抱怨、反悔，很多洞察力正是在这种混乱中存在 我一直在想，通过如此努力地优化完美的输出，我们是否会失去一些重要的东西。不是准确性，而是尽早发现不确定性和差距的能力 当前的训练方法推动模型听起来正确，而不是帮助我们注意到缺失的内容？   由   提交/u/Mediocre_Common_4126  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwdll8/are_we_training_ai_to_sound_confident_instead_of/</guid>
      <pubDate>Fri, 26 Dec 2025 20:06:13 GMT</pubDate>
    </item>
    <item>
      <title>AI辅助预测维护</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwchzy/aiassisted_predictive_maintenance/</link>
      <description><![CDATA[您好！我是一名专门从事工业维护的机械工程专业的学生，​​在我的毕业项目中，我正在为燃气轮机子系统开发和实施人工智能辅助预测维护系统，该系统使用历史和模拟操作数据检测与单一、明确定义的故障模式相关的早期异常，该系统估计剩余使用寿命 (RUL) 并通过模拟 CMMS 工作流程自动生成维护建议和工单。  现在我对人工智能或开发它没有任何背景，我已经使用Matlab进行了很多项目，并且在大学中我们确实使用FFT对设备运行期间的振动误差进行了一些数据处理。  我只是想要一些关于此的建议，特别是如何制作模型的架构，或者我应该从什么开始作为人工智能的基础？    由   提交 /u/EvelyneRe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwchzy/aiassisted_predictive_maintenance/</guid>
      <pubDate>Fri, 26 Dec 2025 19:20:33 GMT</pubDate>
    </item>
    <item>
      <title>扩散法学硕士与自回归法学硕士</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pwatca/diffusion_llm_vs_autoregressive_llm/</link>
      <description><![CDATA[当今人们使用的大多数法学硕士（GPT、Claude、Gemini 等）都共享相同的核心假设，从左到右一次生成一个令牌。  这就是自回归设置。它工作得非常好，但它带来了一些结构性问题： • 延迟：您必须进行令牌→令牌→令牌。即使堆栈中具有并行性，生成步骤本身也是串行的。  • 成本：如果您需要 200-500 个输出令牌，则需要对上下文的某些切片进行 200-500 次前向传递。加起来很快。  • UX 上限：对于许多交互式用例，尤其是代码和 UI 嵌入式助手，1-3 秒的延迟已经太慢了。另一方面，有一种非常不同的方法，但在研究圈之外却很少受到关注：扩散语言模型。  不要“写下一个单词”，而是：  从对整个答案（序列）的嘈杂猜测开始。  以固定数量的步骤优化整个序列，并行更新多个标记。您支付固定数量的优化步骤，而不是“每个令牌一个步骤”。   在小/中规模下，我们已经看到： • 与速度优化的自回归模型（Claude Haiku、Gemini Flash）类似的质量，延迟提高了 5-10 倍）... • ...延迟有数量级的改进，因为您可以利用硬件已经想要提供给您的并行性（GPU/TPU）。这对于以下方面特别有趣：  • 低延迟应用程序（代码自动完成、内联帮助程序、产品内的代理）。  • 在大容量工作负载中，将推理成本削减 5-10 倍比挤出最后一个基准点更重要。显然，扩散法学硕士不是免费的午餐： • 培训更加复杂。  • 您需要仔细的文本序列表示和噪声表。  • 工具和服务基础设施针对自回归 LLM 进行了优化  但从我所在的位置（与构建和部署基于扩散的语言模型的团队合作）来看，感觉该领域对自回归存在巨大的路径依赖偏见，因为首先训练和部署更容易，不一定是因为它是最终状态。   由   提交 /u/InceptionAI_Tom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pwatca/diffusion_llm_vs_autoregressive_llm/</guid>
      <pubDate>Fri, 26 Dec 2025 18:11:30 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在成为一个思考伙伴，还是只是一个非常快速的捷径？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pw0xxz/is_ai_becoming_a_thinking_partner_or_just_a_very/</link>
      <description><![CDATA[最近我注意到人们使用人工智能的两种截然不同的方式。有些人将其视为合作者——提出问题、完善想法、大声思考。其他人则纯粹将其用作捷径——获得输出，继续前进，不要想太多。两者似乎都有效，但随着时间的推移，它们会导致截然不同的结果。我很好奇这里的人们如何看待它。您认为人工智能是否可以帮助您更好地思考，或者主要帮助您更快地完成事情？希望听到不同的观点。   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pw0xxz/is_ai_becoming_a_thinking_partner_or_just_a_very/</guid>
      <pubDate>Fri, 26 Dec 2025 10:09:14 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>