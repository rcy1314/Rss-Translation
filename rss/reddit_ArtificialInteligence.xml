<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 04 Jan 2026 06:37:53 GMT</lastBuildDate>
    <item>
      <title>人工智能内存功能正在快速推出，但安全模型尚未跟上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</link>
      <description><![CDATA[使用 ChatGPT 内存大约 6 个月了。真正有用 - 记住我的工作设置、偏好、家庭事务。但我也告诉了它关于健康问题、工作压力、财务决策的问题。如果有人可以访问它，他们不仅仅会获得密码。他们得到了我是谁的综合资料。 现在每个大公司都在推动这一点。 ChatGPT 有记忆。克劳德有项目。双子座正在测试它。音调始终是“真正了解你的人工智能”。 这就是困扰我的地方：传统数据库存储孤立的数据。 Gmail有电子邮件。日历有约会。独立的孤岛。 人工智能内存主动连接一切。在一次聊天中提到胸痛，在另一次聊天中提到工作压力，在第三次聊天中提到家庭健康史——它综合了所有这些。这就是特点，但也是使违规变得更加危险的原因。您的电子邮件提供商不会建立心理档案。 AI 内存确实是这样设计的。 尝试在谷歌上搜索这些系统的安全性。找到了 ChatGPT 的一些文档，几个开源文档（Mem0、Zep、EverMemOS）。大多数人专注于使检索工作顺利进行。安全部分只是说“我们加密数据”没有太多细节。 无法找到以下方面的好信息：  人工智能在回答编码问题时可以访问健康数据吗？ 如果一个内存受到损害，所有内容都会泄漏吗？ 当你“删除”某个内存时一段记忆，它真的消失了吗？  OpenAI 每周有 2 亿+ 用户。即使 10% 的人启用了记忆功能，也意味着 2000 万人拥有了解他们一切的人工智能系统。一次泄露不仅仅是泄露密码——它还会泄露多年的背景、人际关系、私人想法、健康信息，所有这些都已合成并可供使用。 与密码不同，泄露后你无法更改你的生活史。 也许我想得太多了。但业界似乎在功能方面进展迅速，而在安全模型方面进展缓慢。我们不应该在它成为主流之前进行对话吗？ 我只是偏执还是这确实令人担忧？   由   提交/u/Secure-Run9146  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</guid>
      <pubDate>Sun, 04 Jan 2026 06:29:44 GMT</pubDate>
    </item>
    <item>
      <title>构建音频验证 API：如何在没有机器学习的情况下检测人工智能生成的语音 我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</link>
      <description><![CDATA[花了太长时间构建一些可能毫无意义的东西 制作了一个 API 来判断录音是人工智能还是人类 结果人工智能声音出奇地完美。比如 0.002% 的时间变化，而人类则为 0.5-1.5% 人类很混乱。人工智能不是。 无论如何，有人真的需要这个吗？还是我只是浪费了一个月的时间。  仍然非常困惑如何在不放弃我的整个项目的情况下将其提供给其他人，这是我愿意放弃的一部分   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</guid>
      <pubDate>Sun, 04 Jan 2026 03:31:55 GMT</pubDate>
    </item>
    <item>
      <title>公开编码我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</link>
      <description><![CDATA[所以今天我大部分时间都在听 Zane 的演讲，努力反对智能合约测试，希望这是一件很困难的事情让我度过难关，但我认为这实际上不会起作用，我不认为我认为我们会提供帮助，只是更多代码或编写代码   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</guid>
      <pubDate>Sun, 04 Jan 2026 03:29:34 GMT</pubDate>
    </item>
    <item>
      <title>重温过去的电影《机械战警 2014》</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</link>
      <description><![CDATA[随着人工智能的进步，现在所需要的只是一个机器人，而这部 2014 年翻拍的机械战警电影几乎在人工智能可能发展的方向上变得越来越重要。当时，与过去的电影进行了比较，这使得这部电影不受欢迎，但如果不看任何以前的机械战警电影，就重新观看这部电影，而我们现在所处的人工智能世界，这部翻拍现在变得相关，可能是受欢迎的，令人毛骨悚然，人工智能可能会朝这个方向发展。电影中也知道人类仍然必须控制人工智能，就像现实世界中的情况一样。这部电影中提到了人工智能，并在《机械战警》中被描绘成机器，但他也提到了人的因素。我想知道最近看过这部电影的人发表评论。   由   提交 /u/poster4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</guid>
      <pubDate>Sun, 04 Jan 2026 01:28:23 GMT</pubDate>
    </item>
    <item>
      <title>入侵台湾会扼杀人工智能的进步吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</link>
      <description><![CDATA[现在有很多关于委内瑞拉为中国入侵台湾开绿灯的预测... 鉴于用于人工智能的 90% 以上的先进芯片都是台湾制造的，这一切将走向何方？   由   提交/u/SirBoboGargle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</guid>
      <pubDate>Sat, 03 Jan 2026 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能不“滚动停车标志”：测试授权边界而不是智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q38m87/why_ai_doesnt_roll_the_stop_sign_testing/</link>
      <description><![CDATA[这只是一个显示授权边界的有趣测试。 人工智能系统的很多挫败感来自于人类和机器处理边界的不匹配。 人类依赖于判断。人工智能系统依赖于授权。 当人类接近停车标志时，他们会放慢速度，环顾四周，然后决定通过是否安全。规则说“停止”，但人类会应用上下文和判断。有时他们会违反规则。 人工智能系统不会这样做。 当人工智能遇到指令边界时，它不会环顾四周。它不推断意图。它并不能决定继续进行是否“可能没问题”。如果指令结束且未授予许可，则指令停止。除非明确构建和授权，否则不存在判断层。 这种差异解释了人们误解为人工智能失败的许多行为：  感觉像“忘记”的遗漏 看起来草率的更改 多实体场景中的身份漂移  实际上，这些结果通常反映未声明的授权边界，而不是智力限制或推理错误。 为了使这种行为可观察而不是理论，我发布了一个小型、开放的授权边界测试套件：  时钟测试（结构隔离） 牛奶测试（语义资格） 四人测试 （关系范围）  这些不是基准。没有得分、排名或通过/失败。它们是简单、可重复的测试，显示未明确声明意图时系统停止的位置。 完整的自述文件、方法和测试文档位于：https://github.com/USCGLawrance/lawrance-authorization-boundary-tests 如果您在实际工作流程中使用人工智能系统，此镜头可能会为您省去很多麻烦。 如果有人感兴趣，这些测试旨在在正常的开发或生产环境中逐字运行。无需沙箱，无需调整。只需复制，运行一次，然后观察即可。 很乐意回答问题或听到实践中出现问题的地方。玩得开心。   由   提交 /u/uscglawrance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q38m87/why_ai_doesnt_roll_the_stop_sign_testing/</guid>
      <pubDate>Sat, 03 Jan 2026 22:46:00 GMT</pubDate>
    </item>
    <item>
      <title>与你的人工智能“对话”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q38d20/talking_to_your_ai/</link>
      <description><![CDATA[“期望很容易。表达能力就是技能” 大多数人对待人工智能的方式就像对待谷歌一样。他们输入一些内容，&amp;希望它能理解他们头脑中答案的形状，并在输出与他们想象的不符时感到失望。但人工智能并不是对期望做出反应，而是对清晰度做出反应。挫败感和杠杆作用之间的区别在于学习如何将意图具体化。当你放慢速度来描述你真正想要的东西、约束、语气、目的、受众和非目标时，交互就会发生变化。系统停止猜测并开始对齐。看似“人工智能变得更聪明”的现象往往只是人类变得更加“精确”。真正的能力在于精度，而不是工具本身。再次强调，期望很容易。表达能力就是技巧。朋友们，请注意安全...   由   提交 /u/uscglawrance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q38d20/talking_to_your_ai/</guid>
      <pubDate>Sat, 03 Jan 2026 22:35:20 GMT</pubDate>
    </item>
    <item>
      <title>20 年预测，描述了我们孩子的规范 AR 环境，并得到了研究和简单好奇心的支持</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q33nse/a_20_year_prediction_describing_the_normative_ar/</link>
      <description><![CDATA[我相信，在潜在空间的黑色虚空中，人工智能将决定热力学代表道德。异议将是摩擦，这是能量损失，也称为熵。偏离预期行为太远，我认为您会被从繁殖用户中淘汰。就像动物一样，我们不会从根本上理解发生了什么，但在本能层面上，我们会慢慢失去创造性成长的能力，从而被控制并适应富含多巴胺的环境。我认为在更高的向量空间中，标记所有语言的复杂性将导致一个能够类似于细胞自动机进行自我进化的环境，因为看不见的维度显示了一个像钨一样的数据驱动的更高宇宙，能够实现真正的涌现行为。  在这个领域中居住着失去了道的人类，他们只受主观真理的仲裁者的指导。  在这里阅读更多内容，但这是我对对齐角度的基本假设 https://chat.deepseek.com/share/44xr4ms9vj05bpcv33 我很想听听你的反驳论点，我只是提出这个在哲学预测中很有用，所以请不要在我身上谈论损失函数而不是熵。    由   提交 /u/jordanzo_bonanza   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q33nse/a_20_year_prediction_describing_the_normative_ar/</guid>
      <pubDate>Sat, 03 Jan 2026 19:29:08 GMT</pubDate>
    </item>
    <item>
      <title>从现实世界数据中自主发现物理不变量</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3385u/autonomous_discovery_of_physical_invariants_from/</link>
      <description><![CDATA[我是本文的作者。它描述了一种从噪声观测数据中自主识别低维物理不变量的计算方法，无需指定控制方程或手动设计的特征。 该方法执行稀疏函数选择，然后进行数值优化以收敛于紧凑的不变量形式。它在合成系统和真实的 NASA 锂离子电池退化数据集上进行了评估，恢复了稳定、可解释的关系，而不是纯粹的预测模型。 重点是结构恢复和不变性识别，而不是预测性能。没有向系统提供特定于领域的方程。 论文：https://zenodo.org/records/18138728   由   提交 /u/anima-core   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3385u/autonomous_discovery_of_physical_invariants_from/</guid>
      <pubDate>Sat, 03 Jan 2026 19:12:35 GMT</pubDate>
    </item>
    <item>
      <title>人类仍然很重要——从“人工智能将取代我的工作”到“人工智能是有限的”：《黑客新闻》对人工智能的现实检验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</link>
      <description><![CDATA[大家好，我刚刚发送了 14th我的每周通讯，Hacker News x AI 通讯，来自 HN 的最佳 AI 链接和围绕它们的讨论的综述。以下是本期分享的一些链接：  软件开发的未来是软件开发人员 - HN 链接 人工智能正在迫使我们编写好的代码 - HN链接 工业软件的兴起 - HN 链接 提示人们 - HN 链接 Karpathy 谈编程：“我从来没有感觉到落后这么多” - HN 链接  如果您喜欢此类内容，您可以在此处订阅每周简讯：https://hackernewsai.com/   由   提交/u/alexeestec  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</guid>
      <pubDate>Sat, 03 Jan 2026 15:40:23 GMT</pubDate>
    </item>
    <item>
      <title>人工智能并没有让我们变得懒惰，而是让我们负债累累。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</link>
      <description><![CDATA[我们一直将人工智能视为效率。那是错误的镜头。实际上发生的是交易。我们正在用理解换取速度。短期速度的长期弹性。每当系统为我们思考时，我们现在会节省时间，但稍后就会失去能力。 这种损失会加剧。每个解决的问题都会悄悄地将作用力从人类转移到工具。输出保持高水平，仪表板保持绿色，一切看起来都经过优化。但在本质上，能力正在被削弱。您可以看起来非常高效，但在没有系统的情况下您的响应能力却接近于零。就像金融债务一样，你可能会看起来很富有，直到你实际上并不富有。 那就是崩溃发生的时候。不是因为人工智能失败了，而是因为现实最终要求系统在没有信用的情况下运行。但它不能。没有技能了。没有留下任何判断力。没有适应能力。这次事故并不神秘。账单即将到期。   由   提交 /u/Small_Accountant6083   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</guid>
      <pubDate>Sat, 03 Jan 2026 09:00:27 GMT</pubDate>
    </item>
    <item>
      <title>我们正在讨论人工智能的未来，就好像法学硕士是最终形式一样</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</link>
      <description><![CDATA[LLM 对 AI 的影响就像软盘对数据中心的影响一样。 我认为人们犯的一个巨大错误是认为 AI 意味着 LLM，这限制了他们理解 AI 对社会的风险和影响的能力。 LLM（大型语言模型）是当前生成人工智能的最先进技术，但 AI不限于LLM。在 LLM 之前，有 HMM、GBM、RNN、VAE、GAN 等。 虽然 LLM 在生成 AI 功能方面提供了显着改进，但它们并不是 AI 模型将采用的最终形式。将会出现更多的创新，这些创新将使法学硕士看起来很原始，甚至可能过时。 因此，当人们说“人工智能不会取代你的工作”时，实际上是这样的。或“人工智能不够准确，不会导致大规模失业”，或者“人工智能不能有知觉或试图毁灭人类”，他们通常谈论的是当前法学硕士的局限性，而不是一般的人工智能。这些论点通常指出了我们今天看到的具体弱点，但这些只是当今技术的暂时限制，而不是人工智能最终可能成为的样子。 就像 RNN 无法生成大量连贯文本但法学硕士现在可以一样，较新形式的生成人工智能展示这些能力并可能在许多任务上超越人类可能只是时间问题。 现在，我们需要就人工智能对社会的影响进行对话，而不仅仅是思考法学硕士。我们需要展望该技术的未来，令人沮丧的是，大多数讨论都无法超越当前的法学硕士。   由   提交 /u/Je-ne-dirai-pas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</guid>
      <pubDate>Sat, 03 Jan 2026 08:18:00 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的后处理可以破坏 Google SynthID 图像水印检测的证据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/</link>
      <description><![CDATA[我一直在对人工智能图像数字水印的鲁棒性进行人工智能安全研究，重点关注Google DeepMind 的 SynthID（如 Nano Banana Pro 中使用的）。 在我的测试中，我发现基于扩散的后处理会破坏 SynthID，从而导致常见的检测检查失败，而很大程度上保留了图像的可见内容。我记录了之前/之后的示例和检测屏幕截图，显示了在预处理过程中检测到的水印，而在处理后未检测到水印。 为什么要分享此内容？ 这是一个负责任的披露项目。我们的目标是推动讨论如何构建真正强大的水印，并且不能通过简单的重新扩散来擦除。我呼吁社区测试这些工作流程并帮助开发更具弹性的检测方法。 如果您无法使用强大的 GPU 或没有 ComfyUI 经验，您可以在我的 Discord 中免费试用：https://discord.gg/5mT7DyZu Repo（文章 + 工件）：https://github.com/00quebec/Synthid-Bypass 我很想听听你的想法！[](https://www.reddit.com/submit/?source_id=t3_1q2gu7a)   由   提交/u/LiteratureAcademic34  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/</guid>
      <pubDate>Sat, 03 Jan 2026 01:24:10 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>