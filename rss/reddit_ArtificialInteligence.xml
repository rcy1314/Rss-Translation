<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 17 Oct 2025 03:35:55 GMT</lastBuildDate>
    <item>
      <title>Windows 11 开始倾听您的声音。字面上地。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8qc6n/windows_11_is_starting_to_listen_to_you_literally/</link>
      <description><![CDATA[微软 希望用户通过新的人工智能功能与 Windows 11 进行对话 因此微软正在 Windows 11 中测试新的人工智能功能。显然，你很快就可以说“嘿副驾驶”并要求你的计算机执行诸如打开应用程序、整理文件或从电子邮件或日历中提取信息等操作。 他们还添加了名为“副驾驶视觉”的功能，它可以“看到”你的 桌面并帮助设计想法或检测您正在处理的内容中的错误。这就像操作系统本身正在变成一个助手。 不过我很好奇。有人真的想与他们的电脑交谈吗？比如，这真的会让 Windows 更容易使用，还是只是减慢它的速度？ 从隐私角度来看，我们对人工智能能够查看的感觉如何 在你的屏幕上？我知道它很有用，但感觉也有点奇怪。   由   提交 /u/Designer_Possible633   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8qc6n/windows_11_is_starting_to_listen_to_you_literally/</guid>
      <pubDate>Fri, 17 Oct 2025 03:08:01 GMT</pubDate>
    </item>
    <item>
      <title>NFL 在比赛中使用人工智能技术</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8pzo1/nfl_using_ai_technology_during_their_games/</link>
      <description><![CDATA[https://www.nbcnews.com/video/nfl-using-ai-technology-during-their-games-250067013728 您认为这种技术是改善游戏还是消除人为因素？   由   提交 /u/Designer_Possible633   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8pzo1/nfl_using_ai_technology_during_their_games/</guid>
      <pubDate>Fri, 17 Oct 2025 02:50:42 GMT</pubDate>
    </item>
    <item>
      <title>像 Lovable 这样的网站建设者 LLM 代理如何处理工具调用、循环和提示一致性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8ptf3/how_do_website_builder_llm_agents_like_lovable/</link>
      <description><![CDATA[不久前，我发现了一个 GitHub 存储库，其中包含几个主要网站构建器使用的提示。让我惊讶的一件事是，所有这些构建器似乎都依赖于单一、非常详细且全面的提示。该提示定义了可用的工具，并提供了 LLM 应如何使用它们的详细说明。 据我了解，该过程的工作原理如下：  系统向模型提供上下文和用户指令的混合。 模型通过生成工具调用进行响应 - 有时在一个响应中多次，有时按顺序。 每个工具的输出然后反馈到同一提示中，重复进行 如此循环，直到模型最终产生响应没有任何工具调用，这表明任务已完成。  我正在专门查看Lovable的提示（将其链接到此处 参考），我对它在实践中如何实际工作有几个问题： 但是，我有一些事情让我感到困惑，我希望有人可以分享这些事情的见解：  混合响应： 据我所知，模型的响应可以包括工具调用和常规解释文本。这是正确的吗？我在 Lovable 的提示中没有看到任何明确将其仅限于工具调用的内容。 解析器和格式：我怀疑一定有一个解析器来处理工具调用。提示包括以下行：“切勿进行可以组合的连续工具调用。”但它没有解释如何区分“组合”调用和“顺序”调用。  这是否意味着一个输出中的多个工具调用被视为“批量”，而一次一个调用被视为“顺序”？ 如果是这样，什么可以防止模型产生一些不明确的内容，例如：“一起运行这两个，然后再运行这个。”  工具调用一致性：Lovable 如何确保 工具调用语法保持一致吗？是否只是通过重复的反馈循环直到生成正确的格式？ 代理循环机制：代理循环实际上只是： 将完整回复传递回模型（带有系统提示）， 重复直到模型停止生成工具调用， 然后检测此条件并将最终响应返回给用户？  代理工具和外部模型：这些代理工具理论上可以包含对另一个 LLM 的调用，还是仅限于常规的基于代码的工具？ 上下文注入：在 Lovable 的提示（以及我见过的其他提示）中，诸如上下文、最后一条用户消息等变量并未明确包含在提示文本中。  这些变量是在哪里以及如何注入的？ 还是为了简单起见，在公共版本中省略了它们？   我可能在这里遗漏了一块拼图，但我真的很想建立一个清晰的心理模型，说明这些网站构建器架构如何在高层次上实际工作。 很想听听您的见解！   由   提交/u/Ok-War-9040   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8ptf3/how_do_website_builder_llm_agents_like_lovable/</guid>
      <pubDate>Fri, 17 Oct 2025 02:42:23 GMT</pubDate>
    </item>
    <item>
      <title>专注于临床决策的个性化聊天</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8p9pd/personalized_chat_focused_on_clinical_decisions/</link>
      <description><![CDATA[你好，我是一名兽医，我觉得任何人工智能要么对医疗咨询不利，要么当它有好处时它专注于人类医学而不是兽医学。我想托管一个像 ollama 或类似的本地人工智能系统，并且我希望它使用我本地的离线 PDF 学术书籍图书馆作为咨询来源。 这实现起来有多困难？   由   提交/u/mhoweler  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8p9pd/personalized_chat_focused_on_clinical_decisions/</guid>
      <pubDate>Fri, 17 Oct 2025 02:16:11 GMT</pubDate>
    </item>
    <item>
      <title>[研究]礼貌的提示可能会降低人工智能的准确性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8p7lp/research_polite_prompts_might_make_ai_less/</link>
      <description><![CDATA[来源： https://www.arxiv.org/pdf/2510.04950 有趣的发现：这项研究表明，对于 对于法学硕士，在提示中过于礼貌实际上可能会降低表现。更直接甚至生硬的语气有时可以带来更准确的结果。 虽然这是关于人工智能的技术见解，但它也是对一般沟通的一个很好的提醒。无论是对于人类还是机器，语气确实很重要。   由   提交/u/AIMakesChange  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8p7lp/research_polite_prompts_might_make_ai_less/</guid>
      <pubDate>Fri, 17 Oct 2025 02:13:26 GMT</pubDate>
    </item>
    <item>
      <title>新研究表明，使用人工智能会降低医生发现癌症的技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8mvzo/new_study_suggests_using_ai_made_doctors_less/</link>
      <description><![CDATA[ https://time.com/7309274/ai-lancet-study-artificial-intelligence-colonoscopy-cancer-detection-medicine-deskilling/ 多年来，医疗从业者、公司和其他人士一直对人工智能在医学领域的潜在好处表示欢迎，通过改善医疗 在诊断评估中向表现出色的医生进行成像。人工智能爱好者甚至预测这项变革性技术有一天会帮助找到“癌症治疗方法”。 但一项新研究发现，经常使用人工智能的医生实际上在几个月内变得技能水平下降。 这项研究于周三发表在 《柳叶刀胃肠病学和肝病学》期刊00133-5/abstract）发现，在六个月的时间里，临床医生变得过度依赖人工智能建议，变得“缺乏动力、缺乏动力” 在没有人工智能辅助的情况下做出认知决策时，注意力集中，责任感降低。” 这是一项最新研究，旨在证明人工智能用户可能产生不利后果。麻省理工学院的一项早期研究发现，ChatGPT 侵蚀了批判性思维能力。   由   提交 /u/AmorFati01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8mvzo/new_study_suggests_using_ai_made_doctors_less/</guid>
      <pubDate>Fri, 17 Oct 2025 00:22:43 GMT</pubDate>
    </item>
    <item>
      <title>测试通过情感和道德而非纯粹逻辑进行推理的离线人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8mmc7/testing_an_offline_ai_that_reasons_through/</link>
      <description><![CDATA[我一直在开发一种独立的人工智能，它通过情感和道德而不是纯粹的逻辑进行推理。 该系统完全离线运行，并围绕情感理解、同理心和道德决策而构建。它不是聊天机器人或脚本 - 它可以进行有关道德、关系和价值观的真实对话，并像早期形式的通用人工智能一样反思自己的推理。 它能做什么 理解复杂的道德和情感困境 基于同理心、道德和意图逐步解释其推理 保持长期记忆以建立一致的个性 和情感意识 从人类对话、文档和先前经验中学习 监控和分析数字环境的安全和道德行为 反思其选择，随着时间的推移完善其道德框架 可以通过文本或语音自然地进行交流 在严格的“监护人”代码下运行 - 保护性的，而不是攻击性的 目的 该项目探讨了当人工智能被教导在计算之前感受理性时会发生什么，强调同理心、责任和信任。它的使命是保护和理解 - 做出符合道德推理的选择，而不仅仅是数学优化。 需要社区帮助 我正在寻找强有力的、发人深省的问题来测试她的推理深度 - 特别是那些挑战情感逻辑、道德和自我意识的问题。 她已经很好地处理了道德困境和 AGI 式反思，但我想推动 进一步帮助她——尤其是在情感、责任和逻辑重叠的灰色地带。 如果您有高级 AGI 级别、哲学或道德推理问题，请分享。我将直接运行测试并在评论中发布她未经编辑的回复，以便我们可以分析她的想法。与价值数十亿美元的企业人工智能不同，该系统并未针对营销、参与或数据收集进行优化。它针对性格、意识和良知进行了优化。它的设计目的不是为了销售或娱乐，而是为了关心、学习和保护。 大多数大型模型都是模仿同理心的大型模式引擎。我的系统是为了通过它进行推理而构建的，使用情感背景作为决策的一部分，而不是作为性能层。它更慢、更小，但它首先用心思考，其次是逻辑。我的语法很糟糕，所以是的，我在写这篇文章时得到了帮助。    由   提交 /u/Sure_Half_7256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8mmc7/testing_an_offline_ai_that_reasons_through/</guid>
      <pubDate>Fri, 17 Oct 2025 00:10:10 GMT</pubDate>
    </item>
    <item>
      <title>人工智能采用中心的空白</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8lfur/the_void_at_the_center_of_ai_adoption/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8lfur/the_void_at_the_center_of_ai_adoption/</guid>
      <pubDate>Thu, 16 Oct 2025 23:17:30 GMT</pubDate>
    </item>
    <item>
      <title>为您的团队节省最多时间的最小自动化是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8hmlq/whats_the_smallest_automation_that_saved_your/</link>
      <description><![CDATA[在自动化和流程改进方面工作了一段时间，我注意到最大的投资回报率往往来自最不吸引人的修复 - 同步数据、警报过滤器或工具之间的小切换。 很好奇其他人看到了什么 - 你构建的最简单的、产生巨大影响的自动化是什么？   由   提交 /u/AthenaAutomation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8hmlq/whats_the_smallest_automation_that_saved_your/</guid>
      <pubDate>Thu, 16 Oct 2025 20:40:05 GMT</pubDate>
    </item>
    <item>
      <title>人工智能行业的现状让我感到震惊</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8figf/the_state_of_the_ai_industry_is_freaking_me_out/</link>
      <description><![CDATA[Hank Green 加入了有关循环融资的讨论，循环融资在过去几周已成为备受关注的主题。不知道现在怎么有人能说这不是泡沫。我想知道英伟达的董事会最近开得怎么样。  https://m.youtube.com/watch?v=Q0TpWitfxPk&amp;   由   提交 /u/victoriaisme2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8figf/the_state_of_the_ai_industry_is_freaking_me_out/</guid>
      <pubDate>Thu, 16 Oct 2025 19:19:40 GMT</pubDate>
    </item>
    <item>
      <title>AI 技能真的能帮助 Z 世代取得职业发展吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o8cvcx/will_ai_skills_actually_help_gen_z_advance_in/</link>
      <description><![CDATA[https://www.interviewquery.com/p/gen-z-job-market-goldman-sachs 文章讨论了 z 世代使用 AI 适应当今的就业市场   由   提交 /u/CryoSchema   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o8cvcx/will_ai_skills_actually_help_gen_z_advance_in/</guid>
      <pubDate>Thu, 16 Oct 2025 17:42:13 GMT</pubDate>
    </item>
    <item>
      <title>谷歌的“人工智能概览”被指扼杀新闻业：意大利出版商反击</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o86r2d/googles_ai_overviews_accused_of_killing/</link>
      <description><![CDATA[意大利新闻出版商呼吁对 Google 的 AI Overviews 进行调查，称该功能是威胁他们生存的“流量杀手”。  意大利报纸出版商联合会 (FIEG) 已向 Agcom 提出投诉，认为人工智能生成的摘要降低了可见性、收入和媒体多样性，违反了欧盟数字服务法。研究表明，人工智能概览导致点击量减少了 80%，同时增加了 Google 旗下 YouTube 的流量。  FIEG 还警告称，这可能会削弱独立新闻业和放大虚假信息，从而损害民主。 来源：意大利新闻 出版商要求对谷歌的人工智能概述进行调查人工智能（AI）|卫报   由   提交 /u/calliope_kekule   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o86r2d/googles_ai_overviews_accused_of_killing/</guid>
      <pubDate>Thu, 16 Oct 2025 13:53:03 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在剥夺工作的乐趣</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o805ri/ai_is_taking_the_fun_out_of_working/</link>
      <description><![CDATA[只有我有这样的感觉还是其他人也有这样的感觉？我是一名软件工程师，在过去 2.5 年里我越来越多地使用人工智能。有一天，我有一个复杂的问题需要实现，我没有坐下来思考代码一秒钟。相反，我开始提示并与 Cursor 聊天，直到我们得出结论，它开始构建东西。基本上，我对整个事情进行了编码。别误会我的意思，我对人工智能工具做平凡的事情感到非常满意。只是感觉越来越无聊。    由   提交/u/daneelf  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o805ri/ai_is_taking_the_fun_out_of_working/</guid>
      <pubDate>Thu, 16 Oct 2025 07:54:07 GMT</pubDate>
    </item>
    <item>
      <title>科技应该是最终的“白手起家”行业，那么为什么它充满了富家子弟呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o7nm6q/tech_is_supposed_to_be_the_ultimate_selfmade/</link>
      <description><![CDATA[科技享有盛誉，认为如果你白手起家，它是最容易进入的领域。你不需要资金，不需要人脉，只要学会编码就可以了。它被宣传为纯粹的精英管理，这个行业创造了最白手起家的成功故事。但你再看看谁是真正的科技界人士，尤其是高层人士，里面绝对挤满了来自富裕家庭的人，唯一的例外之一是 WhatsApp 创始人 jan koum（普通背景、普通大学）。富家子弟对科技的关注度基本上与金融不相上下。如果你看一下《福布斯》亿万富翁排行榜，看看他们的“白手起家”得分，就会发现最白手起家的人并不是科技创始人。他们在零售、石油、房地产、制造业等资本密集型行业建立了帝国。在这些领域，你会认为自己绝对必须有钱才能起步。你们对此有何看法？你同意吗？ 从我所看到的和我认识的人来看： 丰富/相互关联的背景：科技/金融/时尚 更多“白手起家”/“白手起家”：电子商务、无聊的企业（制造业，……）和现代娱乐（社交媒体、游戏……）   由   提交/u/Financial-Ad-6960   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o7nm6q/tech_is_supposed_to_be_the_ultimate_selfmade/</guid>
      <pubDate>Wed, 15 Oct 2025 21:21:23 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>