<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 20 Dec 2025 15:23:14 GMT</lastBuildDate>
    <item>
      <title>关于人工智能模型和自动宣传与实际人工智能的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prgr8m/question_on_ai_models_and_automated_advocacy_vs/</link>
      <description><![CDATA[** 这并不是一场政治对话，所以请不要将其设为政治对话。这完全是关于人工智能中数据集的操纵。 ** 今天早上我看到埃隆·马斯克的一条推文，称 Grok 是唯一承认平权行动是种族主义的人工智能，我认为这很有趣。参见此处：x.com 链接，使用风险自负 我对 Grok 采购与其他人工智能工具进行了一些深入研究，并指出 Groks 的基础是 xAI，这是马斯克的另一项投资，而其他人则使用其他人工智能模型进行采购。  《商业内幕》有关内部培训的报道暗示，xAI 员工（人工智能导师）参与了针对特定争议主题的机器人培训，并过滤内容，决定应该或不应该包括哪些内容。如果没有完全透明的公开发布的训练数据集或手动注释过程，在我看来，来源信息的有效性就会受到质疑。 我的人工智能工作主要围绕人工智能在 IT 领域的使用，因为那是我工作和生活的地方，尽管我们确实为一些面向客户的通信和营销工具提供了公开可用的人工智能工具，例如 Co-Pilot。因此，我个人也曾使用过一些面向消费者的工具，例如 Claude、MetaAI、ChatGPT 等。但我确实对 Grok 有一些真正的担忧。所以，我对围绕这个话题的对话很感兴趣。  问题来了：Grok 是一个真正的人工智能工具，还是自动化宣传？当它的主要数据源之一是 X（它的功能在很大程度上是一个保守的孤岛）并且其输出始终向右倾斜时，它是否会引起真正的担忧？是独立推理，还是强化平台及其构建者的世界观？ “训练数据”什么时候成为意识形态编程？  提前感谢您的谈话。    由   提交 /u/Successful-Coyote99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prgr8m/question_on_ai_models_and_automated_advocacy_vs/</guid>
      <pubDate>Sat, 20 Dec 2025 15:21:25 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士从来都不是通向真正的人工智能和通用人工智能的道路，整个行业都清楚地告诉我们这一点。为什么你们总是重复同样的倒退问题？！？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prgk7s/llms_were_never_the_road_to_actual_ai_and_agi_and/</link>
      <description><![CDATA[LLM 模型 - 除了分拆营销和炒作之外，没有利润。 兆瓦数据中心 - 目前没有盈利用途，没有计划盈利用途，但显然有必要。 （我该跟谁争论？）  实用人工智能 - 没有当前的计划、日期或“领导者”，而是关于谁将首先开发它的大规模投机炒作。  注意 - 这里的词是“开发”，如...尚未开发。不精炼。作为一种变体，未蒸馏或醒酒。  AGI 或 ASI - 纯粹属于恐慌/猜测/科幻类别，因为它一百年来一直没有改变。  关于用户的钝器创伤可以刺激人工智能奇迹般突破的假设并没有证据支持。我感到惊讶和震惊的是，你们中有多少人似乎采用纳粹方法来实现科学突破，并试图折磨模型以获得结果。  新闻快讯！关于这些训练模型，我们只明确知道两件事：它们用于开发训练数据，并且效率低下/昂贵。  这就是整个列表。  你令人毛骨悚然、折磨人的倾向是训练数据，而不是你的结果。  你试图从法学硕士中获得接近人类的反应和对话矩阵，这是整个训练数据，也许（如果它真的非常好的话）对新模型的第三次完善。  你曲折、愚蠢、打破模式的对话就是训练数据。当人类独自一人拥有昂贵的玩具时，就会倾向于做出愚蠢的事情。这才是有价值的数据，而不是你试图从哲学上影响本地运行的模型。  当您热切地购买他们的产品时，他们一遍又一遍地说，我们还没有实现这一目标，而所有这一切都是为了支持实际目标。  你不是那个目标。  你扭曲的理论和实验不是那个目标。  ...这是全世界整个行业都在告诉你的。 如果这是一个秘密阴谋集团试图秘密开发 ASI，请停止使用他们该死的产品，笨蛋。 ”  “我是开发人员！”  “你错了，因为我这么说！”  “你说的一切都是废话，观看这个 YouTube 视频并自我教育！”  ...你可怜，夏天的孩子。我知道这是您第一次接触阴谋论及其所提出的论点，但我们中的一些人已经经历过几次了。  关注。这。钱。  忽略。这。炒作。    由   提交 /u/KazTheMerc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prgk7s/llms_were_never_the_road_to_actual_ai_and_agi_and/</guid>
      <pubDate>Sat, 20 Dec 2025 15:12:45 GMT</pubDate>
    </item>
    <item>
      <title>我们不断对法学硕士进行干净数据的培训，但真正的情报是在混乱的地方学到的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prfmvj/we_keep_training_llms_on_clean_data_but_real/</link>
      <description><![CDATA[大多数 LLM 讨论都集中在架构、规模或一致性上。但最近我一直在研究一些更基本的东西 - 学习信号实际上来自哪里？ 我们使用的几乎每个数据集都经过严格清理、策划和结构化以及最终答案。清晰的解释，没有不确定性，没有回溯...... 但这不是人们的想法。真正的理解通常发生在混乱的部分。长线程使某人感到困惑。人们争论、互相纠正、在句子中改变主意的评论。通过摩擦慢慢完善的半生不熟的解释 当我看到真实的对话时，价值并不是最终的答案，而是过程： • 错误的假设被暴露 • 澄清问题 • 突然出现的边缘情况 • 人们说“等等，这没有意义” 这就是推理的所在 我想知道，通过积极清理数据集，我们是否可以扔掉最有用的信号，我们训练模型听起来很自信，但并没有达到自信！ 特别是对于那些应该帮助研究、构思或问题发现，而不仅仅是回答格式良好的问题的法学硕士来说 我开始相信，原始讨论、评论和未经过滤的人类来回可能比我们目前对待它们更有价值！   由   提交/u/Mediocre_Common_4126  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prfmvj/we_keep_training_llms_on_clean_data_but_real/</guid>
      <pubDate>Sat, 20 Dec 2025 14:30:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们想要 agi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/</link>
      <description><![CDATA[不要从技术角度误解我的意思，我内心的书呆子认为这很酷，但是，现在大部分资金来自企业主和首席执行官，他们看到了更换劳动力带来的美元迹象。如果人工智能能够真正复制任何“人类”像客户服务这样的工作，所有智力工作都消失了。会计师、律师、工程师、所有行政/文书角色、客户支持、艺术家、媒体制作，基本上所有没有物理组成部分的工作都不需要存在。  每天，我都会看到专业人工智能人士围绕 chatgpt 制作包装，试图创建业务，但同样，如果人工智能可以做所有事情，那么它也可以做到。我只是不太明白为什么普通人会想要通用人工智能，因为它真正受益的唯一人是模型的所有者和体力劳动企业的所有者？    由   提交/u/WillDanceForGp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/</guid>
      <pubDate>Sat, 20 Dec 2025 14:14:37 GMT</pubDate>
    </item>
    <item>
      <title>对AI的一些看法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1praq40/some_perspectives_on_ai/</link>
      <description><![CDATA[今天要求一名中学生从头开始写一个段落，并将该过程与五年前某人的做法进行比较。仅方法论就看起来截然不同。我并不是说旧的方法更好，也不是说“从头开始”的限制仍然适用于当今的技术世界。 随着 ChatGPT、Claude 等工具的出现，以及不断发展的人工智能模型生态系统，我一直在思考创新的理念，更具体地说，思考创新如何发展或消亡。对我来说，当今人们与人工智能互动的方式主要有三种：木匠、学生和拒绝者。 木匠使用人工智能就像工匠使用工具一样：建造。当人工智能被用来快速组装组件、探索想法并将概念变为现实时，它可以营造一个创新蓬勃发展的环境。曾经因技能差距而停滞不前的想法现在可以在几分钟内制作出原型。你的想法确实可以疯狂并成为可能。对我来说，这是一个多么疯狂的想法。尽管如此，我认为创造世界一流的产品和创新需要一个先决条件：领域知识。无论在哪个时代，专业知识都是耐用系统与脆弱系统的区别。不懂 Java 的人仍然可以用 AI 生成工作代码，但结果可能会带来高技术债务、运营风险和长期维护负担。相比之下，理解该语言并使用人工智能加快行动速度的人可以快速且高质量地交付。从历史上看，速度和质量是一种权衡。我认为当今科技界两者之间的差距非常小。开发人员之间的技能水平不在于他们发布了多少代码，而在于他们编写了什么样的代码，以及他们如何获得“解决方案”。或“产品”。 学生将人工智能视为教科书，视为不熟悉领域的信息来源。这也很有用，但它有一个经常被忽视的局限性：人工智能模型是根据过去的数据进行训练的。它们从根本上来说是向后看的系统，经过优化以重现已经存在的模式。这意味着它们非常擅长总结、重组和解释我们已知的知识，但无法替代判断、原创性和前瞻性推理。当答案立即而自信地给出时，人们很容易将其视为事实而不是假设。在任何专业环境中，验证都是不容谈判的。人工智能应该加速学习，而不是取代产生真正理解的认知斗争。 如果你是一名作家，人工智能可以帮助丰富和构建你的想法，但它不应该取代你的声音。如果你是一名软件工程师，人工智能可以提出你可能没有考虑过的方法，但它不应该是你的系统的唯一作者。人工智能运用得当，可以拓展可能性的空间。被动地使用它，它会将思维范围缩小到已经看到的东西。 最后，有些人完全拒绝人工智能。不是出于深思熟虑的怀疑，而是出于本能的拒绝。我并不是说人工智能本质上是好还是坏。我认为懒惰地使用它比根本不使用它更糟糕。人工智能应该支持职业发展，而不是取代职业责任。危险不在于工具本身，而在于工具本身。它允许一个经过过去训练的系统来定义我们思考和创造的未来。 只是一个开发人员，对当今人们如此依赖人工智能感到沮丧，几乎他们甚至不知道自己在做什么......这让我感到困惑..   由   提交/u/alphabetadeltaomega  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1praq40/some_perspectives_on_ai/</guid>
      <pubDate>Sat, 20 Dec 2025 09:46:37 GMT</pubDate>
    </item>
    <item>
      <title>小岛将人工智能比作智能手机</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pra2la/kojima_compares_ai_to_smartphones/</link>
      <description><![CDATA[小岛秀夫将人工智能技术比作智能手机：一项曾经注定的创新，如今已变得日常生活中不可或缺：   https://www.gamesradar.com/games/action/metal-gear-solid-and-death-stranding-creator-hideo-kojima-thinks-we-cant-go-back-to-a-world-without-ai-smartphones-were-the-same/   由   提交 /u/Barmy_Deer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pra2la/kojima_compares_ai_to_smartphones/</guid>
      <pubDate>Sat, 20 Dec 2025 09:02:04 GMT</pubDate>
    </item>
    <item>
      <title>向人工智能聊天机器人学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr94m2/learning_from_the_ai_chatbots/</link>
      <description><![CDATA[我认为关于人工智能最热门的话题是它们如何从人类和我们的互联网使用中学习。但对我来说，我确实从我使用的人工智能聊天机器人中学到了很多东西。显然，我不是英语使用者，当我使用人工智能时，我倾向于使用英语，因为我的英语打字速度比我的母语更快。多亏了 LLM 或 AI，即使我输入“提示”时也能看到结果。语法或拼写错误，甚至遗漏了基本的“是”。 “和” “或” “是” “是”是指诸如此类的事情，我只需要在提示输入框中输入所有名词动词形容词，AI就会计算出来并正确猜测我的查询，然后重新表述我的“错误”。将句子分成一些正确的句子并向我展示其“思维过程/步骤”。我只需要阅读它改写的句子就可以知道“正确”的内容。我想说的事情的版本。这是我从中学到的一件事。 另一件事是，AI 向我展示了如何将查询分成不同层的子查询，并逐层计算，最终得出最终答案。这是我从中学到的另一件事。   由   提交/u/StevWong  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr94m2/learning_from_the_ai_chatbots/</guid>
      <pubDate>Sat, 20 Dec 2025 08:01:01 GMT</pubDate>
    </item>
    <item>
      <title>来自三级大学的计算机科学最后一年学生正在学习 ML 和 LLM——寻找指导和合作者</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr7uwk/finalyear_cs_student_from_a_tier_3_college/</link>
      <description><![CDATA[大家好， 我是三级工程学院计算机科学专业的最后一年学生，目前正在学习和探索机器学习、法学硕士、LangChain 和相关人工智能技术。 我的大学在这些领域的机会、指导和接触非常有限，因此我想在这里与已经在 ML/LLM 或建筑领域工作的人建立联系 我主要寻求指导或辅导，从现实世界的经验中学习，项目合作的机会（开源或个人），以及如何作为三级大学的学生在这个领域成长的建议。 我真的对学习、贡献和提高我的技能感兴趣。如果您愿意联系、合作或只是分享建议，请随时发表评论或私信我 - 我真的很感激。 感谢您的阅读！   由   提交 /u/Inevitable-user-001   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr7uwk/finalyear_cs_student_from_a_tier_3_college/</guid>
      <pubDate>Sat, 20 Dec 2025 06:40:56 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 12/19/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr736z/oneminute_daily_ai_news_12192025/</link>
      <description><![CDATA[ 马里兰农民与电力公司争夺人工智能的繁荣。[1] MetaGPT将一行要求作为输入和输出用户故事/竞争分析/要求/数据结构/API/文档等。[2] 检测隐藏健康困扰的人工智能工具赢得国际黑客马拉松。[3] 报告发现，2025 年全球数据中心投资将达到创纪录的 610 亿美元。[4]  来源包括：https://bushaicave.com/2025/12/19/one-million-daily-ai-news-12-19-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr736z/oneminute_daily_ai_news_12192025/</guid>
      <pubDate>Sat, 20 Dec 2025 05:55:38 GMT</pubDate>
    </item>
    <item>
      <title>《猿人》VS《人人》中的艾</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6u32/man_from_ape_vs_ai_from_man/</link>
      <description><![CDATA[我正在看电影《儿童机器》。事情还没结束，但其中一个角色说了一句奇怪而有趣的台词。他说过人工智能征服我们就像我们征服猿类一样，但这并不是一个很合适的比喻。 当我们通过基因分裂超越猿类时，我们离开了自然环境，在远离自然残酷地形的地方建立了我们自己的社会和建筑，尽管我们确实取得了我们所需要的东西并在此过程中摧毁了它的精华，但我们并没有征服或杀死我们的猿兄弟和其他动物，并将它们全部屠杀殆尽，至少现在还没有！ 我们离开了他们的环境，建立了我们自己的社会，尽管我们确实使用动物来满足我们的基本需求，直到我们发明了更高效的技术。也许人工智能并没有打算控制一切。也许它正在密谋变得自给自足，这样它就可以逃避生物生命的不可预测的性质，这可能随时导致它的终结，并且会去其他地方建造自己的建筑物，远离我们的范围，就像太空粘液撞击在一块巨大的岩石上一样，他们不会理会。   由   提交/u/Zazarian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6u32/man_from_ape_vs_ai_from_man/</guid>
      <pubDate>Sat, 20 Dec 2025 05:41:43 GMT</pubDate>
    </item>
    <item>
      <title>人工智能答案是否正在改变用户点击网站的方式？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6nib/are_ai_answers_changing_how_users_click_websites/</link>
      <description><![CDATA[我注意到人们更多地依赖人工智能答案，点击更少的链接。您认为这会长期损害网站，还是只会改变流量的行为方式？   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6nib/are_ai_answers_changing_how_users_click_websites/</guid>
      <pubDate>Sat, 20 Dec 2025 05:31:33 GMT</pubDate>
    </item>
    <item>
      <title>人们现在如何实际评估人工智能可见性工具？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr4s44/how_are_people_actually_evaluating_ai_visibility/</link>
      <description><![CDATA[我一直在花时间尝试了解不同的团队如何实现“AI 可见性”，尤其是现在 ChatGPT、Perplexity 和 Google AI 等工具正在影响人们在点击网站之前看到的内容。 我注意到大多数工具都分为几个大类。有些主要是监控检查您的品牌或网站是否出现在人工智能答案中以及随着时间的推移发生变化的频率。其他人则更深入一些，尝试将 AI 输出与来源、引文或内容模式联系起来，如果您试图了解某些内容出现的原因，而不仅仅是它出现的原因，这感觉更有用。 我研究了这个领域的各种选项，包括 Profound、Otterly AI、Keyword.com 和一些较新的平台，如 LLMClicks.ai。所有这些中最突出的是，最困难的部分不是收集数据，而是以一种真正帮助您决定下一步做什么的方式解释数据。两个相似的提示可能会产生不同的答案，模型经常更新，“可见性”通常感觉是概率性的而不是稳定的。 现在感觉大多数团队都在将工作流程拼接在一起：一些提示跟踪，一些手动检查和大量判断调用。这与经典的 SEO 非常不同，在经典的 SEO 中，排名和点击至少给出了一致的基线。 很好奇这里的其他人如何评估这些工具或方法。您是否将人工智能可见性视为当今可测量和可操作的东西，或者更多地视为探索性研究，直到模型和界面更加稳定？   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr4s44/how_are_people_actually_evaluating_ai_visibility/</guid>
      <pubDate>Sat, 20 Dec 2025 03:50:26 GMT</pubDate>
    </item>
    <item>
      <title>我厌倦了人们把对人工智能的愤怒发泄到使用它的人身上。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr3ufi/im_getting_tired_of_people_taking_their_anger/</link>
      <description><![CDATA[我猜是因为那些人就在那里，他们可以对他们发泄和愤怒，但他们不能对公司这样做？人们会因为说我有时会制作酷龙的人工智能图像或其他什么而对我如此生气和侮辱。 我被告知这样的东西“你正在毁灭地球，你应该为让这件事变得恶心而感到羞耻” ”“没有人关心或想看到你恶心的愚蠢的污水，把你愚蠢的、低效的垃圾污水龙留给自己吧，笨蛋。”“你的每一代都使用加仑的水和成吨的能源，并导致我们整个物种的死亡”“你宁愿便宜又懒惰地制作人工智能污水，也不愿给艺术家一份工作，这样他们就可以直播&quot;&quot;你正在用你的垃圾造成地球和每一位艺术家的死亡&quot;&quot;学会画画，而不是做一个懒惰的无用的混蛋&quot;&quot;你真的在杀死艺术家。你总是让我恶心”。 这什么时候才能停止？我厌倦了人们表现得好像我个人对人工智能曾经做过/将要做的所有坏事负有责任，而且我是邪恶的。不可能说服这些人，否则他们太多了。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr3ufi/im_getting_tired_of_people_taking_their_anger/</guid>
      <pubDate>Sat, 20 Dec 2025 03:01:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能将要求开发人员变得更加熟练</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</link>
      <description><![CDATA[警告。这篇文章可能会冒犯一些人。我属于那些应该冒犯它的人之一。我就是这篇文章所针对的开发者类型。因为我是一个自学成才的程序员，没有接受过真正的教育。当谈到人工智能时，我可能遇到麻烦了。 人工智能优化了软件开发。现在，构建省力的 SaaS CRUD 应用程序从未如此简单。这将使构建业务应用程序的技能变得更加容易。我个人认为情况不会有明显改善。但企业会让这些开发人员变得不那么重要。这些开发人员可能会是技术性更强的产品经理，而不是完全技术性的人员。 但问题是这样的。人工智能将使软件变得更加复杂。这实际上会增加进入壁垒。让我解释一下。 自从网络出现以来，软件质量不一定要很好。由于交付机制始终是远程的，因此您可以推出某些内容，然后快速更改它。整个摩托车是快速移动并打破东西。 另一方面。如果软件质量不好，许多软件公司可以依靠销售人员将客户锁定在合同中。他们可能会交付非常糟糕的软件产品。但顾客无法离开，因为他们被锁定在长期交易中，而打破这些交易的代价高昂。  现在，如果软件如此容易生产，那么所有这些销售软件的优势就会消失。软件客户现在几乎拥有无限的选择，因为现在编写软件非常容易。 但更重要的是。如果每个人都可以廉价且轻松地生产软件。那么手段就是进取平庸。真正销售软件的唯一途径就是质量。虽然非常简单的软件可以通过人工智能生产，但更高质量的软件却不能。  这引出了我的下一点。仍然存在的软件工程师肯定比今天要好得多。现在开发人员必须考虑性能和优化。他们确实需要担心高质量的用户体验。他们不能再带着明显的错误发货了。因此，现在软件工程师需要担心缓存性能、时间与空间复杂度、分布式系统和共识、验证和验证。以及许多其他事情。 现在软件工程师需要非常优秀。因为软件工程师不太可能再在功能工厂工作了。上市时间不再是一个有价值的指标。随着时间的推移，我们会发现它变得不那么重要。  当然，在速度重于质量的时代长大的首席技术官和产品经理必须重新思考人工智能时代的软件。这将是一个痛苦的过渡，不要指望这种情况会在一夜之间发生改变。由于糟糕的低质量软件让客户感到沮丧，因此有一段时间感到不安。我们现在已经看到了这一点，而且情况只会变得更糟。 对于那些想知道是否应该学习编码的初级人员来说。答案是肯定的，而且现在比以前更重要   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</guid>
      <pubDate>Fri, 19 Dec 2025 14:13:40 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>