<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 30 Dec 2024 21:18:43 GMT</lastBuildDate>
    <item>
      <title>机器生成的产品广告 将法学硕士与人类表现进行对比</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpxc2b/machine_generated_product_advertisements/</link>
      <description><![CDATA[标题：“机器生成的产品广告将 LLM 与人类表现进行对比” 我每天都在寻找和总结有趣的 AI 研究论文，这样您就不必全部浏览了。今天的论文题为“机器生成的产品广告：将 LLM 与人类表现进行对比”，作者是 Sanjukta Ghosh。 本研究探讨了 AI 生成和人工制作的产品描述的比较性能，并使用详细的评估模型评估了各个方面的有效性。主要关注的是多个 AI 模型（包括 Gemma 2B、LLAMA、GPT2 和 ChatGPT 4）创建的 100 种不同产品的产品描述，并将这些输出与人工编写的描述进行比较。 主要发现：  ChatGPT 4 的优势：ChatGPT 4 的表现始终优于其他模型，在情感、可读性和其他关键指标方面展现出了卓越的语言能力。它代表了人工智能在内容生成方面达到甚至超越人类标准的能力的前沿。 可读性和复杂性：虽然有些模型生成的描述过于复杂，不适合平均阅读水平，但人类撰写的文本仍然在理想的可读性范围内，这表明人类作家能够熟练地制作更容易理解、更受受众欢迎的内容。 说服力和搜索引擎优化：人类作家和ChatGPT 4在说服性内容和搜索引擎优化优化方面处于领先地位，这表明复杂的人工智能有可能模仿人类级别的战略性写作，从而有效地吸引和吸引客户。 情感和号召性用语的有效性：人类生成的文本和ChatGPT 4在情感吸引力和号召性用语的清晰度方面表现出色，而这些领域对细致入微的语言理解至关重要，这肯定了在内容创作中持续采用混合方法的需求。 模型差异：其他 AI 模型，尤其是 Gemma 2B 和 GPT2，表现出明显的差距，通常产生的内容不太连贯，突显了当前 AI 能力之间的差异。  该研究不仅凸显了 AI 在电子商务中日益增长的作用和能力，而且还强调了人类专业知识在制作引人注目、情感上有吸引力的描述方面的持久价值。该研究主张一种混合模型，该模型可以利用AI的效率，同时保持人类为内容创作带来的创造深度。 您可以在此处查看完整的细分：这里 您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpxc2b/machine_generated_product_advertisements/</guid>
      <pubDate>Mon, 30 Dec 2024 20:59:30 GMT</pubDate>
    </item>
    <item>
      <title>研究人员称，人工智能可能很快就会操纵人们的在线决策</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpwbii/ai_may_soon_manipulate_peoples_online/</link>
      <description><![CDATA[ 研究预测将出现“意向经济”，即公司竞标对人类行为的准确预测  https://www.theguardian.com/technology/2024/dec/30/ai-tools-may-soon-manipulate-peoples-online-decision-making-say-researchers    提交人    /u/apokrif1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpwbii/ai_may_soon_manipulate_peoples_online/</guid>
      <pubDate>Mon, 30 Dec 2024 20:14:59 GMT</pubDate>
    </item>
    <item>
      <title>二年级学生，需要帮助建立我的模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpvp6k/2nd_year_student_need_help_with_my_model/</link>
      <description><![CDATA[我正在研究打印扫描图像隐写术。基本上，想象一下图像上不可见的水印。您可以像二维码一样在印刷材料上使用它，但封面图像完全由您决定。这是训练过程的简要分解。我们有一个编码器和解码器。编码器获取输入图像 I 和秘密张量 S，生成残差图像 R。R = 编码器（I，S）编码图像 E 定义为 E = I + R 其中函数编码器只是 I 和 S 连接的前向传递 然后图像损失 IL 定义为 IL = I - 变换（E）其中变换会引入扫描时产生的噪声和图像缺陷 解码器获取 E 并输出 S&#39; S&#39; = 解码器（E） 秘密损失 SL 定义为 SL = S - S&#39; 总损失 TL = IL + SL（过于简单） 现在，我意识到，如果我尝试使用 HSI 颜色空间，隐藏能力可以提高。 在不修改上述任何内容的情况下，我在前向传递之前仅将 I 转换为 I_hsi。 我的逻辑是，鉴于我的模型架构足够复杂，我的模型可以隐式学习转换函数。编码器生成残差，以便它可以更好地隐藏在 HSI 颜色空间中。 我实现了这个简单的修复。修复之前我的总损失为 0.05 修复后我的总损失为 1.73（稳定，相同的超参数） 我的修复逻辑错误吗？我可以做哪些更改来改善损失值？    提交人    /u/Not_A_Chipset   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpvp6k/2nd_year_student_need_help_with_my_model/</guid>
      <pubDate>Mon, 30 Dec 2024 19:48:29 GMT</pubDate>
    </item>
    <item>
      <title>人工智能伦理并非千篇一律，而是根据每个国家的文化结构量身定制的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpv7ux/ai_ethics_arent_onesizefitsall_theyre_tailored_by/</link>
      <description><![CDATA[大家好，我最近在我的博客上发表了一篇帖子，该帖子由一项不完整的研究组成，内容涉及美国、中国和法国大型语言模型的道德框架中嵌入的文化指纹。每个国家的文化、政治和监管环境如何塑造人工智能发展的道德护栏，这令人着迷。 在美国，言论自由和个人权利受到高度重视，法学硕士往往强调隐私，但难以解决偏见、错误信息和有害内容等问题。这里的监管方法往往是被动的，而不是主动的，更注重创新而不是监管。 在中国，道德护栏更多地是关于国家控制。人工智能模型受到严格审查，以符合政治议程并保持社会和谐。政府在监管这些技术方面发挥着核心作用，将集体价值观和国家安全置于个人自由之上。 与此同时，法国在欧盟 GDPR 及其强大的人权传统的指导下，强调隐私、公平和透明。这里的道德问题更多地集中在防止歧视和确保问责制上，反映了欧洲的包容性和社会正义价值观。 这提出了一个有趣的问题：我们真的可以拥有通用的人工智能道德标准吗？还是这些标准本质上是由文化背景塑造的？ 我很想听听你对此的看法！你认为人工智能的道德框架会在全球范围内趋同吗？或者文化影响力是否强大到难以克服？我们可以从这些不同的方法中学到什么？ 期待对话！ 在此处查看完整帖子： https://danielkliewer.com/2024/12/30/cultural-fingerprints    提交人    /u/KonradFreeman   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpv7ux/ai_ethics_arent_onesizefitsall_theyre_tailored_by/</guid>
      <pubDate>Mon, 30 Dec 2024 19:27:52 GMT</pubDate>
    </item>
    <item>
      <title>对于制作用于娱乐和个人用途的人工智能艺术有何看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpujgp/opinions_about_making_ai_art_for_fun_and_personal/</link>
      <description><![CDATA[嗨，我是残疾人社区的一员，我的很多朋友都非常喜欢制作 AI 艺术、音乐等。这是坏事吗？这是在窃取他人的艺术吗？我很矛盾。    提交人    /u/ForeverCalla   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpujgp/opinions_about_making_ai_art_for_fun_and_personal/</guid>
      <pubDate>Mon, 30 Dec 2024 18:59:09 GMT</pubDate>
    </item>
    <item>
      <title>[ 已被 Reddit 删除 ]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hptk42/removed_by_reddit/</link>
      <description><![CDATA[[ 由于违反 内容政策，已被 Reddit 删除。 ]    由    /u/Neat_Ad9686  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hptk42/removed_by_reddit/</guid>
      <pubDate>Mon, 30 Dec 2024 18:17:53 GMT</pubDate>
    </item>
    <item>
      <title>我很好奇，为什么 Google Gemini 针对一个关于图片的看似简单的问题得出了这么多不准确的结果</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hprpr6/curious_as_to_how_google_gemini_had_so_many/</link>
      <description><![CDATA[当我试图回忆“bulb injection（球形注射器）”一词时，我一时想不起来，所以我在谷歌上搜索了一张我记得有的专辑封面，Deftones 的 Adrenaline。 我看到了结果，仔细看了两遍，然后发布在r/deftones中，很多人都回复了，发布了他们的结果差异很大（而且很疯狂）。 不确定这会如何搞砸，因为：  在谷歌搜索“灯泡注射器”时会出现该图像 它在专辑的维基百科页面中的照片标题上说明了它是什么  我也不确定为什么不同的人会产生如此多不同的结果，即使他们的搜索词与我的非常相似，甚至完全相同？    由    /u/joanna_glass 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hprpr6/curious_as_to_how_google_gemini_had_so_many/</guid>
      <pubDate>Mon, 30 Dec 2024 16:59:27 GMT</pubDate>
    </item>
    <item>
      <title>我们是否会永远被困在为我们量身定制的回音室中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpqdux/will_we_be_trapped_in_a_echo_chamber_tailered_for/</link>
      <description><![CDATA[未来5年我们可以用AI来生成逼真的电影，我们有聊天机器人可以生成很多情感词汇，也许在未来，随着自动化越来越先进，每个人都可以用AI为自己建立一个回音室，永远沉浸在这个回音室里，这个回音室里充满了AI生成的内容    submitted by    /u/MPM_SOLVER   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpqdux/will_we_be_trapped_in_a_echo_chamber_tailered_for/</guid>
      <pubDate>Mon, 30 Dec 2024 16:02:17 GMT</pubDate>
    </item>
    <item>
      <title>我可以这样做吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpntnx/can_i_do_this/</link>
      <description><![CDATA[所以，我想知道我是否可以从我已故兄弟与女儿交谈的旧视频中克隆他的声音。我想让他说“我爱你伊莎贝拉”，我不知道就这一点而言，我在法律上被允许做什么。 他于 2019 年被谋杀，但我只有这段大概 90 秒的他声音视频。我有什么选择？    提交人    /u/Sea-Dot6536   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpntnx/can_i_do_this/</guid>
      <pubDate>Mon, 30 Dec 2024 14:01:22 GMT</pubDate>
    </item>
    <item>
      <title>我的一个雄心勃勃的项目</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpnaam/an_ambitious_project_of_mine/</link>
      <description><![CDATA[我这边的简短介绍： 我是一名计算机科学专业的学生，​​对人工智能及其在金融市场中的应用感兴趣。我对交易很感兴趣，尤其是外汇和商品。我参加了 BabyPips 课程，但中途我意识到新闻对市场的影响比技术分析大得多（我更倾向于基本面驱动的观点）。每次看到关于人们通过事件驱动交易赚钱的帖子，我都会想，“我也可以做同样的事情”，但要么是因为上课而不知道这个消息，要么当时我在睡觉或做其他事情，要么就是采取行动太晚了。 那时我开始探索算法交易。虽然它主要关注数字价格模式，但它在捕捉由社会情绪或突发新闻驱动的突然市场变化方面范围非常有限。 所以现在，我正在构思一个系统，该系统不断抓取社交媒体，使用基于 NLP 和 LLM 的方法来检测新兴的叙述和情绪高峰，以免它们完全影响市场并实现交易流程自动化。这只是一个概念想法，我正在寻找有兴趣从事这个了不起的项目并一起集思广益的人。我知道 HFT 已经在使用类似的系统，但它们是专有的。 TL;DR：我是一名计算机科学专业的学生，​​对开发自动化事件驱动的新闻交易 AI 代理感兴趣，并且正在联系有兴趣一起工作的人。出于显而易见的原因，这将是一个闭源项目，但我们甚至需要在开始之前建立必要的技能。    提交人    /u/Civil_Ad_9230   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpnaam/an_ambitious_project_of_mine/</guid>
      <pubDate>Mon, 30 Dec 2024 13:32:33 GMT</pubDate>
    </item>
    <item>
      <title>什么阻碍了你的人工智能实施？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpmzep/whats_holding_back_your_ai_implementation/</link>
      <description><![CDATA[大家好！我很好奇——在贵组织实施 AI 时，您面临的最大挑战是什么？是缺乏资源、内部官僚主义、寻找合适的工具、成本、数据质量，还是其他完全不同的原因？ AI 潜力巨大，但让其起步并不总是一帆风顺的。对我来说，这是一个混合过程，既需要遵循审批流程，又需要确保数据质量达到标准（没有什么比坏数据更能扼杀 AI）。 您最大的限制是什么？您是如何克服的？    提交人    /u/NickBaca-Storni   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpmzep/whats_holding_back_your_ai_implementation/</guid>
      <pubDate>Mon, 30 Dec 2024 13:15:08 GMT</pubDate>
    </item>
    <item>
      <title>微软和 OpenAI 对 AGI 的新定义是内部事务，无法扩展到更广泛的 AI 行业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hpjbpe/microsoft_and_openais_new_definition_of_agi_is_an/</link>
      <description><![CDATA[首先，这个新的 agi 定义对微软非常有利，而对 openai 非常不利，人们不禁要问，微软在谈判如此有利的交易时使用了什么具体筹码。 然而，从技术角度来看，agi 作为一种可以产生 1000 亿美元利润的模型，这个定义可以、也将会被该领域的其他所有人安全地忽略。让我来解释一下原因。 想象一下其他某家公司发布的人工智能模型，该模型几乎可以在人类可以完成的所有任务中与普通人类匹敌。因为它可以体现为一个机器人，所以它也可以像普通人一样跑得快、跳得高、投掷篮球。 它可以像任何学科的普通科学家一样进行科学实验和撰写科学论文。它可以写出一部和普通人写的小说一样引人入胜的小说。它可以像普通律师一样在法庭上打赢官司，提供与普通财务顾问一样合理的财务建议，并像普通会计师一样做会计工作。 为什么我们要处理普通人类的能力而不是最高级的能力？因为一旦我们有了几乎在任何任务上都能超越普通人类的人工智能模型，我们就接近了人工智能或超级人工智能。当人工智能模型在分配给它们的任何任务上甚至比顶尖人类或专家做得更好时，那么可以说它们此时已经达到了人工智能的第一阶段。 当然，在每项任务上都能以微弱优势超越顶尖人类的人工智能和在各个领域和领域中都能以例如 10 倍或 20 倍的优势超越顶尖人类的人工智能之间存在着天壤之别。  但让我们回到 AGI，以更好地理解为什么微软和 OpenAI 刚刚同意的利润指标是他们的内部事务，而且仅仅是他们的内部事务。 让我们想象一下，AGI 不是由营利性开发商发布的，而是由一个使命只是开发和尽可能广泛地分发最强大的开源模型的人发布的。在这种情况下，世界很快就会被各个领域的人工智能专家淹没。但这些专家将均匀地分散在世界各个地区，即使他们永远无法产生数十亿美元的利润，他们也会给每个人带来巨大的利益。假设他们为许多使用它们的公司创造了数千万美元的利润。有人会认真地争辩说这些模型不是真正的 AGI 吗？ 当然不是。AGI 模型没有产生数十亿美元的利润，绝不会否定它们在每个领域和每个领域内匹配人类平均表现的能力。无论它们产生了多少钱，这些模型都将构成 AGI 这一词的合理意义。它们可能还会以我们今天难以想象的积极方式改变我们的世界。 因此，微软和 OpenAI 可能要到 2030 年或更晚才能达到其内部的 AGI 指标。但如果世界其他国家在未来一两年内以更技术准确的定义达到 AGI，我们不应该感到惊讶。    提交人    /u/Georgeo57   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hpjbpe/microsoft_and_openais_new_definition_of_agi_is_an/</guid>
      <pubDate>Mon, 30 Dec 2024 09:08:25 GMT</pubDate>
    </item>
    <item>
      <title>还有人发现 Gemini 总是最没用，尤其是对于基本信息而言吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hp7fio/anyone_else_find_gemini_is_always_the_least/</link>
      <description><![CDATA[简单示例：我想了解有关冰箱的一些信息，但又不想阅读 50 页的手册。 ChatGPT 和 Perplexity 立即找到了相关手册并回答了问题。（我提供了型号） Gemini 首先给了我关于如何在手册中查找的通用答案，当我要求它帮我查找时，它回答说“对不起，我无法搜索个人信息。”在解释了冰箱手册不是个人信息之后，它只是重复了最初的帖子。 这只是一个例子，但我发现无论是历史日期、我想不起来的歌名还是语法问题，在各种应用程序（ChatGPT、Perplexity、Claude、Grok）中，只有 Gemini 永远不能给我一个直接的答案或我想要的答案。 只是我给了它错误的提示，还是其他人也发现了这一点？    提交人    /u/alw515   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hp7fio/anyone_else_find_gemini_is_always_the_least/</guid>
      <pubDate>Sun, 29 Dec 2024 22:15:37 GMT</pubDate>
    </item>
    <item>
      <title>我添加了专业人士的天赋</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</link>
      <description><![CDATA[由于最近对专业内容更加突出的兴趣，我认为一个好的开始是了解用户的哪些答案来自真正了解他们所谈论内容的人。 因此，我通过 mods 使经过验证的专业标签仅可分配。如果您想要该标签，您必须证明您在该领域工作。我把这留给您，我不在乎您的数据，并在看到后删除所有内容。如果您获得了标签，结果发现您对自己的职业撒了谎，无论出于何种原因，您都将被永久禁止，并且无法上诉。 一旦我们拥有足够多的人，我们还可以允许用户将某些帖子限制为仅那些用户进行更专业的讨论。 让我知道您的想法    提交人    /u/ILikeBubblyWater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</guid>
      <pubDate>Wed, 25 Dec 2024 23:49:53 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 24 Dec 2024 15:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>