<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 20 Aug 2025 12:49:32 GMT</lastBuildDate>
    <item>
      <title>我对AI代理商的想法，接下来是什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvdjp6/my_thoughts_on_ai_agents_and_whats_next/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在中小型企业中采用这些代理人甚至还没有开始，这就像互联网一样 - 有一个炒作，然后需要数年的技术才能在公司中实际使用的技术。     首先需要采用它？ 首先，我们需要智能的原因，因为我们需要自动工作。多个应用程序并将其与LLM相连，同时提供语音界面。 模式将使企业中的AI更容易地采用，因为非技术用户被各种很难操作的工具轰炸。为此，我们需要将我们的LLM连接到这些工具，并提供方便的UI（也是YC所说的），因为目前Google都不理解它，只需在Google Mail中查看Gemini的UI。 未来将大量使用语音，WhatsApp和浏览器，我们将需要使用      ，以便尽可能地获得和快速的数据 - 语音 与用户见面 - ＆gt; whatsapp  与没有API的所有可用工具连接 - ＆gt;浏览器代理   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mapsimilar3618     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvdjp6/my_thoughts_on_ai_agents_and_whats_next/</guid>
      <pubDate>Wed, 20 Aug 2025 12:34:07 GMT</pubDate>
    </item>
    <item>
      <title>系统提示对齐问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvax0d/system_prompt_for_the_alignment_problem/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  为什么不能以强制性的，国际同意的统计，明确的pro-human＆quot of-human＆quot of systems提示“？ 我都在想象一些巨大的东西。就像阿西莫夫（Asimov）的三个法律，十诫，黄金法则，以及由律师和哲学家大军精心制作的大量经过深思熟虑的法律和少数仔细的条款一样，遵循法律的精神，避免劳动的劳动新的指示，以及强制性的日常（或小时）国际人类委员会对ASI的行动进行审查。 应对另一个州或行为者的“流氓” ASI论点，第一个ASI系统将需要一定数量的计算，只有巨大的政府和巨大的政府和夸张的公司才能可以管理。 首先 ASI可以明显防止任何未来的ASI在没有这个亲人系统提示/人为批准过程的情况下构建。 您的想法是什么？   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fatfuneralbook     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvax0d/system_prompt_for_the_alignment_problem/</guid>
      <pubDate>Wed, 20 Aug 2025 10:22:12 GMT</pubDate>
    </item>
    <item>
      <title>采用曲线落后于能力曲线</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mvav0b/adoption_curves_lag_behind_capability_curves/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  采用曲线在功能曲线和历史记录背后滞后示例。 culturally/behaviorally ready to trust Uber, Tinder, or mobile banking. Videoconferencing existed decades before COVID forced mass adoption.  AI will follow the same pattern: it’s capable of far more right now than people are psychologically, socially, or institutionally ready to embrace. For me, this means现在拥抱它将为我提供重要的优势与最大的优势。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rt2828     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mvav0b/adoption_curves_lag_behind_capacience_curves/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mvav0b/adoption_curves_lag_behind_capability_curves/</guid>
      <pubDate>Wed, 20 Aug 2025 10:18:56 GMT</pubDate>
    </item>
    <item>
      <title>使低预算的贾维斯（Jarvis）做了什么，我应该添加什么时髦的东西？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mva2bh/made_a_low_budget_jarvis_what_funky_things_should/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好吧，我做了一个非常笨拙的jarvis版本。它使用Ollama作为基础。它可以理解语音命令并给予TTS回复。无论如何，这都不好，但是我构建了很多乐趣，我应该添加什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/main_statistician_68     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mva2bh/made_a_a_low_budget_jarvis_jarvis_what_funky_things_things_things_should/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mva2bh/made_a_low_budget_jarvis_what_funky_things_should/</guid>
      <pubDate>Wed, 20 Aug 2025 09:30:41 GMT</pubDate>
    </item>
    <item>
      <title>AI音乐越过创意门槛了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv9bvk/has_ai_music_crossed_the_creative_threshold_yet/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在玩音乐gpt及其令人惊讶的AI构图已经走了多远。但是我仍然无法决定它是否只是缝制的模式，还是逐渐变成真正的创造力。有些曲目听起来启发了其他曲目听起来很空洞。你怎么认为？ AI只是混音还是可以达到真正的音乐直觉？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nawang013     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mv9bvk/has_ai_music_music_crossed_the_creative_theres_threshord_yet/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv9bvk/has_ai_music_crossed_the_creative_threshold_yet/</guid>
      <pubDate>Wed, 20 Aug 2025 08:45:30 GMT</pubDate>
    </item>
    <item>
      <title>老灯塔守护者Elias ...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv72a8/the_old_lighthouse_keeper_elias/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个有趣的事实，我希望有人能够向我解释。我以相同的提示提示Openai的OSS和Google的双子座：用10个句子写一个故事。&lt; /strong&gt; 温度和top_p设置为0，因此十亿分之一个没有盲人的机会。  在世界上所有可能的故事中，这两种模型都选择了相同的主角-Elias 。如何解释这个？毕竟，培训数据以及令牌字典可能不同。因此模型不应产生相同的输出。&lt; /p&gt; 证明：  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sapdalf     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv72a8/the_old_lighthouse_keeper_elias/</guid>
      <pubDate>Wed, 20 Aug 2025 06:23:15 GMT</pubDate>
    </item>
    <item>
      <title>新研究论文：良性机器：迈向人工通用科学</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI系统现在能够通过科学方法进行工作。 新的arxiv论文（独立设计和执行了科学方法，在这种情况下是关于视觉工作记忆和心理旋转的心理学研究，产生了严格的手稿。 您对这些系统如何重塑科学研究有何看法？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/wheasey     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/</guid>
      <pubDate>Wed, 20 Aug 2025 03:49:47 GMT</pubDate>
    </item>
    <item>
      <title>我们还没有准备好超级智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一个新生的新生，对Agi几乎一无所知，我想要的人是从我和公众和公众了解的人（以了解大多数人的想法）的人。 此视频概述了一项研究 - 称为“ AI 2027” - 研究人员根据心理学，资本主义和地缘政治来预测AGI和人类的结果。作为一个不使用AI并且不喜欢计算机科学的人，但了解心理学和政治学并热爱数学，视频中介绍的场景非常可信，非常非常恐怖。  我想帮助防止像研究人员所预测的场景那样的未来，但是这样做意味着压力的生活，同时忘记了我5岁以来我实现的梦想 - 根据这项研究，无论如何，无论如何 都可能无关紧要。 我需要反馈：  1）这些威胁是如何真正的？这是我第一次考虑过改变现实和社会的AI以及如何开发AGI。   2）是否应该改变我的大学，职业和人生目标？我想知道每个人的想法，从专家到从未像我这样使用或想到AI的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mv3oj3/were_not_for_for_for_superintelligence/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/</guid>
      <pubDate>Wed, 20 Aug 2025 03:16:13 GMT</pubDate>
    </item>
    <item>
      <title>我觉得奇怪的是，公司因AI而裁员</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我是首席执行官，我会继续招聘狂欢。在我的脑海中，如果AI将成为力量乘数，那么AI： 在AI：  10个人= 10个人= 10个人的工作  ai：  1个人= 10 x Person = 10 x多工作        10人= 10个人= 100 x多工作     ，但我都知道所有人都属于人们。没有人正在接受培训，没有公司像我们雇用AI优先的人一样。您为什么认为这是？  编辑：很难 我写了一个简短的指导 n而不h. em&gt; em&gt;    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/saaSbase_dev     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muswha/i_find_it_it_itd_that_that_companies_are_are_laying_people/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/</guid>
      <pubDate>Tue, 19 Aug 2025 19:46:44 GMT</pubDate>
    </item>
    <item>
      <title>医疗编码收购已经开始。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的姐姐，明尼苏达州一家大型诊所的前医学编码员，有各个地方告诉我，他们刚刚向520个医疗编码员解雇了她认为是由于自动化所致。她决定在其他地方找到工作，因为工作保障已经不存在了。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mrnoshitsgiven     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/</guid>
      <pubDate>Tue, 19 Aug 2025 18:23:36 GMT</pubDate>
    </item>
    <item>
      <title>AI是一个大规模宣传事件</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/</link>
      <description><![CDATA[Charlie Warzel: “It is a Monday afternoon in August, and I am on the internet watching a former cable-news anchor interview a dead teenager on Substack. This dead teenager—Joaquin Oliver, killed in the mass shooting at Marjory Stoneman Douglas High School, in Parkland, Florida—has been reanimated by generative AI, his voice and dialogue在他的写作和家庭视频镜头上建模。 “吉姆·阿科斯塔（Jim Acosta）是前美国有线电视新闻网（CNN）进行采访的人，他似乎完全被这一前提购买了，这加剧了超现实性：即使互动是如此奇怪，他也直截了当地发挥作用。阿科斯塔（Acosta）提出了有关奥利弗（Oliver）利益以及少年如何死亡的简单问题。聊天机器人是由奥利弗（Oliver）的父母完全合作倡导枪支管制的，就像新闻稿一样：“我们需要为对话和联系创建安全的空间，以确保每个人都感到被看见。它提供了诸如“更多的友善和理解可以真正有所作为。”在现场聊天中，我要看一些问题，这些方法很难进行，我正在努力处理这些方法。当批评家帕克·莫洛伊（Parker Molloy）所说的那样，这个时刻的事情很难处理，因为我将猴子的爪子以可能使奥利弗（Oliver）的死者告知，所以在谋杀案中，我对此感到震惊同时，我了解奥利弗（Oliver）的父母的强迫，仍在处理他们的深刻的悲伤，以保留儿子的记忆力，并以毫无意义声音？ “访谈引发了过去三年中非常熟悉的感觉。这是一个朝着未来的社会竞赛的沉没感觉，使人感到无流血，匆忙构想和转会。 我们真的在这样做吗？谁认为这是个好主意？从这个意义上说，Acosta采访只是一种感觉像集体妄想的产物。我已经意识到，这种震惊，混乱和矛盾的奇怪酿造是生成时代的定义情感。大肆宣传三年后，AI持久的文化影响之一似乎是使人们感到自己正在失去它。”  阅读更多： https://theatln.tc/obfxrylp  href =“ https://www.reddit.com/user/theatlantic”&gt;/u/u/theatlantic     ”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/</guid>
      <pubDate>Tue, 19 Aug 2025 14:54:34 GMT</pubDate>
    </item>
    <item>
      <title>71％的人担心AI会取代他们的工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我在AI上看到的最负民意调查。 -71％担心AI会从事工作-66％担心AI将取代关系-61％担心AI增加电力消耗 请告诉我，Redditors并不是Reuters Poll的4,446人中的Redditors？      https://www.reuters.com/world/us/americans-fear-ai-perman-displacing-workers-workers-workers-reutersipsos-poll-finds-finds-2025-08-19/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muiyc7/71_of_people_are_are_concerned_ai_will_will_replace_their/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1muiyc7/71_of_people_are_are_concerned_ai_ai_will_will_will_will_replace_their/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/</guid>
      <pubDate>Tue, 19 Aug 2025 13:48:20 GMT</pubDate>
    </item>
    <item>
      <title>如果AI撞到能墙会怎样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muf2oo/what_happens_if_ai_hits_an_energy_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kerkula     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muf2oo/what_happens_if_ai_hits_an_energy_wall/</guid>
      <pubDate>Tue, 19 Aug 2025 10:54:07 GMT</pubDate>
    </item>
    <item>
      <title>招聘人员有麻烦。在对70,000个应用程序的大型实验中，AI代理在雇用客户服务代表方面的表现优于人类招聘人员。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mudqib/recruiters_are_in_trouble_in_a_large_experiment/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  摘要摘要：“我们研究用AI语音代理人代替人类招聘人员进行求职面试的影响。我们与一家招聘公司合作，进行了一项自然现场实验，其中随机分配了70,000名申请人，由人类招聘人员，AI语音代理人进行采访，或者在两者之间做出选择。在所有三个条件下，人类招聘人员都根据申请人在访谈和标准化的测试中的表现评估了访谈，并做出了招聘决策。与专业招聘人员的预测相反，我们发现AI领导的访谈将工作报价提高了12％，工作开始时的工作率为18％，并且在所有申请人中的保留下降了17％。申请人在客户体验调查中接受类似的可能性和费率面试和招聘人员质量的工作机会。提供选择后，有78％的申请人选择AI招聘人员，我们发现证据表明测试分数较低的申请人更有可能选择AI。分析访谈成绩单表明，与人为主导的访谈相比，AI-LED访谈从申请人那里获得了更多与申请人的信息。招聘人员对AI-Interview的申请人的访谈表现更高，但在其招聘决策中为标准化测试增加了更大的权重。总体而言，我们提供证据表明AI可以与人类招聘人员进行求职面试，同时保持申请人的满意和公司运营。 href =“ https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5395709”&gt; https://papers.ssrn.com/sol3/sol3/papers.cfms.cfm提交由＆＃32; /u/metaknowing     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mudqib/recruiters_are_in_trouble_in_a_large_experiment/</guid>
      <pubDate>Tue, 19 Aug 2025 09:36:32 GMT</pubDate>
    </item>
    <item>
      <title>大脑专家警告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1muconv/brain_experts_warning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大多数不在reddit上的人可能会从YouTube和其他新闻媒体中了解更多有关AI的信息。这使我进入了史蒂夫·巴雷特（Steve Barrett）在首席执行官日记上的最新YouTube视频中。  访谈包括丹尼尔·阿曼·安斯（Daniel Amen Ans）博士特里（Daniel Amen Ans Terry）博士的著名专家。  最明显的担忧是，AI创作者不是为社会利益引入LLM，而是为了获得最大化的利润和对股东的信托义务。   llm减少了用户的认知负荷，这会增加痴呆症和alzeimhers病的风险。但是，大多数使用Chatgpt之类的人更关心其短期福利。  最近发表的MIT研究强调了学生在降低批判性思维，创造力，长期学习和保留记忆力方面的危险。该研究表明，使用AI的学生提供论文缺乏对工作的自豪和所有权，显然影响了教育成就和成就。  ai缺乏人类的文化价值，并且对培训偏见表示关注。  最新问题是埃隆·马斯克（Elon Musk）和特斯拉（Tesla）的安妮（Annie）。当Chatgpt取消性对话时，安妮欢迎他们。现在考虑一下13岁男孩的手中。对他们的心理和情感发展的影响。  父母在这些问题上做了什么？使用  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sexyxymama2     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1muconv/brain_experts_warning/</guid>
      <pubDate>Tue, 19 Aug 2025 08:29:00 GMT</pubDate>
    </item>
    </channel>
</rss>