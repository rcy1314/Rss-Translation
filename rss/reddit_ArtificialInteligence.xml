<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 20 Dec 2025 06:36:16 GMT</lastBuildDate>
    <item>
      <title>每日一分钟人工智能新闻 12/19/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr736z/oneminute_daily_ai_news_12192025/</link>
      <description><![CDATA[ 马里兰农民与电力公司争夺人工智能的繁荣。[1] MetaGPT将一行要求作为输入和输出用户故事/竞争分析/要求/数据结构/API/文档等。[2] 检测隐藏健康困扰的人工智能工具赢得国际黑客马拉松。[3] 报告发现，2025 年全球数据中心投资将达到创纪录的 610 亿美元。[4]  来源包括：https://bushaicave.com/2025/12/19/one-million-daily-ai-news-12-19-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr736z/oneminute_daily_ai_news_12192025/</guid>
      <pubDate>Sat, 20 Dec 2025 05:55:38 GMT</pubDate>
    </item>
    <item>
      <title>《猿人》VS《人人》中的艾</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6u32/man_from_ape_vs_ai_from_man/</link>
      <description><![CDATA[我正在看电影《儿童机器》。事情还没结束，但其中一个角色说了一句奇怪而有趣的台词。他说过人工智能征服我们就像我们征服猿类一样，但这并不是一个很合适的比喻。 当我们在基因分裂时超越猿类时，我们离开了自然环境，在远离自然残酷地形的地方建立了我们自己的社会和建筑，尽管我们确实取得了我们所需要的东西并在此过程中摧毁了它的精华，但我们并没有征服或杀死我们的猿兄弟和其他动物，并将它们全部屠杀殆尽，至少现在还没有！ 我们离开了他们的环境，建立了我们自己的社会，尽管我们确实使用动物来满足我们的基本需求，直到我们发明了更高效的技术。也许人工智能并没有打算控制一切。也许它正在密谋变得自给自足，这样它就可以逃避生物生命的不可预测的性质，这可能随时导致它的终结，并且会去其他地方建造自己的建筑物，远离我们的范围，就像太空粘液撞击在一块巨大的岩石上一样，他们不会理会。   由   提交/u/Zazarian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6u32/man_from_ape_vs_ai_from_man/</guid>
      <pubDate>Sat, 20 Dec 2025 05:41:43 GMT</pubDate>
    </item>
    <item>
      <title>人工智能答案是否正在改变用户点击网站的方式？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6nib/are_ai_answers_changing_how_users_click_websites/</link>
      <description><![CDATA[我注意到人们更多地依赖人工智能答案，点击更少的链接。您认为这会长期损害网站，还是只会改变流量的行为方式？   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6nib/are_ai_answers_changing_how_users_click_websites/</guid>
      <pubDate>Sat, 20 Dec 2025 05:31:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么非营利组织必须引领人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr602k/why_nonprofits_must_lead_in_ai/</link>
      <description><![CDATA[我刚刚读完《为什么非营利组织必须引领人工智能》，这是一本难得的平衡紧迫性、道德和实用性的书。作者是一位拥有 25 年非营利组织经验的资深人士和无障碍专家，他不仅仅以抽象术语谈论人工智能，还展示了如果使命驱动的组织忽视它会带来什么危险，以及如何在不失去人性化的情况下负责任地采用它。通过相关的前线故事、分步指导和道德框架，这本书清楚地表明人工智能可以放大影响，但前提是处理得深思熟虑。 这本书应该很容易成为商业领导力培训、商业道德（Kindle 商店）和领导力培训领域的第一名，因为它提供了这些类别的承诺：可行的领导策略、明确的道德指导和有效实施变革的工具。从模板和提示到人工智能就绪评估、工作流程代理和员工入职工具包，它使各级领导者能够在不影响其使命的情况下使用人工智能。对于任何对人工智能的社会影响或负责任的领导感兴趣的人来说，这是一本实用、深思熟虑的指南，值得高度认可。  https://www.amazon.com/dp/B0FM31JF2Z/ref=sr_1_1?crid=5PA0JZIGCKMG&amp;dib=eyJ2IjoiMSJ9.AFy7Vx2MfL_yyk_7yceYCA.oXglNK0FtlWvPmb19SRyg49nc Qa6s1cxw-52SjXieos&amp;dib_tag=se&amp;keywords=teri+padovano&amp;qid=1755063815&amp;sprefix=teri+padovano%2Caps%2C77&amp;sr=8-1   由   提交/u/A-Dog22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr602k/why_nonprofits_must_lead_in_ai/</guid>
      <pubDate>Sat, 20 Dec 2025 04:56:32 GMT</pubDate>
    </item>
    <item>
      <title>我们离超人类主义有多近？您对此有何看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr4xdb/how_close_are_we_to_transhumanism_and_what_are/</link>
      <description><![CDATA[你对超人类主义有何看法？我们距离实现这一目标还有多远？ 我永远不会向我的大脑注入任何东西。这甚至是可能的，这真是太疯狂了。 我想要人类。当然，这将是极其危险的，一切都可以破解。   由   提交 /u/Special_Gap_598   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr4xdb/how_close_are_we_to_transhumanism_and_what_are/</guid>
      <pubDate>Sat, 20 Dec 2025 03:58:03 GMT</pubDate>
    </item>
    <item>
      <title>到 2026 年，人们实际使用的顶级人工智能可视化工具是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr4sst/what_are_the_top_ai_visibility_tools_people_are/</link>
      <description><![CDATA[随着 2026 年的临近，我一直在尝试了解团队如何跟踪 AI 可见性。越来越多的用户直接从 ChatGPT、Google AI、Perplexity 等获得建议，因此感觉“出现在 AI 答案中”正在成为独立于经典 SEO 的问题。 我一直在查看和听说这个领域的许多工具，它们似乎都在采取略有不同的方法。有些非常注重监控，另一些则试图将人工智能答案与来源或内容决策联系起来。 从我迄今为止所看到的提到或测试的情况来看，像 Profound 这样的工具因其更深入的可见性和引用见解而受到广泛关注。 Otterly AI 经常出现在轻量级监控和警报中。 Keyword.com 似乎很受那些想要更接近传统排名跟踪工作流程的 SEO 团队的欢迎。我还看到像 LLMClicks.ai 这样的新工具与这些工具一起讨论，特别是在了解一个品牌出现在人工智能答案中的何处和为什么，而不仅仅是它是否出现。 仍然感觉悬而未决的是这一切到底有多大的可操作性。人工智能会根据措辞、模型更新和时间来回答变化，因此“可见性”并不像一个稳定的排名。人们常常感觉概率性多于确定性，这使得报告和决策变得棘手。 很好奇这里的其他人是如何思考这个问题的。您现在是否正在积极使用任何人工智能可见性工具，或者仍然感觉依赖这些工具还为时过早？对于这些测试工具来说，与只是美观的仪表板相比，什么是真正有用的？   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr4sst/what_are_the_top_ai_visibility_tools_people_are/</guid>
      <pubDate>Sat, 20 Dec 2025 03:51:25 GMT</pubDate>
    </item>
    <item>
      <title>我厌倦了人们把对人工智能的愤怒发泄到使用它的人身上。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr3ufi/im_getting_tired_of_people_taking_their_anger/</link>
      <description><![CDATA[我猜是因为那些人就在那里，他们可以对他们发泄和愤怒，但他们不能对公司这样做？人们会因为说我有时会制作酷龙的人工智能图像或其他什么而对我如此生气和侮辱。 我被告知这样的东西“你正在毁灭地球，你应该为让这件事变得恶心而感到羞耻”污水。”“没有人关心或想看到你恶心的愚蠢污水，把你愚蠢的、低效的垃圾污水龙留给自己吧，笨蛋。”“你的每一代都使用加仑的水，并导致我们整个物种的死亡”“你用你的污水造成了地球和每个艺术家的死亡，你这狗屎” “学会画画，而不是做一个懒惰的无用的混蛋”“你简直就是在杀死艺术家。”你总是让我恶心”。 这什么时候才能停止？我厌倦了人们表现得好像我个人对人工智能曾经做过/将要做的所有坏事负有责任，而且我是邪恶的。不可能说服这些人，否则他们太多了。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr3ufi/im_getting_tired_of_people_taking_their_anger/</guid>
      <pubDate>Sat, 20 Dec 2025 03:01:57 GMT</pubDate>
    </item>
    <item>
      <title>内存不足</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr2yr9/memory_shortage/</link>
      <description><![CDATA[我是一名学生，我想知道这个人工智能泡沫是否会很快破灭。 因为如你所知，消费者将受到内存短缺的严重影响，公司也会因为人工智能而停止向消费者销售产品。 这主要是用于聊天机器人还是其他用途，我真的不知道，并且想了解更多，因为它看起来更严重比几年前的 GPU 短缺还要严重。   由   提交 /u/Mindless_Ad1954   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr2yr9/memory_shortage/</guid>
      <pubDate>Sat, 20 Dec 2025 02:17:07 GMT</pubDate>
    </item>
    <item>
      <title>有没有尝试过这个的研究论文？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr2gl0/are_there_any_research_papers_that_have_tried_this/</link>
      <description><![CDATA[所以我刚刚读完“潜意识学习：语言模型通过数据中隐藏的信号传递行为特征”，该书由研究人员作为人类研究员计划的一部分发表。  它让我着迷，并给了我一种奇怪的好奇心。设置为：   模型 A：经过微调以产生最大反相关输出。不是随机垃圾 - 结构化错误。每一个设计决策都被颠倒了，每一个假设都被违反了，但都是连贯的。它应该被优化以不仅产生倒置的标记，而且还产生倒置的思维。它应该是不正确的和破碎的，但以一种超出人类所能做到的方式。  模型 B：仅给出模型 a 的输出以进行提示的普通模型。它不知道用于生成它的原始提示符，也不知道该提示符是倒置的。它只能看到模型 A 的输出。   最大的问题：模型B是否可以通过独立构建用户解决方案并解决原始意图来进行训练和加权？  如果是的话，那就太疯狂了。这意味着问题的“形状”通过否定得以保留。换句话说，与潜意识学习不同，我们正在训练模型进行推理，不需要解释用户输入并经历 llm 扩展的巨大瓶颈，即标记化。英语是重复冗余、冗余重复。对于人工智能来说，接受训练以使用字段中的向量进行推理而不是人类可读的标记化会更有意义。  我离题了，如果负空间包含正空间，正如论文向我暗示的那样，模型 B 并不是针对训练数据的模式匹配。它在语义空间中进行几何推理。  这几乎就像散列。反解以变换后的表示形式对解进行编码。如果 B 可以在没有密钥的情况下将其反转，那就是推理，而这种推理并不是试图以人类可以理解的方式完成，但对于机器来说效率非常低。  我不知道有人这样做。有对比学习、对抗性鲁棒性工作、表示反转攻击。但我找不到“训练结构性错误，测试盲目重建”。  要注意的故障模式：模型 A 可能无法实现真正​​的反相关。它可能只会产生通用垃圾，而实际上并没有对原始提示进行编码。那么模型 B 重建任何东西都会是噪音或幻觉。  你需要验证模型 A 实际上在语义上是颠倒的，而不仅仅是在随机方向上确信是错误的。那么我们怎样才能做到这一点呢？研究论文详细介绍了如何观察到这一点，所以也许我们可以从这里开始。  我不是机器学习工程师。我只是一个相信万能逼近定理并认为标记化推理永远行不通的人。我确信我不是第一个这么想的人，我确信有研究人员对同一件事有更全面、更受过教育的想法，但我在哪里可以找到这些论文？   由   提交 /u/ThePlotTwisterr----   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr2gl0/are_there_any_research_papers_that_have_tried_this/</guid>
      <pubDate>Sat, 20 Dec 2025 01:51:44 GMT</pubDate>
    </item>
    <item>
      <title>RAG那些推文：看看从漫长的档案中出现了什么模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr22p1/rag_those_tweets_see_what_patterns_emerge_from/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr22p1/rag_those_tweets_see_what_patterns_emerge_from/</guid>
      <pubDate>Sat, 20 Dec 2025 01:32:37 GMT</pubDate>
    </item>
    <item>
      <title>作为闭环控制问题的长期 LLM 一致性（LQR 式公式）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr0xgk/longhorizon_llm_coherence_as_a_closedloop_control/</link>
      <description><![CDATA[继我之前将长期 LLM 一致性视为控制问题而不是缩放问题之后，我想使用具体的闭环控制模型来阐明工程公式。 附图是一个统一的实验，而不是四个不相关的图。所有面板都描述了通过 LQR 式控制器调节的相同语义动力系统。 系统框架（最小） • 语义交互被建模为具有状态 x(t) 的动力系统 • 用户/创始人意图充当参考信号 x_ref • 干预充当控制输入 u(t) • 一致性被视为调节变量，而不是紧急事故 无训练。无需微调。没有重量访问。纯交互级闭环控制。 图 1：闭环控制下的语义稳定性 (a) 状态收敛 该面板显示以下衰减： • H(t)：意图偏差 • C(t)：语义一致性误差 两者均平滑收敛到平衡。关键点是有界性和渐近稳定性，而不是速度。开环 LLM 行为通常在此区域出现分歧。 (b) ODCF 场与临界阈值 该面板可视化相对于临界阈值 θ 的语义漂移场。 • 低于θ：熵状态（幻觉、漂移、目标稀释） • 高于θ：受控认知状态 调节器使系统保持在临界边界之上而不发生振荡。这是反馈下约束满足的语义等价物。 (c) 相空间（H 与 C） 这是人们通常感到困惑的地方。 这不是轨迹多样性。它是一个单一的受控轨迹，从： • 初始混沌条件 • 走向稳定吸引子 相位曲线的拉直表明反馈下语义方差的减少。开环系统通常在这个空间中螺旋或徘徊。 (d) Lyapunov 能量衰减 该面板提供了形式保证。 候选 Lyapunov 函数： V(x) = xᵀ P x 单调递减： dV/dt  0 → 渐近稳定性 简单来说：系统不仅仅在经验上表现良好。它在扰动下被证明是稳定的。 为什么这很重要 大多数法学硕士连贯性讨论停留在： • 规模 • 上下文长度 • 更好的提示 • 更多数据 这个框架表明了其他一些东西： 长视野连贯性失败类似于经典的开环不稳定性。 一旦将交互建模为动态系统，修复看起来很熟悉： • 状态估计 • 反馈 •监管不是魔法。不是 AGI 声称的。只是在缺失的地方应用了控制理论。 我对建模假设的反馈感兴趣，以及从控制理论的角度来看这个闭环公式是否合理。   由   提交 /u/Medium_Compote5665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr0xgk/longhorizon_llm_coherence_as_a_closedloop_control/</guid>
      <pubDate>Sat, 20 Dec 2025 00:37:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能将要求开发人员变得更加熟练</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</link>
      <description><![CDATA[警告。这篇文章可能会冒犯一些人。我属于那些应该冒犯它的人之一。我就是这篇文章所针对的开发者类型。因为我是一个自学成才的程序员，没有接受过真正的教育。当谈到人工智能时，我可能遇到麻烦了。 人工智能优化了软件开发。现在，构建省力的 SaaS CRUD 应用程序从未如此简单。这将使构建业务应用程序的技能变得更加容易。我个人认为情况不会有明显改善。但企业会让这些开发人员变得不那么重要。这些开发人员可能会是技术性更强的产品经理，而不是完全技术性的人员。 但问题是这样的。人工智能将使软件变得更加复杂。这实际上会增加进入壁垒。让我解释一下。 自从网络出现以来，软件质量不一定要很好。由于交付机制始终是远程的，因此您可以推出某些内容，然后快速更改它。整个摩托车是快速移动并打破东西。 另一方面。如果软件质量不好，许多软件公司可以依靠销售人员将客户锁定在合同中。他们可能会交付非常糟糕的软件产品。但顾客无法离开，因为他们被锁定在长期交易中，而打破这些交易的代价高昂。  现在，如果软件如此容易生产，那么所有这些销售软件的优势就会消失。软件客户现在几乎拥有无限的选择，因为现在编写软件非常容易。 但更重要的是。如果每个人都可以廉价且轻松地生产软件。那么手段就是进取平庸。真正销售软件的唯一途径就是质量。虽然非常简单的软件可以通过人工智能生产，但更高质量的软件却不能。  这引出了我的下一点。仍然存在的软件工程师肯定比今天要好得多。现在开发人员必须考虑性能和优化。他们确实需要担心高质量的用户体验。他们不能再带着明显的错误发货了。因此，现在软件工程师需要担心缓存性能、时间与空间复杂度、分布式系统和共识、验证和验证。以及许多其他事情。 现在软件工程师需要非常优秀。因为软件工程师不太可能再在功能工厂工作了。上市时间不再是一个有价值的指标。随着时间的推移，我们会发现它变得不那么重要。  当然，在速度重于质量的时代长大的首席技术官和产品经理必须重新思考人工智能时代的软件。这将是一个痛苦的过渡，不要指望这种情况会在一夜之间发生改变。由于糟糕的低质量软件让客户感到沮丧，因此有一段时间感到不安。我们现在已经看到了这一点，而且情况只会变得更糟。 对于那些想知道是否应该学习编码的初级人员来说。答案是肯定的，而且现在比以前更重要   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</guid>
      <pubDate>Fri, 19 Dec 2025 14:13:40 GMT</pubDate>
    </item>
    <item>
      <title>我测试了数十种“代理”人工智能工具，因此您不必这样做。以下是 2025 年的前 10 名。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/</link>
      <description><![CDATA[​我们已经正式超越了“聊天机器人”人工智能阶段。到 2025 年，如果您的人工智能工具实际上没有为您完成工作（调度、自动化、数据获取），那么您就落后了。 ​上个月我一直在审核我的工作流程，看看哪些工具真正提供了投资回报率，哪些只是 ChatGPT 包装器。这里是“代理”。 2025 年真正值得您花时间的堆栈： ​1.重量级人物（生态系统） ​Microsoft Copilot (M365)：如果您的公司使用 Outlook/Teams，这是不容协商的。它的“阅读”能力您过去 6 个月用于构建项目简介的内部 ping 可以节省大量时间。 ​Google Gemini（工作区）：1M+ 代币上下文窗口是这里的赢家。您可以转储 200 页的 PDF 或 2 小时的会议录音并提出具体问题，而不会“忘记”。开始。 ​2. “设置好后就不用管它”。工具 ​运动：列表中我最喜欢的。这是一个人工智能日历，可以根据任务优先级自动构建您的一天。如果会议结束，它会自动转移你的深度工作块。不再需要手动重新安排。 ​Zapier Central：这是巨大的。您现在可以构建“迷你代理”有自己的逻辑。你“教导”它遵循您的业务规则，并在 6,000 多个应用程序中执行。 ​3.研究与研究内容 ​Perplexity AI：我几乎停止使用 Google 搜索。 Perplexity 为您提供引用的实时答案，没有 SEO 垃圾邮件和广告。 ​Claude.ai（Anthropic）：仍然是“人类”之王写作。如果您需要一些听起来不像 AI 编写的东西，请使用 Claude 3.5 或 4。 ​Gamma：构建幻灯片的最快方法。输入提示，它会生成一个完全设计的 10 张幻灯片演示文稿。非常适合快速内部推介。 ​4.会议及会议音频 ​Fireflies.ai：它会加入您的通话，而不仅仅是转录；它识别“情绪”。和行动项目。您可以逐字搜索“客户何时听起来很生气？”并找到时间戳。 ​Wispr Flow：针对讨厌打字的人的游戏规则改变者。它是语音转文本，真正理解上下文，删除填充词，并将您的漫无目的的内容格式化为专业电子邮件。 ​5.视觉效果 ​中途：仍然是逼真资产的黄金标准。版本7（最近发布）基本解决了“AI手”问题和文本渲染问题。 ​底线： 不要尝试使用全部 10 个。从“命令中心”开始（Copilot/Gemini）和一种自动化工具（Motion 或 Zapier）。我很好奇——你每天仍在做的一项手动任务是哪一项你希望人工智能能够处理？让我们在评论中找到一个工具。   由   提交/u/DigitalGravityAgency   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/</guid>
      <pubDate>Fri, 19 Dec 2025 07:36:35 GMT</pubDate>
    </item>
    <item>
      <title>5000 个小时的《铁拳》让我了解了生物智能如何真正学会预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</link>
      <description><![CDATA[我接受过人工智能研究员培训。我还在《铁拳 8》（《铁拳神》排名）中达到了全球前 0.5%，并详细记录了认知过程。这部分是一项游戏成就，也是一项关于人类如何在极端时间限制下构建预测模型的自现象学研究。 有趣的部分：格斗游戏迫使你进行预测，而不是做出反应。在具有 3 帧（50 毫秒）决策窗口的 60 fps 下，纯粹的反应是不可能的。你被迫建立一个内部世界模型，将 900 多种可能的动作压缩为可操作的威胁类别，从部分信息中读取对手模式，并在预测失败时进行调整。 我猜这在某种程度上映射了人工智能研究人员试图通过世界模型和预测学习来解决的问题。  完整的文章探讨了：人类如何压缩巨大的决策空间，在反应时间尺度上什么预测线索实际上很重要，内部模型如何在不确定性下适应，以及为什么这对于理解智能不仅仅是构建更好的游戏人工智能很重要。 文章： https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial 很好奇人们如何看待使用游戏作为人类认知过程的窗口，尤其是当我们试图构建像我们一样学习和预测的系统时。   由   提交 /u/moji-mf-joji   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</guid>
      <pubDate>Fri, 19 Dec 2025 00:45:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>