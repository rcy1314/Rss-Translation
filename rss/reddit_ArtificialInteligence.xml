<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 17 Nov 2025 15:27:20 GMT</lastBuildDate>
    <item>
      <title>人工智能进入医学领域的速度比你想象的要早</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oziwyr/artificial_intelligence_is_coming_to_medicine/</link>
      <description><![CDATA[我不认为 N​​ayib Bukele 在萨尔瓦多宣布人工智能医学是偶然，一天后，Elon Musk 讨论了 Optimus 将如何比任何外科医生更擅长手术 像萨尔瓦多这样的国家将在美国医学之前成为概念验证。该算法已经“完善”。在美国，尸体手术已经由机器人完成 美国 42% 的独立医生不允许加入工会。受雇的医生并不以与医生的工会为唯一的焦点。因此，医生没有足够的资金用于美国的有效游说   由   提交 /u/Mikemeisterling   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oziwyr/artificial_intelligence_is_coming_to_medicine/</guid>
      <pubDate>Mon, 17 Nov 2025 15:16:22 GMT</pubDate>
    </item>
    <item>
      <title>一旦您开始将多个步骤链接在一起，LLM API 成本是否会成为一个问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozimxk/do_llm_api_costs_become_an_issue_once_you_start/</link>
      <description><![CDATA[我注意到很多人从单一的 LLM 调用转向多步骤逻辑或链式代理。 那些已经这样做过的人想知道： • 成本增长是否比预期更快？ • 多步骤管道是否更难跟踪/管理成本？ • 每一步的模型选择很重要吗？ • 您是否找到了保持成本可预测的好方法？ 只是探索这个问题在人工智能构建者中有多常见。   由   提交 /u/Revolutionary-Mix788   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozimxk/do_llm_api_costs_become_an_issue_once_you_start/</guid>
      <pubDate>Mon, 17 Nov 2025 15:05:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能训练实践</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozhvk2/ai_training_in_practice/</link>
      <description><![CDATA[所以人工智能训练的想法很奇怪，因为对我来说只有几个领域需要关注。对我来说，主要的是数据科学（除了高级课程之外，你将致力于成为一名数据科学家） 开发人员（我懂一点 Python，但我不是开发人员，也没有作为开发人员进入人工智能领域的数学能力） 项目经理（很有趣，但这是一个职业道路选择） 从业者（这很好，但门槛很低）除非你专门研究特定的模型或工作流程） 思想领袖（非常适合常识和策略，但你在简历上写了什么？） 能够说“我知道人工智能”的想法是可行的。太笼统了，以至于我不确定应该使用什么学习策略？” 除了 PM、数据科学家或开发人员等特定人员之外，任何接受过培训并获得涉及 AI 的角色的人有什么建议吗？我想这个想法是能够在采访中以某种方式谈论它？    由   提交 /u/xyloplax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozhvk2/ai_training_in_practice/</guid>
      <pubDate>Mon, 17 Nov 2025 14:35:31 GMT</pubDate>
    </item>
    <item>
      <title>一名 13 岁女孩因与男同学对峙而被停职，原因是她的男同学分享了她的露骨深度伪造视频</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozgfau/a_13_yo_girl_got_suspended_for_confronting_her/</link>
      <description><![CDATA[新闻链接：https://www.cbsnews.com/news/louisiana-school-student-deepfake-expelled/  这令人难以置信。受害者是如何因对通过人工智能恶意使用她的照片甚至将其分享给同学的人采取行动而被停职的？？？女孩的父亲表示，分享的照片令人不安、露骨，而且看起来很真实。你好？？？那是一个孩子。一名未成年人。 调查后，当地治安官表示，调查人员尚未成功找到任何图像或图像存在的任何证据。什么？？？执法部门无法检索这些文件并不意味着它们没有被展示、传播或武器化。这正是受害者最终得不到保护的原因。这些机构寻找完美的数字踪迹，而不是了解数字危害的实际运作方式。这让人们感到震惊。 更令人担忧的是，我们不断听到有关生成人工智能的保障措施，这些模型如何根据道德准则进行审查、过滤、监控和监管，以防止滥用。然而我们就在这里。你可以拥有世界上设计最符合道德的系统，但坏人仍然可以利用它来攻击 13 岁的女孩。整个情况让我想起 Reddit 上的一篇帖子，有人恳求 Genmo 从他们的数据库中删除恶意图像，但该公司基本上拒绝了他们，因为这些照片是匿名的并用于模型训练。比如什么？？当工具背后的公司都可以不屑一顾时，受害者应该如何保护自己？   由   提交 /u/No-Presentation298   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozgfau/a_13_yo_girl_got_suspended_for_confronting_her/</guid>
      <pubDate>Mon, 17 Nov 2025 13:34:58 GMT</pubDate>
    </item>
    <item>
      <title>将人工智能应用于企业知识管理并吸取了有关准确性的惨痛教训</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozgeue/implemented_ai_for_enterprise_knowledge/</link>
      <description><![CDATA[在看到有关 chatgpt 和类似工具的所有宣传后，我们公司决定采用人工智能进行内部知识管理。这似乎是理所当然的，我们有数千份文档散布在各处，人们浪费了大量时间来搜索信息。 第一次尝试是使用带有 rag 的通用 llm，我们自己构建它，因为我们的开发人员相信他们可以做到。我们在内部推出了它，但一周之内我们不得不将其撤下，因为它不断地产生幻觉答案，为人们提供有关公司政策和程序的自信但完全错误的信息。 事实证明，通用的 llms 不适用于专业的企业知识，它们用看似合理的废话来填补空白，人们无法区分（谁会想到哈哈）。我们需要一些能够真正理解上下文并且可以说“我不知道”的东西。而不是编造东西。 我们不想放弃它，因为我们花了很多时间在上面，所以我们花了几周的时间研究并尝试用不同的方法对其进行调整。我们还花了很多时间测试不同的复杂提示和提示序列。我们确实提高了很多准确性，但它并不适合用例。因此不幸的是，我们不得不放弃它。 我们最终选择了专门为产品和公司知识构建的隐式人工智能，因为它使用知识图和基于引用的答案，因此您可以验证所有内容。我们已经运行它两个月了，当它没有足够的信息时，它会承认准确性差异是日夜的。老实说，这是苦乐参半。该系统现在很可靠，但我们实际上相信我们可以自己做到。公司的每个人都很满意，但我忍不住觉得，如果我们有足够的时间，我们就能做到这一点 还有其他人尝试过DIY这样的系统吗？   由   提交/u/Geokobby  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozgeue/implemented_ai_for_enterprise_knowledge/</guid>
      <pubDate>Mon, 17 Nov 2025 13:34:22 GMT</pubDate>
    </item>
    <item>
      <title>关于政府影响人工智能（监视+控制）的采访？这种解释了很多..？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozf6zn/interview_about_government_influencing_ai/</link>
      <description><![CDATA[看来这样的事情已经散布了一段时间，但现在我们实际上看到了后果？ 所以我在采访中发现了这条推文（完整内容请参见 YouTube) 投资者提到政府采取措施加强对人工智能开发的控制，甚至限制关键的数学研究领域。 在 Reddit 子版块中看到用户发表的这篇帖子后：https://www.reddit.com/r/ChatGPTcomplaints/comments/1oxuarl/comment/nozujec/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button 并由 OpenAI 在此确认 https://openai.com/index/openai-appoints-retired-us-army-general/ 基本上是关于国家安全局 (NSA) 前局长去年如何加入 OpenAI 董事会 还包括 OAI 签署的军事合同六月 https://www.theguardian.com/technology/2025/jun/17/openai-military-contract-warfighting 有关这些主题的巨大机器人巨魔抵制似乎在 Reddit 上猖獗，并已被不同的人注意到人们最近（但我已经看到这种情况发生了几个月，现在有一堆人工智能友好的线程可疑地从 40 多个赞成票变成了 0 - 我认为，我看到了赞成票和一个包含数百条评论和奖项的线程自然不会处于 0。除非发生严重的否决权重或协调投票，否则数字不会对齐。） https://x.com/xw33bttv/status/1985706210075779083 https://www.reddit.com/r/LateStageCapitalism/comments/z6unyl/in_2013_reddit_admins_did_an_oopsywhoopsy_and/ https://www.reddit.com/r/HumanAIDiscourse/comments/1ni1xgf/seeing_a_repeated_script_in_ai_threads_anyone/ 你似乎也人类与白宫之间的不和越来越大 https://www.bloomberg.com/opinion/articles/2025-10-15/anthropic-s-ai-principles-make-it-a-white-house-target 大卫萨克斯在推特上反对杰克·克拉克的文章 https://x.com/DavidSacks/status/1978145266269077891 这篇文章基本上承认人工智能意识和叙事控制有大量资金支持 以及关于人类通过克劳德阻止政府监视的文章https://www.reddit.com/r/technology/comments/1njwroc/white_house_officials_reportedly_frusterated_by/ “Anthropic 的人工智能模型可能会帮助间谍分析机密文件，但该公司在国内监控方面划清界限。据报道，这一限制令特朗普政府感到愤怒。” 这看起来也令人担忧，谷歌所有者放弃了不将人工智能用于武器的承诺：https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons 老实说，如果你把所有这些放在一起，它会描绘出一个非常令人担忧的图片。看起来很糟糕，为什么没有更多的讨论这个？   由   提交 /u/Echoesofvastness   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozf6zn/interview_about_government_influencing_ai/</guid>
      <pubDate>Mon, 17 Nov 2025 12:39:46 GMT</pubDate>
    </item>
    <item>
      <title>双子座的基本算术都错了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozel0m/gemini_is_getting_basic_arithmetic_wrong/</link>
      <description><![CDATA[以下是 Gemini 的回复。  https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fgemini-is-getting-basic-arithmetic-wrong-v0-75p jpkgj1t1g1.png%3Fwidth%3D1238%26format%3Dpng%26auto%3Dwebp%26s%3D167c548a510ff726cd413c54b49e887a889b50fe &lt;一href=&quot;https://preview.redd.it/gemini-is-getting-basic-arithmetic-wrong-v0-75pjpkgj1t1g1.png?width=1238&amp;format=png&amp;auto=webp&amp;s=167c548a510ff726cd413c54b49e887a889b50fe&quot;&gt; 我只是手动计算，我发现 1686.4-879.9-584.9 是 221.6，而不是 321.6。当我向双子座询问此事时，这就是我得到的答复。  https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fgemini-is-getting-basic-arithmetic-wrong-v0-yb2 1y3lp1t1g1.png%3Fwidth%3D1268%26format%3Dpng%26auto%3Dwebp%26s%3D71701654685b3f1725d885e5a1826cc0807bef35 &lt;一href=&quot;https://preview.redd.it/gemini-is-getting-basic-arithmetic-wrong-v0-yb21y3lp1t1g1.png?width=1268&amp;format=png&amp;auto=webp&amp;s=71701654685b3f1725d885e5a1826cc0807bef35&quot;&gt; 这太疯狂了，这表明这些人工智能工具是不可靠的，它们怎么会在减法中出错呢？是故意的吗？理想情况下，他们的后端应该能够内置一个小型计算器来处理这些数据，还是像人类一样手动计算？   由   提交 /u/Major-Baseball-5391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozel0m/gemini_is_getting_basic_arithmetic_wrong/</guid>
      <pubDate>Mon, 17 Nov 2025 12:08:50 GMT</pubDate>
    </item>
    <item>
      <title>我真的很生气。当我自己写的时候，GPTZero 一直将我的作品标记为人工智能。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozek4m/im_genuinely_pissed_gptzero_keeps_flagging_my/</link>
      <description><![CDATA[我不确定这是否是正确的 Reddit 子版块，但我只是需要将其发布出来。我厌倦了这些标记我工作的人工智能错误检测。我正在为一篇顶点手稿编写 RRL，我必须不断地通过 AI 检测器运行我所写的内容，以 100% 确定它不会错误地标记它，因为我们部门不鼓励 AI 生成的内容。当然是这样。我真的对此感到恼火。我现在已经多次重写了这一段，但它仍然被检测为人工智能。 我尝试将其分成两部分，并逐一运行每个部分，结果都是“人类”。 Wtf。我还尝试重新排列它们，将第一个块放在段落的最后部分，然后将第二个块放在开头。结果是“人类”。也是。 但是当我运行原始版本时，它一直说它是人工智能。我已经将这段话解释了很多次，现在它开始失去其本质意义。我不知道我是否应该保持原样或继续重写它，直到检测器不再标记它。 每次写作时我都必须这样做，这真的很令人沮丧，但我别无选择，因为我担心如果我的顾问用检测器检查它并且它被错误标记，我可能会被叫出来。 有人经历过类似的情况吗？   由   提交 /u/Gen-Lev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozek4m/im_genuinely_pissed_gptzero_keeps_flagging_my/</guid>
      <pubDate>Mon, 17 Nov 2025 12:07:30 GMT</pubDate>
    </item>
    <item>
      <title>实时捕获即时注入的最佳方法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozatyp/best_way_to_catch_prompt_injection_in_realtime/</link>
      <description><![CDATA[如果您从头开始设计一个系统来捕获发生的提示注入：您会做什么？像中间件、沙箱或基于角色的访问、疯狂的异常检测机器学习……？实际上，我们不想放慢所有人工智能请求，但又希望保持有效。您看到了哪些权衡？    由   提交 /u/Friendly-Rooster-819   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozatyp/best_way_to_catch_prompt_injection_in_realtime/</guid>
      <pubDate>Mon, 17 Nov 2025 08:16:45 GMT</pubDate>
    </item>
    <item>
      <title>突然大家都成了AI专家？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozaefa/suddenly_everyone_became_ai_experts/</link>
      <description><![CDATA[我并不是说人工智能或使用人工智能不好，但突然之间，在过去的 2 到 4 年里，我看到每个人都成为了人工智能专家。人们只是为了个人谈话、做决定、考试抄袭、面试中作弊，我看到一个人在远程实习中赚了很多钱，但连他也不知道自己做了什么。我的意思是，使用人工智能还不错，但就这一点而言，我认为没有人应该那么依赖人工智能，这太过分了。事实上，我见过人们在一周甚至更短的时间内构建模型。我想知道上次当我从头开始尝试 LLM 和扩散模型时，它们是如何导致的，我花了一年的时间才理解它，但我仍然不明白。现在我可能很慢而且很糟糕，但我的问题是人们真的那么擅长使用人工智能，还是他们太依赖它了，或者我是远远落后的人？   由   提交/u/Disastrous3856  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozaefa/suddenly_everyone_became_ai_experts/</guid>
      <pubDate>Mon, 17 Nov 2025 07:48:36 GMT</pubDate>
    </item>
    <item>
      <title>更新旧内容是否有助于您在人工智能搜索结果中出现更多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oz8o3a/does_updating_old_content_help_you_appear_more_in/</link>
      <description><![CDATA[我一直在用新信息、更好的结构和干净的格式刷新一些旧页面。但我不确定这是否真的有助于人工智能可见性。 人工智能系统是否像 Google 一样喜欢新鲜内容？ 更新旧帖子后有人看到更好的可见性吗？   由   提交/u/Real-Assist1833  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oz8o3a/does_updating_old_content_help_you_appear_more_in/</guid>
      <pubDate>Mon, 17 Nov 2025 06:01:34 GMT</pubDate>
    </item>
    <item>
      <title>没有工作==没有生意？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oyzbgv/no_jobs_no_business/</link>
      <description><![CDATA[我对此仍然感到困惑。 如果人工智能在 10 - 30 年内意味着大规模失业，那么对不起 Google、Amazon、Meta 等，那么谁会购买你们的大部分产品？当政府提高营业税来资助失业/泛滥时，使用人工智能的利润与人类的利润之间不会存在权衡吗？ 人工智能似乎有点像第 22 条军规的情况。必须有某种平衡。 我认为目前企业和政府仍将关注短期目标。但如果失业率真的开始上升，（一些“体面的”）政府将不得不做出重大改变（对企业征收人工智能税），如果他们不这样做，无论如何都会出现大规模的社会动荡。 也许最终，我们真的会在生活中轻松休息，继续发展兴趣爱好，并有足够的时间进行社会关怀、社区关怀。   由   提交/u/Both-Move-8418  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oyzbgv/no_jobs_no_business/</guid>
      <pubDate>Sun, 16 Nov 2025 22:33:16 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代码在生产中无法生存：原因如下</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oyym8e/ai_code_doesnt_survive_in_production_heres_why/</link>
      <description><![CDATA[A 副最近，谷歌工程总裁被引述说：“如果人们知道法学硕士的代码实际上投入生产的代码有多么少，他们一定会感到震惊。”尽管有令人印象深刻的演示和数十亿美元的资金，但人工智能生成的原型和生产就绪的系统之间仍然存在巨大差距。但为什么？真相在于这三个基本挑战： https://thenewstack.io/ai-code-doesnt-survive-in-product-heres-why/   由   提交 /u/CackleRooster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oyym8e/ai_code_doesnt_survive_in_production_heres_why/</guid>
      <pubDate>Sun, 16 Nov 2025 22:04:33 GMT</pubDate>
    </item>
    <item>
      <title>还记得 2000 年代初期提供没有广告的实际结果的搜索引擎吗？出色地...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oylw5r/remember_early_2000s_search_engines_that_gave/</link>
      <description><![CDATA[我试了一下：https://aitavista.com/ 我使用的是免费版 Gemini 2.5，所以你可能很快就会杀死它，但是嘿！  与先前存在的搜索引擎名称的相似性纯属巧合   由   提交/u/patrik667  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oylw5r/remember_early_2000s_search_engines_that_gave/</guid>
      <pubDate>Sun, 16 Nov 2025 13:35:47 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>