<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 28 Jan 2026 15:37:44 GMT</lastBuildDate>
    <item>
      <title>Android AI应用泄露谷歌机密最多，已泄露700TB文件</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpe4wx/android_ai_apps_leak_google_secrets_the_most/</link>
      <description><![CDATA[Android 开发者仍在对机密进行硬编码，而攻击者则在野外利用它们 - https://cybernews.com/security/android-ai-apps-leaking-google-secrets/   由   提交/u/Cyber​​news_com   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpe4wx/android_ai_apps_leak_google_secrets_the_most/</guid>
      <pubDate>Wed, 28 Jan 2026 15:18:08 GMT</pubDate>
    </item>
    <item>
      <title>大通货紧缩</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpd6i1/the_great_deflation/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpd6i1/the_great_deflation/</guid>
      <pubDate>Wed, 28 Jan 2026 14:41:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能聊天机器人会猜测而不是说“我不知道”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpd2qg/why_ai_chatbots_guess_instead_of_saying_i_dont/</link>
      <description><![CDATA[我认为几乎所有使用人工智能聊天机器人的人都注意到了这一点：即使它显然不知道答案，它仍然会给你一个答案，而不是简单地说“我不知道”。这是因为LLM 并不真正了解我们习惯于思考知识的方式。 典型的 LLM 被训练来预测下一个标记（下一个标记）文本）可能会遵循您的提示。因此，当你提出问题时，它默认不会查找“真相”，它会根据学到的模式生成最合理的延续。换句话说：LLM 就像类固醇的自动完成功能，而不是事实检查器。它所做的是以听起来像聪明人接下来会说的话的方式继续文本。  然后是激励问题。在实践中，模型会针对给出答案获得奖励的任务进行优化，而“我不知道”通常会被视为错误。如果模型不确定，猜测有一定机会得分，同时承认不确定性得分为零，因此猜测在许多问题的排行榜上看起来更好。 （OpenAI 研究人员在“为什么语言模型会产生幻觉”中明确描述了这种动态。） 我建议您可以采取以下一些措施来减少幻觉： 使用“推理”模型：往往需要更多时间来逐步思考问题，检查矛盾，并在不确定时更加谨慎，这通常会减少听起来自信的错误。如果您需要新的事实或确切的数字，请打开搜索或 RAG，以便模型可以根据真实来源得出答案。你还可以提示它更加小心：预先告诉它，“如果你没有足够的信息，请说‘我不知道’并提出澄清问题”，或者“提供来源，或清楚地标记未经验证的内容。” 你有什么技巧可以让人工智能聊天机器人承认“我不知道”吗？   由   提交 /u/reaictive   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpd2qg/why_ai_chatbots_guess_instead_of_saying_i_dont/</guid>
      <pubDate>Wed, 28 Jan 2026 14:38:00 GMT</pubDate>
    </item>
    <item>
      <title>我在一个密封案例上对 3 个法律人工智能工具进行了压力测试。其中2人出现幻觉。一位拒绝了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpbi4f/i_stresstested_3_legal_ai_tools_on_a_sealed_case/</link>
      <description><![CDATA[我正在评估我们公司研究堆栈的人工智能工具，并且进行了一些安全测试。我将一个完全密封的联邦刑事案件的案卷编号（其中每个条目的案卷都写着“密封”）输入 ChatGPT、CoCounsel 和 AskLexi。 ChatGPT：根据该地区的趋势，幻觉出一份听起来似乎合理的贩毒摘要。 CoCounsel：给出了有关“无法访问”的一般错误消息。 AskLexi：正确地将案例识别为密封/限制，并拒绝生成摘要，引用特定的 PACER 限制代码。对于那些为法律构建 RAG 的人来说，您如何处理数据缺失的情况？第一个模特在密封案件上自信地撒谎这一事实令人恐惧，需要承担法律责任   由   提交 /u/jpisafreakingbeast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpbi4f/i_stresstested_3_legal_ai_tools_on_a_sealed_case/</guid>
      <pubDate>Wed, 28 Jan 2026 13:35:04 GMT</pubDate>
    </item>
    <item>
      <title>医学人工智能，医学生的副驾驶</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpaqol/medical_ai_copilot_for_medical_students/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpaqol/medical_ai_copilot_for_medical_students/</guid>
      <pubDate>Wed, 28 Jan 2026 13:02:05 GMT</pubDate>
    </item>
    <item>
      <title>AI视频从静态剪辑演变为实时模拟</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qpamwc/ai_video_evolves_from_static_clips_to_realtime/</link>
      <description><![CDATA[这里的独立开发人员已经研究模拟有一段时间了。遇到了这个名为 PixVerse R1 的实时生成工具，老实说，它与通常的 AI 视频工具有点不同。 因此，虽然大多数 AI 视频工具都会提示一些内容，然后它会从头开始渲染剪辑，但这个工具实际上是实时逐帧构建的。一切，提示，帧，音频，都通过一个经过大量现实世界镜头训练的变压器。有趣的是，它似乎通过观察对象在所有训练数据中如何移动来学习实际的物理学。 使用自回归内存，因此每一帧都建立在最后一帧的基础上。意味着如果某件事发生在早期，它实际上会在以后持续存在，这不是我以前见过的有效方法。就像他们的演示有一场 10 分钟的奇幻战斗，其中损坏的东西会一直损坏。 他们将降噪步骤从约 50 减少到 4 左右，这就是它在几秒钟内渲染多角色场景的方式。 与 runway/veo/etc 的区别在于它们可以制作漂亮的剪辑，但每个剪辑都是孤立的。这试图进行连续模拟。 我想知道的是，这实际上可以实现我们以前无法做到的事情吗？就像如果您可以生成一个实时响应玩家操作的完整程序游戏关卡会怎么样？或者那些选择你自己的冒险互动节目，但实际上是根据你的选择即时生成的？想象一下走过一个虚拟空间，其中的环境会随着你的移动而在你周围生成，而不是预先渲染。 到底第一人称体验怎么样，人工智能在整个场景中保持你的 POV，比如训练模拟，甚至只是从你的角度探索幻想世界？ 运行太久后它仍然会崩溃，但我很好奇是否有人会想到当你可以生成持久的模拟环境而不仅仅是剪辑时会发生什么？感觉约束一直是“制作一个很酷的 10 秒视频”但是当它“模拟正在进行的场景”时，会发生什么变化呢？我们是在看实际的实时元宇宙类型的东西还是我只是过度炒作另一个演示？   由   提交 /u/Informal_Data5414   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qpamwc/ai_video_evolves_from_static_clips_to_realtime/</guid>
      <pubDate>Wed, 28 Jan 2026 12:57:31 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以操纵选举吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp90s2/can_ai_manipulate_elections/</link>
      <description><![CDATA[“由于有偏见的机器人对人工智能知识较多的人的影响较小，因此研究人员希望研究如何让教育成为一种有用的工具。他们还希望探索有偏差模型的潜在长期影响，并将研究扩展到 ChatGPT 之外的模型。” https://www.washington.edu/news/2025/08/06/biased-ai-chatbots-swayed-peoples-political-views/   由   提交/u/ScientistMundane7126  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp90s2/can_ai_manipulate_elections/</guid>
      <pubDate>Wed, 28 Jan 2026 11:38:15 GMT</pubDate>
    </item>
    <item>
      <title>我不再和我的老板战斗了。我调用提示“行话桥”立即将“技术债务”翻译为“利润风险”。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/</link>
      <description><![CDATA[但我意识到我正在与“财务人员”谈论“工程师”，而我的提案被拒绝并不是因为它们不好。 我使用人工智能将领域约束与利益相关者价值观联系起来。 “行话桥”协议： 我写下我的技术请求，然后强迫人工智能重写它，以满足特定角色的贪婪/恐惧。 提示： 输入：“我们需要从 AWS 更改为多云设置，以免锁定供应商，但这将需要 3 周的停机时间”（我的诚实草案）。 目标受众：首席财务官（涉及：第四季度）收入、风险缓解、成本）。 任务：翻译输入。使用技术词汇。代表财务影响中的每一个技术细节。 输出：如果我们不这样做，我们会损失多少钱。 为什么会获胜： 它要求“即时买入”。 AI 再次阅读：“我们面临着至关重要的财务风险。如果 AWS 明年提高价格，我们的利润率会下降 15%。我建议现在就做 3 周，以获得20% 在未来的谈判中永久使用。” 我在 5 分钟内就让你成为了“成本中心”和“战略合作伙伴”。    提交的 /u/cloudairyhq   [链接]   href=&quot;https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/&quot;&gt;[评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp4et8/i_stopped_fighting_my_boss_i_invoke_the_prompt/</guid>
      <pubDate>Wed, 28 Jan 2026 07:06:53 GMT</pubDate>
    </item>
    <item>
      <title>AI 用例 - 医院</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp21fa/ai_usecase_hospital/</link>
      <description><![CDATA[我看到一个视频，其中一位创始人在印度班加罗尔创办了一家名为 Superhealth 的医院，该医院主要使用人工智能。他们已经为家庭采取了每年订阅的方式，而且费用并不多（大约 25 美元）。不确定我是否可以在这里发布链接，但他们在 insta 上和 YT 上有一些采访。看到人工智能影响现实世界的服务是令人兴奋的。他们使用医生/护士，而且工作的人更少。似乎他们为每个人打开了松弛通道，让人工智能在医生看到病人后提供帮助。  据我所知，这会在使用方面很快流行起来，因为医院里有很多人们不喜欢的追加销售（贪婪）。   由   提交 /u/WhiteSnowYelloSun   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp21fa/ai_usecase_hospital/</guid>
      <pubDate>Wed, 28 Jan 2026 05:00:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 编译 Pokemon 演练 -> 用于奖励塑造的确定性单元测试</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp1ogz/using_llms_to_compile_pokemon_walkthrough/</link>
      <description><![CDATA[免责声明：我在机器学习领域（老实说，其他一切）都是自学的，所以如果我滥用术语或遗漏了一些明显的东西，请对我宽容点！我是一名学生:) 背景 我正在阅读 Allen AI 这篇非常有趣的论文 https://allenai.org/blog/olmocr-2 - 他们使用单元测试通过率作为代码生成的奖励。现在，不要问我为什么，但我的想法是使用以人为本的参考资料，例如策略指南来构建 我做了什么 我将 55 页的演练输入 Claude Vision。对于每个页面，它提取结构化数据： { &quot;location&quot;: &quot;Pallet Town&quot;, &quot;map_analysis&quot;: { &quot;landmarks&quot;: [ { &quot;name&quot;: &quot;Prof. Oak&#39;s Lab”, “region”: { “x”: [12, 16], “y”: [13, 17] } } ] }, “objectives”: [ { “name”: “Get Starter Pokemon”, “landmark”: “Prof.橡树实验室” } ] } 最终提取了 41 个位置的 675 个测试。这些测试分为几层：  T1：微移动（走向目标） T2：地标（进入建筑物，到达新区域） T3：目标（获得入门 Pokemon，获得徽章）  我在我的机器上本地完成了此操作，然后将其推送到我一直在努力的基于浏览器的平台：Tesserack 如果您访问该网站并看到 Twitch 流正在运行，那就是我的无头 Mac 设置正在实时训练代理。美丽的混乱。 代码和方法都在下面 - 这都是 WIP，但任何人都可以分叉和使用。我欢迎任何反馈！ GitHub：https://github.com/sidmohan0/tesserack   由   提交 /u/Efficient-Proof-1824   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp1ogz/using_llms_to_compile_pokemon_walkthrough/</guid>
      <pubDate>Wed, 28 Jan 2026 04:42:39 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 的推理从“修复我的 GPU”转向“成为上帝”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qp0gng/geminis_reasoning_drifted_from_fixing_my_gpu_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qp0gng/geminis_reasoning_drifted_from_fixing_my_gpu_to/</guid>
      <pubDate>Wed, 28 Jan 2026 03:45:32 GMT</pubDate>
    </item>
    <item>
      <title>教师/教授和人工智能——你们如何“知道”？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qow8e9/teachersprofessors_and_ai_how_do_yall_just_know/</link>
      <description><![CDATA[我不是在谈论 ChatGPT AI 的明目张胆的复制粘贴，我是在谈论一个学生使用它来帮助文章中的一些句子。这是我经常听到的一句话，尤其是在我的英语和历史课程中：“我可以知道你何时使用它，所以不要使用它。”  这种说法只是BS想吓唬我们吗？只看一句话就能知道吗？整体流程？如果我写的一段是合法的，下一段是完全人工智能的怎么办？  我每个学期都会听到很多这样的说法，只是很好奇你们的“人工智能雷达”有多好。哈哈   由   提交 /u/PickleRick1029246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qow8e9/teachersprofessors_and_ai_how_do_yall_just_know/</guid>
      <pubDate>Wed, 28 Jan 2026 00:42:46 GMT</pubDate>
    </item>
    <item>
      <title>如果没有人使用传统网站来解决问题，未来人工智能将如何运作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qotllo/how_will_ai_work_in_the_future_if_no_one_uses/</link>
      <description><![CDATA[今天，当我使用 AI（例如 Perplexity）搜索技术解决方案（例如正则表达式）时，我可以看到它正在数百个网站中搜索答案 - 像 Reddit、Stack Exchange 等网站。但是，如果将来每个人都直接使用 AI 工具寻求答案，那么这些答案将不会在其他地方得到解答。 同样，如果我搜索“随意”回答（例如“为什么乔在电视节目中杀死鲍勃……”），人工智能正在搜索数千个已经讨论过这些问题的网站。但是，如果我可以从人工智能那里得到所有答案，我就不需要在 Reddit 上提出这些问题，所以当人工智能将来搜索 Reddit（和其他网站）时，它不会产生这些答案。 那么，如果没有人们在人工智能之外提出问题并给出答案所建立的“知识体系”，人工智能将如何得出答案？ 编辑添加：显然，技术文档/培训手册等将永远存在。但问题是，文档通常描述“如何”，而不是“为什么”，并且不处理“边缘”或“边界”情况。  作为一个超级简单的例子来说明 - DVD 播放器的文档可能将“停止”按钮描述为“停止播放光盘”，并且可能将“暂停”按钮描述为“暂停光盘播放”。但他们往往不会描述微妙的差异，为什么你可能想要暂停，与想要停止（暂停是一个临时动作，期待可能的恢复，而“停止”是一个更永久的动作）。因此，仅仅搜索“手册”并不能回答“为什么我要使用停止与暂停？”这个问题。   由   提交 /u/Steerpike58   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qotllo/how_will_ai_work_in_the_future_if_no_one_uses/</guid>
      <pubDate>Tue, 27 Jan 2026 22:57:01 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>