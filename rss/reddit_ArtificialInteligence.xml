<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 25 Aug 2025 21:21:10 GMT</lastBuildDate>
    <item>
      <title>为何押注廉价的AI推理是LLM-Wrapper创业公司和VCS的冒险举动</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n01e41/why_betting_on_cheap_ai_inference_is_a_risky_move/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  启动型和VCS在LLM-WRAPPERS上银行 - 换货界面或在第三方大型语言模型上构建的插入界面或应用程序，通常会以较小或负有利率转售 - 走上tigrope。假设使用这些模型的收入成本（COGS）将继续下降是一个大胆的赌博。它依靠用户满足当前型号功能的内容，而不是推动更强大的系统或复杂的用例。 当然，小查询，计算或文档摘要的成本会以对数下降。但是很快，用户将期望LLMS生成整个论文，播客，商业模型，季度报告，IPO招股说明书，电影或视频游戏。能够深入推理的高级AI代理人将处理长达数小时的任务，处理每次会议的数千个查询和数十亿个令牌。 预测五年内将使用多少代币或GPU人类使用。它可以归结为两个Occam的剃须刀场景：  推断变得如此便宜，实际上可以忽略不计，正如Sam Altman最近声称的那样。  AI在竞争环境中的AI应用程序的应用程序始终将足够强大的计算在最强大的范围内留在最理想的情况下，同时将利润付诸实践。 70年前，它绊倒了另一种破坏性技术。美国原子能委员会负责人曾声称核电有一天会忽略不计的边际成本。如果廉价推断是真正的迫在眉睫，那么每个新的LLM或Imaging模型发布都不会融化AI提供商的服务器。 我相信Jevons Paradox在这里更有意义。即使相同的产出变得更便宜，需求飞涨，更复杂的应用程序以及新的用例，例如自动驾驶，机器人技术和现实世界中的模拟，在行业和科学中的现实世界模拟也将使数据中心保持最大化，并且芯片以全油门运行。 更便宜的推理仍然可以具有竞争力的优势。如果您要在超级评分中运行模型，从而使COGS收取三倍或以成本的五倍购买NVIDIA GPU，则可能会将自己的价格从市场上销售。这就是为什么像Google这样的技术巨头已经建立了自己的AI处理器已有十年了，而不是在公开市场上支付15倍的计算。 您怎么看？特别是所有闪亮的AI初创公司？推断成本会崩溃，还是需要计算的要求保持超过效率的提高？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tf1155     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1N01E41/WHY_BETTING_ON_CON_CHEAP_AIE_IS_IS_IS_IS_A_RISKY_MOVE/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n01e41/why_betting_on_cheap_ai_inference_is_a_risky_move/</guid>
      <pubDate>Mon, 25 Aug 2025 20:17:16 GMT</pubDate>
    </item>
    <item>
      <title>相同的提示，不同且相互矛盾的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n01bl4/same_prompts_different_and_conflicting_answers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人在使用相同的提示中使用相同的提示遇到了问题，然后在使用相同的提示开始新讨论时会收到冲突或不同的响应？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/normal_apricot8761     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n01bl4/same_prompts_different_and_conflicting_answers/</guid>
      <pubDate>Mon, 25 Aug 2025 20:14:41 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt是否曾经帮助您解决了医生无法的严重健康问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n01aga/has_chatgpt_ever_helped_you_solve_a_serious/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我很好奇，如果这里的任何人在医生无法给出一个严重的健康问题上，我很好奇。   “认真”我不一定意味着它必须是生命或死亡，我的意思是对您的健康或质量的质量造成的症状（我的健康症状，疾病，都会遇到良好的症状，误解了您的状态，误解了，误解了，误解了，误解了，误解了，误解了，误解了，误解了，误解了，误解了，误解了，不一管理，或者至少帮助您指向正确的方向。 如果您有一个故事，我很想听听它是如何发生的以及Chatgpt扮演了什么角色。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n01aga/has_chatgpt_ever_helppt_ever_helped_you_solve_a_serious/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n01aga/has_chatgpt_ever_helped_you_solve_a_serious/</guid>
      <pubDate>Mon, 25 Aug 2025 20:13:28 GMT</pubDate>
    </item>
    <item>
      <title>ELI5：“下一步的标记预测”在AI中意味着什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00x9u/eli5_what_does_next_token_prediction_mean_in_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，每当人们谈论AI模型（例如ChatGpt）工作时，他们就会提到旁边的“临近预测”。但是，这实际上是什么意思？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mindexplorer11    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n00x9u/eli5_what_does_does_next_next_next_token_token_token_mean_mean_in_in_ai/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00x9u/eli5_what_does_next_token_prediction_mean_in_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 19:59:50 GMT</pubDate>
    </item>
    <item>
      <title>AI和Jobs：AI会从就业市场增加或减去吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00rlt/ai_and_jobs_will_ai_add_or_subtract_from_the_job/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，而最初的看法是AI取代了作业，这是杰克逊霍尔（Jackson Hole）在不同方向上共享的学术研究的最初经验证据。详细信息：   https://www.forbes.com/sites/paulocarvao/2025/208/25/ai-and-and-jobs-the-fed-is-weighing-ingighing-ingighing-inflation-fearation-fears-and-labor-market-market-risk/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ublyoption7980     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n00rlt/1n00rlt/ai_and_jobs_will_will_ai_ai_ai_ai_ai_asubtract_from_from_from_the_job/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00rlt/ai_and_jobs_will_ai_add_or_subtract_from_the_job/</guid>
      <pubDate>Mon, 25 Aug 2025 19:53:46 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI SaaS初创公司只是在GPT周围包装吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究很多AI工具，感觉就像10分中的9个基本上是用一个不错的UI和一些自动化的自动化。有些人确实有用，但是大多数人都感到匆忙，就像创始人正在追逐炒作，而不是建立持久的价值。 您认为如何将“炒作”工具与未来几年实际上生存的工具分开？   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_ai_saas_startups_just_just_wrappers_arappers_araund_gpt/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_saas_startups_just_just_just_wrappers_arappers_around_gpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</guid>
      <pubDate>Mon, 25 Aug 2025 19:43:49 GMT</pubDate>
    </item>
    <item>
      <title>Google应该在Shapez / Shapez上进行RL 2</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwrzn/google_should_do_rl_on_shapez_shapez_2/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   shapez对于rl来说很棒;清晰的渐进信号需要很多（实际上）的推理，2D（Shapez）或3D（Shapez 2）网格，不需要实时管理。你们怎么看？还有其他看起来像很棒的环境的游戏吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_landscape_6819     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwrzn/google_should_do_rl_on_shapez_shapez_2/</guid>
      <pubDate>Mon, 25 Aug 2025 17:24:13 GMT</pubDate>
    </item>
    <item>
      <title>人类在AI方面有什么替代/互补性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwhfw/what_alternativecomplementarity_for_humans_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   随着AI逐步接管许多专业活动，可以肯定的是，必须接受这项技术而不是闭上眼睛，但我们必须反思这种情况。那么，人类在AI方面有什么替代/互补性？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzwhfw/what_alternativecomplentarity_for_humans_in/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwhfw/what_alternativecomplementarity_for_humans_in/</guid>
      <pubDate>Mon, 25 Aug 2025 17:13:29 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）的Xai在AI比赛中起诉Apple和Openai，App Store排名</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    投诉称​​，苹果和Openai合谋抑制了Xai的产品，包括Apple App Store。 “如果不是因为与Openai的独家交易，Apple将没有理由避免在其App Store中更突出地包含X App和Grok App的特色，” Xai说。 苹果和Openai没有立即回应置评请求。 本月初，马斯克威胁要苏普蒂蒂诺，加利福尼亚州的苹果公司在他的社交媒体平台上的一篇文章中说，苹果的行为是“除了在App Store的Aii Company以外的任何AI Company都无法在App Store中获得＃1。”苹果与OpenAI的合作关系已将其AI平台融合到iPhone，iPad和Mac。 Microsoft Bass（MSFT.O）以及中国的初创公司DeepSeek都在加利福尼亚州的联邦法院（Sam Altman）起诉Openai及其在加利福尼亚州联邦法院的首席执行官Altman。 Maker Epic Games命令Apple允许Mike Scarcella的报告。    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzu6r7/elon_musks_xai_sues_sues_sause_apple_and_openai_over_over_ai/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 15:49:49 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院说95％的企业AI失败了 - 但这是5％的正确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近关于企业AI的麻省理工学院研究重击： 95％的生成AI飞行员没有ROI 。大多数项目在“试点炼狱”中停滞不前，因为员工花费的时间比节省时间更多。  突出显示了5％成功部署的方法：   验证税→大多数AI系统是“自信是错误的” 。即使是微小的不准确性，也迫使人类重新检查每个输出，从而删除ROI。  学习差距→工具通常不会保留反馈，适应工作流程或随着使用而改善。没有学习循环，飞行员停滞不前。  暂时正确＆gt;自信错误→赢家正在建立： 量化不确定性（具有信心得分或“我不知道”的回应） 旗帜缺失上下文而不是虚张声势   从纠正中持续不断改进（“准确性的fly fly fly fly fly fly fly fly fly fly fly fly fly&gt;      大的要点： Enterprise AI并没有失败，因为模型还不够强大。之所以失败，是因为他们不承认自己  不  知道。  ，如果有时会说“我不知道”，您会更信任AI吗？您如何在实际工作流中平衡速度与验证？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/praveenweb   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_ai_ai_fails_ai_fails_but_heres_heres_what/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</guid>
      <pubDate>Mon, 25 Aug 2025 15:14:31 GMT</pubDate>
    </item>
    <item>
      <title>会计AI：Sage Copilot数据故障的教训</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzsnnb/ai_in_accounting_lessons_from_sage_copilots_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近阅读了一篇有关涉及 Sage Copilot 的情况，Sage Group的AI助手。据报道，当询问发票时，该工具从其他客户的帐户中披露了有限的详细信息。 Sage将其描述为一个小问题，确认没有暴露实际发票，并表示问题很快解决了。 虽然影响似乎很小，但它突出了一个重要的一点：当在会计或财务中使用AI时，数据隔离和隐私保护措施至关重要。当涉及敏感的客户信息时，即使是小故障也可能引起人们的担忧。似乎提醒您，从一开始就需要在体系结构中内置隐私控制。 很好奇听到您的想法：公司应如何在维持客户机密性的同时采用AI？    阅读完整的文章        &lt;！提交由＆＃32; /u/u/oncleangel     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzsnnb/ai_in_in_accounting_lesson_from_sage_copilots_data/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzsnnb/ai_in_accounting_lessons_from_sage_copilots_data/</guid>
      <pubDate>Mon, 25 Aug 2025 14:53:49 GMT</pubDate>
    </item>
    <item>
      <title>男子用溴化钠交换餐盐后住院...因为Chatgpt说了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在华盛顿，一名60岁的男子在医院里花了3个星期的幻觉和偏执狂，在用溴化钠替换了奶盐（氯化钠）。   OpenAI在其政策中指出，ChatGpt不是医疗顾问（尽管老实说，大多数人，大多数人都不会阅读精美的印刷品）。 The fair (and technically possible) approach would be to train the model (or complement it with an intent detection system) that can distinguish between domains of use: - If the user is asking in the context of industrial chemistry → it can safely list chemical analogs. - If the user is asking in the context of diet/consumption → it should stop, warn, and redirect the person to a professional source.  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzr8tg/man_hospitalized_after_swapping_tapple_salt_with/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</guid>
      <pubDate>Mon, 25 Aug 2025 13:58:48 GMT</pubDate>
    </item>
    <item>
      <title>我花了一个月的时间测试Chatgpt与Claude作为AI导师与真正的学生。这实际上是有效的（什么无）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我花了一个月的时间测试chatgpt vs claude作为与真正的学生的AI辅导员。这是实际起作用的（以及什么不起作用）   chatgpt = speed demon进行考试准备，克劳德=思维教练，以深入理解。策略性地使用=改变游戏规则。 所以我是一名教育家，他厌倦了没有真实数据的所有AI炒作。决定实际测试Chatgpt的学习模式和Claude的学习模式，与50多名不同学科的50名学生整整一个月。 最令人惊讶的发现？   他们正在解决完全不同的问题。它就像将一辆跑车与远足的靴子与远足的靴子和完全不同的效果进行比较。   chatgpt学习模式在需要时获胜：   快速的作业帮助（快速解决数学问题40％） 逐步逐步过程 最后一分钟的考试cramming  清楚，清晰，清晰的解释模式对于：   实际理解概念（35％的保留率更好） 创意项目和论文 构建批判性思维 坚持   我的建议策略的瞬间：   使用克劳德（Claude  数学问题：通过3分找到圆的方程     chatgpt：直接进行配方，系统求解，在2分钟内进行检查的答案     claude：  &#39;什么使三个点特殊形成圆圈？首先导致真正的几何直觉，然后是JEE/竞争考试的数学  ？整天Chatppt。因为真正擅长数学？克劳德（Claude）的方法建立了一个基础，使您可以解决您从未见过的奇怪问题。 学生的底线： 停止询问哪个AI更好”并开始询问“哪个AI适合我现在要做的事情。您的经验是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fun-bet2862     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzgk4v/i_spent_a_month_month_testing_chatgpt_vs_claude_claude_as_as_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 04:01:21 GMT</pubDate>
    </item>
    <item>
      <title>您的大脑成为训练数据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不久前，我看着一个男人经历了AI的演变的tiktok。他提出了一个坚持我的声称（不确定是原来是他的）。他说，建立单人亿万美元的公司的人不会是一个从头开始编码AI的人，而是可以使AI自动化的人，而是可以让AI依靠身份并通过提示来操纵这些身份以在某些情况下操纵某些事情的人。基本上，创建了使某人以某种方式行事的最佳方法的模拟，并且拥有最人文数据的人，其中很多人可以训练AI来做到这一点。 我想到的第一个人是埃隆·马斯克（Elon Musk）。从这个角度来看，我认为他的大部分冒险与此相吻合并不是一个巧合。 x用于数据。特斯拉进行决策。作为个性和模拟。最糟糕的是，Neuralink。如果这成为标准，那么我们大脑中的芯片本质上将我们的身份变成AI的培训数据。而不是AI仅仅猜测我们从数字足迹或输入的东西中做什么，顺便说一句，这些东西已经很准确，它实际上会知道我们甚至在我们思考之前的一举一动。有访问该培训数据的人可以控制我们，模拟我们将准确地行事的情况。 那么，您如何看待？我只是偏执吗？我只是说明显的大声吗？您认为将有防御措施的保障措施吗？您还能添加什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/braiiie     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</guid>
      <pubDate>Mon, 25 Aug 2025 01:16:06 GMT</pubDate>
    </item>
    <item>
      <title>“ Palantir的工具构成了我们刚刚开始理解的隐形危险”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定这是正确的论坛，但这觉得很重要：  https://www.theguardian.com/commentisfree/2025/aug/24/palantir-artificial-intelligence-civil-rights  “被称为智力，监视，目标获取和侦察（ISTAR）系统，这些工具由几家公司构建，允许用户 track，track，detain，new and of war of war a a sake a sape a sape a sape a saper a sap a a sai  由ISTAR技术陷阱驱动的牵引力比移民以及他们的家人以及他们的家人以及他们的家人以及他们的家人以及他们的家人，以及他们的家人，以及他们的家人，以及他们以及他们的家人，以及他们以及他们的连接。他们似乎侵犯了第一和第四修正案的权利：首先，建立了庞大且无形的监视网络，这些网络限制了人们在公开场合共享的东西，包括他们遇到的人或旅行的地方；其次，通过启用无需进行保证的搜索和无人偏见的范围，而他们的知识很快。 href =“ https://www.amnestyusa.org/press-releases/usa-global-tech-made-by-palantir-palantir-palantir-and-babel-ind-babel-street-street-street-survreillance-theats-to-pro-pro--------------- href =“ https://www.thenation.com/article/world/world/nsa-palantir-israel-israel-gaza-ai/tnamp/”&gt;加沙的居民  - 他们的人权。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz9w0u/palantirs_tools_pose_pose_an_invisible_danger_danger_we_we_are/”&gt; [link]   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</guid>
      <pubDate>Sun, 24 Aug 2025 22:43:37 GMT</pubDate>
    </item>
    </channel>
</rss>