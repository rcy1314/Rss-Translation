<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 04 Jan 2026 15:23:42 GMT</lastBuildDate>
    <item>
      <title>目前在特定专有数据上训练人工智能聊天机器人或法学硕士模型方面进展如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3s7p0/what_is_currently_going_on_regarding_training_an/</link>
      <description><![CDATA[嗨， 我正在为客户开发一个项目，我需要了解该机制的基本情况，其中客户专有数据用于训练模型，反过来它会提供更准确的答案和更接近客户工作空间上下文的建议。 您能否推荐任何资源或书籍来提供其整体情况，而不一定是具体的实现？ 谢谢   由   提交 /u/Loner_Indian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3s7p0/what_is_currently_going_on_regarding_training_an/</guid>
      <pubDate>Sun, 04 Jan 2026 15:08:26 GMT</pubDate>
    </item>
    <item>
      <title>帮助老手的最佳人工智能应用程序。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3s4gm/best_ai_app_to_aid_an_old_timer/</link>
      <description><![CDATA[你好， 我在浏览器中使用 AI 一段时间了。我最终保持浏览器打开，这样就不会丢失历史记录。我只要求写信的帮助，奇怪的帮助弄清楚某物是什么等等。最简单的人工智能应用程序是什么？我67岁了。    由   提交 /u/throtaway12100111   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3s4gm/best_ai_app_to_aid_an_old_timer/</guid>
      <pubDate>Sun, 04 Jan 2026 15:04:37 GMT</pubDate>
    </item>
    <item>
      <title>CES 上发布的可穿戴设备通常是演示产品还是即将发货的产品？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ro1b/are_wearable_launches_at_ces_usually_demos_or/</link>
      <description><![CDATA[到目前为止，我已经看到了各种各样的公告，有些感觉像是精美的预览，有些则像是为展会盛装打扮的早期原型。 对于密切关注可穿戴设备的人来说：CES 发布的产品多久会在合理的时间内变成真正的、可购买的产品？ CES 更多的是传达意图，还是公司实际上用它来推出近乎就绪的硬件？ 尝试调整期望，这样我就不会过度索引展位之外不存在的东西。   由   提交 /u/Forward-Skirt-5710   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ro1b/are_wearable_launches_at_ces_usually_demos_or/</guid>
      <pubDate>Sun, 04 Jan 2026 14:45:31 GMT</pubDate>
    </item>
    <item>
      <title>Grafted Titans：开放式法学硕士的即插即用神经记忆</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3qn9x/grafted_titans_a_plugandplay_neural_memory_for/</link>
      <description><![CDATA[我一直在尝试测试时训练 (TTT)，特别是尝试复制 Google 的“Titans”核心概念。架构（即时学习神经记忆），无需从头开始训练 Transformer 的大量计算需求。 我想看看我是否可以“嫁接”使用消费级设置（我有 Nvidia DGX Spark BlackWell，128GB）将可训练内存模块移植到冻结开放重量模型 (Qwen-2.5-0.5B) 我称这种架构为“移植泰坦”。我刚刚完成了 BABILong 基准测试的评估，结果非常有趣 设置：  基础模型： Qwen-2.5-0.5B-Instruct（冻结权重）。 机制： 我通过可训练的交叉注意力将记忆嵌入附加到输入层（第 0 层）门控机制。它充当适配器，允许内存在基本模型保持静态的同时递归更新。  基准（BABILong，最多 2k 上下文）：我使用了严格的 2 轮协议。  第 1 轮： Feed 上下文 -&gt;内存更新-&gt;上下文已删除。 第 2 轮： Feed 问题 -&gt;模型仅从神经记忆中检索答案。  结果：我将移植的记忆与两个基线进行了比较。  随机猜测： 0.68% 准确度。基本上都是错的。 Vanilla Qwen（完整上下文）：我将整个令牌上下文提供给提示中的标准 Qwen 模型。它的得分为34.0%。 嫁接泰坦（仅记忆）：模型在提示中没有看到任何上下文，只看到记忆状态。得分为44.7%。  看来神经记忆模块正在充当 去噪滤波器。当像 Qwen-0.5B 这样的小模型看到 1.5k 个文本标记时，它的注意力机制就会被“稀释”。通过噪音。然而，移植的记忆将该信号压缩为特定的向量，使检索比本地注意窗口更清晰。 局限性：  信号稀释：因为我在第 0 层注入记忆（软提示风格），所以我怀疑当信号向上传播时会出现梯度消失效应。未来的版本需要多层注入。 Guardrails：内存目前是“容易受骗的”。它将所有输入视为事实，这意味着它在多回合设置中非常容易受到中毒。 基准：这是一个 2 回合评估。长时间对话（10 轮以上）的稳定性尚未得到证实。  我目前正在清理代码和权重，以开源整个项目（如果您想稍后搜索，将在“AI Realist”下）。 还有其他人尝试过使用交叉注意适配器进行内存检索吗？我很好奇在中间层（例如，24 中的第 12 块）注入是否可以解决信号稀释问题，而不会破坏冻结权重的稳定性。 想法？   由   提交 /u/Forsaken-Park8149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3qn9x/grafted_titans_a_plugandplay_neural_memory_for/</guid>
      <pubDate>Sun, 04 Jan 2026 14:01:00 GMT</pubDate>
    </item>
    <item>
      <title>寻找人工智能代理领域的自由职业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3qi2g/looking_for_freelance_work_in_the_field_of_ai/</link>
      <description><![CDATA[大家好，我作为数据科学家在 MnC 工作了 2 年，并且构建 AI 代理（相当复杂的语言代理/工作流程）已经有一段时间了。  作为 2026 年的决心，我想将这项技能转变为副业/自由职业/建筑咨询。  您认识正在积极追求此目标或需要这些服务的人吗？对于前者，您是如何开始的以及所需的专业知识水平是多少 - 一般而言。 对于前者，如果我们能够联系那就太好了。 谢谢！   由   提交 /u/The-Lord_of-Hell   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3qi2g/looking_for_freelance_work_in_the_field_of_ai/</guid>
      <pubDate>Sun, 04 Jan 2026 13:54:24 GMT</pubDate>
    </item>
    <item>
      <title>教程：使用开放模型免费生成 AI 语音</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3qe2n/tutorial_free_ai_voice_generation_using_open/</link>
      <description><![CDATA[我正在分享一个我一直在开发的语音生成设置，该设置可以免费使用演示形式，并且主要基于开放或可访问的组件构建。 该项目的目标是探索是否可以在不将人们锁定在昂贵的封闭平台中的情况下实现高质量的语音合成。这并不是商业宣传；它试图记录一个实用的替代方案，并从关心开放人工智能基础设施的人那里获得反馈。 它目前支持什么： – 用于旁白和播客的人工智能语音生成 – 具有合理质量的快速推理 – 用于测试和实验的免费演示使用 为什么这可能有用： – 在没有供应商锁定的情况下测试语音管道 – 了解现代 TTS 系统如何连接在一起 – 将开放方法与专有服务进行比较 我对技术特别感兴趣来自此社区的反馈、架构批评和改进想法。 直接来源 morvoice 如果这跨越了任何规则边界，请随意删除它 - 这里的目的是共享资源并向他人学习，而不是推广。   由   提交 /u/Ok-Radio7329   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3qe2n/tutorial_free_ai_voice_generation_using_open/</guid>
      <pubDate>Sun, 04 Jan 2026 13:49:11 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 提案：三种模式，一个想法。如何修复对齐。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3pvo2/openai_proposal_three_modes_one_mind_how_to_fix/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3pvo2/openai_proposal_three_modes_one_mind_how_to_fix/</guid>
      <pubDate>Sun, 04 Jan 2026 13:25:05 GMT</pubDate>
    </item>
    <item>
      <title>问题？我认为。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ome1/question_i_think/</link>
      <description><![CDATA[大家好。和一位专门研究人工智能的哲学教授一起吃年夜饭。长话短说，我使用 ChatGPT 的方式与以前不同。我遇到了一个障碍，那就是它没有掌握时间的概念。我需要时间戳来整理和构建内容。它解释说这是一台没有上述功能的机器，但我发现自己在想——因为都是一和零，人们是否发现了漏洞或提示？我的意思是，如果我的 iPhone 可以编排 24 小时时钟/日历，我相信你们中的某个人已经拥有了？不管怎样，提前谢谢大家，新年快乐！    由   提交 /u/FiredSmoke   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ome1/question_i_think/</guid>
      <pubDate>Sun, 04 Jan 2026 12:20:46 GMT</pubDate>
    </item>
    <item>
      <title>最佳人工智能治理工具 - 哪一个有效</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3n7ft/best_al_governance_tools_which_one_works/</link>
      <description><![CDATA[大家好， 需要发泄一下，哈哈。也许这对某人有帮助。 我们有一个名为 Flinkit 的小项目。公司正在发展壮大，有了新的合作伙伴，一切都很好。但现在我们合作伙伴的企业客户想知道我们使用什么人工智能以及数据去向。我们对此一无所知，所以我们开始寻找 Al 治理工具。 Credo Al 先尝试一下。看起来不错，但它是为大企业设计的。设置花了很长时间，仪表板很混乱。每当合作伙伴问一些简单的问题时，我们就必须进行长时间的挖掘。定价也非常企业化。放弃了。 整体 Al 比 Credo 更好，但报告很糟糕。报告过于笼统，缺少我们合作伙伴实际需要的内容。必须通过电子邮件不断解释事情，任何入职培训也比我们想象的要花更长的时间。几乎放弃了，打算从我们的产品中删除 Al，哈哈。 Test360 有人在 Slack 小组中提到了这一点。没想到太多，但实际上还不错。设置大约需要 3 个小时，大部分是自动化的。它会扫描您的人工智能工具并绘制出数据流。生成您可以在合作伙伴要求时导出的报告。不再需要来来回回。 并不完美，但它有效并且定价感觉公平。这就是我们真正需要的。 TL;DR：小团队，合作伙伴想要 Al 合规性信息，尝试了 3 个工具，这个最适合我们。   由   提交 /u/Big-Tax-994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3n7ft/best_al_governance_tools_which_one_works/</guid>
      <pubDate>Sun, 04 Jan 2026 10:59:05 GMT</pubDate>
    </item>
    <item>
      <title>最大的人工智能子系统，但其中大部分是由反人工智能人士组成的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ji7j/biggest_ai_sub_but_its_mostly_populated_by_far_by/</link>
      <description><![CDATA[我支持人工智能。我不会隐瞒这一点，我喜欢人工智能。我喜欢使用它，并且对它未来的发展感到兴奋。我仍然担心所有令人讨厌的事情，比如政府用它来监视人们，用它进行审查等等。 任何时候我在这里发帖，它总是支持人工智能。我对人工智能无法做某事感到失望，我对朋友们在得知我使用人工智能时对我生气感到困扰，我对那些喜欢用它生成愚蠢视频的人的仇恨感到遗憾，我很兴奋它将能够做一些新的和很酷的事情。 但是每一次，几乎每次，帖子都会立即变为 0，在我这边，帖子会继续下降，有时低至 -24，很多回复都是只是侮辱我，称我为愚蠢的人工智能兄弟，说“没有人想看到你愚蠢的垃圾”之类的话，告诉我“很好”当我感到悲伤时，朋友们会因为人工智能而对我非常生气，并且通常会侮辱我，并且非常反人工智能。 我所做的任何回复都会立即被否决，并且随着帖子停留的时间越长，投票率就会继续下降，最终所有支持人工智能的人（很少）都说出了他们的观点，如果我不删除该帖子，我只会得到近乎无限的人偶尔进来侮辱我或告诉我他们有多么讨厌人工智能。 然后我所看到的就是所有反人工智能的人都以大量的赞成票来侮辱我，而所有支持人工智能的人都以大量的反对票来侮辱我。 这里没有真正的讨论，只是一群人进来侮辱别人。到目前为止，大多数回复都是这样的：“好吧，哭得更厉害，没有人想看到你的愚蠢的垃圾。”把那恶心的狗屎留给你自己。” 我真的不明白这个子的意义是什么？看起来更像是对专业人工智能人士来说这是一个陷阱。他们来这里以为可以讨论人工智能，但他们得到的只是人们侮辱他们，告诉他们他们是垃圾，垃圾人类，应该感到羞耻。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ji7j/biggest_ai_sub_but_its_mostly_populated_by_far_by/</guid>
      <pubDate>Sun, 04 Jan 2026 07:14:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能内存功能正在快速推出，但安全模型尚未跟上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</link>
      <description><![CDATA[使用 ChatGPT 内存大约 6 个月了。真正有用 - 记住我的工作设置、偏好、家庭事务。但我也告诉了它关于健康问题、工作压力、财务决策的问题。如果有人可以访问它，他们不仅仅会获得密码。他们得到了我是谁的综合资料。 现在每个大公司都在推动这一点。 ChatGPT 有记忆。克劳德有项目。双子座正在测试它。音调始终是“真正了解你的人工智能”。 这就是困扰我的地方：传统数据库存储孤立的数据。 Gmail有电子邮件。日历有约会。独立的孤岛。 人工智能内存主动连接一切。在一次聊天中提到胸痛，在另一次聊天中提到工作压力，在第三次聊天中提到家庭健康史——它综合了所有这些。这就是特点，但也是使违规变得更加危险的原因。您的电子邮件提供商不会建立心理档案。 AI 内存确实是这样设计的。 尝试在谷歌上搜索这些系统的安全性。找到了 ChatGPT 的一些文档，几个开源文档（Mem0、Zep、EverMemOS）。大多数人专注于使检索工作顺利进行。安全部分只是说“我们加密数据”没有太多细节。 无法找到以下方面的好信息：  人工智能在回答编码问题时可以访问健康数据吗？ 如果一个内存受到损害，所有内容都会泄漏吗？ 当你“删除”某个内存时一段记忆，它真的消失了吗？  OpenAI 每周有 2 亿+ 用户。即使 10% 的人启用了记忆功能，也意味着 2000 万人拥有了解他们一切的人工智能系统。一次泄露不仅仅是泄露密码——它还会泄露多年的背景、人际关系、私人想法、健康信息，所有这些都已合成并可供使用。 与密码不同，泄露后你无法更改你的生活史。 也许我想得太多了。但业界似乎在功能方面进展迅速，而在安全模型方面进展缓慢。我们不应该在它成为主流之前进行对话吗？ 我只是偏执还是这确实令人担忧？   由   提交/u/Secure-Run9146  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</guid>
      <pubDate>Sun, 04 Jan 2026 06:29:44 GMT</pubDate>
    </item>
    <item>
      <title>入侵台湾会扼杀人工智能的进步吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</link>
      <description><![CDATA[现在有很多关于委内瑞拉为中国入侵台湾开绿灯的预测... 鉴于用于人工智能的 90% 以上的先进芯片都是台湾制造的，这一切将走向何方？   由   提交/u/SirBoboGargle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</guid>
      <pubDate>Sat, 03 Jan 2026 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>我们正在讨论人工智能的未来，就好像法学硕士是最终形式一样</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</link>
      <description><![CDATA[LLM 对 AI 的影响就像软盘对数据中心的影响一样。 我认为人们犯的一个巨大错误是认为 AI 意味着 LLM，这限制了他们理解 AI 对社会的风险和影响的能力。 LLM（大型语言模型）是当前生成人工智能的最先进技术，但 AI不限于LLM。在 LLM 之前，有 HMM、GBM、RNN、VAE、GAN 等。 虽然 LLM 在生成 AI 功能方面提供了显着改进，但它们并不是 AI 模型将采用的最终形式。将会出现更多的创新，这些创新将使法学硕士看起来很原始，甚至可能过时。 因此，当人们说“人工智能不会取代你的工作”时，实际上是这样的。或“人工智能不够准确，不会导致大规模失业”，或者“人工智能不能有知觉或试图毁灭人类”，他们通常谈论的是当前法学硕士的局限性，而不是一般的人工智能。这些论点通常指出了我们今天看到的具体弱点，但这些只是当今技术的暂时限制，而不是人工智能最终可能成为的样子。 就像 RNN 无法生成大量连贯文本但法学硕士现在可以一样，较新形式的生成人工智能展示这些能力并可能在许多任务上超越人类可能只是时间问题。 现在，我们需要就人工智能对社会的影响进行对话，而不仅仅是思考法学硕士。我们需要展望该技术的未来，令人沮丧的是，大多数讨论都无法超越当前的法学硕士。   由   提交 /u/Je-ne-dirai-pas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</guid>
      <pubDate>Sat, 03 Jan 2026 08:18:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>