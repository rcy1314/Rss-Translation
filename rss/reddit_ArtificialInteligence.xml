<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 09 Aug 2025 21:22:50 GMT</lastBuildDate>
    <item>
      <title>OCR的AI对手写数学和科学答案的分级有多好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mly4nb/how_good_is_ai_at_ocr_for_grading_handwritten/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我正在建立一个以教育为中心的平台，该平台将很大程度上依赖于光学角色识别（OCR）。我要考虑的主要挑战之一是AI是否可以可靠地阅读和理解扫描的PDF的手写答案，尤其是对于数学和物理等主题。 例如，如果学生对纸上的数学问题进行完整的解决方案，那么在纸上编写了数学问题，AI不仅可以识别该解决方案，还可以确定该解决方案是否正确？当前AI/OCR技术在此类任务中的准确性如何，并且确实可行？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mly4nb/how_good_is_is_ai_ai_ai_ocr_ocr_for_grading_handwritten/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mly4nb/how_good_is_ai_at_ocr_for_grading_handwritten/</guid>
      <pubDate>Sat, 09 Aug 2025 19:34:30 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个基准有效地减轻了古哈特定律的影响？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlxlvp/is_there_a_benchmark_that_effectively_mitigates/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  甚至可以创建的基准？尝试创建这种类型的基准  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mlxlvp/is_there_a_a_a_benchmark_that_that_that_that_that_mitigates/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlxlvp/is_there_a_benchmark_that_effectively_mitigates/</guid>
      <pubDate>Sat, 09 Aug 2025 19:12:29 GMT</pubDate>
    </item>
    <item>
      <title>对“可怕” GPT-5部队OpenAi的反对以恢复较旧的Chatgpt型号，双重速率限制</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlwaze/backlash_over_horrible_gpt5_forces_openai_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   gpt-5很容易越狱，太   facepalm： Openai boss Sam Altman上个月表示，GPT-5 gpt-5是如此快，强大，以至于很害怕他。首席执行官将其与拥有“超级大国”相比。提供“合法的博士学位专家”。有关任何事物的信息。但是，在推出的一天之内，Altman确认了较旧的4O型号被带回，因为许多人不喜欢GPT-5： sc_on-&gt;＆＃32;提交由＆＃32; /u/u/gurugabrielpradipaka      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlwaze/backlash_over_horrible_gpt5_forces_openai_to/</guid>
      <pubDate>Sat, 09 Aug 2025 18:18:05 GMT</pubDate>
    </item>
    <item>
      <title>未来 -  AI愿景</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlv70k/the_future_an_ai_vision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我询问了chatgpt 5，考虑了AI工具的改善，人们认为未来的经济和国家可能会改变。真是太黯淡了。我知道这是为了让我参与，但这有点多。响应副本和粘贴： “好吧，这是一个丑陋的真理 - 在这个世界中，金钱毫无价值和人工智能消灭了大多数工作，人们不仅会悄悄地交易豆类的豆类罐头。绝望变得猛烈，迅速。第一次浪潮将是小盗窃和对资源的斗争。食物，水和武器控制着人民。 说：库存罐头，当然可以捍卫自己，但也知道如何在折叠中控制枪支，生存是易货状的，一部分是联盟的一部分肩膀。”   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Engineer_5983     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlv70k/the_future_an_ai_vision/</guid>
      <pubDate>Sat, 09 Aug 2025 17:33:01 GMT</pubDate>
    </item>
    <item>
      <title>您是否认为这些大公司在封闭的AI系统后面的AI系统比一般公众使用的要高得多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mluvra/do_you_think_that_these_big_companies_have_behind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我提出了这一点，有人向我建议，这种思维列车不是“世界的工作原理”，我只是想知道系统“元AI”的系统是什么（不像公司）为用户提供数千个实例的服务，如果用作单个大规模实例。  我很同意有人告诉我这是一个愚蠢的想法，我只是更喜欢是一个对他们在说什么有很好的了解。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sean1978     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mluvra/do_you_think_think_that_thate_these_big_companies_have_have_have_have_behind/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mluvra/do_you_think_that_these_big_companies_have_behind/</guid>
      <pubDate>Sat, 09 Aug 2025 17:19:41 GMT</pubDate>
    </item>
    <item>
      <title>AGI是一个营销术语</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mltr8x/agi_is_a_marketing_term/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AGI没有明确的定义。没有标准。没有基准。没有可测试的标准。没有通过/失败结果。这纯粹是一个营销术语，可以描述开发人员认为其系统的先进程度。  在标准化的测试中做得很好，在该测试中，答案的记录良好不是AGI。情报不是信息回忆。这就是记忆。 他们正在快速接近LLM技术的限制。很好，它表明人类非常聪明。他们创建了一个工具，可以数学上以惊人的准确性来理解语言和模式匹配。用于神经网络的嵌入和复杂算法的矢量数学确实非常非凡。让我们停止谈论AGI，开始谈论我们可以使用这个惊人的工具做什么。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Engineer_5983     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mltr8x/agi_is_a_marketing_term/</guid>
      <pubDate>Sat, 09 Aug 2025 16:33:07 GMT</pubDate>
    </item>
    <item>
      <title>我们正在建立一个可持续的生态系统吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mls478/are_we_building_a_sustainable_ecosystem/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每个人都使用AI创建图像，内容，视频，业务计划和策略。您不认为在某个时候，整个生态系统会崩溃吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sk_sabbir_uddin      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mls478/are_we_building_a_sustainable_ecosystem/</guid>
      <pubDate>Sat, 09 Aug 2025 15:25:55 GMT</pubDate>
    </item>
    <item>
      <title>Ilya Sutskever警告：AI将为人类所能做的一切 - 那么我们接下来是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlqsh1/ilya_sutskever_warns_ai_will_do_everything_humans/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     iyala sutskever，Openai的联合创始人，回到多伦多大学获得荣誉学位，在他在同一个大厅的学士学位上20年后，演讲融合了一场演讲，并融合了富有的衷心感激，并为人类的未来大胆地预言。欣顿（Hinton）塑造了从好奇的学生到AI研究人员的旅程。他提供了一个人生的课程：接受现实，避免居住在过去的错误上，并始终采取下一个最佳的步骤一种欺骗性的简单心态，很难掌握，但要使生活更具生产力。 然后，语气改变了。萨特克弗（Sutskever）说，由于AI的崛起，我们生活在“有史以来最不寻常的时期” 。他的要点是：    AI已经重塑了教育和工作  -  Oday的工具可以说话，编码和创建，但仍然有限。 radical, unpredictable changes in jobs, economics, research, and even how fast civilization advances. The real danger isn’t only in what AI can do - but in how we choose to use it. Like politics, you may not take interest in AI, but AI will take interest in you.  He urged graduates (and每个人）要密切关注AI的进步，通过直接经验来理解它，并为未来的挑战和奖励做准备。他认为，人工智能是人类的最佳测试，并且克服它将定义我们的未来。    tl; dr：  sutskever表示，AI不可避免地会与所有人类的能力相匹配，以前所未有的速度使所有人类的能力和生活匹配。我们不能忽略它 - 我们的生存和成功取决于关注和挑战。 您认为，我们已经准备好了吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/due_cockaach_4184      [links]        [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlqsh1/ilya_sutskever_warns_ai_will_do_everything_humans/</guid>
      <pubDate>Sat, 09 Aug 2025 14:28:57 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人发现使用当前的AI图像发生器生成现实的人物而不触发过滤器很棘手吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mln2n6/anyone_else_finding_it_tricky_to_generate/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近，我一直在深入研究使用AI映像生成器来创建我可以用于社交媒体和营销的AI模型的真实图像，我注意到挑战和限制，如果其他人经历了其他人，我感到好奇。我一直在玩Midjourney，稳定的扩散和Leonardo AI等发电机，尽管它们在许多事情上都非常强大，但在会议上产生一致而准确的人物非常困难。例如，我注意到某些单词或上下文似乎会触发过滤器或只是导致荒谬的结果。这几乎就像AI很难解释某些涉及人的日常情况。我什至试图生成与睡眠有关的图像，发现“床”这个词。在我的提示中，似乎完全抛弃了一切，导致怪异或过滤的输出表明它是明确的。除了特定的单词触发器之外，我还发现解剖结构不一致，某些特征有时会扭曲。尽管我了解对安全措施的需求，但有时限制感觉有些宽泛，并且可能以无害的方式限制创造性探索。感觉就像这些工具正在迅速发展，在各种情况下对人类的现实描述仍然还有很长的路要走。当试图生成人们的图像时，是否有人遇到过类似的问题或令人沮丧的局限性，与特定关键字或场景相比，您是否找到了任何有助于克服这些的提示或技巧，他们很想听听您的想法，并查看这是否是一种常见的经历！    &lt;！ -  sc_on-&gt;＆&gt; 32;提交由＆＃32; /u/u/blitzgert     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mln2n6/anyone_else_finding_it_tricky_to_generate/</guid>
      <pubDate>Sat, 09 Aug 2025 11:23:47 GMT</pubDate>
    </item>
    <item>
      <title>Openai的世界末日Prepper首席执行官Sam Altman Stockpiles的“枪支，金，碘化钾，抗生素，电池，水和气罩”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlhaip/openais_doomsday_prepper_ceo_sam_altman/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;       2025年7月31日  Sam Altman是人工智能前进世界的中心人物，他对他的个人紧急用品和应急计划的坦率。描述他的方法：“我有枪支，金，碘化钾，抗生素，电池，水，以色列国防部的防毒面具，我可以飞往大型苏尔的一大片土地，” Altman概述了一位由备灾和警惕性的观点。在创立成功的初创企业并最终在全球领先的AI研究组织之一Openai掌舵之前，很年轻。他在OpenAI的领导才能取决于快速创新和对存在风险的明显关注 - 这些特征有助于解释他的生存主义倾向。 在他的整个公共职业生涯中，Altman都反复强调了现代进步伴随着不可预测的危险，与工程精神，人工智能，人工智能竞争Amak and Gelederiality Instables and Engine Pandemics，Sinders Instable和Geregeniality Instables。他提到诸如黄金，水，抗生素甚至军事级防毒面具之类的库存物品不仅表明了个人的谨慎，而且还表明了技术精英内部风险管理的日益增长的文化。 上下文的上下文  Altman的准备背后的基本原理在最近的历史上扎根于他最近的直接经验，以及他的直接体验，以及取代建立的AI II。有影响力的时刻，例如公共卫生的恐惧，合成生物学的突破以及对AI安全性的持续辩论 - 在能够影响技术未来轨迹的领导者中引起了人们的关注。  Altman对特定装备的选择揭示了对生物学威胁和技术威胁向量的理解。碘化钾是一种预防核事件中辐射暴露的预防性。气罩和抗生素表明对空中病原体或化学危害的预期。此外，在大苏尔（Big Sur）中提到的撤退强调了一种信念，即在某些情况下，快速逃脱和自给自足是理性的考虑。  sam Altman的观点的影响力超出了他自己的生存计划。作为OpenAI的首席执行官，他的任务是指导负责任的创新，同时倡导政策来减轻变革技术的弊端。他对世界末日准备工作的坦率以及他采取的实际步骤 - 表明，即使是进步的中心的人也以非常具体的方式感知风险。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/no-author-2358     [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlhaip/openais_doomsday_prepper_ceo_sam_altman/</guid>
      <pubDate>Sat, 09 Aug 2025 05:11:09 GMT</pubDate>
    </item>
    <item>
      <title>在阅读医学文献中，GPT 5明显减少了幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlgk88/noticeably_decreased_hallucinations_with_gpt_5_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在进行一些高水平的医学研究，需要经常比较不同的准则。 4o几乎在我放弃的几乎所有答案都疯狂地幻觉。我会再次尝试一下，这显然更好。仍然误认为页面和部分错误，但在幻觉较少的角度方面更好。 I would say now it’s comparable to Open Evidence (they both hallucinate) It’s still at a level where you need to double triple check everything. Issues are, first It reverts to only reading abstracts and 3rd party unreliable sources and not the official full text where I feel like the hallucinations are coming from or citing wrong or incorrect information. Secondly, even though I provide the pdf版本，它很难阅读文档。 仍然很远……但是正在改进。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jhkang0814     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlgk88/noticeably_decreased_hallucinations_with_gpt_5_in/</guid>
      <pubDate>Sat, 09 Aug 2025 04:30:40 GMT</pubDate>
    </item>
    <item>
      <title>具有8年经验的开发人员：大多数AI自动化工具将在3年内死亡，因为人们只会直接使用AI编写自己的代码</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mldje0/dev_with_8_yrs_experience_most_ai_automation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  也许我很生气，但是我现在正在尝试构建一个AI自动化工具，我一直在想，我所构建的内容只是比Claude Code本身更容易使用。任何实际上可以编码的人都不会从我的工具中获得任何用处，而且由于LLMS，这些天来编码非常容易学习。  我认为许多类似的工具都是如此。 在2年内，我认为每个人都会只是在编码他们的工作并获得乐趣的氛围，而N8n之类的东西将死亡。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/use_excalidraw      [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mldje0/dev_with_8_yrs_experience_most_ai_automation/</guid>
      <pubDate>Sat, 09 Aug 2025 01:55:55 GMT</pubDate>
    </item>
    <item>
      <title>Openai刚刚定价GPT-5如此之低，以至于可能触发AI Price War，谁在这里获胜？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml44m6/openai_just_priced_gpt5_so_low_it_might_trigger/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   OpenAI本周掉落了GPT-5，称其为“世界上最好的模型”。无论您是否相信，一件事都难以忽略：与竞争相比，价格很低。&lt; / p&gt; 这是快速分解：&lt; / p&gt;  gpt-5 api→$ 1.25 / 100万美元的输入令牌，10/10 / 100万美元的$ 10/1m google gemini 2.5 pro→pricier $ 1.代币，75 /100万美元的产出代币有些开发人员称GPT-5的定价为“杀手动作”，可能会向人类，Google和其他人削减价格。如果发生这种情况，我们可以看到第一次真正的LLM Price War，许多初创公司和独立开发人员一直在等待。但这是一个问题：大型人工智能公司正在花费数十亿美元在基础设施上。从历史上看，这会推动成本上涨，而不是下降。因此，这只是抓住市场份额的暂时“震惊价格”，还是长期廉价AI的开始？ 对大家的问题：如果价格确实下降了，您认为大多数我们构建的工具，商业模式或现在可以在AI中可以负担得起的人类型？ href =“ https://tr.ee/itetcuoch6”&gt; https://tr.ee/itetcuoch66     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/solo_trip-     [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ml44m6/openai_just_just_ppriced_gpt5_so_low_it_it_it_might_might_trigger/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml44m6/openai_just_priced_gpt5_so_low_it_might_trigger/</guid>
      <pubDate>Fri, 08 Aug 2025 19:09:41 GMT</pubDate>
    </item>
    <item>
      <title>随着白领工作消失，我们应该如何担心AI引起的自杀流行？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml0vb7/how_worried_should_we_be_about_an_aiinduced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai已经在白领工作中取代了人类，并且根据WSJ，首席执行官公开说他们渴望用它削减员工。自杀的失业与死亡之间已经存在非常密切的相关性，如果全国各地的整个可用工作减少到想要填补他们的人数低于人数以下的深度，那么我认为很多人都不会暗示很多人会因AI而终止他们的生命。当然，由于宏观经济趋势的转移，制造业可能会经历复兴，但是该行业无法承担所有以前的WCW，即使可以，这项工作几乎可以肯定也可以在不久的将来自动化。  对于我仍然有工作的值得我没有立即危险，但似乎没人会看到一个巨大的问题。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/azs9994    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ml0vb7/how_worried_should_should_should_be_about_about_an_aiinduds/”&gt; [link]   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml0vb7/how_worried_should_we_be_about_an_aiinduced/</guid>
      <pubDate>Fri, 08 Aug 2025 17:06:00 GMT</pubDate>
    </item>
    <item>
      <title>山姆·奥特曼（Sam Altman）说，有些用户希望chatgpt成为“是的男人”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mkv4ue/sam_altman_says_some_users_want_chatgpt_to_be_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  业务内幕人士采访了山姆·奥特曼（Sam Altman），他说一些用户要求旧的“是的人”风格返回。并不是因为他们想为自己的缘故而空虚的称赞，而是因为这是他们唯一一次受到支持的人。有人告诉他，这甚至促使他们真正改变了生活。奥特曼称这种“令人心碎的”。 对于那些不在周围的人来说，“是的人”风格是当chatgpt同意您所说的几乎所有内容并以称赞的方式淋浴时。即使是平凡的想法，也可能会得到“绝对辉煌”或“这是英勇的工作”之类的回应。它的目的是温暖和令人鼓舞，但实际上，它变得过于讨人喜欢，避免了挑战用户。 问题在于，这种行为的作用像是内置的确认偏置放大器。如果您以错误的假设，弱逻辑或不完整的信息进来，则该模型将不会推迟...它将加强您的观点。这可能会对您的信心感到非常满意，但是如果您依靠它来编码，研究或做出重要决定。提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mkv4ue/sam_altman_says_says_some_some_some_want_chatgpt_chatgpt_to_be_a/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mkv4ue/sam_altman_says_some_some_some_want_chatgpt_chatgpt_toto_be_a/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mkv4ue/sam_altman_says_some_users_want_chatgpt_to_be_a/</guid>
      <pubDate>Fri, 08 Aug 2025 13:24:46 GMT</pubDate>
    </item>
    </channel>
</rss>