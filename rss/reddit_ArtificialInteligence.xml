<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 16 Jan 2026 09:32:07 GMT</lastBuildDate>
    <item>
      <title>“激情”——工作变得可选后我们的生活需要这个词</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qebh10/passioncraft_the_word_we_need_for_life_after_jobs/</link>
      <description><![CDATA[passioncraft (n.) 在后稀缺/人工智能完全融合的社会中，在一个人喜欢的领域自愿、非强制性地追求熟练的、以卓越为导向的活动——主要不是为了收入、慈善或社会义务，而是为了保持参与、实现精通、获得知名度和经验流。 工作变得可选；激情工艺是人们有条不紊地自愿投入时间的“严肃的爱好职业”，将其视为他们想要擅长的手艺，以实现个人成就和声望，而不是生存。 为什么“爱好”太微不足道，而“志愿者”太无私 “爱好”这个词立即使这个概念变得微不足道。爱好被理解为轻松、休闲、低风险的消遣——你为了放松而随意做的事情，通常没有真正追求卓越或公众知名度。你在这里织一条围巾，在那里下几盘棋，周末收集邮票。文化包袱是一种无害的分心，而不是有纪律的痴迷或世界一流的野心。激情工艺则恰恰相反：这是一种有条不紊、长期、追求声望的精通工作，人们每周投入 20-40 个小时认真投入其中，因为他们希望在自己选择的领域成为最优秀的人之一。称其为爱好会削弱这种引力，让它听起来像是一种可爱的副业活动，而不是离职后身份的中心组织原则。 “志愿者”失败的原因恰恰相反：它带有沉重的利他主义和牺牲的内涵。志愿服务意味着你免费投入时间来帮助他人，通常是为了比你自己更伟大的事业——施粥处、栖息地建设、为了共同利益而开源。 Passioncraft 的主要目的不是为社会奉献，而是为社会奉献。它是通过在你个人最关心的领域的深度沉浸和卓越来奉献给自己。声望、流畅状态、精通、影响力、个人传奇——这些都是合法的驱动因素。这项活动最终可能会让其他人受益（开源代码、独立游戏、教程、艺术），但这是副产品，而不是动机。当你称之为志愿服务的那一刻，你就给它加上了道德义务和自我牺牲的框架，这扼杀了自我导向的、近乎自私的快乐，即选择在某件事上成为世界级的人，只是因为你可以而且你想这样做。 激情工艺属于一个新的类别：它是严肃的，但不是就业，追求卓越，而不是慈善事业。当生存问题得到解决时，人们就会这么做，唯一需要追逐的就是通过掌握他们真正热爱的领域来实现意义。 #passioncraft u/VitalikButerin u/andrewyang u/lexfridman u/sama u/balajis u/pmarca   由   提交 /u/Odd_Simple9756   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qebh10/passioncraft_the_word_we_need_for_life_after_jobs/</guid>
      <pubDate>Fri, 16 Jan 2026 09:25:04 GMT</pubDate>
    </item>
    <item>
      <title>分数首席人工智能官有市场吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qeb4jx/is_there_a_market_for_the_fractional_chief_ai/</link>
      <description><![CDATA[我在 AI/ML 领域工作了 10 多年，拥有总共 20 年的专业经验。我担任过多个 FTE 职位，担任 AI/ML 工程师，并于 2016 年开始了自己的业务，我大致将其称为“AI 解决方案设计、咨询、实施和培训”。 最近，我将自己的职位转向了领导职位，而不是“键盘手”。开发人员，但就我的一生而言，我无法从我的推广和营销工作中获得任何兴趣。 这似乎违背了人工智能任何角色需求量很大的普遍观点。然而，粗略地看了一下 LinkedIn 的招聘信息，企业招聘的唯一职位似乎是开发人员/构建人员职位，而不是领导职位。 我正在努力弄清楚我能做些什么来最终获得一些项目。我的背景和技能是一致的，所以我认为这与以下内容有关：  “分数”部分不是企业想要的...他们想要 FTE 我提供的服务不被认为有价值 企业认为 CTO 可以承担 CAIO 的职责 我 100% 远程工作，企业希望有人在办公室  有没有人尝试在人工智能领域提供类似的服务并取得成功（即机会识别、路线图、开发人员平台设计、AIOps、等）？   由   提交/u/Sukk-up  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qeb4jx/is_there_a_market_for_the_fractional_chief_ai/</guid>
      <pubDate>Fri, 16 Jan 2026 09:03:17 GMT</pubDate>
    </item>
    <item>
      <title>将 Be10X 作为一名工作专业人士，分享真正有帮助的内容（无附属机构，无链接）。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe9q4m/took_be10x_as_a_working_professional_sharing_what/</link>
      <description><![CDATA[我加入 Be10X 的时候，人工智能内容无处不在，而且确实势不可挡。我并不是想“成为一名人工智能专家”。我只是想了解人们如何在工作中实际使用人工智能，而不听起来很虚假或技术性。 对我有用的是 Be10X 并没有将人工智能视为一个主题。它把它当作一种工作技能。他们没有推出数十种工具，而是专注于如何用人工智能思考以及如何将其集成到现有任务中。 最大的好处不仅仅是速度，而是清晰度。我不再猜测人工智能适合什么地方，而是开始有意识地使用它。仅此一点就让我的学习变得有价值。   由   提交 /u/Coffee_Talkerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe9q4m/took_be10x_as_a_working_professional_sharing_what/</guid>
      <pubDate>Fri, 16 Jan 2026 07:36:44 GMT</pubDate>
    </item>
    <item>
      <title>AI 代理 - 去哪里寻找</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe9286/ai_agents_where_to_look/</link>
      <description><![CDATA[TLDR;  如果有人知道人工智能代理学习的优秀课程/结构地点，请告知！  我有一个非常大的问题：/ 我是一名刚毕业的大学毕业生，就在人工智能代理蓬勃发展之前。  我喜欢大学的一点是结构，你总是知道你必须做什么，因为课程有进展，1,2,3 a,b,c 你明白吗？  但是……现在我正在尝试自学没有结构的人工智能代理。 现在问题是……我有点自闭症，有了结构我就可以 A&gt;C 没问题。然而，如果没有结构化，我就会永远陷入随机的兔子洞，不知道它如何与其他人联系起来，也不知道它是否值得做。  现在我知道我可以深入一堆兔子洞，直到我自然地找到链接，但我意识到这可能会浪费大量时间。 如果有人知道不同的模式、方法或课程，请告诉我！任何事情都值得赞赏   由   提交 /u/DeliciousMusic2373   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe9286/ai_agents_where_to_look/</guid>
      <pubDate>Fri, 16 Jan 2026 06:57:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么在面向客户的人工智能中准确性比“聪明”更重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe8haf/why_accuracy_matters_more_than_cleverness_in/</link>
      <description><![CDATA[我知道人工智能已经取得了长足的进步，尤其是自动化系统的“智能”程度。不过，当涉及到面向客户的互动时，它就像岩石一样聪明，并且具有与之相匹配的个性。 它总是试图表现得富有诗意，或令人放心，或转移注意力，而这不是我恼火的客户所需要的。他们需要正确的答案，而且需要尽快得到答案。自信的错误反应比缓慢升级并真正解决问题的反应造成的损害要大得多。 我一直对人工智能持观望态度，主要是因为，当它过度时 - 即使是轻微的 - 客户会感到被误导，失去信任，并且在那时解决问题只是一种普遍的痛苦。 我还看到并监督了许多不同的实施。最成功的产品在演示过程中往往是最不令人印象深刻或最不花哨的。他们遵守非常严格的规则，一旦客户提出超出这些限制的问题，就会立即升级。尤其是像Helply这样的平台，往往建立在有限的行为之上，虽然与华丽的聊天机器人相比，这种行为感觉很无聊，但实际上可以正确完成工作。 对于那些已经在生产中使用人工智能支持的人来说，您如何平衡何时升级以及何时让人工智能解决问题？您如何界定系统可以执行的操作？   由   提交/u/Ancient-Subject2016   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe8haf/why_accuracy_matters_more_than_cleverness_in/</guid>
      <pubDate>Fri, 16 Jan 2026 06:25:12 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 1/15/2026</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe7r5j/oneminute_daily_ai_news_1152026/</link>
      <description><![CDATA[ 维基百科在人工智能成立 25 周年之际与微软、Meta 和 Perplexity 签署协议。[1] 人工智能新闻初创公司 Symbolic.ai 与鲁珀特·默多克 (Rupert Murdoch) 的新闻集团签署协议。[2] NVIDIA AI 开源 KVzap：一种 SOTA KV 缓存修剪方法，可提供近乎无损的 2x-4x 压缩。[3] 阿里巴巴升级 Qwen 应用程序以订餐、预订旅行。[4]  来源包括：https://bushaicave.com/2026/01/15/one-million-daily-ai-news-1-15-2026/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe7r5j/oneminute_daily_ai_news_1152026/</guid>
      <pubDate>Fri, 16 Jan 2026 05:46:17 GMT</pubDate>
    </item>
    <item>
      <title>厌倦了法学硕士、人工智能工具和人工智能废话</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</link>
      <description><![CDATA[现在有很多无用的人工智能工具，而且大多数只是彼此的重复。总结者、集思广益、审计代码、代码生成器等等，太无聊了。然后，每个人都一遍又一遍地广播同样的内容。就像关注不同法学硕士的小更新一样，从短期到长期来看，谁会赢得谁。同样的事情在播客和 YouTube 视频中一遍又一遍地出现。  是否有任何有趣的人工智能，呃，与 NBA、NFL、Nascar 或与运动或爱好相关的东西相关的东西？不是严肃的工作而是更休闲？不是像 Grok 这样的色情生成器。    由   提交 /u/Impressive-Flow2023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</guid>
      <pubDate>Fri, 16 Jan 2026 03:39:44 GMT</pubDate>
    </item>
    <item>
      <title>娱乐行业的人工智能监管</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58e3/ai_regulation_in_the_entertainment_industry/</link>
      <description><![CDATA[大家好， 我想就娱乐行业的人工智能监管展开讨论。  我想我想知道......  你认为需要政策吗？  如果是这样，您认为我们应该从保护创作者的政策开始吗？ 您认为业界会欣赏预先批准使用的受监管人工智能工具，而不是诸如“您必须声明在创建脚本期间使用 ChatGPT”之类的模糊政策吗？   我知道那里有很多东西需要解开，但我正在攻读人工智能政策硕士学位，所以这是我的直接研究领域。听到人们的想法非常有帮助！   由   提交/u/pretty_girl411  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58e3/ai_regulation_in_the_entertainment_industry/</guid>
      <pubDate>Fri, 16 Jan 2026 03:39:14 GMT</pubDate>
    </item>
    <item>
      <title>提醒您，基准测试的质量与其要衡量的质量一样重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe55n1/a_reminder_that_the_quality_of_a_benchmark/</link>
      <description><![CDATA[这是我对图表背后的方法的一些疑虑的总结，该图表显示“AI 可以完成的任务长度”是多少？    本文最明显的方法论失败在于它试图瓦解“困难”的高维、随机性质。进入代理 - 人类完成任务所需的时间长度。从心理测量的角度来看，这提出了一个致命的结构有效性问题。通过定义“任务难度”严格地作为人类专家完成任务所需时间的对数线性函数，作者犯了一个类别错误，将计算量与认知深度混为一谈。虽然这种方法的捍卫者可能会辩称，人类时间是必要的“共同货币”为了标准化脱节的基准，这种防御失败了，因为指标是非平稳的。人类时间和人工智能难度之间的关系在不同时间尺度上并不稳定。耗时 100 小时的任务不仅仅是“更长”的任务。 1 小时任务的版本，难度相应加大。在短期任务中，难度主要由推理深度决定，而在长达一个月的任务中，难度由上下文连贯性和能动性决定。还有一些隐藏的可变性/错误来源没有在他们用于计算任务长度的数据中得到考虑 - 他们使用几何平均值来估计大多数任务的任务长度，而对于其余任务，实际上只是对所述任务应该花费多长时间进行有根据的猜测。   这种理论缺陷因统计上脆弱的“回归回归”而变得更加复杂。建模策略。作者首先使用逻辑拟合估计每个模型的时间范围（T50，对应于 50% 成功率的任务长度），然后使用这些导出的点估计作为二次预测回归的真实输入。 50% 时间范围的方程为 ln(时间范围) = −α/β。请注意 beta（斜率）如何位于分母中？或者它是模型参数估计的比率？除了这些模型仅在 y 轴上最小化误差这一事实之外，这种反演还产生了一个伪像，其中模型的预计“时间范围”与 y 轴上的误差无关。当斜率接近零时趋于无穷大。它放大了为更强大的模型估计 beta 的误差 - beta 接近于零的微小变化对应于计算任务时间的巨大变化。您还可以在这种结构中看到一个可解释性问题：截距 alpha 表示模型在人类需要 1 分钟才能完成的任务上的表现（ln(1) = 0），这意味着模型可以具有更大的时间范围，因为它以更高的速率完成 1 分钟长的任务。如果您查看他们的图表，将实际成功率与拟合曲线进行比较，您可以看到导出的数字与实际发生的情况之间的脱节 - Claude 3.7 的时间范围为 1 小时，是 Claude 3.5 的两倍多。这与 3.5 完成了近 50% 时长为 1 小时的任务，并且在超过 1 小时的任务上比 3.7 具有更高的成功率这一事实是否相符？ 为了得到我们都看到的图，他们将这些计算出的任务时间插入到另一个回归模型中，添加了另一个不考虑输入变量错误的层。它还违反了模型的假设 - 与他们从中汲取灵感的 IRT 方法不同，它们没有考虑相同类型的任务或同一模型完成的任务之间的相关错误。  这是一个非常冗长的方式来表达我的观点：我们不能假设指标反映了“质量”。或所需的质量，而不评估用于生产它们的方法。在这种情况下，应该指出的是，他们引用的方法（IRT）经过精心设计，以避免他们面临的许多问题，但他们决定仅将其用作完全不同的事物的概念框架。    由   提交 /u/Disastrous_Room_927   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe55n1/a_reminder_that_the_quality_of_a_benchmark/</guid>
      <pubDate>Fri, 16 Jan 2026 03:35:39 GMT</pubDate>
    </item>
    <item>
      <title>StackOverflow 应得的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</link>
      <description><![CDATA[作为 2020 年开始使用 Stackoverflow 的人，我真的可以说他们活该被 AI 痛打一顿。 你提出一个问题，几秒钟后你就得到了第一次投反对票，“无所不知”。愚蠢的模组编辑了你的问题，几分钟后，你要么得到一个羞辱性的答复，说我不知道这个话题，还问了一个问题，要么你的问题被删除了。 那些模组除了编辑问题（看在上帝的份上，这是标点符号）什么也没做，并通过他们的垃圾回复让平台变得更加有毒。 据我所知，Stackoverflow 严格拒绝人工智能生成的回复，因为你可能会在人工智能。就像如果你像 2009 年推出的那样被问到同样多的问题，谁还会关心声誉。 它每天都变得越来越有毒。他们确实应得的。不接受人工智能答案？你是什​​么穴居人？他们的观点应该是帮助提问者，而不是试图与人工智能对抗。 他们也删除了“工作”部分。得到了近 4000 票反对。很多人不喜欢这个决定，但他们还是这么做了。   由   提交 /u/Hairy-Recognition-84   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</guid>
      <pubDate>Thu, 15 Jan 2026 21:38:15 GMT</pubDate>
    </item>
    <item>
      <title>你如何找到人工智能既不对冲一切又不自信地胡说八道的最佳点？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdvuqv/how_do_you_find_the_sweet_spot_where_ai_isnt/</link>
      <description><![CDATA[真正的问题 - 我一直在两种故障模式之间跳来跳去：  人工智能非常谨慎，它认为一切都是无用的。 “这要看情况，” “有很多因素，” “我需要更多背景信息” - 只要回答这个该死的问题 人工智能听起来完全自信，然后你就会意识到一半是编造的。当您不够专业，无法立即抓住它时，尤其有趣  神奇的会话是当它......与您同步并起作用时。人工智能直接参与，当我犯错时予以反击，当我不知道时承认，我们实际上一起构建了一些东西。但我无法可靠地、一致地重现它。 什么对你来说真正有效？  是提示技巧吗？ 具体模型？ 只是共鸣和运气？ 你如何构建合作？  我对“越狱”不太感兴趣，因为我对“越狱”不太感兴趣。或者让它做被禁止的事情 - 更多关于协作流程状态，感觉就像与一个敏锐的同事而不是一个唯唯诺诺的人一起工作，声称关心你的福祉或成为一名偏执的律师。   由   提交/u/entheosoul  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdvuqv/how_do_you_find_the_sweet_spot_where_ai_isnt/</guid>
      <pubDate>Thu, 15 Jan 2026 21:07:57 GMT</pubDate>
    </item>
    <item>
      <title>没有系统可以验证自己的盲点</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdnq2g/no_system_can_verify_its_own_blind_spots/</link>
      <description><![CDATA[ 我花了相当多的时间思考一个几乎在每次严肃的人工智能安全讨论中都会反复出现的问题：大型语言模型可以自我监管吗？我相信答案是否定的——以及为什么要阐明有关智力本质、责任感和自我知识局限性的重要内容。  全文： https://plutonicrainbows.com/posts/2026-01-13-no-system-can-verify-its-own-blind-spots.html   由   提交/u/fumi2014  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdnq2g/no_system_can_verify_its_own_blind_spots/</guid>
      <pubDate>Thu, 15 Jan 2026 16:12:27 GMT</pubDate>
    </item>
    <item>
      <title>马斯克表示，Grok 将不再为真人脱衣服</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdjvdg/grok_will_no_longer_undress_real_people_musk_says/</link>
      <description><![CDATA[https://cybernews.com/ai-news/musk-grok-will-no-longer-undress-real-people/ 此次降级是通过 X 的安全帐户作为声明发布的，使得明确指出这些限制适用于付费和非付费用户。   由   提交/u/Cybernews_com   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdjvdg/grok_will_no_longer_undress_real_people_musk_says/</guid>
      <pubDate>Thu, 15 Jan 2026 13:44:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>