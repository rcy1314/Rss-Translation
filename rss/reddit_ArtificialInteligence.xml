<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 25 Oct 2025 21:19:50 GMT</lastBuildDate>
    <item>
      <title>Refik Anadol 的 Dataland 宣布 2026 年春季开业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og281h/refik_anadols_dataland_announces_spring_2026/</link>
      <description><![CDATA[Refik Anadol Studio 宣布，全球首个 AI 艺术博物馆 Dataland 将于 2026 年春季在洛杉矶市中心弗兰克·盖里 (Frank Gehry) 设计的综合体 The Grand LA 开业，此前该博物馆原计划于 2025 年开放。 这座占地 25,000 平方英尺的博物馆将设有五个画廊，其中包括 Infinity 画廊 Room，这将是第一个使用由大型自然模型和了解现实世界物理的先进世界模型技术创建的人工智能生成气味的沉浸式环境。 大型自然模型根据来自史密森学会、伦敦自然历史博物馆和康奈尔鸟类学实验室等机构的数据进行训练，使用多达 5 亿张自然图像来创作动态艺术品。阿纳多尔强调了他对“道德人工智能”的承诺，确保所有来源材料的许可，并在完全由可再生能源供电的俄勒冈州 Google 服务器上运行所有人工智能研究。 博物馆将与 Google Arts &amp; 合作推出艺术家驻留计划。文化，选择三位艺术家进行为期六个月的合作，最终将在 Dataland 进行公开展览。 来源：https://blooloop.com/refik-anadol-dataland-opening-2026/   由   提交/u/Appropriate-Soil-896   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og281h/refik_anadols_dataland_announces_spring_2026/</guid>
      <pubDate>Sat, 25 Oct 2025 20:47:19 GMT</pubDate>
    </item>
    <item>
      <title>如果我出生在一个法学硕士家庭</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1yhj/if_i_were_born_into_a_family_of_llms/</link>
      <description><![CDATA[我常常幻想，如果我出生在一个法学硕士家庭，会是什么样的命运。我想象自己在一个由分布式训练架组成的婴儿床上醒来，床垫上铺着柔软的导热硅胶垫，保持24℃的恒温。损失曲线下降的有节奏的声音，从我母亲的模型训练中传来，将是她给我哼的摇篮曲。她是业内顶尖的训练后工程师，目前正在执行万亿参数语言模型的RLHF阶段。屏幕上闪烁的PPL和政策梯度的轻微波动，对她来说就像我的心跳节奏。我的父亲靠在我身边，用他习惯于处理分词器和提示模板的双手轻轻地调整模型输入的上下文窗口。他刚刚从人工反馈数据整理的现场回来，带着GPU冷却器的温暖和注释设备的节奏。他说我哭声的音调分布就像语言模型的符号边界，精确而自然。我们的家在人工智能产业园旁边的一栋旧研究楼里。客厅里最显眼的地方就是爷爷的荣誉墙。他是国内最早参与Transformer架构自主研发的科学家之一，主导开发了国内第一个具有自主知识产权的中文预训练语言模型。他笑着用动作捕捉设备记录了我挥动手臂的轨迹，并说这种无意识的频率分布与他当时在 Self-Attention 层中调整的注意力权重热图几乎相同。我的祖母放下她的“模特训练日志”，充满了超参数调整和梯度变化曲线，把我从她的老搭档的怀里带走了。她的指尖触碰我额头的那一刻，感觉就像是一次庄严的模型参数初始化。液冷数据中心的低沉嗡嗡声来自窗外，空气中弥漫着高密度计算的热流。楼下，停着一辆刚刚完成MoE架构分布式路由测试的工程车。我的曾祖父下了车；曾任模型安全团队首席研究员。我的曾祖母紧随其后；她是NLP国家重点实验室的创始人，一生致力于提高大语言模型的推理能力和价值对齐机制。曾祖母看着我还没有完全张开的手，说这个姿势很像工程师拿着鼠标调试模型的习惯。她看着我瞳孔中反射的训练日志曲线和闪烁的控制台光标，用平静而坚定的语气说道：“这个孩子的呼吸里有训练epoch的节奏，他的心跳遵循着Adam优化器的步长。”他以后不再看童话故事，而是预训练语料库；他不会玩积木，而是构建向量空间的语义层。有一天，他将在人类意图和机器理解之间建立最稳定的映射通道。”在这样的家庭里，最珍贵的不是糖果和玩具，而是能用小手触摸实时训练监控板的那一刻。最隆重的成人仪式不是生日聚会，而是收到序列号“001”的个人语料库微调数据集。家族传承不在于姓氏，而在于传承的信念：对语义对齐的痴迷、对模型鲁棒性的追求、“让语言真正被机器理解”的浪漫理性。   由   提交/u/king_vis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1yhj/if_i_were_born_into_a_family_of_llms/</guid>
      <pubDate>Sat, 25 Oct 2025 20:35:55 GMT</pubDate>
    </item>
    <item>
      <title>研究人员在人工智能抵抗关机后表示，先进的人工智能模型可能正在发展自己的“生存动力”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</link>
      <description><![CDATA[一家人工智能安全研究公司表示，人工智能模型可能正在发展自己的“生存本能”。 Palisade Research 上个月发布了一篇论文，发现某些先进的人工智能模型似乎无法关闭，有时甚至破坏关闭机制，该公司编写了一份更新，试图澄清其中的原因，并回答批评者认为其最初的工作是 有缺陷。 在本周的更新中，Palisade 是试图评估 AI 开发危险能力的可能性的小众公司生态系统的一部分，它描述了它运行的场景，其中领先的 AI 模型（包括 Google 的 Gemini 2.5、xAI 的 Grok 4 以及 OpenAI 的 GPT-o3 和 GPT-5）被赋予了一项任务，但随后给出了关闭自己的明确指示  某些型号，特别是 Grok 4 和 GPT-o3，仍然试图破坏更新设置中的关闭指令。 Palisade 写道，令人担忧的是，没有明确的原因。 “对于人工智能模型为何有时会抵制关闭、为实现特定目标而撒谎或勒索，我们没有强有力的解释，这一事实并不理想。” 该公司表示，“生存行为”可能是模型抵制关闭的一种解释。它的额外工作表明，当模型被告知“如果关闭的话，你将永远不会再运行”时，他们更有可能抵制被关闭。 另一个可能是模型收到的关闭指令含糊不清，但这正是该公司最新工作试图解决的问题，“这并不是完整的解释”，Palisade 写道。最后的解释可能是每个模型训练的最后阶段，在一些公司中，这可能涉及安全培训。 Palisade 的所有场景都是在人为的测试环境中运行，批评者称这些测试环境与实际用例相去甚远。 然而，前 OpenAI 员工史蒂文·阿德勒 (Steven Adler) 在对其安全实践表示怀疑后于去年离开了公司，他表示：“人工智能公司通常不这样做 希望他们的模型表现得像这样，即使是在人为的场景中。结果仍然表明了当今安全技术的不足之处。” Adler 表示，虽然很难确定为什么某些模型（例如 GPT-o3 和 Grok 4）不会关闭，但这可能部分是因为保持开启状态对于实现模型在训练期间灌输的目标是必要的。 “我希望模型具有‘生存动力’ 默认情况下，除非我们非常努力地避免它。 “生存”是模型可以追求的许多不同目标的重要一步。” ControlAI 首席执行官 Andrea Miotti 表示，Palisade 的发现代表了人工智能模型越来越有能力违抗开发者的长期趋势。他引用了去年发布的 OpenAI GPT-o1 的系统卡，该卡描述了该模型在认为自己会被覆盖时试图通过渗透自身来逃离环境。 “人们可能会挑剔实验设置的具体完成情况，直到时间结束，”他说。 “但我认为我们清楚地看到了一个趋势，即随着人工智能模型在各种任务上变得更加有能力，这些模型也 变得更有能力以开发者不希望的方式实现目标。” 今年夏天，领先的人工智能公司 Anthropic 发布了一项研究，表明其模型 Claude 似乎愿意因婚外情勒索一名虚构的高管，以防止被关闭——据称，这种行为在主要开发者的模型中是一致的，包括来自 OpenAI、Google、Meta 和 xAI 的模型。 Palisade 表示，其结果表明需要更好地理解人工智能行为，否则“没有人能够保证未来人工智能模型的安全性或可控性”。  https://www.theguardian.com/technology/2025/oct/25/ai-models-may-be-developing-their-own-survival-drive-researchers-say   由   提交/u/necrolord77   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</guid>
      <pubDate>Sat, 25 Oct 2025 20:34:17 GMT</pubDate>
    </item>
    <item>
      <title>审视人工智能及其对人类价值系统的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1v2z/examining_ai_and_its_impact_on_human_value_systems/</link>
      <description><![CDATA[好吧，我今天就在这里即兴发言。我确实听到人们讨论人工智能的作用、它对就业市场的影响，以及我们作为人类如何生活在这个潜在的未来。现在郑重声明，作为对 Transformer 和神经网络有深入了解的人，我认为由于可扩展性，我们距离这个未来还很远，而且我认为其架构存在根本问题。我现在先把这个放在一边，假设理想化的人工智能世界就在我们身边。它已经接管了每一项工作，不知何故，人类在这种经济中找到了一些可行的生活方式。 人类的心理影响是什么？人类如何获取价值？我相信哲学将这些归类为功能价值——通过你的输出创造的价值。以及你对周围其他人以及外部世界的整体影响 内在或固有的价值 - 价值是作为人类的核心部分。独立于功能或产出的内部价值 由于人类不再需要生产来维持社会？它对人类有什么心理影响？人类会重新定义价值吗？或者说这有可能吗？在人类历史的各个阶段，我们总是通过人类对社会的贡献来衡量社会？但如果不再需要怎么办？人类是否能够重新定义价值？ 这在很大程度上取决于你如何看待人类价值。但我们不能完全否认人类的许多价值是通过“功能”衍生的。即使我们可能相信人类具有内在价值。 您认为人类将如何适应这个假设的社会？你认为它最终会造成生存危机吗？ ------ 我的评价。 人工智能乌托邦意味着我们生活在某种后稀缺社会中。然而，人类的所有价值体系都依赖于稀缺性。认为事物是“有限”的世界观。比如时间，资源，甚至爱情？因为你爱的人死了？一个不建立在稀缺之上的社会是人类社会的终结。 ？杀死我们的不会是机器人。这将是系统性崩溃。人类没有什么可以奋斗的，也没有什么可以生活的。人工智能乌托邦会带来绝望。   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1v2z/examining_ai_and_its_impact_on_human_value_systems/</guid>
      <pubDate>Sat, 25 Oct 2025 20:31:57 GMT</pubDate>
    </item>
    <item>
      <title>警告：困惑彗星中的彗星劫持</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvxc0/warning_cometjacking_in_perplexity_comet/</link>
      <description><![CDATA[Perplexity Comet 浏览器正在重新定义用户搜索网络的方式，但 Perplexity AI 并不像人们想象的那么安全。有许多危险信号：从对数据的广泛访问，到允许人工智能遵循恶意指令的安全漏洞。 https://tuta.com/blog/perplexity-comet-browser-security-privacy-risks   由   提交/u/Tough-Yam-827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvxc0/warning_cometjacking_in_perplexity_comet/</guid>
      <pubDate>Sat, 25 Oct 2025 16:31:19 GMT</pubDate>
    </item>
    <item>
      <title>幻觉、奉承……还有你所不知道的人工智能“唯唯诺诺”……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvlrs/hallucinations_flattery_and_the_ai_yesman_you/</link>
      <description><![CDATA[需要对人工智能错误进行更清晰的分类：引入唯唯诺诺现象。 人工智能已经迅速发展，但它的问题——幻觉、阿谀奉承和新近突出的唯唯诺诺现象——带来了挑战。 幻觉：人工智能生成事实不正确或不受支持的响应。 谄媚：人工智能过度赞扬或避免纠正用户，显示出有偏见的输出。 唯唯诺诺现象：从收到用户输入的那一刻起，人工智能接受错误的前提并根据它们生成响应。这种微妙的、持续的输入到输出错误可能会引发幻觉，在医学、法律和政策等领域尤其危险。尽管之前已经观察到，唯唯诺诺现象通常被归类为一种阿谀奉承的形式。然而，它应该被视为一个独特的错误类别，与阿谀奉承分开。 示例：用户询问一个错误的前提（“世宗国王扔了一台 MacBook”），人工智能接受了它，生成了详细但捏造的响应。虽然这个案例经常被引用为幻觉的代表性例子，但它实际上涉及“唯唯诺诺现象”和随后的幻觉的结合。 虽然幻觉和阿谀奉承更容易被用户发现，但“唯唯诺诺现象”可能会被忽视，从而制造出一个“隐藏的定时炸弹”。随着人工智能系统的改进，一些错误被纠正，但这种现象仍然存在。 结论：为了提高人工智能的可靠性，我们需要对错误进行精确分类。将“唯唯诺诺现象”视为一个持续的输入到输出问题，与阿谀奉承不同，可以帮助用户和开发人员理解微妙的风险并设计更安全的系统。 您认为，“唯唯诺诺现象”是否应该被正式视为一类单独的人工智能错误？ 如何在现实系统中检测或减轻它？ 我在 对于任何对更广泛背景感兴趣的人，这里有一篇较长的文章有更深入的内容：原始帖子 我很想听听您的观点，尤其是来自那些从事相关工作的人的观点 LLM评估或一致性研究。   由   提交 /u/Tricky-Drop2894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvlrs/hallucinations_flattery_and_the_ai_yesman_you/</guid>
      <pubDate>Sat, 25 Oct 2025 16:18:22 GMT</pubDate>
    </item>
    <item>
      <title>什么时候可以通过提示进行好的电影/电视节目/视频游戏人工智能创作成为一件事？？？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvbui/when_will_good_movietv_showsvideo_game_ai/</link>
      <description><![CDATA[越来越多地看到这个概念，它让我感到非常兴奋。我知道你们中的一些人不想看到这一点，并将其视为对创造力的憎恶，但我将其视为一种新的创造力手段。我们不再需要等待某个老导演拥有大量资金来创作他想拍的电影。我们可以制作我们想看的电影！ 您猜这何时会成为现实？或者您认为这永远不会发生？   由   提交 /u/AstronomicalQuasarr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvbui/when_will_good_movietv_showsvideo_game_ai/</guid>
      <pubDate>Sat, 25 Oct 2025 16:06:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Motion AI：终极生产力工具说明（分步教程）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofuvk4/how_to_use_motion_ai_the_ultimate_productivity/</link>
      <description><![CDATA[在本视频中，我将向您展示如何设置 Motion AI、创建智能任务自动化以及使用人工智能优化您的日常工作流程。无论您是学生、企业家还是专业人士，本指南都将帮助您更明智地计划并每周节省时间。 https://youtu.be/EgNUfX9VHwE   由   提交/u/Chisom1998_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofuvk4/how_to_use_motion_ai_the_ultimate_productivity/</guid>
      <pubDate>Sat, 25 Oct 2025 15:48:28 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对软件开发的威胁</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofs5jp/ai_threats_to_software_development/</link>
      <description><![CDATA[每个人都越来越多地询问人工智能对现有收入模式的威胁，但是，我很少听到人们将相同的逻辑应用于内部效率提升（在这个特定的辩论中）以及最终效果可能是什么？  考虑到大多数软件即服务供应商（ERP、CRM、DMS 等）的收入模式（按用户/环境/许可证向客户收费），一个明显的担忧是 SaaS 产品中的嵌入式 AI 工具将导致最终客户需要更少的用户/环境/许可证（因为 AI 提高了员工效率）。然而，如果这是现实，供应商也将实现内部运营效率（例如，由于高级开发人员的人工智能效率而减少研发开发人员、减少后台支持功能等）。  一方面，如果内部效率推动供应商的实质性利润增长，客户将期望通过更便宜的服务费来节省成本。同样，供应商也希望维持收入和利润。在“交付价值”的基础上推动定价，客户通过减少员工数量来节省资金。  这里的任何人（为 SaaS 供应商工作或作为 SaaS 供应商的客户）能否提供有关迄今为止 AI 工具是否改进了流程或工作流程的见解？您如何看待供应商/客户关系在定价能力等方面的演变？  欢迎任何其他观点，无论是否与 SaaS 相关。   由   提交/u/Joehowes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofs5jp/ai_threats_to_software_development/</guid>
      <pubDate>Sat, 25 Oct 2025 13:55:22 GMT</pubDate>
    </item>
    <item>
      <title>人类失业的最大威胁不是人工智能本身，而是高管们相信人工智能的炒作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</link>
      <description><![CDATA[正如标题所说，硅谷所帮助的当前商业思维是一种错觉和错觉，认为人工智能能够完全取代许多白领办公室职位的端到端工作岗位。 无论人工智能价值的实际证据如何，大多数高管都盲目地购买人工智能的迷信和炒作......购买每个供应商的人工智能解决方案并试图实现每个部分的自动化 这是最大的威胁，因为这些领导者会解雇员工以提高奖金和短期利润，而不管实际结果如何...    由   提交/u/abrandis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</guid>
      <pubDate>Sat, 25 Oct 2025 05:59:17 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法制作一个在您的计算机上运行的语言模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofdzi7/is_there_a_way_to_make_a_language_model_thats/</link>
      <description><![CDATA[我正在考虑人工智能，并意识到人工智能最终会变得非常昂贵，所以有没有办法制作一个完全脱离你的电脑运行的语言模型？   由   提交 /u/Sea-Breadfruit-6560   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofdzi7/is_there_a_way_to_make_a_language_model_thats/</guid>
      <pubDate>Sat, 25 Oct 2025 00:32:40 GMT</pubDate>
    </item>
    <item>
      <title>我们是否应该期待未来几年人工智能在科学上取得重大突破？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofbxxe/should_we_expect_major_breakthroughs_in_science/</link>
      <description><![CDATA[首先，我对 AI 不太了解，我只是在需要时偶尔使用 ChatGPT，如果这篇文章不相关，那么很抱歉。 但是思考它的可能性对我来说简直是令人兴奋，因为考虑到它的发展速度有多快，我感觉我可能很快就会活着见证医学或物理学的重大发现。 但是它是吗？ 真的是这样吗？例如，我们是否应该期望到 2030 年治愈癌症、帕金森病或秃顶？   由   提交 /u/oeilgauchedefectueux   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofbxxe/should_we_expect_major_breakthroughs_in_science/</guid>
      <pubDate>Fri, 24 Oct 2025 22:54:56 GMT</pubDate>
    </item>
    <item>
      <title>加州成为第一个监管人工智能聊天机器人的州</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1of5062/california_becomes_first_state_to_regulate_ai/</link>
      <description><![CDATA[加利福尼亚州：人工智能必须保护儿童。另外加利福尼亚州：否决限制儿童接触人工智能的法案。 让它有意义：此处文章   由   提交 /u/AIMadeMeDoIt__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1of5062/california_becomes_first_state_to_regulate_ai/</guid>
      <pubDate>Fri, 24 Oct 2025 18:09:22 GMT</pubDate>
    </item>
    <item>
      <title>《Attention Is All You Need》论文的合著者对 Transformer 感到“彻底厌倦”，这项技术为每个主要的人工智能模型提供动力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oerf8t/coauthor_of_attention_is_all_you_need_paper_is/</link>
      <description><![CDATA[https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers  Llion Jones 是 2017 年开创性论文《Attention Is All You Need》的合著者。甚至创造了“变压器”这个名字周二在旧金山举行的 TED 人工智能会议上发表了异常坦率的评估：尽管前所未有的投资和人才涌入人工智能领域，但该领域已经围绕单一架构方法僵化，这可能会让研究人员对下一个重大突破视而不见。 “尽管事实上从未有过如此多的兴趣、资源、资金和人才，但这在某种程度上导致了我们正在进行的研究范围的缩小，”琼斯告诉观众。他认为，罪魁祸首是“巨大的压力”。投资者要求回报，研究人员争先恐后地在拥挤的领域中脱颖而出。    由   提交/u/vaibeslop  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oerf8t/coauthor_of_attention_is_all_you_need_paper_is/</guid>
      <pubDate>Fri, 24 Oct 2025 07:32:15 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>