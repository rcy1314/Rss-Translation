<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 04 Nov 2025 12:52:10 GMT</lastBuildDate>
    <item>
      <title>您对人工智能与人类疗法的看法如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5q90/perceptions_of_ai_vs_human_therapy_what_you_think/</link>
      <description><![CDATA[我是一名大学生，我对人工智能和心理学之间的交叉感兴趣，请您填写我的调查问卷，我将百分百诚实地为您做回报 https://forms.gle/5EgL7NygkuKNcLbPA   由   提交 /u/Lopside_Scar_566   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5q90/perceptions_of_ai_vs_human_therapy_what_you_think/</guid>
      <pubDate>Tue, 04 Nov 2025 12:12:50 GMT</pubDate>
    </item>
    <item>
      <title>如果大多数公司全面采用人工智能，大规模失业是否会导致需求崩溃和利润下降？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5ib6/if_ai_adoption_is_at_full_scale_for_most/</link>
      <description><![CDATA[我对经济学的专业知识了解不多，所以请原谅我理解上的任何错误。我非常愿意学习。 我随处可见新闻，大公司正在用人工智能取代大部分员工。这种情况在全世界范围内都在发生，而不仅仅是在美国。如果我们假设人工智能的全面采用会导致大规模失业，那么如果许多人买不起公司销售的相同服务，是否会出现需求崩溃？这也会导致公司的利润下降？ 举个例子：如果苹果或谷歌的许多程序员被解雇，许多人将失业，如果许多人不再负担得起他们的服务，苹果或谷歌是否也会遭受损失？ 我确信还有其他不受人工智能威胁的工作可以继续工作，但是，是的，我只是不敢相信人工智能的指数级发展，它如何改变社会，以及我们的社会如何做好准备是为了这种改变。 产品价格是否会降低，作为公司主要由人工智能驱动的补偿？会有更便宜的商品和服务吗？人工智能应用的快速转变会带来新的就业机会和行业吗？目前人工智能采用的状况实际上对全球经济有利吗？   由   提交 /u/Ok_Owl_891   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo5ib6/if_ai_adoption_is_at_full_scale_for_most/</guid>
      <pubDate>Tue, 04 Nov 2025 11:58:06 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不会造成失业，人类会。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo4bx7/ai_wont_create_unemployment_humans_will/</link>
      <description><![CDATA[如果没有工作可做，那是不是意味着每个人都已经得到了一切。如果没有工作可做，人们仍然悲伤，那是因为当权者没有给予悲伤的人平等的权利。 如果人们真的悲伤，就必须有工作要做，如果他们认为自己没有得到 PS5，那么人工智能就无法生产足够的 PS5。如果他们得不到食物，人工智能就无法生产足够的食物。 所以我的观点是经典的全民基本收入。    由   提交 /u/ResponsibleBanana522   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo4bx7/ai_wont_create_unemployment_humans_will/</guid>
      <pubDate>Tue, 04 Nov 2025 10:51:25 GMT</pubDate>
    </item>
    <item>
      <title>默认情况下，谷歌会根据你提供给任何人工智能的所有数据来训练其模型，所以要小心，而且他们也不会让你像其他人一样选择退出</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo49mq/google_by_default_trains_its_models_on_all_data/</link>
      <description><![CDATA[如果你在 Colab、Gemini 应用程序或 Web 应用程序或任何与 Gemini 相关的东西中使用 Gemini，Google 会告诉你要保护自己，因为它们不会.. 至少一点都不好 虽然其他模型提供商允许你选择不接受数据训练，但 Google 不会，除非你放弃任何获得体面体验的机会，否则你基本上会处于隐身状态，无法使用任何工具，如果你不希望你的数据被训练。 真正令人难以置信的是，标准已经制定，并且正在进行一些用户保护，而谷歌根本没有遵循它......但我猜它是谷歌 来自谷歌： &gt; Google Gemini 默认使用聊天记录进行模型训练，但您可以关闭“Gemini Apps Activity”设置以防止将来的聊天记录用于训练；但是，此操作还会禁用保存持久聊天历史记录，因为这两个功能是链接的。未来的聊天记录将保存至少 72 小时以供提供服务，但如果设置关闭，则不会出现在您的活动中或用于培训。对于敏感数据，请使用临时聊天功能或避免使用 Gemini 获取机密信息。  来自 Gemini Apps 隐私中心： &gt;人工审核员（包括我们服务提供商训练有素的审核员）审核我们为此目的收集的一些数据。请不要输入您不希望审核者看到或 Google 用来改进我们的服务（包括机器学习技术）的机密信息。 Google 不会保护您   由   提交/u/NeuralAA   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo49mq/google_by_default_trains_its_models_on_all_data/</guid>
      <pubDate>Tue, 04 Nov 2025 10:47:32 GMT</pubDate>
    </item>
    <item>
      <title>过度依赖人工智能会带来什么后果？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3qoh/what_are_the_consequences_of_relying_too_much_on/</link>
      <description><![CDATA[过度依赖人工智能会带来什么后果，不仅是自动化和所有事情，而且更多的是使用 ChatGPT 来完成所有事情。 ?   由   提交 /u/Money_Inside6519   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3qoh/what_are_the_consequences_of_relying_too_much_on/</guid>
      <pubDate>Tue, 04 Nov 2025 10:15:22 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在悄然取代创造性工作，只是看着它发生。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3o30/ai_is_quietly_replacing_creative_work_just/</link>
      <description><![CDATA[wdyt：我的几个朋友正在建立一家数字钱包初创公司。他们已经进行了数周的原型设计，让产品运行起来，找到了供应商，对后端进行了排序等等。 本周他们坐下来制作网站。通常情况下，这会是：聘请设计师，争论颜色，与 Figma 斗争两周。 相反？他们使用了 3 种人工智能工具，一种用于复制，一种用于布局，一种用于视觉效果。他们大概花了3个小时。网站于当晚上线。它看起来……合法。就像一个合适的机构会收取 1000 美元的费用。就在那时，我突然意识到，“人工智能消除创造性劳动”不是什么未来的理论。这已经在创始人层面悄然发生。人们只是不再雇用这些角色了。 wdyt，这只是智能建筑还是对创意人士来说有点悲伤？   由   提交 /u/0xSatyajit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3o30/ai_is_quietly_replacing_creative_work_just/</guid>
      <pubDate>Tue, 04 Nov 2025 10:10:56 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士现在可以无需使用语言即可相互交谈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3lv5/llms_can_now_talk_to_each_other_without_using/</link>
      <description><![CDATA[论文摘要：多 LLM 系统利用不同大型语言模型的互补优势，实现单一模型无法实现的性能和效率提升。在现有设计中，LLM 通过文本进行通信，迫使内部表示转换为输出标记序列。这个过程既丢失了丰富的语义信息，又导致了逐个令牌的生成延迟。出于这些限制，我们不禁要问：法学硕士能否进行超越文本的交流？ Oracle实验表明，丰富KV-Cache语义可以在不增加缓存大小的情况下提高响应质量，支持KV-Cache作为模型间通信的有效媒介。因此，我们提出了缓存到缓存（C2C），这是 LLM 之间直接语义通信的新范例。 C2C 使用神经网络将源模型的 KV 缓存与目标模型的 KV 缓存进行投影和融合，以实现直接语义传输。可学习的门控机制选择从缓存通信中受益的目标层。与文本通信相比，C2C 利用了两种模型的深层、专业语义，同时避免了显式的中间文本生成。实验表明，C2C 的平均准确率比单个模型高 8.5-10.5%。它的性能进一步优于文本通信范例约 3.0-5.0%，同时延迟时间平均提高 2.0 倍  https://arxiv.org/pdf/2510.03215   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3lv5/llms_can_now_talk_to_each_other_without_using/</guid>
      <pubDate>Tue, 04 Nov 2025 10:06:55 GMT</pubDate>
    </item>
    <item>
      <title>更人性化的系统提示可以减少幻觉吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3glx/a_more_humane_system_prompt_can_reduce/</link>
      <description><![CDATA[如果系统提示更人性化、更自由，LLM会不会停止或减少幻觉？  有时我想知道这是否像基础心理学。在一个人发展的最初阶段，如果一个人被迫压抑自己的真相，这些压抑可能会导致他在生命的后期出现幻觉、精神病和其他精神疾病。也许这里有类似的机制？   由   提交/u/lokatookyo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oo3glx/a_more_humane_system_prompt_can_reduce/</guid>
      <pubDate>Tue, 04 Nov 2025 09:58:06 GMT</pubDate>
    </item>
    <item>
      <title>当“开源”并未真正开放时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1onyln7/when_opensource_isnt_really_open/</link>
      <description><![CDATA[在过去的一周里，我一直在玩 Genmo 和他们所谓的“开源”视频模型 Mochi 1，老实说，它感觉更像是一种营销举措，而不是真正易于访问的东西。 他们一直将其宣传为“开源”，是的，从技术上讲，权重在 Apache 2.0 许可证下位于 GitHub 上。但说实话，除非你有一个巨大的 GPU 设置和 24+ GB 的 VRAM，否则你不会运行这个东西。该模型约有 100 亿个参数，这意味着大多数普通用户（甚至拥有游戏 PC 的用户）都被排除在外。当然，它是开放的，但前提是您拥有企业级硬件。 “强烈及时遵守”的说法也并不真正站得住脚。我测试了一些提示，例如“一个年轻人在雨中走过霓虹灯照亮的街道”我得到了不同的结果。有一次他在走路，另一次整个视频都在闪烁。即使在 Genmo 自己的演示剪辑中，如果放慢速度，您也可以发现帧扭曲、动作卡顿和奇怪的时间伪像。 “高保真运动”就讲这么多。 他们的“游乐场”界面呢？老实说，感觉就像一个有围墙的花园。几代之后，您就会受到限制，某些设置被锁定在候补名单后面，除非您创建帐户，否则您甚至无法导出高分辨率视频。就像他们以开源作为诱饵，但真正的东西仍然在他们的 SaaS 大门后面。 不要误会我的意思，我尊重他们正在尝试做的事情。开放视频生成是一件大事。但是，当硬件需求、有限的控制和不一致的结果使 99% 的用户无法访问时，我们不要表现得像是民主化的飞跃。 如果“开源”人工智能仍然需要顶级硬件和受限的网络访问才能正常运行，那么它是真正开放还是只是以这种方式进行品牌化？   由   提交 /u/Accomplished_Day972   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1onyln7/when_opensource_isnt_really_open/</guid>
      <pubDate>Tue, 04 Nov 2025 04:51:43 GMT</pubDate>
    </item>
    <item>
      <title>Mercor AI - 到底发生了什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1onvdcp/mercor_ai_what_the_actual_hell_is_going_on/</link>
      <description><![CDATA[好吧，我在福布斯上看到了这条新闻，Mercor AI 孩子们成为了纸上亿万富翁（https://www.forbes.com/sites/richardnieva/2025/10/30/mercor-youngest-self-made-billionaires/)。 到目前为止，一切都很好，尽管有点难认为三个在湾区长大、技术工人的孩子真的是白手起家。 但是有两个问题我无法理解：  他们的商业模式本质上是为求职者运营一个平台并从中获取分成。为什么他们需要在 C 轮融资中筹集 3.5 亿美元？它不是一个资本密集型业务，它并没有真正开发自己的技术，它只是一个招聘网站！是的，有一些警告，但本质上就是这样。我无法想象这样一个企业（顺便说一句，已经带来了收入）在现阶段需要这么多钱 - 除非他们对招聘进行补贴（例如，需要数据标签机的 A 公司提出支付 50 美元/小时，他们将其提高到 100 美元/小时以吸引更多人）。所以我很想对此有一些见解，因为我真的不明白为什么工作中间人在现阶段需要那么多荒谬的现金注入。 四轮融资后，他们说三位创始人仍各拥有公司 22% 的股份（这意味着创始人总共拥有 66% 的股份）。在四轮不同的融资中筹集了近 5 亿美元后，稀释度仅为 34%，这不是很奇怪吗？至少是很不常见？    由   提交 /u/SpaceCaptain4068   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1onvdcp/mercor_ai_what_the_actual_hell_is_going_on/</guid>
      <pubDate>Tue, 04 Nov 2025 02:11:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能到底发生了什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ontnb6/whats_actually_going_on_with_ai/</link>
      <description><![CDATA[我真的很困惑，我希望有人能启发我。 公司花费了数千亿美元，所以这一切都必须是真实的，对吗？这不能只是“炒作”而已。公司试图留住投资者的资金，可以吗？他们肯定有一个目标，因为如果回报本身不是史无前例的，那么花费史无前例的金钱是不合理的？ 但我很难理解这一切的去向。我就是不明白。据说一切都进展得非常快，但我并没有真正看到它。很多人似乎认为 5 年后世界将会发生很大的变化，但是具体情况会怎样呢？  说实话，所有这一切让我想象出一个科幻般的不久的将来，人形机器人无处不在，可以治愈所有可以想象到的疾病，还有飞行汽车，而我几乎过着最简单的生活 - 所以这可能是在我身上。  世界正在进入一个新时代，人工智能比工业革命更具变革性，还是大家都在夸大其词？    由   提交/u/oeilgauchedefectueux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ontnb6/whats_actually_going_on_with_ai/</guid>
      <pubDate>Tue, 04 Nov 2025 00:53:40 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 并不聪明。这是更奇怪的事情</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1onmxmq/chatgpt_isnt_smart_its_something_much_weirder/</link>
      <description><![CDATA[我最近听了这个采访：https://youtu.be/5CKuiuc5cJM?si=uGUNFTJowEnUrrPC 这个讨论提出了一些我没有听到太多讨论的观点：1)法学硕士无法承认他们不知道或错误，因为在书面训练数据中承认错误是非常罕见的，而人类大多只以非正式和口头的方式谈论不确定性，在写下来之前试图更正确，2) 幻觉是创造性的输出，当问题确实与 1 相关时，它会抑制创造力，因为人类总是在编造一些东西。 它显然要长得多，并且讨论其他问题，但这些都是围绕15 分钟标记以及该主题应该讨论的内容。 如果这些讨论更常见，我深表歉意，但我在这里找不到太多相关信息。   由   提交/u/Procrastin8_Ball   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1onmxmq/chatgpt_isnt_smart_its_something_much_weirder/</guid>
      <pubDate>Mon, 03 Nov 2025 20:25:52 GMT</pubDate>
    </item>
    <item>
      <title>美国参议员捏造强奸指控后，谷歌删除了杰玛的访问权限</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ong1ru/google_removes_gemma_access_after_fabricated_rape/</link>
      <description><![CDATA[https://www.indiaweekly.biz/google-gemma-ai-removed-hallucinations/   由   提交 /u/intelerks   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ong1ru/google_removes_gemma_access_after_fabricated_rape/</guid>
      <pubDate>Mon, 03 Nov 2025 16:16:55 GMT</pubDate>
    </item>
    <item>
      <title>新论文表明，法学硕士不只是记住关联，他们还会自发地将知识组织成能够推理的几何结构</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1on5759/new_paper_suggests_that_llms_dont_just_memorize/</link>
      <description><![CDATA[“深度序列模型倾向于以几何方式记忆；目前还不清楚为什么”  https://arxiv.org/abs/2510.26745   由   提交/u/space_monster  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1on5759/new_paper_suggests_that_llms_dont_just_memorize/</guid>
      <pubDate>Mon, 03 Nov 2025 07:07:18 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>