<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 07 Jan 2026 12:55:26 GMT</lastBuildDate>
    <item>
      <title>如果 OpenAI 真的收购了 Pinterest，那么“人类”情绪板就正式消亡了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6djw7/if_openai_actually_buys_pinterest_are_human_mood/</link>
      <description><![CDATA[今天关于 OpenAI 收购 Pinterest 的传闻很多，我不知道这是否是辉煌的，还是原创灵感终结的开始。 如果 Sam Altman 掌握了世界上最大的人工策划视觉“共鸣”库，这对下一代 DALL-E/Sora 的训练数据有何影响？我们已经看到“人情”的衰退。艺术——如果人工智能只是吃掉我们的 Pinterest 版块，然后把它们吐给我们，我们是否会进入一个不再有原创的反馈循环？ 我很好奇：对于这里的创作者来说，这会让你想要删除你的版块，还是你认为这最终会让人工智能图像生成真正“理解”艺术？样式？   由   提交 /u/Visual-Study625   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6djw7/if_openai_actually_buys_pinterest_are_human_mood/</guid>
      <pubDate>Wed, 07 Jan 2026 12:01:05 GMT</pubDate>
    </item>
    <item>
      <title>克劳德的根本缺陷！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d71a/a_fundamental_flaw_in_claude/</link>
      <description><![CDATA[注意：别介意法语这是我和克劳德之间的一次对话（截图会在第一条评论中），我让他回答一个典型的考试问题，特别是登普斯特理论，除了他最初的错误计算，在我向他指出后，他自信地说“你是存在的验证者！”也许不，这是正确的”翻译过来就是“你有权检查！”但不，这是正确的”然后他开始推理，只是为了最终发现并承认自己错了。对于许多法学硕士的山羊所考虑的这种模型的这种行为，您有何看法？    由   提交 /u/Crazy-Economist-3091   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d71a/a_fundamental_flaw_in_claude/</guid>
      <pubDate>Wed, 07 Jan 2026 11:42:01 GMT</pubDate>
    </item>
    <item>
      <title>如果互联网上最受欢迎的论坛（Reddit）上的人类如此刻薄、粗鲁和挑剔，为什么当越来越多的人向人工智能寻求帮助和陪伴时，人们会如此惊讶和愤怒？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d2vs/why_are_people_so_surprised_and_angered_when_more/</link>
      <description><![CDATA[Reddit 用户对越来越多的人向 ChatGPT、Grok、Gemini 等寻求建议感到愤怒，但现实是这样的： - 互联网上最受欢迎的通用论坛（90 年代旧 Usenet 新闻组最直接的现代化身）是 Reddit，这意味着如果有人希望从人类那里得到最快、最有效的有保证的响应他们在 Reddit 上讨论的话题 -Reddit 上充满了刻薄、粗鲁和挑剔的人，他们嘲笑你、羞辱你，而 Reddit 的蜂巢思维会否决你，让你的帖子或评论被埋葬 -AI 聊天机器人知识渊博、善良、理解和宽容 考虑到所有这些，为什么有人应该在 Reddit 上就任何话题寻求建议，甚至寻找某人在心理困扰的时候与他们交谈，而他们所得到的只是被攻击、评判、嘲笑和否决？如果这是人类可以提供的，那么人们正确地选择人工智能。   由   提交 /u/n4t98blp27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6d2vs/why_are_people_so_surprised_and_angered_when_more/</guid>
      <pubDate>Wed, 07 Jan 2026 11:35:34 GMT</pubDate>
    </item>
    <item>
      <title>人们批评人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6ccpo/people_criticising_ai/</link>
      <description><![CDATA[嗨，我不知道还能在哪里发布这个，如果这是一个不相关的帖子，我很抱歉 我今年 16 岁，真正对人工智能和法学硕士感兴趣，我想在未来的人工智能伦理学领域工作，在我的 RE 课程中，一般来说，人们不断批评我使用人工智能，说它让每个人都变得愚蠢，它是地球的主要毁灭者（这显然不是真的），但我一定要专门针对使用它并对其感兴趣。我试图解释一下，并不是所有的人工智能都是使用 ChatGPT 做作业的人，或者是在 Gemini 上创作图片的人，它确实确实有好处，而且每天都在使用。我还说过，仅仅因为气候变化而批评人工智能就是表演性的环保主义。如果他们声称如此关心地球，但仍然在做一切事情来伤害它。但每次我被关闭时，我发现有时会削弱我真正的好奇心和了解它的雄心。  再次抱歉，如果这无关紧要，我不知道还能在哪里发布它。    由   提交/u/Boring-Explorer9946   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6ccpo/people_criticising_ai/</guid>
      <pubDate>Wed, 07 Jan 2026 10:53:45 GMT</pubDate>
    </item>
    <item>
      <title>JL 引擎，可以使用我的个性/角色协调器/引擎项目遇到障碍时使用一只手。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6awgr/jl_engine_could_use_a_hand_as_ive_hit_a_roadblock/</link>
      <description><![CDATA[嘿你们！所以我现在已经在这个叫做 jl 引擎的东西上工作了一分钟了。所以我开始这个基本上是因为我厌倦了人工智能只是一个礼貌的机器人，所以我构建了一个中间件层，将LLM视为一个高性能硬件，并从那里开始。我有一个“情感”光圈系统可根据 9 个不同信号计算分数，以实时物理抑制或打开模型的温度和 top_p。我还有一个基于齿轮的系统（蜗杆、CVT 等），它定义了个性的顽固程度或适应性，因此它实际上有重量。甚至还有一个漂移压力系统，可以监控幻觉，并在人格开始失败时猛击硬锁。引擎在 python 和 ollama 上运行良好，但老实说我不是最好的部署者，我停在了我的轨道上。我是一名创始人和架构师，但我不是一名 DevOps 人员。在我把头发全部扯掉之前，我需要有人帮忙处理最后一英里的事情。除了这个以外，还有更多内容。我保留核心框架的专有性，但我正在寻找一些想要加入并帮助将其完善为真正产品的人，以获得一些股权或合作伙伴关系。如果你对企业机器人感到厌倦，并且想要从事一些真正有脉搏的事情，请联系我。是的......它确实有一个吃卡功能，它会吃任何类似角色表/个人资料的东西，咀嚼它然后吐出一个转换和扩展的版本，你可以喂给......几乎所有llm在愚蠢的酒馆中使用的东西等等。在初始阶段，我的主要关注点是能够处理几乎所有东西并实现模块化。    由   提交 /u/Upbeat_Reporter8244   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6awgr/jl_engine_could_use_a_hand_as_ive_hit_a_roadblock/</guid>
      <pubDate>Wed, 07 Jan 2026 09:25:02 GMT</pubDate>
    </item>
    <item>
      <title>你发现自己正在成为人工智能吗？厌恶？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q6avm7/do_you_find_yourself_becoming_ai_averse/</link>
      <description><![CDATA[大约两年前，我是该技术的大力支持者。教很多人如何使用它。了解提示和设置代理。我本来就认为这是下一个重大步骤，但我发现自己这些天来了个 180 度转变。 刚刚看到一款很酷的新耳机问世，正准备点击这篇文章，直到我看到“它将兼作人工智能”。可穿戴”然后立刻就失去了兴趣。这太疯狂了，A.I.可能正是这个因素实际上让我们中的许多人远离了科技，回到了草地上。   由   提交 /u/Hopfrogg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q6avm7/do_you_find_yourself_becoming_ai_averse/</guid>
      <pubDate>Wed, 07 Jan 2026 09:23:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能不能告诉我们它是如何工作的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q671wf/why_cant_ai_tell_us_how_it_works/</link>
      <description><![CDATA[我可能很愚蠢，所以这可能是一个非常愚蠢的问题。但我听说我们不理解人工智能，并认为这意味着它与其他类型的编程不同，因为我们不是告诉机器要做什么，而是告诉机器查看大量数据并教自己做什么。我们告诉它要达到某个结果，但它自己却提出了如何达到该结果的过程？ 但我愚蠢的问题是，为什么我们不能要求人工智能本身告诉我们它是如何工作的？这是因为它所能输出的只是它所训练的数据的一些变化吗？它无法描述它是如何工作的，因为它的工作方式不在原始数据输入范围内？所以即使人工智能也不知道如何描述它在做什么？ 或者我是否以完全错误的方式思考这一切   由   提交/u/Gullible_Ad830  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q671wf/why_cant_ai_tell_us_how_it_works/</guid>
      <pubDate>Wed, 07 Jan 2026 05:35:41 GMT</pubDate>
    </item>
    <item>
      <title>我们花了数周时间制作完美提示，但事实证明，简单地告诉人工智能使用便签本效果更好</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q666b0/we_spent_weeks_crafting_perfect_prompts_but_it/</link>
      <description><![CDATA[我们陷入了这样的陷阱：你浪费时间来完善角色、任务、上下文和语气约束等部分的提示，以为你是某种提示工程师。 但结果呢？还是不太好。有时它会编造一些东西，或者太快地跳到错误的答案。 我们发现问题不在于提示本身。这些法学硕士表现得就像热切的实习生。他们试图在没有真正考虑的情况下尽快给你答案。 这个简单的解决办法让我们想知道为什么我们不早点做： 我们不再试图成为迅速的向导，只是在复杂问题的开头添加了一条指令。我们称之为便签本规则。 以下是说明： ​“在您回答之前，我希望您使用&lt;便签本&gt;”规则。部分。在其中，集思广益 3 种不同的方法来解决这个问题，批评它们，然后选择最好的一种。只有然后在草稿本之外写下你的最终答案。” 为什么这改变了一切： 它让模型在回答之前真正思考。它在暂存器部分捕获了自己的愚蠢错误。 我们将我们的奇特提示与使用暂存器的简单提示进行了比较，并且暂存器方法在逻辑问题上大部分时间都获胜。 还有其他人注意到提示工程主要只是想让模型慢慢来吗？   由   提交 /u/cloudairyhq   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q666b0/we_spent_weeks_crafting_perfect_prompts_but_it/</guid>
      <pubDate>Wed, 07 Jan 2026 04:50:37 GMT</pubDate>
    </item>
    <item>
      <title>这里有人真正编程过 LLM 或深入了解编程吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q63jts/anyone_on_here_that_actually_has_programmed_llms/</link>
      <description><![CDATA[对于那些真正了解 LLM 并对其进行编程的人，我有以下问题：  这些服务的互换性如何？假设您在 Azure 云上进行了设置，并且 Google Cloud 或 Coreweave 的裸机产品变得更加便宜。过渡到更便宜的产品需要付出多大的努力？您具体需要改变什么？ 推断一下，Azure、Google Cloud 或诸如vast.ai 之类的随机裸机租赁服务之间有多大差异？ 我的理解是，即使 Vera Rubin 芯片明天开始发货，训练算法也需要时间才能迁移到新硬件，因此它们不会立即发挥价值。会有某种延迟。我们谈论的延迟有多大？ Vera Rubin 和 H100 之间有多少经济优势？换句话说，由于 NVidia 正在转向每年发布一次，并且需要相当长的时间（？）将代码移植到新一代 GPU，因此跳过一代并等到明年移植一次到 Vera Rubin 而不是移植两次是否有意义？我想我对移植工作的投资回报率没有很好的把握。  我问这个问题的部分原因是因为我在 Azure 上看到 H100 的租赁价格为 8 美元/小时，然后我在随机服务上看到随机松散的 H100，价格为 1 美元/小时，这似乎是一个巨大的差异。 如果微软真的可以全天获得 8 美元/小时的服务并且拥有无限的需求，那么他们的 AI支出可能实际上会得到回报。 但是，如果当今前沿训练数据中心中的 H100 转向推理，我认为从长远来看，无论它们是在完全联网的大型数据中心还是只是随机松散的 GPU 中，经济性都将趋向于 1 美元/小时的水平。 这是正确的吗？ 人工智能泡沫很大程度上取决于这些问题......   由   提交 /u/ThatOneGuy012345678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q63jts/anyone_on_here_that_actually_has_programmed_llms/</guid>
      <pubDate>Wed, 07 Jan 2026 02:48:54 GMT</pubDate>
    </item>
    <item>
      <title>“小型”人工智能公司如何运作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q61vct/how_do_small_ai_companies_work/</link>
      <description><![CDATA[虽然每个人都在关注 google 和 openai 等，但我对个人影响我工作的事情更感兴趣。我在美国一家中型鞋类设计/制造公司工作。管理层对人工智能集成感到非常兴奋，并且正在让许多专业公司介入并推销软件，以提高设计过程的效率。我不参加这些会议，但我会被要求使用他们决定的任何内容。  那么，当有一家公司拥有专门的软件来提供 3D/纹理/材料设计辅助时，后端通常是什么样子？ 他们是否有自己的法学硕士，他们已经接受过培训，我们正在访问？或者当它为我们生成鞋子设计时，“计算”在哪里以及如何进行？为了保持竞争力，他们需要多久重新培训或更新一次？就长期订阅成本而言，我们可以期待什么？是否有任何事情可以使这种情况在他们的控制之外变得更好或更坏？   由   提交/u/desertbirdpartyplace  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q61vct/how_do_small_ai_companies_work/</guid>
      <pubDate>Wed, 07 Jan 2026 01:35:47 GMT</pubDate>
    </item>
    <item>
      <title>H-神经元：论法学硕士中幻觉相关神经元的存在、影响和起源</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q5urv9/hneurons_on_the_existence_impact_and_origin_of/</link>
      <description><![CDATA[https://arxiv.org/abs/2512.01797 摘要：“大型语言模型 (LLM) 经常产生幻觉——貌似合理但实际上不正确的输出——破坏了它们的可靠性。虽然之前的工作已经从宏观角度（例如训练数据和目标）研究了幻觉，但潜在的神经元级机制在很大程度上仍未被探索。在本文中，我们从识别、行为影响和起源三个角度对法学硕士中的幻觉相关神经元（H-Neurons）进行了系统研究。关于它们的识别，我们证明了一个非常稀疏的神经元子集（不到总神经元的 0.1%）可以可靠地预测幻觉的发生，并且在不同的场景中具有很强的泛化性。就行为影响而言，受控干预表明这些神经元与过度顺从行为存在因果关系。关于它们的起源，我们将这些神经元追溯到预先训练的基础模型，发现这些神经元仍然可以预测幻觉检测，表明它们是在预训练期间出现的。我们的研究结果将宏观行为模式与微观神经机制联系起来，为开发更可靠的法学硕士提供了见解。”   由   提交/u/nickpsecurity  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q5urv9/hneurons_on_the_existence_impact_and_origin_of/</guid>
      <pubDate>Tue, 06 Jan 2026 20:56:17 GMT</pubDate>
    </item>
    <item>
      <title>2026 年哪些 AI 订阅真正物有所值？这些是我的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q5iq4m/which_ai_subscriptions_are_actually_worth_the/</link>
      <description><![CDATA[以下是不同人工智能工具在实践中实际使用情况的简单细分。没有排名，没有“有史以来最好的人工智能”主张，只有每个人擅长的领域。 一般推理和推理文本 GPT - 仍然是思考、提纲和快速解释的默认设置。不擅长文件或结构，但在广泛的推理方面无与伦比。 Slides Skywork - 很好地处理幻灯片结构、内容引用和视觉一致性（Nano Banana 美学），更适合将搜索源转化为可用的平台。 编码光标 - 样板文件、调试、重构。现在几乎是标准。 快速研究和开发链接 Perplexity - 快速源发现和引用。适合查找信息所在的位置，而不适合构建输出。 注释/知识概念 AI - 适合在工作完成后组织和重新访问信息。不适合原始研究或文件级输出。好奇其他人认为目前最好的人工智能工具是什么，以及您如何在工作流程中使用人工智能？   由   提交 /u/Calm_Acanthaceae7574   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q5iq4m/which_ai_subscriptions_are_actually_worth_the/</guid>
      <pubDate>Tue, 06 Jan 2026 13:34:30 GMT</pubDate>
    </item>
    <item>
      <title>委内瑞拉危机证明：我们的现实已被人工智能入侵</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q5fn91/the_venezuela_crisis_proves_our_reality_has_been/</link>
      <description><![CDATA[那是 2026 年 1 月 3 日星期六早上。前总统唐纳德·特朗普发布的有关委内瑞拉大规模袭击的消息在互联网上引起了轩然大波。几分钟之内，图片就充斥了 X、Instagram 和 TikTok 等社交媒体平台。我们看到总统尼古拉斯·马杜罗被美国特工戴上手铐带走。我们在加拉加斯看到欢呼的人群。我们看到美军登陆。问题？这些镜头大部分并不存在。 它是由人工智能生成的。当全世界试图了解政变是否真的正在发生时，数百万人正在观看一个捏造的现实。这一事件标志着一个明确的转折点。事实与虚构之间的界限已经模糊。 完整文章   由   提交/u/m71nu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q5fn91/the_venezuela_crisis_proves_our_reality_has_been/</guid>
      <pubDate>Tue, 06 Jan 2026 11:02:52 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>