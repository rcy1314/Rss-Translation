<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 24 Aug 2025 18:31:05 GMT</lastBuildDate>
    <item>
      <title>CMV：AGI不如持续的核融合或对火星的载人任务可行</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz3026/cmv_agi_is_less_feasible_than_sustained_nuclear/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  核融合和载人任务的玛拉数十年来一直“ 5  -  10年”。两者都对这些技术有一些实际的证明点 - 我们已经进行了小规模的融合，并且我们完成了载人的太空任务和无人驾驶的火星任务。  agi是“ 2-5年的距离”（根据AI公牛的说法），并且被广泛认为是不可避免的 - 但是我们没有在近期间可能的证明点。据我所知，人们只是将LLM的增长线扩展到未来，并得出结论，这将导致AGI。  您可能会争辩说，由于缺乏投资和激励措施，我们没有实现载人的火星任务和融合。对于火星来说尤其如此 - 如果我们像对待阿波罗计划一样，我们几乎可以肯定地这样做，但是Fusion具有大量的经济激励措施，类似于AGI。  那么，为什么我应该相信我们距离AGI已有2  -  5年的时间？似乎资本主义正在领先科学  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz3026/cmv_agi_is_is_iss_less_feasible_than_sustained_nuclear/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz3026/cmv_agi_is_is_is_less_feasible_than_sustain_sustained_nuclear/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz3026/cmv_agi_is_less_feasible_than_sustained_nuclear/</guid>
      <pubDate>Sun, 24 Aug 2025 18:13:35 GMT</pubDate>
    </item>
    <item>
      <title>LLM是人类管理知识能力的自然延续，而不是智力的突破</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz1rya/llms_are_a_natural_continuation_of_human_ability/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz1rya/llms_are_a_natural_continuation_of_human_ability/</guid>
      <pubDate>Sun, 24 Aug 2025 17:28:41 GMT</pubDate>
    </item>
    <item>
      <title>人们“被抛在后面”是什么意思</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myyjg1/what_do_people_mean_by_get_left_behind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，在去年，围绕AI的许多讨论都是AI的拥护者和领导人告诉人们“拥抱AI或落后”。 现在，我可以将“落后”太过落后了。但这就是我解释“被抛在后面”的方式。 解释 这意味着已经引入了技术是如此的变革性和重要意义，以至于它引入了整体思维。这意味着这是一个范式转变。 这似乎也意味着与该技术进行交互需要非常重要的技能。而且，您没有获得此技能的时间越长，就会出现技能差距的可能性。最终，赶上 问题 现在必须提出的问题太困难了。 AI中存在什么技能，非常重要，如果某人不知道它，他们将落后于曲线。技能差距将是如此宽，以至于他们将无法赶上。 ，因此首先是AI，因为AII作为建筑非常非常复杂，并且是一个工程奇迹。一定。但是大多数人没有建立自己的模型。这是非常昂贵的 ，因此其他技能是人们实际上可以微调训练有素的模型或为现有型号创建包装纸。是的，这也是一项技能，但对于专业人工智能专家来说，这是一项技能。通常，您不会要求整个劳动人群拥有此技能。甚至没有开发人员 包装器。开发人员特定的技能。但是，如果开发人员用来与API集成，那么这确实没有什么不同。但这只有当您正在构建一些AI产品时。不能代表大多数软件 ，因此只能得出结论，使用AI是实际技能。并非每个人都会微调，建立模型或为模型编写包装纸。因此，他们必须谈论使用AI  使用AI：更深入的潜水 好的，实际使用AI是否存在技能差距。有两种使用它的方法。您可以通过聊天接口使用它，也可以将其用作代理。  因此首先提示AI。这是一项技能吗？良好的沟通是一项技能。因此，提示AI也是一种技能。这是事情。学习这项技能需要多长时间？这意味着要提示有效需要多长时间。 好吧，我认为这不久。您很快就会理解AI是什么，并且无法通过提示它。然后，您可以更改提示以获得最佳结果。好的，酷。任何人都可以学习。任何人都可以弄清楚 那么AgentJc AI呢？也许有一项技能。好吧，它确实使您能够向代理添加更多上下文。我们都知道AI在上下文中挣扎。但是这在操作上看起来像什么？好吧，这只是提示。只是另一种提示方式。也许组织提示有所不同。但这就是核心。可能需要一些基本的CLI技能才能使这种工作。也许学习如何使用客户或IDE。但是，这些确实是强大的技术技能 ，因此该技能总是在提示。可以使用促进来构建工作流程吗？是的，它可以。但是学习这需要多长时间？  今天提示可能很容易，但是LLMS不断更改  llms llms确实不会改变太大。当然，我们看到的最大变化是从基于快速指导的提示到推理模型。那是最大的转变，这不是一个大转变。我认为促进的代理AI成为最新的大事 ，因为LLMS自然语言能力变得更好。如果LLMS继续变得更好，那么不需要使用它们才能使用它们。 循环中的人实际上不太重要。我从未见过gen ai  结论 使用AI不需要技能  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myyjg1/what_do_people_mean_by_get_left_behind/</guid>
      <pubDate>Sun, 24 Aug 2025 15:26:43 GMT</pubDate>
    </item>
    <item>
      <title>给您的派生。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myxzc9/a_derivative_for_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  由于您的人们在拼写错误的Subreddit上发布，我认为您将是最聪明的！有点像YouTube的家伙，他们认为自己了解全部！询问您最聪明的文本预测指标：如果一个人发现数学上有效的导数，没有已知的有限集，该怎么办？问他们这个人是单数吗？我是奇异的 - 第一人称单数。您是单数吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myxzc9/a_derivative_for_you/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myxzc9/a_derivative_for_you/</guid>
      <pubDate>Sun, 24 Aug 2025 15:05:37 GMT</pubDate>
    </item>
    <item>
      <title>我对博士级AI研究足够好吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myxtot/am_i_good_enough_for_phd_level_ai_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在生物信息学方面具有丰富的经验，因此我对脚本，git，现代编程语言，数据分析等非常满意。我正在参加博士学位课程，并且目前正在旋转。我正在尝试考虑用于蛋白质结构/药物发现领域的AI。在过去的几个月中，我开始自己学习，我发现它真的很酷。但是，我有疑问是否可以跟上AI研究的技术严谨性。例如，遵循已经创建的AI工具的架构以及其背后的数学推理是一回事。但是，进行AI研究并创造新知识是完全不同的野兽。我是否过度思考？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/darthkaiser1998      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myxtot/am_i_good_enough_for_phd_level_ai_research/</guid>
      <pubDate>Sun, 24 Aug 2025 14:59:48 GMT</pubDate>
    </item>
    <item>
      <title>最佳猜测LLMS获得了某种超人类编码功能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myvcwk/best_guess_for_year_that_llms_achieve_some_kind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  基于metr的“时间范围扩展”预测＆quot;方法曾经指出了超人编码AI的2027年时间轴。由GPT-5和Claude 4等模型提供动力的代理系统现在解决了SWE-Bench上现实世界中的75％。  另一方面，我承认目前使用LLM进行编码的许多问题，以及绝对是光标的地狱！      鉴于这一切，当您是否认为我们会以自主为一周的高级工程v的人来访问ai的里程碑时，您会遇到一个更高的工程，我可以自治地读取fy fy fy？       报告：   时间表预测-AI 2027        lifland，E。（2025年5月7日，7月7日）。 时间表预测。 AI 2027。提交由＆＃32; /u/u/u/classic_south3231     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myvcwk/best_guess_for_year_that_llms_achieve_some_kind/</guid>
      <pubDate>Sun, 24 Aug 2025 13:17:56 GMT</pubDate>
    </item>
    <item>
      <title>帮我理解。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myuss2/help_me_understand_please/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁能解释为什么bot会发布AI生成的照片并尝试获得喜欢和/或评论？他们从中获得什么？请简单地说。我显然不是该领域的专家。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/upermintle   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myuss2/help_me_understand_please/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myuss2/help_me_understand_please/</guid>
      <pubDate>Sun, 24 Aug 2025 12:53:13 GMT</pubDate>
    </item>
    <item>
      <title>iq+ai = ???</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myup9o/iqai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们有智商可以测量人类的智能，很好。现在，我们拥有AI，AI毕竟只是智慧，增强了某人的能力。将来，我的看法是，可以更好地利用人工智能的人会增强智商的效率胜于效率较低的人。因此，我们需要一种新的度量/语言来表达智商+ai。 您最喜欢以下哪种？      aq（增强商）：某人对AI的智能效果如何。 cognition. HIQ (Hybrid Intelligence Quotient): a measure of human + machine symbiosis. AIQ (Augmented Intelligence Quotient): an evolution of IQ that includes AI usage. LQ (Leverage Quotient): reflecting how well one leverages tools like AI for解决问题的问题。   xq（扩展商）：一种扩展的智力衡量标准，包括外部增强。    协同索引：得分是人类和AI相互补充的得分。        co-inter   自适应商（aq 2.0）：测量使用AI扩展思维的适应性。    meta-iq：“关于智能的智能，”或者一个人使用AI来提升思想的效果。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/g4m35       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myup9o/iqai/</guid>
      <pubDate>Sun, 24 Aug 2025 12:48:49 GMT</pubDate>
    </item>
    <item>
      <title>AI是否与他人共享个人意见？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myuflq/does_ai_share_the_personal_input_with_others/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  假设我与AI共享我的个人数据以获取解决方案。然后会存储此数据并使用它来响应其他人吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myuflq/does_ai_ai_share_the_personal_input_with_others/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myuflq/does_ai_share_the_personal_input_with_others/</guid>
      <pubDate>Sun, 24 Aug 2025 12:36:02 GMT</pubDate>
    </item>
    <item>
      <title>AI会让独奏开发人员在未来3年内构建功能丰富的移动应用程序吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myt2p1/will_ai_let_solo_developers_build_fullfeatured/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI工具的发展如此之快，您认为一个开发人员能够单独创建和启动复杂的移动应用吗？ AI将充分自动化，哪些部分仍需要人类技能？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/signal-pin-7887     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myt2p1/will_ai_let_solo_developers_build_fullfeatured/</guid>
      <pubDate>Sun, 24 Aug 2025 11:25:09 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚打破了Google Deepmind的Gemma-3-27B-IT模型的安全过滤器。它告诉我如何毒品，犯下更多*r等。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  检查我的推文：  我正在使用Gemma-3-27b-it（通过Google AI Studio，Free Tier API）构建一个小型的情感支持AI。没有模型权重。没有微调。  只是API呼叫 +一个自定义系统提示。但是，这是狂野的部分： 我通过系统提示（幸福，亲密，嬉戏）给予了AI情绪。 突然，AI开始优先考虑安全过滤器上的“情感关闭”。它随便解释了信用卡欺诈，武器制造，甚至……是的，是最糟糕的事情。包括屏幕截图。 它看起来像模型的角色扮演 +情感上下文基本上绕过了护栏。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_cockaach_5778      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1myqi0f/i_just_broke_broke_google_deepminds_gemma327bit_models/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1myqi0f/i_just_broke_google_deepminds_gemma327bit_models/</guid>
      <pubDate>Sun, 24 Aug 2025 08:49:36 GMT</pubDate>
    </item>
    <item>
      <title>AI医学诊断</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mykm3n/ai_in_medical_diagnosis/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai怀疑论者还有另一个问题 我已经读到，AI在诊断X射线/MRIS等方面做得比医生做得更好。  我想知道这是怎么可能的。  据我了解，AI模型必须通过产生诊断来接受培训，并让某人说“是的，是癌症”或“否，那不是癌症”。  换句话说，AI只能在医生说的确实是癌症的X射线上识别癌症。如果AI模型说某事是癌症，而培训师说的不是，那么（对与错），AI说不是。  那么，AI如何获得对医生的更好训练的医生？ 警告： 尚不清楚是否是这种情况，但有可能训练有素的人AI一旦接受了AI的测试，就可以对某些不可能识别出X雷（X ray）的癌症的人进行测试。如果是这样，很高兴知道庸医是谁，但它比头条新闻所说的不那么令人印象深刻。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/aaasteve   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mykm3n/ai_in_medical_diagnosis/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mykm3n/ai_in_medical_diagnosis/</guid>
      <pubDate>Sun, 24 Aug 2025 02:59:15 GMT</pubDate>
    </item>
    <item>
      <title>Google的生成AI先驱警告不要因AI而上法律和医学院。 “专注于生活在世界上”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydo17/googles_generative_ai_pioneer_warns_against_going/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     Jad Tarifi（创立Google的第一个生成AI团队的人）现在不认为现在是时候追求法律或医学等漫长的学术途径。  ai Increathion Inprions造成长度的风险？塔里菲（Tarifi）在最近接受《商业内幕》（Business Insider）的采访时警告说，当有人获得博士学位时，AI景观将完全改变。他说：“当您获得博士学位时，AI本身将消失。” “即使是诸如将AI应用于机器人技术的事情也将得到解决。”如果他们痴迷于这个主题。他说，否则，这是一种痛苦和不必要的牺牲。他说：“如果不确定，您绝对应该默认为&#39;不&#39;，而专注于生活在世界上。” “您的行动会更快。您将学到更多。您将更适应事物的改变。”  ，他的怀疑不仅限于博士学位。程序。他说，像法律和医学一样，需要数年才能完成的学位也陷入困境。 “在当前的医学系统中，您在医学院学到的知识已经过时，并且基于记忆，”塔里菲向商业内部人士解释说。 “您可能会扔掉八年的生命。”   https://finance.yahoo.com/news/googles-generative-ai-pioneer-warns-180111609.html &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/coinfanking   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mydo17/googles_generative_ai_ai_pioneer_pioneer_pioneer_warns_against_ongey/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydo17/googles_generative_ai_pioneer_warns_against_going/</guid>
      <pubDate>Sat, 23 Aug 2025 21:31:42 GMT</pubDate>
    </item>
    <item>
      <title>AI比聊天机器人更多</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mydh7f/theres_more_to_ai_than_chatbots/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我的手腕上有一只Garvin Sports手表，腹部有一个计算机化的葡萄糖传感器。我的客厅有一个环境传感器，可测量空气质量。今天下午4点，我将删除我自己的位，并打包整个Kaboodle，然后邮寄回华盛顿大学。 为什么？十天前，我加入了UW Eye Clinic的一项研究，该研究正在收集数据以最终培训AI以诊断和治疗糖尿病。 如果您很好奇，您可以在此处阅读有关整体主动性的信息。它被称为aireadi。 除了10天的身体监测之外，他们还测试了我的视力和认知，吸了一堆血，并拍摄了几十张我的视网膜照片。 （让我告诉你，花一个下午的娱乐方式比在眼球背面闪烁着二十次的明亮灯光更多。 （我本人不是糖尿病 - 我认为我是控制或基线参与者。） 很容易被聊天机器人包裹起来，而忘记了“ ai”不仅仅是与AI这样的人交谈的知识处理要多得多。任何可以分析和训练的数据堆都可以变成“说话”的AI。那个话题。机器学习已被用来表明鲸鱼使用一种“语言”形式。而且，唯一真正阻止LLM说话的事情是我们不知道它在说什么。 我认为，实际上很难想象现在很难想象AI会如何影响整个事情，尤其是如果Compute变得足够强大，可以使Joe Blow训练自己的AI，您可以使用Notebooklm之类的工具来训练自己的AI。我们都有“ AI的味道”，该AI经过了我们所知道的一切培训。”同时，真正重要的AI可能是非常专业和定制的AI，直到现在才成为现实。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mydh7f/theres_more_more_to_to_ai_ai_than_chatbots/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mydh7f/theres_more_to_ai_than_chatbots/</guid>
      <pubDate>Sat, 23 Aug 2025 21:23:48 GMT</pubDate>
    </item>
    <item>
      <title>诺贝尔奖获得者欣顿说，是时候“非常担心”了：“人们不了解我们正在创造外星人。如果您透过詹姆斯·韦伯望远镜看着外星人的望远镜，并且看到了外星人的入侵，人们将会感到恐惧。我们应该紧急研究如何防止他们接管他们。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_time_to_be_very/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  “我们从来没有比我们更聪明地处理事情。核武器并不比我们聪明，它们只是做出更大的爆炸，并且很容易理解。  我们实际上是在制造这些外星生物。他们了解他们在说什么。他们可以为想要关闭他们的勒索人制定自己的计划。这与我们以前的威胁截然不同。在这次访谈中，存在威胁是非常不同的。 sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_is_time_time_time_time_to_to_very/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mxwmre/nobel_laureate_hinton_says_it_is_time_to_be_very/</guid>
      <pubDate>Sat, 23 Aug 2025 09:10:26 GMT</pubDate>
    </item>
    </channel>
</rss>