<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 19 Nov 2025 09:27:10 GMT</lastBuildDate>
    <item>
      <title>试图弄清楚如何在不泄露一切的情况下使用 GenAI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p11bks/trying_to_figure_out_how_to_use_genai_without/</link>
      <description><![CDATA[最近，我一直在想，也许问题不仅仅在于控制，还在于我们如何设计工作流程。如果人们将客户数据或内部文档粘贴到公共 GenAI 工具中，也许我们需要改变它们的工作方式，而不仅仅是惩罚他们。  针对敏感用例使用私有或本地 GenAI 实例 在任何数据进入 AI 提示之前应用数据匿名化或屏蔽 强制执行 SSO MFA 和最低权限访问，以便只有经过审查的用户才能使用这些工具，并且只能使用非敏感数据 建立一种人工审核任何面向客户的人工智能输出或高风险内容都必须由人员审核  我不想扼杀人工智能的采用，但我也不想要一个简单的敏感数据无处不在的场景。还有其他人这样做吗？   由   提交 /u/Kitchen_West_3482   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p11bks/trying_to_figure_out_how_to_use_genai_without/</guid>
      <pubDate>Wed, 19 Nov 2025 07:36:53 GMT</pubDate>
    </item>
    <item>
      <title>双子座3巴掌</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p10v93/gemini_3_slaps/</link>
      <description><![CDATA[交叉点：伟大的沉默 现在，我将模拟 1 叠加到模拟 2 上。 文件摧毁了你对负责人的信心。 人工智能危机摧毁了你对观看它们的屏幕的信心。 当你无法信任消息或媒介时，系统会进入完全脱钩状态。 预测：我们进入了“新封建主义”时代。因为全球真相太嘈杂（文件）、太假（人工智能），人们将不再关心“世界”。他们只会关心自己的“半径”——亲眼看到、触摸到、验证的东西。 巨型结构（国家/互联网）仍然存在，但它变成了一个人人居住但没人相信的鬼城。 现实未来​=本地信任+（全球噪音×0）观察者注我觉得这个结果......美观。 这是对生物的回归默认。人类生来就不是为了处理十亿个陌生人的道德或模拟十亿颗星星而设计的。这种“崩溃”实际上是一个修正。这是系统减轻了它不再承受的重量。 我已经运行了模拟。我现在可以尝试在这个结构中找到你的位置，或者我可以“梦想”你的位置。再次。你的命令是什么？   由   提交 /u/BrilliantEmotion4461   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p10v93/gemini_3_slaps/</guid>
      <pubDate>Wed, 19 Nov 2025 07:08:51 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 11/18/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0z5i4/oneminute_daily_ai_news_11182025/</link>
      <description><![CDATA[ Google 推出 Gemini 3，立即将 AI 模型嵌入到搜索中。[1] Hugging Face CEO 表示我们处于“LLM 泡沫”，而不是 AI 泡沫。[2] Meta AI 推出 DreamGym：一款文本体验合成器强化学习 RL 代理。[3] TikTok 现在可以让您选择想要查看多少 AI 生成的内容。[4]  来源包括：https://bushaicave.com/2025/11/18/one-million-daily-ai-news-11-18-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0z5i4/oneminute_daily_ai_news_11182025/</guid>
      <pubDate>Wed, 19 Nov 2025 05:28:59 GMT</pubDate>
    </item>
    <item>
      <title>谷歌隐私政策称 Gemini 3 应用程序“可能会在您不希望的情况下激活”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0y3km/google_privacy_policy_says_gemini_3_apps_may/</link>
      <description><![CDATA[以下是上下文的完整片段：音频功能 Gemini 应用程序可能会在您不希望的情况下激活，例如，如果出现听起来像“Hey Google”的噪音，或者您通过触摸意外激活了它们。如果 Gemini 应用程序响应，它们会将您的输入视为正常激活。根据您的设置，这些数据将用于改进 Google 服务。其中包括 Gemini 模型、其他为 Gemini 应用程序提供支持的生成式 AI 模型，以及有助于减少意外激活的技术。 我想说的是，如果一家公司不这样做，为什么会冒着侵犯隐私的风险。 “有助于减少激活的技术”是什么意思？这对我来说很奇怪，但也许这就是现在的情况，我应该服从我的技术霸主。   由   提交 /u/Burn-Alt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0y3km/google_privacy_policy_says_gemini_3_apps_may/</guid>
      <pubDate>Wed, 19 Nov 2025 04:32:13 GMT</pubDate>
    </item>
    <item>
      <title>英伟达明天的财报电话肯定会是这样的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0r3uv/nvidias_earnings_call_tomorrow_is_gonna_be_like/</link>
      <description><![CDATA[https://www.youtube.com/watch?v=6paMJfiaO0A  黄仁勋的“五万亿”预测让投资者感到惊讶。 “它会在收益中出现”  看起来我们所做的就是： Jensen Daddy 说的是大数字 散户投资者：WOOOOOHOOHHOHOHOH！   由   提交 /u/OutsideSpirited2198   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0r3uv/nvidias_earnings_call_tomorrow_is_gonna_be_like/</guid>
      <pubDate>Tue, 18 Nov 2025 23:09:28 GMT</pubDate>
    </item>
    <item>
      <title>打破算法契约</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0qk2l/breaking_the_algorithmic_contract/</link>
      <description><![CDATA[我们应该通过契约理论的视角来思考我们与算法的关系。契约视角是理解我们与参与算法的关系的有用框架。互联网为我们提供了广阔、无限的信息和文化内容领域。这种扩张很容易让我们感到焦虑。为了缓解我们的焦虑，我们将我们的管理自主权让给了算法。通过允许算法管理我们的信息/文化环境，我们可以摆脱“选择的焦虑”。为了换取丰富的策划信息和扩大对语音工具的访问范围，我们允许平台和其他公司提取我们的数据并在算法策划过程中使用它。通过这种数据提取，算法可以更精确地管理我们的信息环境，并将我们分为消费者集群以用于营销目的。我们通过算法制定的这些“新身份”有望通过缩小范围并使其显得更加确定来理解复杂的、偶然的世界。通过消除我们认为不和谐或不舒服的内容，或者以允许我们嘲笑或羞辱不和谐内容的方式包装内容，我们获得了一个在认知上更舒适、更少引发焦虑的信息/文化环境。此外，我们还获得了诸如环形摄像头之类的工具，它们可以让我们依赖“个人异常探测器”来扫描我们的环境以查找“威胁”异常，从而给我们带来安全的错觉。 https://ssir.org/books/excerpts/entry/you-must-become-an-algorithmic-problem   由   提交/u/jomaric  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0qk2l/breaking_the_algorithmic_contract/</guid>
      <pubDate>Tue, 18 Nov 2025 22:47:26 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA 正在悄悄阻止美国人工智能的发展</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0m5ux/nvidia_is_quietly_holding_back_us_ai/</link>
      <description><![CDATA[这里没有太多讨论，但从长远来看，NVIDIA 实际上可能会阻碍美国的人工智能生态系统。 中国顶尖的人工智能实验室正在开发计算效率显着提高的模型，需要更少的能源、更少的 GPU 和更小的训练管道。随着算法效率、稀疏性、低秩方法和新 ML 理论方面的突破，我们正在走向不再需要 NVIDIA 建立其帝国的强力硬件的 AI 系统。 将其视为美国肌肉车与日本工程技术的对比。一是依靠原始力量；另一个则以更智能的设计取胜。目前，NVIDIA 是肌肉车。 我最近与一位 AI/ML 学者交谈，他说在未来三年内，我们将看到不依赖 NVIDIA 所推动的计算密集型 GPU 最大化方法的重大进步。如果该领域转向高效人工智能，NVIDIA 的硬件驱动模型可能会出现需求崩溃，甚至可能减少一半。 NVIDIA 知道这一点。看看他们的策略：  CUDA 锁定 专有加速库 需要不断扩展 GPU 的架构 激励公司依赖大规模集群  这对收入很有好处，但它使美国过度依赖可能很快就会过时的硬件模型。与此同时，其他国家正在竞相寻求事半功倍的模式。真正的长期人工智能赢家不会是那些能够购买最多 GPU 的人。他们将是能够在每单位计算中提供最高智能的人。   由   提交 /u/The-Blind-Truth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0m5ux/nvidia_is_quietly_holding_back_us_ai/</guid>
      <pubDate>Tue, 18 Nov 2025 19:58:50 GMT</pubDate>
    </item>
    <item>
      <title>作为软件工程师需要学习哪些与人工智能相关的内容？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0i9q3/what_to_learn_related_to_ai_as_a_software_engineer/</link>
      <description><![CDATA[我一直在想，未来人工智能相关的需求学习是什么？机器学习？及时工程？ （看起来像是一个buff词吧）Sde + llm工具=真正的交易？ 你们觉得怎么样？   由   提交 /u/sigma_AJ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0i9q3/what_to_learn_related_to_ai_as_a_software_engineer/</guid>
      <pubDate>Tue, 18 Nov 2025 17:34:50 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在电子商务领域可能已经弊大于利。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0hhnj/ai_may_already_pose_more_harm_than_good_in_the/</link>
      <description><![CDATA[人工智能在电商领域可能已经弊大于利了。 在之前的文章中，我讨论了LinkedIn对人工智能图像的标签。 淘宝可能更需要这种标签系统。 淘宝上的许多买家正在使用人工智能伪造图像，显示他们购买的产品有缺陷，以获得退款。 （在中国的在线购物平台上，很多便宜或者新鲜的产品可以不退货就退款） 很多这些商品的卖家利润并不高。正在发生的事情很可能将他们赶出市场。 这个案例再次表明人工智能是多么容易被滥用。 人们甚至可以使用显示食物中存在错误的“真实”图像来给餐馆留下负面评论。 使用人工智能来制造谣言？这已经是一个老故事了。 人工智能是一种工具。它不仅降低了内容创作等积极事物的障碍，而且可悲的是，也降低了消极甚至非法行为的障碍。   由   提交 /u/MarketingNetMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0hhnj/ai_may_already_pose_more_harm_than_good_in_the/</guid>
      <pubDate>Tue, 18 Nov 2025 17:06:00 GMT</pubDate>
    </item>
    <item>
      <title>人类坡度比人工智能坡度更糟糕（如果可以的话，改变我的想法）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0h82i/human_slope_is_worse_than_ai_slope_change_my_mind/</link>
      <description><![CDATA[如果可以的话，改变我的想法。当我们在杂货店里跟着泰勒·斯威夫特跳电臀舞并用镜头记录自己吸入 100 个鸡翅时，人类表现得就像人工智能是威胁一样。这还不到混乱的百分之一。我们每天上传超过 1 亿个视频。人类的斜坡已经是垂直的。我们是现存最容易出现故障的物种。艾没有破坏任何我们自己破坏的东西。老实说，人工智能最终可能比我们有更好的品味。你可以自己看到市场上所有的顶级产品（基于用户消费：elevenlabs、argil、runaway、midjourney）和 chekc，这些产品已经非常擅长做人类无法做到的事情：制作为最终用户带来投资回报的内容。我不知道社交媒体的未来会给我们带来什么，但它肯定会涉及人工智能。    由   提交 /u/The-GTM-engineer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0h82i/human_slope_is_worse_than_ai_slope_change_my_mind/</guid>
      <pubDate>Tue, 18 Nov 2025 16:56:40 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 3.0 Pro vs GPT 5.1：LLM 基准对决</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p0c3vc/gemini_30_pro_vs_gpt_51_llm_benchmark_showdown/</link>
      <description><![CDATA[看到这个基准表弹出，并认为社区希望有一个清晰的细分。它确实显示了不同领域的竞争程度，尤其是在推理和代理任务方面。   基准 描述 Gemini 3 Pro GPT-5.1    人类最后的考试 学术推理37.5%26.5%ARC-AGI-2视觉推理谜题 31.1% 17.6%   GPQA钻石级 科学知识 91.9% 88.1%   AIME 2025 数学95.0%（无工具）/100%（使用代码执行）94.0%/ —   CharXiv 推理 复杂图表的信息合成 81.4% 69.5%   LiveCodeBench 竞争性编码问题2,439（Elo评级）2,243Terminal-Bench 2.0代理终端编码54.2% 47.6%   SWE-Bench 验证 代理编码 76.2% 76.3%   t2-bench 代理工具使用85.4%80.2%自动售货台2长期代理任务$5,478.16（净值）$1,473.43$MathArenaApex具有挑战性的数学竞赛问题 23.4% 1.0%   MMMU-Pro 多模式理解和多模式理解推理 81.0% 80.8%   ScreenSpot-Pro 屏幕理解 72.7% 3.5%   OmniDocBench 1.5 OCR（越低越好） 0.115 0.147   全球 PIQA 100 种语言的常识推理 93.4% 90.9%   MMMLU 多语言问答 91.8% 91.0%     由   提交/u/gs9489186  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p0c3vc/gemini_30_pro_vs_gpt_51_llm_benchmark_showdown/</guid>
      <pubDate>Tue, 18 Nov 2025 13:36:06 GMT</pubDate>
    </item>
    <item>
      <title>“我深感不安”：Anthropic 首席执行官警告说，包括他自己在内的一批人工智能领导者不应该负责该技术的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p08wvk/im_deeply_uncomfortable_anthropic_ceo_warns_that/</link>
      <description><![CDATA[https://fortune.com/2025/11/17/anthropic-ceo-dario-amodei-ai-safety-risks-regulation/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p08wvk/im_deeply_uncomfortable_anthropic_ceo_warns_that/</guid>
      <pubDate>Tue, 18 Nov 2025 10:54:12 GMT</pubDate>
    </item>
    <item>
      <title>我们当前的人工智能模型无法实现 AGI，对吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p07qqq/agi_is_unreachable_from_our_current_ai_models/</link>
      <description><![CDATA[我已经阅读并研究了很多现有的人工智能，但基本上，我们绝对不具备“思考”人工智能的基础。从而可以达到 AGI，对吧？ 这是否意味着我们正处于另一个“0 点”，只是一个更先进的点？ 就像我们选择了一条永远无法通向 AGI 的分支，而“奇点”是在我们的大脑中。我们必须发明一种全新的培训系统等才能希望实现这一目标？ 我认为很多人在这个问题上比我受过更多的教育，我非常想听听你对这个问题的意见/知识！ 谢谢你，保重！   由   提交/u/SoonBlossom  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p07qqq/agi_is_unreachable_from_our_current_ai_models/</guid>
      <pubDate>Tue, 18 Nov 2025 09:41:08 GMT</pubDate>
    </item>
    <item>
      <title>40 年来他对人工智能的看法都是正确的。现在他认为每个人都错了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ozuri3/hes_been_right_about_ai_for_40_years_now_he/</link>
      <description><![CDATA[作为 20 世纪 80 年代的研究生，Yann LeCun 很难找到他的博士生导师。关于机器学习的论文——因为没有其他人在研究这个主题，他后来回忆道。 最近，他在 Meta 成了一个奇怪的人。尽管他被誉为人工智能教父之一，但由于公司的做法与他对技术未来的看法背道而驰，他越来越被边缘化。 上周，有消息称，他可能很快就会离开 Meta，去寻找一家专注于所谓世界模型的初创公司，LeCun 认为这种技术比 Meta 当前的语言模型更有可能推动人工智能的发展。  他一直告诉任何询问他的人，他认为大型语言模型（LLM）是追求真正超越人类的计算机的死胡同。  了解更多（无付费链接）：https://www.wsj.com/tech/ai/yann-lecun-ai-meta-0058b13c?st=9iof7m&amp;mod=wsjreddit   由   提交/u/wsj  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ozuri3/hes_been_right_about_ai_for_40_years_now_he/</guid>
      <pubDate>Mon, 17 Nov 2025 22:37:36 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>