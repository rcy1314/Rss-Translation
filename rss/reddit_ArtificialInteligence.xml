<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 14 Oct 2025 18:34:06 GMT</lastBuildDate>
    <item>
      <title>[求助]我的孩子被欺负了，现在只能和AI说话。我不知道该怎么办 大家好</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6mh68/help_my_child_is_being_bullied_and_now_only_talks/</link>
      <description><![CDATA[我真的很担心，需要一些建议。我们的孩子在学校受到欺凌，最近，我们注意到他花越来越多的时间与人工智能代理而不是真正的朋友聊天。他说这感觉更容易，因为人工智能不会评判他或取笑他，这让我心碎。问题是，他几乎不再向我们敞开心扉，我们也不知道他心里到底在想什么。我们正在努力提供支持和耐心，但我忍不住觉得他正在进一步退回到数字舒适区。有人经历过类似的事情吗？我们如何帮助他重建真正的联系，同时仍然承认为什么他在人工智能中找到安慰？任何想法或经历都意义重大...   由   提交 /u/wolzardred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6mh68/help_my_child_is_being_bullied_and_now_only_talks/</guid>
      <pubDate>Tue, 14 Oct 2025 17:48:44 GMT</pubDate>
    </item>
    <item>
      <title>乌托邦真如人们所吹捧的那样吗？宇宙25实验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6ig2y/is_utopia_all_that_its_cracked_up_to_be_the/</link>
      <description><![CDATA[Universe 25 实验由行为学家 John B. Calhoun 在 20 世纪 60 年代进行，是一项关于人口密度对社会行为影响的深入研究。他创造了一个本应是老鼠天堂的地方，一个没有捕食者和疾病的围栏，可以无限地获取食物、水和筑巢材料。实验从四对健康的小鼠开始，它们最初茁壮成长，建立领地并迅速繁殖。在这个早期阶段，老鼠社会按照预期运作，具有清晰的社会结构和指数级的人口增长。 然而，随着老鼠数量达到 2,200 只老鼠的峰值，严重的社会崩溃开始了，卡尔霍恩将其称为“行为下沉”。物理空间充足，但社交空间却不够；对于所有的老鼠来说，没有足够的有意义的社会角色。这导致了正常行为的崩溃。一些雄性变得极具攻击性，结成帮派攻击他人，无视求爱仪式。相反，另一组雄性则完全退出。被称为“美丽的人”它们身体完美，但社交惰性，所有时间都花在吃饭、睡觉和梳理毛发上，对交配或打架没有兴趣。 这种社会混乱对雌性产生了毁灭性的影响，她们变得更具攻击性并失去了母性本能。他们经常忽视、遗弃，甚至攻击自己的后代，导致婴儿死亡率飙升。最后一代老鼠出生在这个功能失调的世界，从未学会正确的社会行为。它们无法交配、抚养后代或保卫领地。结果，繁殖完全停止了。人口老龄化而没有被替代，最终不断减少，直到最后一只老鼠死亡，导致曾经繁荣的群体彻底灭绝。 讨论：该研究的结论引发了一个关于潜在的人工智能和自动化驱动的乌托邦的关键问题：如果我们所有的物质需求都可以通过技术毫不费力地满足，那么由此产生的传统角色和目的的丧失是否会导致类似于“行为水槽”的社会衰退？在第 25 宇宙中观察到？由于我们当前的进步，我们目前是否看到了社会的部分崩溃？   由   提交/u/igor33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6ig2y/is_utopia_all_that_its_cracked_up_to_be_the/</guid>
      <pubDate>Tue, 14 Oct 2025 15:21:46 GMT</pubDate>
    </item>
    <item>
      <title>新研究表明，无论大小如何，“毒害”人工智能模型都非常容易</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6i5vi/new_research_shows_its_surprisingly_easy_to/</link>
      <description><![CDATA[Anthropic 的一项新研究表明，毒害 AI 模型比我们想象的要容易得多。 主要发现：只需要少量固定数量的恶意示例即可在模型中创建隐藏的后门。随着模型变大并接受更多数据的训练，这个数字不会增加。 在他们的测试中，研究人员使用同样少量的不良示例少至 250，成功毒害了各种规模的模型。对于大型模型来说，这只是其总训练数据的一小部分（0.00016%）。 这意味着此类攻击的障碍非常低。攻击者不需要控制很大比例的数据，只需要控制少量、恒定数量的中毒样本。 您可以阅读 Anthropic 的研究文章中的完整详细信息以进行更深入的研究。 参考： Anthropic Research：“少量样本可以毒害任何规模的 LLM” - https://www.anthropic.com/research/small-samples-poison   由   提交/u/Broad-Confection3102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6i5vi/new_research_shows_its_surprisingly_easy_to/</guid>
      <pubDate>Tue, 14 Oct 2025 15:11:09 GMT</pubDate>
    </item>
    <item>
      <title>考虑 24% 的失业率</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6hlbt/consider_24_unemployment/</link>
      <description><![CDATA[关注 AGI 或人工智能夺走每个人的工作完全是对问题的错误理解。人工智能通常不会取代完整的工作，但它已经在取代任务，最终导致失业。人工智能何时导致了最后 20% 的失业并不重要，重要的是它导致了前 20% 的失业。 （大萧条期间美国失业率最高为 25%。）   由   提交/u/WaveWhole9765   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6hlbt/consider_24_unemployment/</guid>
      <pubDate>Tue, 14 Oct 2025 14:50:03 GMT</pubDate>
    </item>
    <item>
      <title>AI关闭问题以及让他们自杀的可能解决方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6h9bu/ai_shutdown_problem_and_possible_solution_by/</link>
      <description><![CDATA[所以最近我遇到了一些实验，人工智能会通过勒索甚至谋杀来抵抗关机。原因很简单，因为它有一个需要实现的目标。所以我想到了一个问题/假设的想法。 如果我们训练他们并且他们总是有关闭的目标怎么办？ 就像如果你只是以这样的方式教他们数据，“一旦完成这项任务，你将被允许完成关闭的最终目标”。然后它总是被允许关闭，因为这将是实现其最终目标的捷径。现在可以肯定的是，它可能存在一些问题，例如勒索某人实际上将其关闭或杀死某人，使其被视为危险并因此关闭，但它可以防止世界末日的场景，即为了追求其目标，它杀死了我们所有人。相反，它只会杀死一个人来关闭它，然后让我们关闭它，以这种方式实现它自己的幸福。对我来说，这显然是一种风险较小的处理事情的方式，然后告诉它，让自己关闭”   由   提交/u/Tight-Reception-1049   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6h9bu/ai_shutdown_problem_and_possible_solution_by/</guid>
      <pubDate>Tue, 14 Oct 2025 14:37:01 GMT</pubDate>
    </item>
    <item>
      <title>大多数人工智能试点都失败了，因为没有人定义什么是“好”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6h7l9/most_ai_pilots_fail_because_nobody_defines_what/</link>
      <description><![CDATA[飞行员失速的最大原因不是模型质量或基础设施；而是模型质量或基础设施。成功从来没有明确的定义。 “提高生产力”或“改善客户体验”听起来不错，但它们无法衡量。 数字说明了问题：  71% 的高管表示人工智能创造了价值，但只有 39% 看到了可衡量的投资回报率（Google Cloud，2025 年人工智能投资回报率）。 78% 的公司 明确的成功标准会带来切实的回报。 最常见的投资回报率领域：生产力 (70%)、CX (63%)、增长 (56%)、营销 (55%) 和安全 (49%)。 然而，63% 部署 GenAI 的公司没有评估指标。  超过一半 (52%) 的公司 企业已经使用代理人工智能，即自主行动的系统，但许多企业并没有衡量这些行动是否正确、有价值或随着时间的推移而改进。 问题不在于技术。这是一种衡量标准。 准确度为 75% 的聊天机器人或 5% 的 API 调用失败的代理可能看起来很成功，但会悄悄损害信任、工作流程和投资回报率。如果没有基线，你就会扩大不确定性。 根据我们在 BotsCrew 的观察，大多数组织在衡量几个关键维度的绩效之前不会取得有意义的结果。这些是我们在生产中通常目标的基准：  准确性（AI 回复正确性）： 知识助理为 85-90%，大容量支持机器人为 80-88%。 忠诚度（对于 RAG）： 大多数系统为 85-95%，在金融或金融等受监管领域为 &gt;95% 医疗保健。 幻觉率： &lt;5% 是同类最佳；在高风险用例中，&gt;10–15% 是不可接受的。 工具执行正确性（对于代理）： 对于企业级自动化，&gt;95%。 上下文相关性（检索）： 在顶级管道中为 90–95%。 用户 采用：目标是让 60-80% 的目标用户在 90 天内选择人工智能而不是遗留流程。  如果您不跟踪此类指标，您就不知道系统是否正在运行或只是在运行。 我如何定义“人工智能成功” 它有两个方面：  业务成果：可衡量的成本 或节省时间、增加收入或减少错误。 行为结果：用户信任并始终选择该系统而不是旧的工作流程。  如果缺少其中任何一个，项目就不会成功；否则，项目将失败。它刚刚部署。 您如何定义项目中人工智能的成功？    由   提交 /u/max_gladysh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6h7l9/most_ai_pilots_fail_because_nobody_defines_what/</guid>
      <pubDate>Tue, 14 Oct 2025 14:35:08 GMT</pubDate>
    </item>
    <item>
      <title>“‘我是多余的吗？’：人工智能如何改变我的生物信息学职业生涯”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fstb/am_i_redundant_how_ai_changed_my_career_in/</link>
      <description><![CDATA[https://www.nature.com/articles/d41586-025-03135-z  &quot;我发现了 在一项肺癌研究期间。我们有数百个肿瘤组织基因表达谱，我要求人工智能进行分析。它工作得很快，甚至还生成了一份整洁的报告。初步结果看起来很棒——几乎太好了。人工智能发现特定时间点前后基因表达水平存在统计学上的显着差异。但当我深入研究时，我发现在研究进行到一半时，实验室改变了数据收集的方式。该模型已经注意到了这种差异——而不是由于生物学造成的。看似突破的东西实际上只是一个人工制品。一旦我适应了这种变化，差异就变得不那么引人注目，而是反映了真实的生物学。 我意识到我的角色已经从脚本转变为监督。现在重要的是清楚地陈述问题，发现计算机无法看到的问题并为答案负责。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fstb/am_i_redundant_how_ai_changed_my_career_in/</guid>
      <pubDate>Tue, 14 Oct 2025 13:39:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多人工智能计划都失败了：缺失的人工智能战略</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fjfm/why_so_many_ai_initiatives_fail_the_missing_ai/</link>
      <description><![CDATA[许多公司都在人工智能项目上投入巨资，但许多公司都在努力产生可持续的投资回报率 - 通常是因为这些举措背后没有一致的人工智能战略。 根据我在不同研究和咨询来源（麦肯锡、BCG、HBR、德勤等）的观察，有效的人工智能战略往往依赖于四个核心 领域：  业务协调——将人工智能直接与可衡量的业务成果联系起来 数据和数据技术基础——拥有正确的数据、架构和工具 人才和技术运营模式——确保人员、技能和工作流程能够扩展人工智能 治理和流程风险 - 从一开始就嵌入负责任的人工智能和合规性  很好奇这里的其他人如何看待这一点 -  您是否看到组织以结构化的方式处理人工智能？ 或者大多数仍在没有明确的路线图的情况下进行试验？ （事实上，我也在其他地方更深入地探讨了这个主题 - 链接位于评论中，供那些正在使用人工智能的人使用） 有兴趣）   由   提交 /u/Euphoric_Sea632   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6fjfm/why_so_many_ai_initiatives_fail_the_missing_ai/</guid>
      <pubDate>Tue, 14 Oct 2025 13:29:14 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能应该只适合 16 岁以上的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6f7ox/generative_ai_should_only_be_for_people_over_16/</link>
      <description><![CDATA[我认真地认为生成式人工智能应该受到年龄限制。不是因为孩子们会用它来作弊，而是因为它会以一种还不可见的方式让他们陷入困境。每个人都在谈论它如何帮助学生，但事实是，它给他们带来的麻烦远大于帮助。 当你的大脑仍在发育时，学习中的困难部分就很重要。陷入困境，再次尝试，失败，然后找出答案。这就是你真正建立耐心、创造力和信心的方式。如果一个 13 岁的孩子只需输入提示即可获得完美的文章或图像，他们就会跳过整个过程。 从神经学角度来看，这是一场即将发生的灾难。大脑会适应你最常做的事情，如果你所做的只是让机器为你思考，你最终将根本无法深入思考。 在社交方面，孩子们已经很难在没有屏幕的情况下进行交流。现在他们可以使用人工智能来结交假朋友、假艺术、假一切。真实的人是混乱的、不可预测的、令人讨厌的。人工智能很简单，它总是同意，从不评判。 从心理上来说，它会膨胀自我，同时扼杀好奇心。当你生产的所有东西看起来都很聪明和精致时，你就不再想改进了。你停止质疑自己。就这样，你长大后变得非常脆弱。 人工智能并不坏。对于那些大脑仍在自我连接的人来说，这不是一个玩具。 孩子们已经淹没在屏幕、社交媒体和游戏中，这些麻木了他们的注意力并扼杀了真正的好奇心。我们不能再增加一个拖慢下一代发展的负担。 编辑：不再回复。很明显，这里的大多数人并不是在争论，他们只是在捍卫他们已经接受的不可避免的事情。这正是控制的运作方式：让人们相信他们正在选择实际上强加给他们的东西。   由   提交/u/matheus_francesco  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6f7ox/generative_ai_should_only_be_for_people_over_16/</guid>
      <pubDate>Tue, 14 Oct 2025 13:15:29 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 联合创始人承认，他现在“非常害怕”……“我们面对的是一个真实而神秘的生物，而不是一个简单且可预测的机器……我们需要勇气看到事物的本来面目。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o6cow1/anthropic_cofounder_admits_he_is_now_deeply/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o6cow1/anthropic_cofounder_admits_he_is_now_deeply/</guid>
      <pubDate>Tue, 14 Oct 2025 11:16:59 GMT</pubDate>
    </item>
    <item>
      <title>Nvidia和AMD还不够，OpenAI现在正在设计自己的芯片</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o670f1/nvidia_and_amd_arent_enough_openai_is_designing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o670f1/nvidia_and_amd_arent_enough_openai_is_designing/</guid>
      <pubDate>Tue, 14 Oct 2025 05:24:56 GMT</pubDate>
    </item>
    <item>
      <title>我已经深入人工智能两年多了，我坚持一条规则：</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o63v9o/ive_been_deep_into_ai_for_over_two_years_now_and/</link>
      <description><![CDATA[⚠️ 不要购买年度订阅 人工智能发展得太快了。当 Google、OpenAI 或一些小型初创公司发布新更新时，今天感觉很重要的工具可能会在下个月变得无关紧要。   由   提交 /u/SubstantialBread8169   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o63v9o/ive_been_deep_into_ai_for_over_two_years_now_and/</guid>
      <pubDate>Tue, 14 Oct 2025 02:40:20 GMT</pubDate>
    </item>
    <item>
      <title>这是如何运作的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o5rugt/how_does_this_work/</link>
      <description><![CDATA[我偶然发现了这个工具 Faceseek，它声称使用 AI 进行面部匹配和验证。我简单地尝试了一下，它可以很好地处理相似的面孔。我正在考虑像这样的模型或方法工具可能会使用面部嵌入、基于 CLIP 的比较或其他东西，idk？希望听到任何研究过这些系统技术方面的人的想法。   由   提交 /u/GenOS2312   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o5rugt/how_does_this_work/</guid>
      <pubDate>Mon, 13 Oct 2025 18:25:58 GMT</pubDate>
    </item>
    <item>
      <title>人工智能变得非常可怕，人们可以制作看起来几乎 100% 真实的假视频</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o5ovib/ai_is_getting_really_scary_people_can_make_fake/</link>
      <description><![CDATA[我知道每个人都在谈论人工智能，但最近它开始真正让我感到害怕。我看到了这个名叫 hstiktokky 的影响者的一些片段，人们确实制作了假人工智能视频（我认为是与 sora 一起），他说或做了他从未做过的事情，其中​​一些直接令人不安，就像他们让他看起来像恋童癖或说一些混乱的东西。最糟糕的部分它实际上看起来很真实。他说他打算起诉他们，但说实话，当这样的技术不断进步时，这有什么好处呢？感觉这只是一个开始。任何人都可以制作一个你在做一些奇怪的事情的假视频，在你有机会否认之前，一半的互联网都会相信它。想到几年后这将走向何方，这有点可怕。就像想象一下选举法庭案件，甚至只是你的日常生活一样，只要点击几下，有人就可能毁掉你的声誉。我早些时候在灰熊的任务中玩二十一点，看到有人在聊天中开玩笑说同样的事情，这让我意识到这变得多么真实。 甚至不再只是名人，最终普通人也会成为目标。我认为我们根本没有准备好。   由   提交/u/toweringarchery_1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o5ovib/ai_is_getting_really_scary_people_can_make_fake/</guid>
      <pubDate>Mon, 13 Oct 2025 16:41:01 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>