<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 01 Jan 2026 21:23:51 GMT</lastBuildDate>
    <item>
      <title>[P] KaggleIngest——为AI编码助手提供丰富的竞赛环境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1cfht/p_kaggleingestprovide_rich_competition_context_to/</link>
      <description><![CDATA[一个开源工具，用于从 Kaggle 竞赛/数据集中提取内容并对其进行排名，并针对法学硕士进行格式化。 将有关竞赛的所有元数据放入单个上下文文件中。 kaggleingest 。 com    由   提交 /u/Low-Mastodon-4291   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1cfht/p_kaggleingestprovide_rich_competition_context_to/</guid>
      <pubDate>Thu, 01 Jan 2026 19:19:29 GMT</pubDate>
    </item>
    <item>
      <title>热力学约束可以解释为什么当前的人工智能系统可能无法产生新知识吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1arvm/can_thermodynamic_constraints_explain_why_current/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1arvm/can_thermodynamic_constraints_explain_why_current/</guid>
      <pubDate>Thu, 01 Jan 2026 18:14:37 GMT</pubDate>
    </item>
    <item>
      <title>您认为转折点会在什么时候？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1agvj/when_do_you_think_the_breaking_point_will_be/</link>
      <description><![CDATA[GPU 价格是否会达到数千美元，普通人完全无法构建 PC，您认为需要多长时间人们才会说“够了”。我们正在失去自己的个人享受，去受益于一些人认为可能会导致整个人类衰落的事情。   由   提交 /u/Big-Interest3314   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1agvj/when_do_you_think_the_breaking_point_will_be/</guid>
      <pubDate>Thu, 01 Jan 2026 18:02:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么视频推理仍然没有解决（即使使用 VLM）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q1984k/why_reasoning_over_video_still_feels_unsolved/</link>
      <description><![CDATA[在使用视觉系统时，我不断遇到同样的问题： 我们如何以可靠、可解释和可扩展的方式推理图像和视频？ VLM 在单一模型中做了很多工作，但它们经常遇到以下问题：  长视频， 一致的跟踪， 和扎根的解释  最近，我一直在探索一种更加模块化的方法：  专门的视觉模型处理感知（对象、跟踪、属性）， LLM 对结构化输出的推理， 可视化仅突出显示解释中实际引用的对象。  这似乎更适合以下用例：  流量和监视分析， 安全或合规性监控， 审查长视频并提出有针对性的问题， 解释*为什么*检测到某些内容，而不仅仅是*什么*。  我很好奇这里的其他人对此有何看法：  VLM 是最终状态还是中间步骤？ 模块化人工智能系统在哪些方面仍然可以制造更多 今天缺少什么可靠的视频推理？  我提供了一个简短的演示视频，展示了这种管道在实践中的表现。 很想听听想法。   由   提交 /u/sjrshamsi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q1984k/why_reasoning_over_video_still_feels_unsolved/</guid>
      <pubDate>Thu, 01 Jan 2026 17:12:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的进步可能会迫使我们回归面对面对话，将其作为唯一值得信赖的沟通媒介。我们可以做些什么来确保保持对其他通信方式的信任？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q17max/ais_advances_could_force_us_to_return_to/</link>
      <description><![CDATA[一年之内，我们可以预期，即使是专家也很难区分“真实”和人工智能生成的图像、视频、音频记录，这些图像、视频、音频记录是在第一批生成式人工智能工具民主化 1-2 年后创建的。 这是一个公平的预测吗？我们能做些什么，才能不陷入一个在线信息荒芜的时代，我们相信沟通来源的唯一方式是通过面对面的互动？ 我担心的因素： -人们可以使用人工智能创建虚假图像、视频、音频来说谎或冒充你的亲戚/亲人。 -如果训练数据被有意或无意地泄露，法学硕士可能会被操纵。  可能的结果： -我们被欺骗并做出错误的决定。  -我们不再信任任何人或任何事物（包括法学硕士，尽管他们今天看起来很有前途） 随着教学，我们开始看到口语考试已经变得越来越普遍。这是一个可能被更广泛使用的解决方案。  结束这种情况的唯一方法似乎是巨魔农场（或巨魔爱好者）的效率将提高 100 倍，而其造成的损害规模将更加严重。而且除非亲自见面，否则你无法知道某人的真实身份。 我是否过于悲观？ 注意： - 我是一名具有一定技术知识的人工智能爱好者。我真诚地希望法学硕士助理在克服所有挑战后能够留下来。   - 我试图在 r/s 上发布类似的内容，指出人工智能将推动人类进行更多面对面互动的讽刺，但最近在那里发布了类似的帖子，所以它被删除了。我有兴趣听听别人的意见。    由   提交 /u/l4mpSh4d3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q17max/ais_advances_could_force_us_to_return_to/</guid>
      <pubDate>Thu, 01 Jan 2026 16:06:24 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>人工智能视频的“合成器”类比感觉很准确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q13p9x/the_synth_analogy_for_ai_video_feels_accurate/</link>
      <description><![CDATA[20 世纪 30 年代的音乐家抗议“机器人”真的很困扰我。这感觉就像视频制作的当前状态。 我经营一个利基科学频道（主要是业余爱好），老实说，我 90% 的倦怠来自于寻找素材。我有一个关于熵或费米悖论等抽象内容的脚本，但将其可视化意味着需要花费数小时清理库或解决不太适合的通用剪辑。 最近决定测试专用的太空代理工作流程。我没有对每一个镜头进行即时设计，而是直接为其提供核心概念。它实际上进行了研究，并按顺序生成了与叙述相匹配的视觉效果。 输出并不完美——我不得不重新滚动一些比例看起来不合适的场景。但这把周末的编辑变成了几个小时。感觉不太像“自动化艺术”。更像是从 4 轨录音机升级到 DAW。您仍然需要这个想法，但摩擦已经消失了。 对于这里的高级用户来说可能没什么新鲜的，但对于单独的创作者来说，它感觉很重要。   由   提交 /u/ProgrammerForsaken45   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q13p9x/the_synth_analogy_for_ai_video_feels_accurate/</guid>
      <pubDate>Thu, 01 Jan 2026 13:01:11 GMT</pubDate>
    </item>
    <item>
      <title>​我使用图像分析构建了一个“演绎引擎”来复制福尔摩斯的逻辑。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q138z1/i_built_a_deduction_engine_using_image_analysis/</link>
      <description><![CDATA[大家好， 作为一名作家和技术爱好者，我一直在寻找“演绎科学”。在悬疑小说中，它是专门的人工智能应用程序的完美候选者。为了宣传我的新书《221B Reboot》，我决定超越传统营销并构建一个功能性工具。 项目：221B 演绎引擎使用基于视觉的人工智能来分析用户上传的个人空间（桌子、架子、入口）的照片。它不只是标记对象，而是使用自定义提示框架来应用演绎启发法，解释磨损模式、项目组织和环境“线索”。推断主体的习惯和个性。 目标：我想看看是否可以使用生成式人工智能来弥合虚构角色的才华与现实世界的用户体验之间的差距。这是“跨媒体讲故事”中的一个有趣的实验——使用一个应用程序让读者体验主角的方法论。 在这里查看：https://221breboot.com/ 我很好奇这个社区对使用人工智能实现这种“创造性逻辑”的看法。应用。是不是真的感觉像是“演绎”？还是人工智能真的很擅长“冷读”？   由   提交/u/dfinwin  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q138z1/i_built_a_deduction_engine_using_image_analysis/</guid>
      <pubDate>Thu, 01 Jan 2026 12:35:03 GMT</pubDate>
    </item>
    <item>
      <title>信息连续性理论</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0ukhm/information_continuity_theory/</link>
      <description><![CDATA[生命是什么？本文介绍了信息连续性理论 (ICT)，这是一个概念框架，将生命定义为结构化信息通过复制在时间中持续存在。信息通信技术并未将有机体、基因或健康视为主要的解释单位，而是将能够代代相传的信息视为生命的基本实体。进化被重新定义为环境约束下差异信息持久性的历史结果。该理论与基质无关，适用于生物、文化和人工系统。讨论了对人工生命和人工智能的影响。 https://lesslethalballistics.com/information-continuity-theory/   由   提交 /u/MyStarNamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0ukhm/information_continuity_theory/</guid>
      <pubDate>Thu, 01 Jan 2026 03:25:16 GMT</pubDate>
    </item>
    <item>
      <title>电费上涨 11%，而使用量下降 15%</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0tezi/electricity_bill_up_11_while_usage_is_down_15/</link>
      <description><![CDATA[在我们地区，我们正在建设数据中心。  https://blockclubchicago.org/2025/08/27/ai-use-and-data-centers-are-causing-comed-bills-to-spike-and-it-will-likely-get-worse/ 真令人沮丧。我们已经尽了自己的努力来限制使用、降低热量、使用 LED 灯泡、限制圣诞照明，并尽我们所能来阻止账单上涨。仍然上涨了11%。将使用量减少 15% 并不容易。 我没有充分利用人工智能工具来证明每月多付 11% 的电费是合理的。无论我喜欢与否，我都会为我从未注册过的服务支付每月的订阅费。  我不知道如何处理这个问题。   由   提交/u/Engineer_5983  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0tezi/electricity_bill_up_11_while_usage_is_down_15/</guid>
      <pubDate>Thu, 01 Jan 2026 02:18:59 GMT</pubDate>
    </item>
    <item>
      <title>我们是否正在从“人工智能工具”转向人工智能认知支架/外骨骼？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0swz8/are_we_moving_from_ai_tools_to_ai_cognitive/</link>
      <description><![CDATA[我一直在思考一种转变，这种转变似乎源于人们实际使用人工智能的方式，而不是源于 AGI 推测或模型基准。感觉我们可能正在远离人工智能作为“工具”，而转向更接近认知支架的东西——或者我宽松地称之为认知外骨骼。如果这个框架是正确的，那么 2026 年感觉像是一个合理的拐点。 我所说的“认知外骨骼”并不是指植入物、脑机接口或任何神经系统。我的意思是人工智能系统充当外化的认知结构：随着时间的推移保留上下文的系统，适应人们的推理方式而不仅仅是他们提出的问题，并支持判断和推理路径而不是仅仅产生输出。这感觉与提示响应交互、任务完成或副驾驶式自动完成完全不同。这些仍然像工具一样。这开始感觉像是认知本身的延伸。 目前（2024-2025），大多数人工智能的使用仍然是事务性的。我们提出问题，得到答案，完成任务，然后继续前进。交互重置。但似乎正在出现的是一种不同的使用模式：持久的个人背景、长期记忆原语、重复的交互塑造行为，以及人们越来越多地“思考”人工智能，而不是简单地询问它的结果。在某些时候，系统不再感觉像你操作的软件，而是开始表现得更像你所依赖的认知基础设施。 一个令人不安的暗示是，这些系统并不能平等地让每个人受益。它们倾向于放大内部结构、判断质量和元认知。就像物理外骨骼一样，它们不教授基础知识；它们增强了姿势。好的结构可以很好地扩展，坏的结构可以很差地扩展。这表明未来的差距主要不是关于人工智能的获取，而是关于人们如何思考它。 2026 年对我来说引人注目的原因并不是因为任何单一模型的发布。这是多种趋势的融合：更好的记忆力和个性化、持续而不是间歇性地使用人工智能、围绕思考而不是离散任务组织的工作流程，以及从“即时技巧”到认知一致性的逐渐转变。当这些融合时，主要的使用模式可能会发生翻转。 我很好奇这里的其他人如何看待这一点。您是否已经将人工智能主要视为一种生产力工具，或者感觉它更接近于认知支架？ “认知外骨骼”对于正在出现的事物来说是一个有用的框架，还是一个误导性的框架？   由   提交 /u/Weary_Reply   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0swz8/are_we_moving_from_ai_tools_to_ai_cognitive/</guid>
      <pubDate>Thu, 01 Jan 2026 01:50:39 GMT</pubDate>
    </item>
    <item>
      <title>如果“集成”人工智能系统没有真正集成，那么它还有什么意义呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0o2vi/what_is_the_point_of_integrated_ai_systems_if_it/</link>
      <description><![CDATA[我举个例子。我的工作一直促使我们使用 MS Copilot，所以我决定尝试一下。从简单的事情开始，我使用了“集成” AI 将带有会议请求的电子邮件转换为日历项目并将其输入 Outlook。令人惊讶的是，它不能这样做！它能做的最好的事情就是导出到 .ics 并告诉我如何将其导入到我的日历中，这比我自己做需要更多的时间。它无法自动执行繁琐的工作任务，例如创建日历项目。这不是“由人工智能驱动”。这是 chatgpt 的一个美化的快捷方式。  为什么还要费心“整合”呢？人工智能何时无法与其集成的软件实际交互？   由   提交 /u/cactuscoleslaw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0o2vi/what_is_the_point_of_integrated_ai_systems_if_it/</guid>
      <pubDate>Wed, 31 Dec 2025 21:37:15 GMT</pubDate>
    </item>
    <item>
      <title>NSFW 是否可能永远不会被允许使用大型公司制造的模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0lveh/is_it_likely_that_nsfw_will_never_be_allowed_with/</link>
      <description><![CDATA[我说的是 Google Veo、Sora、Kling、Nano Banana 等。 即使 20 年后，这些公司仍然会过滤 NSFW、色情和暴力内容的可能性有多大？任何出来竞争的新公司都会这样做吗？   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0lveh/is_it_likely_that_nsfw_will_never_be_allowed_with/</guid>
      <pubDate>Wed, 31 Dec 2025 19:53:59 GMT</pubDate>
    </item>
    <item>
      <title>人工智能数据中心导致印度水资源压力加剧</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q0eukr/indias_water_stress_due_to_ai_data_centers_to/</link>
      <description><![CDATA[印度的人工智能数据中心担心会加剧所在社区的水资源压力 “之前，我们可以在 30 米左右找到水。” “去年，我们不得不将井深加深到近 180 米。村里的一些地方，水深已经超过了250米。” 大量的水被蒸发了。水确实回到了环境中，但不是回到同一个地方，不是以同样的形式，也不是按照社区所依赖的同一时间线。这种差异正是问题所在。很大一部分作为水蒸气蒸发到空气中。该蒸气不会返回当地含水层。因此，您可以看到在这种情况下，印度和当地社区将对此感到多么愤怒。 https://asia.nikkei.com/business/technology/artificial-intelligence/india-s-ai-data-centers-feared-to-worsen-host-community-water-stress   由   提交/u/ranaji55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q0eukr/indias_water_stress_due_to_ai_data_centers_to/</guid>
      <pubDate>Wed, 31 Dec 2025 14:55:12 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>