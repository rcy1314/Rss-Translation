<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 05 Jan 2026 09:37:16 GMT</lastBuildDate>
    <item>
      <title>大多数“及时改进”只是添加更多文字，而不是更加清晰。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4guhr/most_prompt_improvements_are_just_adding_more/</link>
      <description><![CDATA[我不断看到提示通过变得更长、更详细、更冗长而得到“改进”。但有一半的时间输出并没有变得更好——它只是变得更加受限和通用。 我们是否混淆了细节和清晰度？在什么时候提示不再是指导并开始过度拟合？   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4guhr/most_prompt_improvements_are_just_adding_more/</guid>
      <pubDate>Mon, 05 Jan 2026 09:02:21 GMT</pubDate>
    </item>
    <item>
      <title>不久前我建议使用“本能”来帮助对齐</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4g4g9/a_little_while_ago_i_suggested_using_instincts_to/</link>
      <description><![CDATA[如果你能弄清楚如何赋予人工智能类似于动物的本能行为，那么它可能不太可能出现不一致。在 Reddit 上提到这一点大约一周后，我看到一些“人工智能研究员”谈论它。  让大家知道，我是最早谈论这个问题的人之一。    由   提交/u/VOIDPCB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4g4g9/a_little_while_ago_i_suggested_using_instincts_to/</guid>
      <pubDate>Mon, 05 Jan 2026 08:16:27 GMT</pubDate>
    </item>
    <item>
      <title>您实际使用人工智能处理过的最复杂的工作任务是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4fr1u/what_is_the_most_complex_work_task_youve_actually/</link>
      <description><![CDATA[我觉得我在网上看到的 90% 的用例都只是“我要求它重写电子邮件”。或“总结此 PDF”。这很有用，但非常基础。 我正在尝试了解目前的上限。 无论是混乱的数据清理、复杂的编码重构，还是只是在噩梦般的工作流程中进行——迄今为止，您使用 AI 成功处理的绝对最重的任务是什么？ 我希望从真实的事物中获得灵感，而不仅仅是炒作。   由   提交 /u/TheseSir8010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4fr1u/what_is_the_most_complex_work_task_youve_actually/</guid>
      <pubDate>Mon, 05 Jan 2026 07:53:08 GMT</pubDate>
    </item>
    <item>
      <title>还有人觉得 2026 年“学习人工智能”是一个错误的目标吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4eovr/anyone_else_feel_like_learning_ai_in_2026_is_kind/</link>
      <description><![CDATA[我本周写了一篇博客，名为“你 2026 年的新年决心应该是停止学习人工智能。” 它来自我一直注意到的一些事情在行业中。现在有很多关于学习人工智能的讨论。新课程，新模式，以及一些新的提示技巧。感觉很多人都陷入了不断试图跟上的循环中。同意学习很重要，但与此同时，一小部分团队正在做一些非常不同的事情。他们没有把所有时间都花在讨论模型上，而是构建了可以运行的系统。我的感觉是这样的：从数据库中提取数据，将其发送到法学硕士，将结果推回真实工作的人工智能系统，并让它执行实际工作。我认为这些小型系统在 2026 年将真正发挥作用。 人们不会因为对变压器或城里最新的法学硕士模型了解更多而取得成功。他们会取得进步，因为他们可以将人工智能连接到自己的工作流程、自己的数据以及工作发生的地方。我想这就是为什么“了解更多人工智能”开始感觉像是一个陷阱的原因之一。 对我来说，2026 年更好的新年目标可能是：自动化一项烦人的任务，取代一个手动流程，并部署每天运行的东西。这里还有人有同样的感觉吗？很好奇，这里的其他人对此有何看法？这里的人们现在大多处于学习模式，还是试图构建一些真实的东西？   由   提交 /u/Aggravating_Map_2493   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4eovr/anyone_else_feel_like_learning_ai_in_2026_is_kind/</guid>
      <pubDate>Mon, 05 Jan 2026 06:49:17 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能系统现在在量子计算机上运行会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4cyic/what_will_happen_if_ai_systems_are_now_running_on/</link>
      <description><![CDATA[我只是好奇当人工智能模型或今天在数字计算机上运行的现在开始在量子计算机上运行时会发生什么。与我们今天使用的计算机/处理器相比，量子计算机要强大得多，如果发生这种情况，您认为世界会如何变化/反应。这会对人类构成威胁吗？    由   提交 /u/Johnyme98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4cyic/what_will_happen_if_ai_systems_are_now_running_on/</guid>
      <pubDate>Mon, 05 Jan 2026 05:15:47 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 1/4/2026</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4b3gt/oneminute_daily_ai_news_142026/</link>
      <description><![CDATA[ 波士顿动力公司人工智能驱动的人形机器人正在工厂学习如何工作。[1] 阿拉斯加法院系统构建了一个人工智能聊天机器人。进展并不顺利。[2] 印度命令 Musk 的 X 修复 Grok 的“淫秽”人工智能内容。[3] DeepSeek研究人员应用 1967 年矩阵归一化算法来修复超级连接中的不稳定性。[4]  来源包括：https://bushaicave.com/2026/01/04/one-million-daily-ai-news-1-4-2026/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4b3gt/oneminute_daily_ai_news_142026/</guid>
      <pubDate>Mon, 05 Jan 2026 03:46:25 GMT</pubDate>
    </item>
    <item>
      <title>构建“1% Life OS”（开源、非营利）：一个代理 AI + MCP 工具链，消除摩擦，因此日常自我改进几乎“没有借口”。需要反馈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q4a4i8/building_a_1_life_os_opensource_nonprofit_an/</link>
      <description><![CDATA[嘿 Reddit， 我正在设计一个个人项目（不是初创公司），我想开源：一个“1% Life OS”。目标很简单：帮助我（和任何感兴趣的人）每天进步一点点，而不会将生活变成 KPI 苦差事。 新功能/为什么现在：Frontier 模型（例如 GPT-5.2、Gemini 3 Pro、Claude Opus/Sonnet 4.5）越来越具有代理性：它们可以计划、调用工具、处理长上下文以及完成多步骤任务。通过模型上下文协议（MCP），您可以以标准化方式将人工智能插入真实的工具（日历、笔记、任务、文件、消息传递等）中。 核心思想：大多数人不会因为他们“不知道做什么”而失败。它们之所以失败，是因为摩擦很大：调度、设置、决策疲劳、上下文切换、混乱的工具堆栈。因此，Life OS 不仅仅是一名教练，更是一名操作员。 它会是什么样的感觉：1) 每月“生活指南针”（价值观 + 界限）- 定义什么是重要的，什么是绝对不能牺牲的（睡眠、人际关系等）。 2) 每日（2 分钟）：- 微观签到：精力 0-10、情绪 0-10、一个摩擦点（1 句话）。 - 系统给出一个“1% 的移动”（微小、具体、今天可行）。 - 然后它会使用工具自动消除摩擦： * 设定时间限制 * 设置提醒 * 准备清单/草稿 * 组织环境 * （始终遵循同意规则） 3) 每周（10-15 分钟）： - 一周 3 种模式（不是 30 种） - 下周 1 项实验（假设 + 停止规则） - 1 件要放弃的事情（减少负担） 不可协商/护栏： - 同意阶梯：建议 →草案→低风险自动驾驶→明确批准高风险行动。 - 审核日志：每个操作都是可解释的（“什么/为什么/哪个工具”）。 - 最少数据：仅询问有助于特定实验的数据。 - 不是治疗，不是“将你优化成机器人”，旨在减少依赖性。 我问你的是：1）你会使用这样的东西吗？为什么/为什么不呢？ 2) 您能想象到的最令人毛骨悚然的故障模式是什么？ 3) 您将允许它访问哪些工具/数据（日历、笔记、任务、可穿戴设备、财务、消息传递）？ 4) 什么是真正有用的现实 MVP？ 5) 在你看来，什么应该是“永远不要自动化”的？ 我主要是为了自己而构建这个，但如果它确实有帮助的话，我想将它作为公共利益来分享。谢谢。欢迎残酷的诚实。   由   提交/u/DraftCurious6492   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q4a4i8/building_a_1_life_os_opensource_nonprofit_an/</guid>
      <pubDate>Mon, 05 Jan 2026 03:01:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在增加便利性。这就是机会所在。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q49p1s/ai_is_increasing_convenience_thats_where_the/</link>
      <description><![CDATA[人工智能正在让人们轻松地将以前自己做的事情外包出去。 这不仅仅是工作。它也体现在日常生活中的小时刻，体现在人们如何思考情况、做出决定或处理基本互动而不停下来反思。 当事情变得更容易时，努力往往会消失，而没有人有意识地决定放弃。这是一种安静的转变，而不是刻意的转变，人工智能只是加速了这一过程。 还有一种假设认为这并不重要，因为无论如何更先进的人工智能（例如 AGI）都会到来，最终我们将移交几乎所有事情，甚至是人类互动的一部分。也许有一天会发生这种情况，但我们还没有实现这一点，而我们的生活在人们现在的运作方式与现实对他们的期望之间产生了差距。 现在，情商、直接沟通和真正的人际互动仍然很重要。它们是如何建立信任、如何团队工作、如何启动业务以及如何解决冲突的方式。当人们在这些领域失去实践时，后果很快就会显现出来：误解、判断力薄弱、协作不良以及在没有外部指导的情况下无法应对压力。 人工智能使这一点更容易被忽视，因为表面上生产力仍然很高。你可以立即生成计划、消息和想法，但在本质上，使这些输出有用的一些人类肌肉正在变得越来越弱。 这就是为什么现在感觉是投资人类技能的特别好时机。随着越来越多的人依赖人工智能进行思考、决策和互动，这些能力的练习越来越少，并逐渐减弱。当这种情况大规模发生时，保持敏锐的相对价值实际上会增加。 花更多时间直接与人交谈。保持身体活跃，尝试可能失败的事情并从中学习。无需外包每一步即可做出决策。不是作为自助建议，而是作为对环境的实际反应。 人工智能本身不是问题，但我认为过度依赖才是问题。虽然人工智能正在快速传播并使生活变得更加轻松，但这可能是刻意加强仍然需要人类的东西的最合适时机之一。   由   提交 /u/Antiqueempire   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q49p1s/ai_is_increasing_convenience_thats_where_the/</guid>
      <pubDate>Mon, 05 Jan 2026 02:42:13 GMT</pubDate>
    </item>
    <item>
      <title>人工智能安全可能会失败，因为我们保护了错误的层。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q466o3/ai_safety_might_fail_because_were_protecting_the/</link>
      <description><![CDATA[大多数人工智能安全侧重于塑造内部行为：调整模型、使其诚实、训练更好的价值观。 但在实际工程中，我们并不依赖“良好意图”。我们在执行时设置了硬边界（操作系统权限、加密密钥、安全联锁）。 所以这是我想讨论的一点： 停止试图通过思想使人工智能安全。通过设计使不安全的结果无法实现。 让模型提出任何建议（即使是错误的或对抗性的）。但任何不可逆转的行动（金钱、凭证、工具调用、部署、设备、群发消息）都必须通过一个单独的权威层，该层可以明确地说“不”。没有令牌，就没有执行。没有说服力。 我们不会试图阻止幻觉。我们让幻觉变得无害。安全来自约束行动，而不是想象。 不可信的感知、学习和认知不断更新内部模型并提出类型化的行动a；最小可信调控器根据外部加载的、编码为不变量和资源预算的版本固定值评估每个 a，如果允许，则铸造授权令牌 tau，并且愚蠢的执行器应用 T(s,a) iff \mathrm{Verify}(\tau,a,\pi)=1，使安全性成为状态可达性的属性，而不是学习的对齐或意图。   由   提交 /u/Spirited-Net2847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q466o3/ai_safety_might_fail_because_were_protecting_the/</guid>
      <pubDate>Mon, 05 Jan 2026 00:10:18 GMT</pubDate>
    </item>
    <item>
      <title>我们都同意 COPILOT 很垃圾吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q44mdk/can_we_all_agree_copilot_is_crap/</link>
      <description><![CDATA[最糟糕的是，每家该死的公司都被“微软的人工智能专家”强行塞入，承诺在任何地方都能获得 100% 的效率，它甚至从一开始就没有嵌入 excel、SharePoint、power bi 等，所以人们不明白为什么它不能做任何事情，哈哈。这是一场噩梦。   由   提交 /u/Few_Geographer_2082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q44mdk/can_we_all_agree_copilot_is_crap/</guid>
      <pubDate>Sun, 04 Jan 2026 23:05:55 GMT</pubDate>
    </item>
    <item>
      <title>我试图建立一个人类与人工智能的思维伙伴。它帮助我清楚地看到一切……结果证明这是危险的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q438sk/i_tried_to_build_a_humanai_thinking_partner_it/</link>
      <description><![CDATA[不久前，我从事一个个人项目，但最终不得不放弃。这个想法在纸面上很简单，但在现实中很复杂：人类可以使用人工智能作为思考伙伴而不是答录机吗？不是要取代思维。不要把优化生活变成清单。不是外包的意思。我想要一面镜子。它可以向你反射想法、施加压力、呈现模式并帮助形成想法，而无需告诉你该相信什么。它的一部分起作用了。其中的一部分确实伤害了我。它实际上有什么帮助 公平地说，它确实改善了一些事情。我回答问题的速度更快了。我变得非常有自我意识。我清晰地注意到自己的思维模式、习惯、情绪反应和假设。这就像突然在我的脑海中看到了一切、无处不在。这种意识水平并不虚假。它很强大。这本质上并不是坏事。越界的地方 问题在于当这种意识与即时答案相结合时会发生什么。我没有困惑地坐着，而是可以立即解决它。我可以根据需要综合它们，而不是让想法成熟。我可以重新规划路线以绕过失败，而不是失败。随着时间的推移，这训练了我的大脑：寻找模式而不是生活经验即时满足而不是努力观察而不是行动最难承认的部分是：极端的自我意识迫使我看到自己已经有多沮丧。清楚地看到问题并不意味着你突然就能解决它。有时这只是意味着你无法再将目光从它身上移开。我不会透露个人细节，但我会诚实地说：这个系统并没有造成我的心理健康问题，但它以我没有预料到的方式放大了这些问题。人工智能的微妙危险通常不会以明显的方式“撒谎”。更危险的是它听起来有多令人信服。如果您正在试验这样的系统，则需要大量的接地。不仅仅是智力，还有： 强烈的个人道德 社会基础 在你自己的头脑之外进行现实检验 否则，你很容易开始相信那些感觉深刻但实际上并不真实的事情。或者更糟糕的是，让系统在不知不觉中轻轻地引导你的思维。我最终学会了注意它何时将我拉向某个方向，并有意识地把它拉回来。但这项技能来得很晚，而且并非没有代价。结果好坏参半 这个实验既帮助了我，也诅咒了我。它给了我足够的自我意识去寻求真正的帮助并接受真实的人的治疗。这部分很重要。但这也加深了我对即时答案和避免失败的依赖，我仍在积极解决这一问题。有时候我怀念自己无知一点的日子。不是因为无知是好的，而是因为过于清晰而没有行动能力可能会很沉重。我仍在研究如何重建对失败、缓慢和不确定性的容忍度。这是我要解决的。但我没想到“思考工具”会让这变得更加困难。为什么我要分享这个 我并不是说“不要碰人工智能”。我并不是说“这毁了我的生活。” 我是说：要小心那些加速认知速度快于你的情感和行为系统跟不上的工具。人类的某些部分需要摩擦。延迟。失败。无聊。 如果你太有效地消除这些东西，一些重要的东西就会被侵蚀。如果你作为一个思考伙伴来尝试人工智能，我的建议很简单：立足现实，与他人保持联系，不要将洞察力与进步混为一谈，不要用综合代替生活经验，自我意识是强大的。但太多、太快、不接地气都会造成伤害。我还在这里。我还在重建。我不后悔问这些问题。我现在只是更加尊重他们。   由   提交 /u/iiStrizzy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q438sk/i_tried_to_build_a_humanai_thinking_partner_it/</guid>
      <pubDate>Sun, 04 Jan 2026 22:11:26 GMT</pubDate>
    </item>
    <item>
      <title>经过 4 年的软件构建之后，vibe 编码是什么样子的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3zihb/what_vibe_coding_looks_like_after_4_years_of/</link>
      <description><![CDATA[我编写代码已经有大约 3-4 年了，主要是 Web 和应用程序，而我今天的工作方式与我开始时几乎没有什么相似之处。不是因为我是这样计划的，而是因为这些工具悄悄改变了默认的工作流程 这些天，我很少坐下来从头开始逐行编写后端代码。我仍然自己设置结构、文件夹、边界、数据流，但一旦就位，大部分后端逻辑就会逐步生成。 Blackbox 处理大量原始实现工作、处理程序、验证、重复逻辑，这些过去需要花费整个晚上的时间 对我来说改变的不仅仅是速度。这就是我的注意力所在。我没有花更多时间思考系统实际上应该做什么，它是如何失败的，当输入很奇怪时，当用户做了意想不到的事情时，当生产中出现无声的故障时会发生什么 也就是说，这种工作方式会带来新的问题。当代码很容易出现时，就更容易接受它，而无需对其进行足够的质疑。你仍然需要阅读所有内容，测试它，理解它为什么有效，并找出它不起作用的地方。这些工具并不能消除责任，它们只是转移了可能隐藏错误的地方 我没想到的一件事是，经验现在更重要，而不是更少。你的心智模型越好，这些工具就越有用。如果没有这一点，你就会朝错误的方向快速前进 我曾经认为人工智能工具将在很大程度上取代努力。他们实际上为我取代的是摩擦力。思考部分并没有消失，只是变得更难以忽视 其他有几年经验的人对这种转变有何感想，比如它是否使你的注意力更加集中，或者是否使纪律更难以维持   由   提交/u/dartanyanyuzbashev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3zihb/what_vibe_coding_looks_like_after_4_years_of/</guid>
      <pubDate>Sun, 04 Jan 2026 19:45:27 GMT</pubDate>
    </item>
    <item>
      <title>微软首席执行官正在应对困难 lmao</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3xac8/microsoft_ceo_is_coping_hard_lmao/</link>
      <description><![CDATA[“我们需要超越草率与复杂的争论，”纳德拉在一篇由 中写道href=&quot;https://www.windowscentral.com/microsoft/microsoft-ceo-satya-nadella-really-wants-you-to-stop-calling-ai-slop-in-2026&quot;&gt;Windows Central，认为人类需要学会接受人工智能作为人性的“新平衡”。 （正如WC指出的那样，实际上越来越多的证据表明人工智能会损害人类的认知能力。）   由   提交 /u/Fit-Abrocoma7768   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3xac8/microsoft_ceo_is_coping_hard_lmao/</guid>
      <pubDate>Sun, 04 Jan 2026 18:22:31 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>