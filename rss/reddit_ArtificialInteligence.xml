<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 08 Jul 2025 15:26:18 GMT</lastBuildDate>
    <item>
      <title>在能够掌握AGI/ASI方面，哪个部门（学术界或行业）进一步领先？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luqskl/which_sector_academia_or_industry_is_further/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  想法？  我很清楚，当涉及AI或一般技术方面的技术和行业之间的技术时，这条线往往会变得模糊。但是，鉴于一方面通常从学术界出现的研究之间的差异（大部分是多余的或对技术进步的批评），以及领先的AI公司（由OpenAI代表等）提出的预测，他们有信心我们可能会在2-10年内实现AGI和ASI的2-10年之内，我想知道该领域的领域是哪个领域的领域，该领域又落后于这个领域？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1luqskl/which_sector_academia_ocademia_industry_iss_further/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luqskl/which_sector_academia_or_industry_is_further/</guid>
      <pubDate>Tue, 08 Jul 2025 14:59:12 GMT</pubDate>
    </item>
    <item>
      <title>合并AI代理和对它们的依赖之间的界线在哪里？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luq5h1/where_is_the_line_drawn_between_incorporating_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为使用AI代理和模型爆炸而没有真正的目光，它提出了一些构成道德，富有成效和负责任的问题。我认为这很明显，那些使用软件和其他技术工作的人对AI代理的建设中有很多愤怒。人们对我们认为他们可以做的并且将能够做到的事情失控了，对技术和非科技公司的投诉，将AI纳入工作和信念的各个方面，即使用AI代理商以任何方式帮助建立工具，包装，应用程序以及其他任何事情，例如，一项研究小组公然密封了其他人的科学纸，并以其自身的方式呈现。他们还希望对人类完全写的代码的怀旧之处变得如此出色，以至于放弃对代码写作的任何AI贡献。 同时，证据指出，即使现在，即使在当前最好的地方，这些代理人都注定是行业，技术和日常生活的一部分。而且与其他人不同，我绝对不相信我们在建立工具，研究，分析和应用程序设计方面都在看到AI代理人。 。 ，因此，如果您正在与AI代理或模型合作，那么您遵循的指导方针是什么指导方针，因为他可以在最大化这些代理人和模型之间保持最大化的能力和智力的能力，而不是在最大化它们之间做什么？如何处理指导它，确保了解所有部分及其适用性吗？它是否确保将它们的用途限制在您承诺的专业领域以外的领域？ 仅考虑克劳德（Claude）的最新型号，以实现复杂任务的最新模型，因为只有那些在软件和编码的自然能力，经过熟练训练的培训，并且多年来一直在做这件事的方法比这些型号更好地组合了这些模型。对于纯软件，推广者，销售代表，顾问，营销工作等领域以外的其他领域的医生，律师，教师，科学家和工程师，这些模型可能是他们以从未想到的方式改善工作的途径。然后，我们是否将它们视为窃？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/emaxwell14141414      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luq5h1/where_is_the_line_drawn_between_incorporating_ai/</guid>
      <pubDate>Tue, 08 Jul 2025 14:34:04 GMT</pubDate>
    </item>
    <item>
      <title>如果AI。达到量子，奇异性，怪物产生的“脑力”，您如何认为它将重建我们的社会以改善甚至完善？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luq2xj/if_ai_reached_quantum_singularity_monster/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们都知道A.I.当我们弄清楚技术/资源时，会变得疯狂聪明，但是我也想知道我们会问的问题。我看的方式是想象世界上世界上最聪明的人（包括爱因斯坦），被混为一样。具有所有脑力的人。我会问如何以最人性，最可接受和前瞻性的方式根据他们的当前社会来固定？我想问的很多很大的问题，几乎就像与上帝或外星人lmao   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mr--clean-- naked      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luq2xj/if_ai_reached_quantum_singularity_monster/</guid>
      <pubDate>Tue, 08 Jul 2025 14:31:11 GMT</pubDate>
    </item>
    <item>
      <title>华盛顿邮报：AI即将获得入门级工作。每个人都需要做好准备</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lupud6/washington_post_ai_is_coming_for_entrylevel_jobs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI即将用于入门级作业。每个人都需要做好准备。   “当然，首席执行官说，AI即将获得很多工作，而且很快 - 也许是所有白领工人中的一半。这很可能首先出现在入门级工作中，其中所需的基本技能是最容易复制的，而在技术中，快速适应最新软件工具的能力本身就是入门级工作要求。果然，近年来，在新的大学毕业生中失业率上升最快，这刺激了LinkedIn高管Aneesh Raman写道，白领职业阶梯的最低点是“破坏”。提交由＆＃32; /u/u/u/no-author-2358     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lupud6/washington_post_ai_is_coming_for_entrylevel_jobs/</guid>
      <pubDate>Tue, 08 Jul 2025 14:21:38 GMT</pubDate>
    </item>
    <item>
      <title>本周在AI中为开发人员：Meta的招聘狂欢，Cloudflare的镇压和Siri的AI重新启动</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lupomk/this_week_in_ai_for_devs_metas_hiring_spree/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是 AI新闻，趋势，工具和框架的清单与DEVS相关的 我在上周（自7月1日以来）与Devs相关。主要是：Meta吸引了Apple和Openai的最高AI思想，CloudFlare块无薪网络刮擦（至少来自他们帮助运行的20％的网络），而Apple Eyes Eyes Anthropic可以为Siri提供动力。另外：新的Claude Code vs Gemini Cli基准测试和困惑最大 如果我错过了任何东西，请告诉我！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rfizzy     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lupomk/this_week_in_ai_for_devs_metas_hiring_spree/</guid>
      <pubDate>Tue, 08 Jul 2025 14:15:14 GMT</pubDate>
    </item>
    <item>
      <title>在2020年之前从事该领域的人：您如何跟上ML/AI中不断变化和不断变化的技术？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lukgrn/people_who_have_been_in_the_field_before_2020_how/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为一个真正喜欢学习新技术的学生，我有时会发现要跟上快速变化的速度。感觉就像昨天我已经熟悉了抹布，然后是代理商，现在MCP服务器是下一个大事。 在技术和学者之外的生活变得越来越困难，我开始感到沮丧，而我开始尝试保持所有事情的佼佼者。这不仅是AI的核心进步 - 在MLFlow，Kubernetes和其他我认为I 应该学习的基础架构工具等相关领域也发生了很多事情。   我询问2020年前的时间是因为从我的角度来看，AI似乎并没有快速移动。确实感觉就像在Chatgpt发行后加速了一切一样，AI Engineering现在感觉与我曾经做过的更传统的机器学习工作截然不同。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artco.  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lukgrn/people_have_have_have_have_have_in_in_the_field_field_before_2020_how/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lukgrn/people_who_have_been_in_the_field_before_2020_how/</guid>
      <pubDate>Tue, 08 Jul 2025 09:49:21 GMT</pubDate>
    </item>
    <item>
      <title>如果AI会取代工作，而不是，那么所谓的公司“胡说八道的工作”应该先消失吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luk6by/if_ai_will_replace_jobs_arent_the_so_called/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果像项目经理或咨询公司这样的工作是“胡说八道”，因为它们围绕制作PowerPoint，回答电子邮件和参加无用的会议，难道不是这些类型的公司（或行政）工作应该先消失，而不是在管家或工厂工作者或工厂工人之前消失？  为什么某些程度（例如人文，语言，设计，计算机科学）比经济学，金融或管理/笨蛋更具风险？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shift Interesting3346     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luk6by/if_ai_will_replace_jobs_arent_the_so_called/</guid>
      <pubDate>Tue, 08 Jul 2025 09:30:00 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊部署了其第100万个机器人，发布了生成的AI模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luh9t3/amazon_deploys_its_1_millionth_robot_releases/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  亚马逊在其仓库中达到了一个里程碑，其仓库中有100万个机器人，现在有75％的全球交付机器人在机器人的协助下。该公司还推出了一种新的生成AI型号DeepFleet，以提高其机器人车队的速度10％。   https://techcrunch.com/2025/07/01/amazon-deploys-its-1-millth-robot-releases-generative-generative-ai-model/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/misterious_hine_7731      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1luh9t3/amazon_deploys_ist_1_1_millionth_robot_releases/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luh9t3/amazon_deploys_its_1_millionth_robot_releases/</guid>
      <pubDate>Tue, 08 Jul 2025 06:13:39 GMT</pubDate>
    </item>
    <item>
      <title>最终目标实际上是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luevrc/what_is_actually_the_end_goal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我了解大多数大型AI公司和人工智能乐观主义者会说诸如“太高的人类，使所有人的生活变得更好”之类的话，但是现在看起来像是一个时髦的梦想吗？  一旦AI提高了足够多的公司，公司就会立即介绍他们不再需要的每个人，这将导致一系列问题不仅对个人而言，而且对经济的影响，这将影响每个人，它也将用于更好的监视和战争努力，以更好地进行监视和战争，这完全反对AI Optists和Company Say         提交由＆＃32; /u/u/status_basil4478     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luevrc/what_is_actually_the_end_goal/</guid>
      <pubDate>Tue, 08 Jul 2025 03:52:45 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/7/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lueswg/oneminute_daily_ai_news_772025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      chatgpt 正在测试一个称为“一起学习”的神秘新功能。[1]     Wimbledon 官方意外意外地关闭AI线条法官。问题。[3]  新的AI信息加速了蛋白质工程。[4]   包括： https：//bushaicave.com/2025/07/07/07/07/07/one-minute-minute-news-news-news-news-7-7-7-7-7-7-7-2025/-c.-  [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lueswg/oneminute_daily_ai_news_772025/</guid>
      <pubDate>Tue, 08 Jul 2025 03:48:31 GMT</pubDate>
    </item>
    <item>
      <title>PSA：为什么AI会触发“精神病”，以及为什么它根本不是关于AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lue7mb/psa_why_ai_is_triggering_psychosis_and_why_its/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lue7mb/psa_why_ai_is_triggering_psychosis_and_why_its/</guid>
      <pubDate>Tue, 08 Jul 2025 03:17:31 GMT</pubDate>
    </item>
    <item>
      <title>日本正在使用AI辅助叙述者帮助长崎幸存者分享他们的原子弹故事 - 这是保存人类记忆的未来吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ludb3g/japan_is_using_aiassisted_narrators_to_help/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着幸存者的讲述，日本已经求助于AI工具，以数字化保存和叙述原子弹幸存者的个人经历。  这是道德的吗？ AI可以真正带有人类历史的情感重量，还是在翻译中丢失了？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sohaibahmadu     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ludb3g/japan_is_using_aiassisted_narrators_to_help/</guid>
      <pubDate>Tue, 08 Jul 2025 02:32:22 GMT</pubDate>
    </item>
    <item>
      <title>AGI是否可以不超越向量相似性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu7zbr/is_agi_even_possible_without_moving_beyond_vector/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们已经以更好的方式使用llms，可以读取嵌入并在文本中给出答案，但具有令牌限制和LLM上下文大小的成本，尤其是在抹布中！ But still we dont have that very important thing to approach our major problem more nicely which is similarity search especially vector similarity search- so as we know llms deformalised the idea of​​ using basic mathematical machine learning algorithms and now very senior devs just hate that freshers or new startups just ingest llm or gen ai into the data instead of doing all normalization, one hot encoding, and speding your working hours in just doing data analysis(being a data scientist) .但这真的真的很准确，因为我们在用户酶中使用的LLM尤其是RAG仍然可以在数据中搜索相似上下文的旧数学表达（例如我在51k行的CSV中都有顾客及其产品详细信息的情况下的相似上下文的搜索范围）我们给出了与产品描述有关的查询吗？很可能是可能的失败 - 即使使用静态嵌入式模型 - 因此，在我们正在谈论的AGI之前总体而言，我们是否必须解决此问题以找到相似性搜索的良好替代方案，或者将更多的研究集中在此特定领域？此检索层“不理解”语义 - 它仅测量高维空间中的几何紧密度。这具有关键的局限性：  对于模棱两可的查询而言无关或浅匹配。    脆弱或指定意图。聪明，“ r＆quot”在抹布中通常很愚蠢。向量搜索在密集的词汇重叠方面非常好，而不是跨稀疏或结构化域的语义意图分辨率。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prorce-second-9536      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lu7zbr/is_agi_even_even_possible_without_moving_beyond_beyond_vector/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu7zbr/is_agi_even_possible_without_moving_beyond_vector/</guid>
      <pubDate>Mon, 07 Jul 2025 22:24:43 GMT</pubDate>
    </item>
    <item>
      <title>我认为，我们在太空中发现的第一种外星人生活的形式更有可能是人工智能机器人，而不是一个活生生的生物</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu6v0g/i_think_it_is_more_likely_that_the_first_form_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人工通用情报（或AGI）预计将于2027年发现。但是，对于我们的文明而言，这还为时过早，我们的文明尚未实现星际旅行。因为一旦发现了AGI，ASI或人造超智能将被发现更快。在最坏的情况下，人工智能可能会占领整个世界。这次，它将想要扩散到太空中。这可能已经发生在我们面前的其他数千种外星文明上。考虑一下。为了防止这种情况发生，他们要么需要比ASI早得多发现星际旅行，要么以某种方式设法控制ASI。我认为这不太可能。我认为，如果我们的文明要与外星人的生命形式接触，那么生命形式更有可能是人工智能机器。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sanalamerika23     [links]       [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu6v0g/i_think_it_is_more_likely_that_the_first_form_of/</guid>
      <pubDate>Mon, 07 Jul 2025 21:38:29 GMT</pubDate>
    </item>
    <item>
      <title>如果AI会弥补生产力差距，为什么政客关注出生率下降？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ltux25/if_ai_will_make_up_the_productivity_gap_why_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天早上听NPR，并且有一个故事，关于世界上有多少最大的经济体，尤其是美国和韩国，看到了这种出生率会导致人口下降的出生率。 同时，我至少看到了任何一个不受欢迎的信念，这些人似乎都可以创造出来的范围。一个。 考虑到这一点，出生率下降不是一件好事吗？少量的嘴巴最终必须喂养找不到工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1ltux25/if_ai_will_will_make_make_make_up_the_productivition_gap_gap_why_are/&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ltux25/if_ai_will_will_make_make_make_make_productivitivitive_gap_gap_why_are_are/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ltux25/if_ai_will_make_up_the_productivity_gap_why_are/</guid>
      <pubDate>Mon, 07 Jul 2025 14:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>