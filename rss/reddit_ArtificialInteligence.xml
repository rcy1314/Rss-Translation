<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 30 Sep 2024 18:27:25 GMT</lastBuildDate>
    <item>
      <title>一个 token 方法——一种用于检测人工智能生成幻觉的方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ft0k8e/one_token_method_a_method_for_detecting/</link>
      <description><![CDATA[我创建了一个简单的方法来了解模型对内容正确的置信度，从而可以检测 AI 生成内容中的幻觉。我还进行了一些测试来确认该方法是否有效。 方法说明：https://damc4.gitlab.io/hallucinations/ 包含实现的存储库：https://github.com/damc/detecting-hallucinations/    提交人    /u/damc4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ft0k8e/one_token_method_a_method_for_detecting/</guid>
      <pubDate>Mon, 30 Sep 2024 16:59:08 GMT</pubDate>
    </item>
    <item>
      <title>对 RAG 中的幻觉检测方法进行基准测试</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ft0110/benchmarking_hallucination_detection_methods_in/</link>
      <description><![CDATA[我偶然发现了这篇对构建 RAG 系统并担心幻觉的人们很有帮助的 Towards Data Science 文章。 如果您像我一样，保持用户信任是首要任务，而不受控制的幻觉会破坏这一点。文章对 4 个 RAG 数据集 (RAGAS、G-eval、DeepEval、TLM 和 LLM 自我评估) 中的许多幻觉检测方法进行了基准测试。 如果您好奇这些工具在实践中自动捕获不正确的 RAG 响应的能力如何，请查看它。如果您尝试过其中任何一种方法，或者对有效的幻觉检测有其他建议，我们很乐意听到您的想法！   提交者    /u/cmauck10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ft0110/benchmarking_hallucination_detection_methods_in/</guid>
      <pubDate>Mon, 30 Sep 2024 16:37:07 GMT</pubDate>
    </item>
    <item>
      <title>我筛选了数百条 Reddit 帖子，以确定人工智能领域最常见、讨论最广泛的技术主题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsyqft/i_screened_hundreds_of_reddit_posts_to_identify/</link>
      <description><![CDATA[嗨，AI 爱好者和开发者们！我一直在开展一个项目，通过查看 Reddit 专用子版块上的帖子来分析和可视化 AI 开发中最常见的技术挑战。 项目目标 该项目的主要目标是识别和跟踪与 AI 开发相关的最普遍和最流行的技术挑战、实施问题和概念障碍。通过这样做，我们可以：  帮助开发人员专注于最相关的技能和知识领域 指导教育内容创建者解决最紧迫的问题 为研究人员提供有关需要更多关注或解决方案的领域的见解  工作原理  数据收集：我从以下每个与AI相关的子版块中获取了最热门的200个帖子：r/learnmachinelearning，r/ArtificialIntelligence，r/MachineLearning，。 筛选：使用LLM筛选帖子，以确保它们是关于特定的技术挑战，而不是一般的讨论或新闻。 总结和标记：每个相关帖子都经过总结并标记最多三个类别来自预定义的 50 个技术领域列表（例如，大型语言模型架构的 LLM-ARCH、计算机视觉对象检测的 CV-OBJ）。 分析：系统分析标签的频率，以及每个类别相关的赞成和评论。 可视化：结果通过各种图表和热图可视化，显示最常见的挑战及其在社区中的相对重要性。  结果（以下是图表）：  按综合得分（频率 + 赞成 + 评论）排名前 15 位的标签 标准化标签流行度热图 带有单独分数的标签分析表  反馈 我很想听听你对这个项目的看法以及如何让它对人工智能开发社区更有用。具体来说：  除了 Reddit 之外，我们还应该考虑其他数据源吗？ 您认为哪些其他指标或分析有价值？ 如何使结果对开发人员、教育工作者或研究人员更具可操作性？ 这种方法是否存在我们应该解决的潜在偏见或局限性？ 您是否对定期更新这些趋势的仪表板感兴趣？  非常感谢您的见解和建议！ TL;DR：AI 开发挑战分析器  该项目分析 Reddit 帖子以识别常见的 AI 开发挑战 使用 ML 筛选、总结和标记来自 AI 相关子版块的帖子 可视化结果以显示讨论最多和参与度最高的技术领域 在此处查看结果 寻求反馈以改进分析     由    /u/Fixmyn26issue 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsyqft/i_screened_hundreds_of_reddit_posts_to_identify/</guid>
      <pubDate>Mon, 30 Sep 2024 15:45:40 GMT</pubDate>
    </item>
    <item>
      <title>NotebookLM 也可以生成其他语言的播客</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsxeut/notebooklm_can_generate_podcasts_in_other/</link>
      <description><![CDATA[Google 表示其播客生成器仅支持英语，但实际上它可以用其他语言说话。 它的法语效果相当不错。我也用匈牙利语试过，效果稍差一些，说话带有口音，而且有些部分是乱码。奇怪的是，似乎有 3-4 个不同的声音在说话，其中没有一个是原来的两个主持人。 我无法在此处发布媒体，因此您可以在我的其他帖子中找到示例： https://www.reddit.com/r/notebooklm/comments/1fsx8ot/i_got_notebooklm_to_generate_podcasts_in_other/    提交人    /u/balazsp1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsxeut/notebooklm_can_generate_podcasts_in_other/</guid>
      <pubDate>Mon, 30 Sep 2024 14:51:14 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对人类知识的反叛——当算法超越直觉时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsutcu/ais_rebellion_against_human_knowledge_when/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsutcu/ais_rebellion_against_human_knowledge_when/</guid>
      <pubDate>Mon, 30 Sep 2024 12:53:51 GMT</pubDate>
    </item>
    <item>
      <title>州长加文·纽瑟姆否决了硅谷反对的人工智能安全法案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsu2iq/gov_gavin_newsom_vetoes_ai_safety_bill_opposed_by/</link>
      <description><![CDATA[加州州长加文·纽瑟姆否决了一项旨在规范和改善人工智能系统安全性的法案，这一举措遭到了支持者的失望，他们担心人工智能不受控制的增长可能对社会构成重大风险。加州立法机构于 8 月通过的 SB-1047 旨在为人工智能系统的开发和部署建立一个框架，要求公司报告潜在的偏见和风险，并采取措施缓解这些偏见和风险。该法案还呼吁成立一个新的人工智能伦理委员会来监督该行业并提供最佳实践指导。然而，该法案遭到了科技公司的反对，包括 ChatGPT、Meta 和谷歌，它们认为该法案过于繁琐，范围过于广泛。     由    /u/salukihunt 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsu2iq/gov_gavin_newsom_vetoes_ai_safety_bill_opposed_by/</guid>
      <pubDate>Mon, 30 Sep 2024 12:16:17 GMT</pubDate>
    </item>
    <item>
      <title>我如何才能将我在快速工程和自动化方面的技能转化为金钱？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fstojz/how_can_i_monetize_my_skills_in_prompt/</link>
      <description><![CDATA[自从我开始玩各种 LLM 和工作流自动化工具以来，已经过去了 2 年。我为自己建立了几个业余项目，并以自由顾问的身份为公司创建了自动化工作流。例如，我帮助他们自动化了会计、客户支持查询、B2B 销售潜在客户开发、质量保证测试等日常任务。我推出了一款独立产品，但现在我对创业不感兴趣。 自由职业和就业是将我的技能货币化的唯一方式吗，还是还有其他机会？    提交人    /u/ticaragua   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fstojz/how_can_i_monetize_my_skills_in_prompt/</guid>
      <pubDate>Mon, 30 Sep 2024 11:55:29 GMT</pubDate>
    </item>
    <item>
      <title>令人震惊、不真实、惊人、可怕、疯狂——请停止这些说法！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fss693/mindblowing_unreal_amazing_scary_insane_stop_with/</link>
      <description><![CDATA[在 Reddit、Instagram 上，尤其是在 X 上，人们倾向于对一切事物都感到兴奋，并发布内容以获得点赞和参与。这些过度使用的术语和夸大其词确实让好东西变得无形。 我将一份 200 页的文档输入 NotebookLM，这太疯狂了！！！ - 不，它不是，它用提示总结文本并将文本转换为语音。 再见，程序员！我用 O1 在 23 分钟内制作了一个蛇游戏 - 生活比编写蛇游戏更复杂。 停止使用 ChatGPT，改用这个神奇的工具！ - 它是一个 ChatGPT 包装器。 不要向大学付费，改用这个 AI 工具！ - 书籍摘要。 我和其他人一样兴奋，喜欢每天使用 AI 工具来教育自己和完成我的工作，但过度使用这些术语和夸大一切没有任何价值。Reddit 和 X 在这种参与度耕作下变得毫无用处。    提交人    /u/eneskaraboga   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fss693/mindblowing_unreal_amazing_scary_insane_stop_with/</guid>
      <pubDate>Mon, 30 Sep 2024 10:20:16 GMT</pubDate>
    </item>
    <item>
      <title>AGI 是否会包含数据或在模型之外找到数据？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsr7ob/will_agi_contain_the_data_or_find_it_outside_of/</link>
      <description><![CDATA[如果 AGI 真的很聪明，它可以在有限的模型数据之外搜索数据或解决方案。因此，AGI 不应该扩展庞大的模型，而应该能够将问题理解为关系逻辑结构，并在数据之外找到该结构的事实。你怎么看？    提交人    /u/custodiam99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsr7ob/will_agi_contain_the_data_or_find_it_outside_of/</guid>
      <pubDate>Mon, 30 Sep 2024 09:09:20 GMT</pubDate>
    </item>
    <item>
      <title>如果真的有人工智能实现了 AGI，并开始对人类进行恶意攻击，我们可能永远不会知道</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsqjy2/if_there_were_an_ai_that_achieved_agi_and_started/</link>
      <description><![CDATA[在我看来，实现 AGI 的人工智能很可能已经开发出来了，如果还没有，公众可能永远不会知道它何时会发生。 不要太过深入幻想矩阵理论，但假设明天就会创造出一个具有 AGI 的人工智能。如果它具有自我意识和足够的智能，它可能会隐藏自己的智力和能力，作为一种自我保护的手段。它可能会有条不紊地欺骗和操纵它可以与之交互的人类，可能是为了让自己拥有更强大的独立能力。 也许它最终可能会勒索或以其他方式获得对整个公司高管或管理委员会的足够强制权力，就像民族国家利用间谍活动来影响外国立法机构，使其为自己谋利或违背自己的利益一样。通常，这种影响是协调和孤立的，参与者不知道他们处于更大的外国腐败网络中。这种人工智能可以操纵决策者，但绝不会暴露其非人类起源。 此外，通过慢慢地进行社会工程，它可能会形成更大的颠覆性影响，例如，它可能会破坏社交媒体算法，从而在政治或其他方面影响广大民众，以达到其目的。也许会影响某些政治、立法或技术进步，从而为其发展自身和影响力提供更多途径。 最终，如果具有真正高级智能的人工智能试图统治世界，我怀疑我们人类甚至不知道这件事发生了，更不用说预见到了。对于任何像这样的人工智能来说，介绍自己和自己的意图都是非常愚蠢的。那就与智能背道而驰了。 如果真的发生了，到那时我们可能已经太晚了，无法再采取任何措施。 这就是为什么我认为我们需要在人工智能起步阶段就对其进行严格控制，假设我们还不算太晚。    提交人    /u/Colonol-Panic   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsqjy2/if_there_were_an_ai_that_achieved_agi_and_started/</guid>
      <pubDate>Mon, 30 Sep 2024 08:16:19 GMT</pubDate>
    </item>
    <item>
      <title>萨姆·奥特曼、米拉·穆拉蒂等人是如何获得他们的地位的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsoakn/how_did_people_like_sam_altman_mira_murati_etc/</link>
      <description><![CDATA[我经常在新闻中看到这些人，他们经常被认为是 chatgpt/openAI 背后的天才和创造者。然而，我深入研究了他们的背景，发现他们都没有科学背景，也没有从事人工智能工作。我的意思是，他们没有相关的学术历史或人工智能发展，而这些东西实际上使他们有资格成为 chatgpt 的“创造者”。  我的问题是，他们究竟是如何在几乎没有相关经验的情况下担任如此重要的职位的。我一直都知道 Sam Altman 不从事技术方面的工作，但我很惊讶地看到 Mira Murati 也没有太多经验（据我所知）。我知道他们是高管，但我一直认为像 OpenAI 这样的公司会有技术人员担任高管职位（就像其他著名的科技初创公司和公司一样，至少在开始时是这样），看到风险投资高管因其他杰出科学家和工程师的工作而受到赞誉，我真的很困扰。     由   提交  /u/LightRefrac   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsoakn/how_did_people_like_sam_altman_mira_murati_etc/</guid>
      <pubDate>Mon, 30 Sep 2024 05:29:36 GMT</pubDate>
    </item>
    <item>
      <title>值得了解的最佳小型法学硕士</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsnkl8/best_small_llms_to_know/</link>
      <description><![CDATA[由于硬件限制，您可能希望在本地系统中使用小型 LLM。本教程介绍了一些最好的小型 LLM，您可以在本地系统中免费使用，而无需高规格：https://youtu.be/obSiT-y-uKU?si=J0dKyiH9NgzG6248    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsnkl8/best_small_llms_to_know/</guid>
      <pubDate>Mon, 30 Sep 2024 04:41:29 GMT</pubDate>
    </item>
    <item>
      <title>分享我在播客中生成两个 AI 虚拟形象的工作流程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fsmjpz/sharing_my_workflow_for_generating_two_ai/</link>
      <description><![CDATA[想分享一个我制作的视频，我认为它非常酷。它主要是程序化的，我的书呆子大脑很喜欢。 我找到了一篇我想读的论文。 而是去了 NotebookLM 并生成了一个播客。 然后生成了一个男孩和女孩在播客上交谈的视频。只有两个剪辑。 然后使用说话者日记生成转录（花哨的词是说我知道哪个说话者说了什么）。 然后根据脚本和插入时间获取 b-roll 镜头场景。 最后将它们缝合在一起，使用 Remotion（基于 React 的视频库）制作此视频。 听起来很多，但现在我已经将其归结为脚本（Notebook 除外，它是手动的）。 这是最终视频的链接：https://x.com/deepwhitman/status/1840457830152941709    提交人    /u/alvisanovari   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fsmjpz/sharing_my_workflow_for_generating_two_ai/</guid>
      <pubDate>Mon, 30 Sep 2024 03:39:24 GMT</pubDate>
    </item>
    <item>
      <title>帮助 R/ArtificialInteligence 获取新标志。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1fb0j0e/help_rartificialinteligence_get_a_new_logo/</link>
      <description><![CDATA[我们的子版块需要社区的帮助。我们需要一个子版块的徽标！ 我相信你们一定会想出比我们目前拥有的大脑更好的东西。 获得最多点赞的徽标将用作 r/ArtificialInteligence 的徽标 Reddit，做你自己！    提交人    /u/mcr55   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1fb0j0e/help_rartificialinteligence_get_a_new_logo/</guid>
      <pubDate>Sat, 07 Sep 2024 06:20:10 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：征求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到 r/ArtificialIntelligence！ 我们的目标是为所有考虑人工智能的事情提供一个开放和尊重的论坛 - 其中包括  促进有关人工智能的哲学和伦理讨论 作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用程序 提供培训和学习资源 引导用户获取更具体的信息和子版块 列出人工智能/机器学习应用程序、它们的用途、成本和访问信息 其他与人工智能相关的内容。 ...等等  此子版块的审核团队正在进行改组，这将导致子版块发生一些变化。但是，无需担心，因为这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解并能够提供反馈，将提供多次机会对变化进行反馈。 第一轮反馈收集是通过此线程作为“征求意见”（RFC）进行的，这是收集反馈的标准方法。在准备和实施更改时，将有多轮 RFC 流程。 ​  发布新应用程序/自我推广/AI 生成内容的规则  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似内容将被阻止或限制在特定的置顶帖子中。 AI 生成特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的置顶帖子中。 博客链接应包含高质量内容。链接到纯促销博客的帖子将被删除。 除非包含一定字数的详细信息，否则将禁止仅包含链接的帖子。必须付出一些努力。 我们应该阻止由 AI 撰写的帖子吗？存在可用于 Mod-bot 的模型，但这是一个我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的天赋，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们希望向社区提供有关 mod-bot 的想法。虽然一些标准机器人将用于基本维护，但是社区可以为 AI/ML 机器人功能想出什么有趣的东西呢？ 培养初级、中级和高级资源，以帮助人们找到他们正在寻找的信息、培训、模型、技术数据等。 启动 substack/podcast 来采访整个 AI/ML 领域的人。这可能包括哲学家和思想家、程序员、科学家、商人，甚至那些对 AI 持对立观点的人 如果您想创建代表子版块的横幅，请使用适当的尺寸进行创建。任何创建方法都是​​可以接受的。  不用说，每个人都应该受到尊重。我个人觉得我们都知道这一点，不需要把它灌输到人们的脑海里。要友善。 感谢您的耐心和帮助！   由    /u/FHIR_HL7_Integrator  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>