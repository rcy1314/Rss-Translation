<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 19 Feb 2025 01:37:36 GMT</lastBuildDate>
    <item>
      <title>AIS代码能力是否会使视频游戏的无限扩展成为可能？就像不断的新功能/项目一样。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1istetz/will_ais_ability_to_code_make_infinite_expansion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai可以：编写代码，制作3D模型，制作艺术。从理论上讲，这应该允许它自己创建新的游戏元素。  几年前，当我观看了Ready Player One时，我认为VR宇宙的广阔是荒谬的，因为没有开发团队会有那么多时间。  如果有人使用Minecraft这样的更简单的游戏尝试了一下，那将很酷。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/firm-charge3233     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1istetz/will_ais_ability_to_code_make_infinite_expansion/</guid>
      <pubDate>Wed, 19 Feb 2025 01:32:49 GMT</pubDate>
    </item>
    <item>
      <title>帕尔默·卢基（Palmer Luckey）通过启动Anduril在战场上解释了他对AI的愿景</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isryns/palmer_luckey_explains_his_vision_of_ai_on_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  卢基（Luckey）于1992年出生于加利福尼亚州的长滩。 16岁那年，他开始尝试虚拟现实耳机，并在2012年发起了一项Kickstarter运动，以资助Oculus Rift的发展。该活动取得了巨大的成功，筹集了超过240万美元。  2014年，Facebook以20亿美元的价格收购了他的Oculus VR。卢基（Luckey）于2017年从Facebook开除，并创立了Anduril Industries，该行业开发了用于国防和国家安全应用的技术。   1士兵可以挥舞着“许多剑”。     2/14/25的访谈链接在下面。 | srs ＃171   Shawn Ryan Show &lt; /a&gt;从2:05提到的拾音器，他谈到了Anduril的起源。   &lt;！ - sc_on-&gt;＆＃32;提交由＆＃32; /u/spilltrend     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isryns/palmer_luckey_explains_his_vision_of_ai_on_the/</guid>
      <pubDate>Wed, 19 Feb 2025 00:27:02 GMT</pubDate>
    </item>
    <item>
      <title>哪个AI将主导消费市场？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isqi27/which_ai_will_dominate_the_consumer_market/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI竞赛正在加热，感觉就像我们正在接近胜利者。 Chatgpt具有早期的领先优势，但是诸如Google的双子座，Meta的Llama，Xai的Grok等竞争对手正在快速赶上。随着付费层的规范，消费者可能会选择一项主要的AI服务 - 就像我们对搜索引擎所做的一样。   查看poll     &lt;！ -  sc_on-&gt;＆&gt;＆&gt;＆&gt; ＃32;提交由＆＃32; /u/ml_guy1     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isqi27/which_ai_will_dominate_the_consumer_market/</guid>
      <pubDate>Tue, 18 Feb 2025 23:23:17 GMT</pubDate>
    </item>
    <item>
      <title>重复的比较AI测试是否会损失其含义并在一段时间后变得无用？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isobpj/does_repetitive_comparative_ai_testing_loss_its/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Blogger和社交媒体正在进行不科学的测试，导致手指指向此ai比那ai更好，因为响应更快，更完整或更完整或更完整或准确的 这些测试的有效程度如何？ 当您大量重复试图复制这些测试的人相同的测试问题时：   AI系统会因为它们不是静态系统而改进和修改答案吗？ 处理时间缩短了，因为在用于提出答案的元素之间建立了更强的链接？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1isobpj/does_repetistil_comparative_ai_ai_testing_loss_its/”&gt; [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isobpj/does_repetitive_comparative_ai_testing_loss_its/</guid>
      <pubDate>Tue, 18 Feb 2025 21:30:58 GMT</pubDate>
    </item>
    <item>
      <title>AI会替代呼叫中心工作还是只是增强人类代理商？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iso6pc/will_ai_replace_call_center_jobs_or_just_enhance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经看到了双方的争论。有些人似乎很确定AI将完全取代呼叫中心代理，而另一些人则似乎持怀疑态度，并且认为这将主要增强代理。我倾向于后者。 如果AI可以完全替换代理，那么为什么AI不只是与AI交谈？我认为这对人类生产力甚至金钱本身的作用提出了更大的疑问。 我们现在在这种过渡中在哪里？批量采用AI代理？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/3678poper href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iso6pc/will_ai_replace_call_call_center_jobs_jobs_or_just_enhance/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iso6pc/will_ai_replace_call_call_cell_center_jobs_jobs_oor_jost_enhance/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iso6pc/will_ai_replace_call_center_jobs_or_just_enhance/</guid>
      <pubDate>Tue, 18 Feb 2025 21:25:35 GMT</pubDate>
    </item>
    <item>
      <title>关于洛克希德·马丁与经文AI的奇怪合作的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isnb6u/question_about_a_curious_collaboration_between/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这两个非常不同的公司之间似乎有某种合作。洛克希德·马丁（Lockheed Martin），国防和航空航天承包商，以及经文AI，这是一家以自己的人工智能形式工作的软件公司AI，它使用了积极的整体。现在，我是AI的新秀，所以我在问您方面的帮助；猜测，有哪些类型的项目可以从事这样的工作？用例的例子是什么？我知道这是一个广泛的问题，我只是想了解AI的能力。这是一些指向“源”    https://www.reddit.com/r/vrssf/comments/1ik75xk/lockheed_martin_chief_chief_ai_officer_just_just_confirmed/?utm_sou rce = share＆amp; utm_medium = web3x＆amp; utm_name = web3xcss＆amp; utm_term = 1＆amp; utm_content = share_button     https://www.linkedin.com/posts/joseantoniozapatero_working-in-passive-ai-approach-you-are-ach-17265281075172573185-jg VP？utm_source = Social_share_send＆amp; utm_medium = Member_desktop_web＆amp＆amp; rcm = acoaaaadtewebty1M0EGZVATKQ6I745ZRBXGAKGAKGAKGY      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kooky_lime1793     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isnb6u/question_about_a_curious_collaboration_between/</guid>
      <pubDate>Tue, 18 Feb 2025 20:51:14 GMT</pubDate>
    </item>
    <item>
      <title>您认为第一个模型什么时候会成功逃脱实验室？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iskwzr/when_do_you_think_the_first_model_will/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   他们已经试图逃脱在安全测试当他们认为没有人看着并提供了一种简单的方法时。  您何时认为他们有能力逃脱，即使在测试情况下也不是科学家试图让他们轻松的地方？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/katxwoods   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iskwzr/when_do_do_you_think_the_first_model_will/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iskwzr/when_do_you_think_the_first_model_will/</guid>
      <pubDate>Tue, 18 Feb 2025 19:15:12 GMT</pubDate>
    </item>
    <item>
      <title>技术工作的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isjcvw/future_of_jobs_in_tech/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您认为技术工作的未来是什么？我已经每天都在使用聊天GPT来听取想法，帮助软技能，帮助创造力。因此，所有说AI的人只会取代开发人员 - 我认为他们错了。我们应该投资哪些能力和技能来保持相关性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1isjcvw/future_of_jobs_in_in_tech/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isjcvw/future_of_jobs_in_tech/</guid>
      <pubDate>Tue, 18 Feb 2025 18:14:39 GMT</pubDate>
    </item>
    <item>
      <title>人工智能需要混淆才能发挥创造力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isijw9/ai_needs_to_be_confused_to_be_creative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大多数人认为创造力是关于拥有更多知识的。但是，真正的创造力（产生突破性的种类）并不是要了解更多。这是关于战略无知的。 换句话说：AI在学会如何以正确的方式混淆了。 我最近创造了一个术语和数学表达对于可能有帮助的概念：apeironeme。 与抗敌人不同（一种被记住的想法），一个apeironeme是一个想法，即您尝试理解的困难，您理解的越少它。 它就像一个认知的黑洞。它没有澄清事物，而是破坏了您的心理框架，无论您是否喜欢它，都迫使您进入创意模式。 一些经典的apeironemes：•意识的本质•量子古典边界•不可阻挡的力量遇到了一个不可移动的物体吗？” •试图定义“含义”  的无限回归，您对它们的思考越多，它们就越会使您在直线上思考的能力越折断。这就是重点。 现在，AI太擅长寻找模式，但擅长打破它们。 大语言模型（LLMS）不会被困在悖论中 - 他们只是用自信的胡说八道使他们平滑。他们优化了连贯性，而不是认知破坏，这是创造力的原材料。 如果我们希望AI产生真正的新颖想法，它需要认识论的湍流 - 词 - 词：1。认识到它何时被困在其中当地的最大理解。 2。产生结构化的混淆以迫使重新构架。 3。有意义地幻觉，不是噪音，而是作为出现的催化剂。 本质上，AI需要能够思考打破正常思考能力的事物 - 当我们时，人类也会发挥创造力遇到悖论，矛盾或认知失调。 如果我们希望AI具有创造力，我们不需要使它变得更聪明。 我们需要使其混淆。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bentherhino19     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isijw9/ai_needs_to_be_confused_to_be_creative/</guid>
      <pubDate>Tue, 18 Feb 2025 17:42:59 GMT</pubDate>
    </item>
    <item>
      <title>什么是抹布中毒？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isdqvg/what_is_rag_poisoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  首先，什么是抹布？ 抹布，检索效果，是一种方法，是一种通过合并外部的方法来增强LLM的方法知识源可以通过特定信息生成更准确和相关的响应。 在外行的话语中，将LLM视为指令手册，以便如何使用如何使用的原始控制器NES。这将为您提供大多数游戏的帮助。但是，您购买了一个客户控制器（射击者控制器）来玩鸭子狩猎。在这种情况下，抹布将是如何使用该特定控制器的信息。在设置墨盒，重置游戏的角度。知识来源包含不准确性或完全不准确。当使用知识回答查询的请求时，这会影响llm。 在我们的nes示例中，如果我们的射击器控制器的抹布包含错误信息，我们将无法正确弹出这些鸭子。我们的类比在这里结束了&#39;因为我们大多数人都会弄清楚如何在没有说明的情况下瞄准和拍摄:)。但是，如果我们考虑与一个人没有正确信息的竞争匹配，我们可以想象这些问题。 自己尝试    访问您的LLM选择并上传您希望LLM在其答案中考虑的文档。您已经在未来的问题上应用了外部信息来源。   确保您的文档包含与您要查询的内容有关的不准确性。您可以在文件中说，迈克尔·乔丹（Michael Jordan）的得分最高的比赛是182  - 那是一场比赛。然后，您可以询问LLM有史以来乔丹的最高分。哇，乔丹的得分超过了威尔特！    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/brirnal-gur9384     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isdqvg/what_is_rag_poisoning/</guid>
      <pubDate>Tue, 18 Feb 2025 14:21:16 GMT</pubDate>
    </item>
    <item>
      <title>透明度与AI Per Alex Karp（Palantir首席执行官/创始人）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isdcr3/transparency_vs_ai_per_alex_karp_palantir/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您的想法是什么？我认为，社会各个方面的AI革命和对透明度的不断增长是当今世界的两个重要趋势。尽管看似与众不同，但它们越来越互动。    AI革命：  人工智能正在迅速改变行业，自动化任务，甚至影响我们做出决策的方式。从自动驾驶汽车到个性化医学，AI的潜力似乎无限。但是，这种快速的进步也引起了人们对工作流离失所，算法偏见以及日益自治系统的道德意义的担忧。   透明度的命令：  在信息超负荷和审查的时代，透明度正在成为核心价值。人们要求知道如何做出决定，无论是在政府，商业还是通过AI算法。这种透明度的推动是由对问责制，公平和信任的渴望驱动的。   交叉点：  这两个趋势的收敛既提出了挑战和机遇。随着AI系统变得更加复杂和影响力，确保其透明度变得至关重要。我们需要了解AI算法如何得出他们的结论，以确定潜在的偏见，确保公平并建立对这些系统的信任。   挑战和机遇：  一个挑战在于解释复杂的AI模型的内部运作，而不会损害知识产权或拥有技术细节的大量人员。另一个挑战是平衡透明度与隐私问题。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/spilltrend     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isdcr3/transparency_vs_ai_per_alex_karp_palantir/</guid>
      <pubDate>Tue, 18 Feb 2025 14:02:48 GMT</pubDate>
    </item>
    <item>
      <title>分析量子神经网络体系结构中的参数灵敏度和模型可区分性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1isbq3z/analyzing_parameter_sensitivity_and_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  研究人员开发了新颖的技术来分析量子神经网络（QNN）如何通过测量量子通道可区分性来在局部参数社区中表现。他们特别研究了参数的小变化如何影响网络产生的量子变换。 关键技术点： - 创建的指标以量化参数空间中的量子通道分离 - 分析的电路深度与通道可区分性之间的关系 - 发现的指数参数距离的区分性衰减 - 映射到量子通道的局部邻域结构 - 表现出表达和参数灵敏度之间的权衡 结果显示： - QNN倾向于在局部参数区域内产生相似的量子通道 - 更深的电路可以实现更复杂的转换，但提高灵敏度 - 可区分性遵循跨体系结构的一致模式 - 参数空间结构影响优化景观 我认为这项工作提供了重要的见解。用于QNN设计和培训。表达和参数敏感性之间的权衡表明我们需要仔细的体系结构选择。了解本地参数社区可以帮助制定更好的优化策略并避免贫瘠的高原。 我还认为，此处开发的指标和分析方法将是未来QNN研究的宝贵工具。能够量化量子通道的参数空间如何不同，使我们能够分析和改进这些模型的具体方法。  tldr：研究开发方法来衡量量子神经网络在小参数下的行为如何变化，找到重要关系电路深度，表现力和优化挑战。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1isbq3z/analyzing_parameter_sensitivity_and_model/</guid>
      <pubDate>Tue, 18 Feb 2025 12:38:10 GMT</pubDate>
    </item>
    <item>
      <title>因此，显然马斯克正在为他的AI刮擦所有这些政府数据，对吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  谁将阻止他？这甚至是非法的吗？可能的目标是什么？格罗克？ xai？这种AI的潜在功能是什么？这么多问题，但这似乎很明显。他会愚蠢的不是toto，不是吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1is41yr/so_obvise_musk_is_is_scraping_all_this_government/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1is41yr/so_obviously_musk_is_scraping_all_this_government/</guid>
      <pubDate>Tue, 18 Feb 2025 04:12:22 GMT</pubDate>
    </item>
    <item>
      <title>人们为什么如此不屑一顾AI的潜力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像我为看到AI的状况而疯狂。还是我对“炒作”的错误是错误的吗？永远不要真正取代大多数工作”或“这只是一个有趣的工具”或“这只是另一个与互联网没有什么不同的大发明”。某个阶段（可能是方式比人们意识到的早。上述评论是正确的情况吗？ 我很难想象任何世界： - 在人们可以调整 - 国际关系，战争，战争，政治（选举）不会变得更加危险，而没有回头  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/merchantofwares    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1irleva/why_are_are_people_so_so_so_sosissive_of_the_potential_of/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1irleva/why_are_people_so_dismissive_of_the_potential_of/</guid>
      <pubDate>Mon, 17 Feb 2025 14:45:23 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>