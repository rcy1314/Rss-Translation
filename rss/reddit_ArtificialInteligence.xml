<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 29 Aug 2025 21:20:43 GMT</lastBuildDate>
    <item>
      <title>害怕未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3jid6/afraid_of_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好吧，基本上我想成为一名作家，但恐怕AI可以代替艺术中的人。目前还不是，但是谁知道20年后？此外，根据Chatgpt的创建者的说法，AI将失去许多工作。而且我更害怕山姆·奥特曼（Sam Altman）。老实说，对人工智能有什么其他事情需要做什么？他们不能只是个人助理吗？现在，每个人都使用AI，而是用作工具，而是用作自己的替代品，而不是因为有意义的话而不是来自自己的东西。我不希望我们的竞赛能够发展为这一目标。我真的很害怕。您认为会发生什么？有工作，思维方式，控制任何制度，政治，公司或任何一般的工作？我现在也许有一点恐慌攻击。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/midetetas3000     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3jid6/afraid_of_the_future/</guid>
      <pubDate>Fri, 29 Aug 2025 21:16:35 GMT</pubDate>
    </item>
    <item>
      <title>AI取代艺术工作？我不这么认为...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3jcs3/ai_replacing_art_jobs_i_dont_think_so/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，虽然我显然要发布一些pro-ai，鉴于这是一个人工智能组，但我反对在许多情况下使用AI的方式。我不会对此进行详细说明，因为这对我的帖子并不重要，我不想陷入困境（如果您需要详细信息，请私下给我发消息）。  我确实认为艺术家认为他们的工作有风险，因为AI艺术有些愚蠢。因为，老实说，如果您有AI的风险，请首先与AI区分开。您可能不是一个伟大的艺术家。这很难吞咽，但是任何可以从中赚钱的好艺术家都没有受到威胁。抱怨它的人比什么都没有创造力和情感。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/whitesox-fan   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3jcs3/ai_replacing_art_jobs_i_i_dont_think_so/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3jcs3/ai_replacing_art_jobs_i_dont_think_so/</guid>
      <pubDate>Fri, 29 Aug 2025 21:10:08 GMT</pubDate>
    </item>
    <item>
      <title>您认为接下来会严重影响Al的哪些领域？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3fcfa/what_fields_do_you_think_al_will_seriously_impact/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们已经可以看到AI在科学，健康和编码等领域中表现很高。这些曾经被认为是安全的领域，但AI被证明了。我很好奇这里的人们期望的是巢的大领域将被重塑。是教育，法律，金融，新闻或更出乎意料的事情吗？您认为在未来2  -  3年内最容易变化哪些行业？我认为，如果我们可以通过适当的事实检查实现解决幻觉，新闻/媒体可能是接下来的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/queasy_system9168     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3fcfa/what_fields_do_you_think_al_will_seriously_impact/</guid>
      <pubDate>Fri, 29 Aug 2025 18:31:21 GMT</pubDate>
    </item>
    <item>
      <title>在Sphere Ai Slop上称呼Oz的巫师是对艺术家的侮辱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3eo01/calling_wizard_of_oz_at_the_sphere_ai_slop_is_an/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是的，他们的艺术得到了AI的支持。但这并不是说他们去了chatgpt说，“成为oz big pls的巫师”。这些都是真正的资深艺术家，他们创造了这一点，并将其作品称为Ai Slop，只是因为它得到了AI的支持。有趣的是，这些人认为自己更聪明，在道德上是反对的，当时他们是那些将批判性思维卸载给tiktok并热情地讨厌他们不了解的东西的人。人们出于许多不同的原因不喜欢AI，有些是有效的，有些是无效的，但是无论您是否是AI粉丝，这些艺术家所做的两年的辛勤工作都是错误的。我什至看到有人说艺术家是懒惰的叛徒。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u lulgbtorsothing     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3eo01/calling_wizard_of_og_oz_at_the_sphere_sphere_ai_ai_ai_slop_is_is_is_an/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3eo01/calling_wizard_of_oz_at_the_sphere_ai_slop_is_an/</guid>
      <pubDate>Fri, 29 Aug 2025 18:05:24 GMT</pubDate>
    </item>
    <item>
      <title>梅塔（Meta</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3dn1s/meta_says_bring_ai_to_the_interview_amazon_says/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  看起来越来越多的人正在使用AI进行技术访谈。一个统计数据说 65％的求职者在此过程中的某个地方已经使用了它。这给经理和人力资源带来了一个棘手的问题：您是真的评估人及其技能，还是AI正在接受采访？  事实是，公司被分割了：      meta 公开允许AI在编码访谈中使用，称候选人应在雇用时会在相同的条件下工作。  Zuckerberg甚至称AI “您可以在您的公司中拥有代码的一种中级工程师，”和Meta的一种实际上使其官方作弊。      Amazon ，另一方面，甚至可能   无论哪种方式，很明显，技术招聘处于一个很大的过渡中：  如果AI被录取，访谈也应评估提示技能以及如何在工作流程中应用AI。同样重要的是：软技能，例如解决问题，跨团队的沟通以及了解业务需求。如果要委派给AI，那么这些问题甚至更重要的是。   如果禁止AI ，公司将需要在两个方面进行适应：   - 培训招聘人员和面试官以发现可疑行为。诸如侧面瞥了一眼另一个屏幕，奇怪的沉默或“过度抛光的答案”之类的东西。所有这些都可以发出未经授权的AI使用。    - 使用新工具来检测假候选人。这些是更极端的情况，，但报道说它们已经上升了。  最后，我认为这对许多公司来说都是一个真正的问题。你们都怎么看？允许AI使用并专注于评估候选人如何使用它，或者招聘过程是否应该在没有LLMS的情况下可以做什么？  来源：     https://www.businessinsider.com/meta-job-candidates-use-ai-coding-interviews-2025-7      https://www.cnbc.com/2025/04/08/fake-job-job-seekers-use-use-ai-te-interview-for-for-remote-jobs-jobs-jobs-jobs-jobs-ceos-ceos-say.html       https://www.inc.com/jessica-stillman/are-they-a-they-a-great-job-candidate-or-just-iust-using-using-ius--ris-res-5-questions-to-to-t-t-t-t-tel-tell/91154910         &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3dn1s/meta_says_bring_ai_ai_tto_the_tthe_interview_amazon_says/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3dn1s/meta_says_bring_ai_ai_the_tthe_tthe_tthe_interview_interview_amazon_saysay/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3dn1s/meta_says_bring_ai_to_the_interview_amazon_says/</guid>
      <pubDate>Fri, 29 Aug 2025 17:26:53 GMT</pubDate>
    </item>
    <item>
      <title>针对一家数十亿美元的制药公司的仲裁：双方都同意AI合格的仲裁员，但论坛试图与退休法官进行阻止</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3dn28/arbitration_against_a_multibilliondollar_pharma/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正处于仲裁和联邦请愿书中，反对一家数十亿美元的制药公司。  hollingsworth诉sanofi-aventis v.Sanofi-aventis v.Sanofi-aventis v.3：25-cv-01342-ab 受访者一致认为，仲裁员必须具有AI和新兴技术的资格。 •取而代之的是，仲裁论坛试图强迫退休的法官名单，在职业生涯结束时的程序人士，没有AI经验，确切的类型公司更喜欢，因为他们是“安全的”。 •这就是为什么现在在联邦法院进行干预的原因。   这是更大的虚伪：  •十亿美元的律师事务所每天都在使用AI，以进行发现，合同审查，合规性和策略。 •公司在全球范围内花费数万亿美元，以使自己更强大。 •但是，当一个普通人使用人工智学来平息运动环境时，社会突然说：“那不是真实的法律。这是个玩笑。你做不到。”   大多数人认为AI只是为了制作愚蠢的tiktoks或列表。但是，如果您每天都使用它来增强您的智能，学习案例法，完善论点，学习策略并与十亿美元的公司作斗争？ 这就是我一直在做的事情。这不是“让AI为我做。”我是一个正在研究，学习和建筑文件的人。 所以真正的问题：我们是否要继续嘲笑个人使用AI，而公司在没有限制的情况下悄悄地将其武器化？还是这是我们开始转移权力动态的那一刻，AI不再为强大的娱乐而开始对我们其他人进行正义？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/starkingProcess5105     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3dn28/arbitration_against_a_multibilliondollar_pharma/</guid>
      <pubDate>Fri, 29 Aug 2025 17:26:53 GMT</pubDate>
    </item>
    <item>
      <title>从事PRD并将其转换为工程的感觉就像是酷刑 - 其他人吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3d5vl/working_on_prds_and_transforming_them_to/</link>
      <description><![CDATA[I am a new Product manager and I swear every cycle it’s the same struggle:  Sit through hours of calls Try to pull insights from messy notes / Slack threads / support tickets Write a 10-page PRD nobody reads Hand it off to design for mockups 然后，手动将其分解为Jira门票  ，到工程前的时候，感觉已经丢失了几周，一半的上下文消失了。奇怪 -   you&gt;您 you 如何处理？您吗？ 您是否找到了任何使它吸得更少的骇客/工具？  很想听听别人的经历 - 也许我只是做错了。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shahzanm72     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3d5vl/working_on_prds_and_transforming_them_to/</guid>
      <pubDate>Fri, 29 Aug 2025 17:09:01 GMT</pubDate>
    </item>
    <item>
      <title>特朗普政府将自动化健康不平等</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3bd8i/the_trump_administration_will_automate_health/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   craig spencer：“白宫的AI行动计划，7月发布，仅提及&#39;医疗保健&#39;，但它是第二届特朗普政府最后果的健康政策之一。席卷了ai浪费的雄心勃勃的ai，以ai的态度，派遣了私人私人行为，私人的私人行为，又有私人的私人行为，又有私人划分的私人行为，又有创新的行为，又有创新的行为。 Dei&#39;-将对医学的实践，公共卫生的治理方式以及被抛弃的人会产生长期的影响。这些动作不仅是象征性的，而且还塑造了被衡量的内容，被研究和哪些发现发表的内容。现在，这些相同的约束正在进入AI本身的发展。根据政府的政策，开发人员有明确的动力来做出设计选择或选择不会引起政治审查的数据集。进入医学的未来和历史表明，一旦偏见被编码为临床工具，即使是几十年来，也可能需要数十年的时间 - 如果它们完全被撤消。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/theatlantic     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3bd8i/the_trump_administration_will_automate_health/</guid>
      <pubDate>Fri, 29 Aug 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>5年时间表：2030</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b560/5_year_timeline_2030/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您对未来五年自动化的工作的诚实想法是什么？我们已经在餐馆拥有售货亭，最近我看到了无人驾驶卡车（以及可能取代Uber和Lyft的公司）在德克萨斯州的某些高速公路上部署了很多入门级数据输入工作。可以说，可以翻转开关，大多数工作明天可能会消失。从技术上讲，我们在那里。但是在立法上，我认为赶上可能需要十年或更长时间。特朗普（美国）刚刚解雇了乔布斯女士，因为他不喜欢这些数字。它可能而且可能只会变得更糟。我觉得随着人工智能的进展，世界可能会整夜变化。但是实施所有这些的法律篮球将需要花费时间。政府可以将其推出并合理地控制即将来临的变化，这是没有简单的方法。 你们对此有何看法？  首先要去哪些工作，需要多长时间？  立法是什么样的？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/minuse injury3471     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b560/5_year_timeline_2030/</guid>
      <pubDate>Fri, 29 Aug 2025 15:52:20 GMT</pubDate>
    </item>
    <item>
      <title>与AI合作的方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b4ba/approach_to_collaboration_with_an_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b4ba/approach_to_collaboration_with_an_ai/</guid>
      <pubDate>Fri, 29 Aug 2025 15:51:26 GMT</pubDate>
    </item>
    <item>
      <title>是否有可以产生音乐成绩的AI聊天机器人？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b2sx/is_there_an_ai_chatbot_that_can_produce_musical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  像大多数人一样，我想成为作曲家而不必做任何实际工作。是否有AI可以为我做到这一点？提交由＆＃32; /u/u/u/cramber-flarmp     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n3b2sx/is_there_an_ai_ai_ai_ai_chatbot_that_that_can_can_produce_musical/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n3b2sx/is_there_an_ai_chatbot_that_can_produce_musical/</guid>
      <pubDate>Fri, 29 Aug 2025 15:49:47 GMT</pubDate>
    </item>
    <item>
      <title>我喜欢当人们使用AI来完善他们的帖子时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n395bm/i_like_when_people_use_ai_to_refine_their_posts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它使语法和段落断裂。它放置了适当的标点符号。阅读帖子感觉就像有一种可靠的格式。  我不是在捍卫那些用它来完成创意写作的人，但是如果您想向世界传达的东西，并且想使用AI来完善/重写它吗？前进。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kristisoko     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n395bm/i_like_when_people_people_ai_ai_refine_to_refine_to_refine_their_their_posts/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n395bm/i_like_when_people_use_ai_to_refine_their_posts/</guid>
      <pubDate>Fri, 29 Aug 2025 14:36:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以做基本数学吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n36930/can_artificial_intelligence_do_basic_math/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在听Anthropic最近的视频“ AI模型如何思考”基于他们对可解释性的研究，并发现了一些见解，他们分享了非常有趣的。例如，有证据表明LLM可以进行简单的数学（加法）。 可解释性是试图通过观察其中间神经层中发生的事情来理解LLM的工作方式的领域。在类比中，他们的工作类似于神经科学家对有机大脑的作用：他们使LLMS执行某些任务，并查看LLM打开神经元来处理这些任务的神经元。   很多人认为，LLMS认为，LLMS只是自动化工具，并且只能基于toke的信息，以前就可以看到它的信息。但是人类的研究表明，这并不是那么简单。  杰克·林赛（Jack Lindsey）共享一个简单但非常有趣的示例，每当您获得模型总和两个数字时，第一个数字以“ 9”结尾。第二个以数字“ 6”结尾。触发LLM的相同神经元。但是有趣的部分实际上是可以发生这种情况的上下文的多样性。  当然，当您输入“ 9 + 6 =“”时，这些神经元将被触发，但是当您询问LLM的LLM年度第6卷发表了特定年度期刊的第六卷时，它们也会触发。他们没有增加提示的是，该期刊首次于1959年发表。  LLM可以正确预测第六卷是在1965年出版的。但是，当观察到哪些神经元触发时，他们见证了添加数字的神经元的6＆quot;和“ 9”正如约书亚·巴特森（Joshua Batson）总结的那样，这所暗示的是，即使LLM在其培训期间看到该期刊的第六卷在1965年出版，这表明，这表明该模型仍然表明，该模型“仍然愿意”，这表明这一表明的是，该期刊的第六卷已在1965年发表，这表明了这一点。为此特定情况进行数学。 这样的发现表明，LLMS可能比简单的模式匹配在更深的结构上运行。可解释性研究仍处于早期的早期，但是它开始揭示这些模型在引擎盖下的推理可能比我们假设的更多。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n36930/can_artcover_intelligence_do_do_do_basic_math/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n36930/can_artificial_intelligence_do_basic_math/</guid>
      <pubDate>Fri, 29 Aug 2025 12:36:32 GMT</pubDate>
    </item>
    <item>
      <title>知道人工智能的人将大大取代那些没有的人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎有些人主张知道AI的人将大大取代那些不在未来的就业市场上的人。但是，这真的如何区分？谁不能只是学会命令AI或编写提示？不应用AI每个人都可以做的事情吗？这就是AI的目的，即使是新手也可以应用 - 对吧？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2wjjw/people_that_knoke_ai_ai_ai_will_massiver_massiver_replace_those/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2wjjw/people_that_know_ai_will_massively_replace_those/</guid>
      <pubDate>Fri, 29 Aug 2025 03:15:31 GMT</pubDate>
    </item>
    <item>
      <title>今天的AI模型真的是“聪明的”，还是只是好的图案机器？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我越多地使用chatgpt和其他LLM，我想知道的越多，我们是否过度使用智能一词？ 不要误会我的意思，它们很有用。我每天使用它们。但是在大多数情况下，感觉就像是预测，而不是真实的推理。他们不会像人类那样“理解”上下文，并且在需要真正常识的任何事物上跌跌撞撞。 所以这是我的问题，如果这不是真正的智力，您认为下一个大步是什么样的？更好的架构超出了变形金刚？更多的多模式推理？完全有什么？ 好奇这个社区的立场：我们是在通往AGI的道路上，还是只是建立越来越更好的自动完成？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_just/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n2qe3u/are_todays_ai_models_models_really_intelligent_or_or_just/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n2qe3u/are_todays_ai_models_really_intelligent_or_just/</guid>
      <pubDate>Thu, 28 Aug 2025 22:32:14 GMT</pubDate>
    </item>
    </channel>
</rss>