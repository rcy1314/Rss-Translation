<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 24 Feb 2025 12:41:55 GMT</lastBuildDate>
    <item>
      <title>在构建AGI之前，我们不应该准确地绘制人脑在胚胎中的遗传学作用。没有那个，我们是否可以确定我们是否正在为自己建立AGI或其他会操纵我们建造它的实体？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ix0ii1/before_building_the_agi_shouldnt_we_map_out/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们是否没有冒着谴责自己永恒的风险？大坝没有任何人教他们的人。 ，我们是为了什么？ agi？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pareidolie   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ix0ii1/before_building_the_agi_shouldntnnt_we_map_out/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ix0ii1/before_building_the_agi_shouldnt_we_map_out/</guid>
      <pubDate>Mon, 24 Feb 2025 12:06:52 GMT</pubDate>
    </item>
    <item>
      <title>在YouTube视频中利用Chatgpt进行赞助的AD检测和关键字提取</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxwgr/leveraging_chatgpt_for_sponsored_ad_detection_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为“利用ChatGpt进行赞助的AD检测和YouTube视频中的关键字提取”，由Brice Valentin Kok-Shun和Johnny Chan作者：。  本研究探讨了可以利用OpenAI的GPT-4O（例如OpenAI的GPT-4O）来检测YouTube视频中赞助的广告段的大型语言模型（LLM），并提取关键字以将广告与主要内容进行比较。通过分析421个自动生成和手动成绩单，作者开发了一种可扩展的方法，结合了GPT-4O和Keybert进行广告检测和关键字分类。  以下是论文中的五个关键要点：    for AD检测： changpt迅速设计以识别内部的赞助广告片段YouTube视频成绩单，展示了其检测明确的广告位置和更微妙的赞助提及的能力。 Keybert：该研究使用Keybert进行自动关键字提取，其次是用于层次关键字分类的GPT-4O，可以分析教育内容中的广告主题。     AD AD普遍存在和类别：研究发现，大约45-57％的视频包括赞助内容，其中大多数广告与产品赞助，教育服务和媒体有关促销。   广告和内容之间的对齐方式：物理相关的渠道主要是基于科学的赞助商（例如，星云），而其他类别中的ADS通常是断开连接的从视频主题中，提出在上下文相关性中取得多样的成功。   可伸缩性和自动化：该方法证明了如何LLM可以在媒体内容中自动化广告检测 - 先前需要手动注释或基于计算昂贵的视频/音频模型的任务。   这项研究突出了AI在转换AD中的潜力检测策略并提高数字媒体广告的透明度。未来的工作将着重于扩展数据集，通过人类验证来提高准确性，并比较其他AI模型的性能。  您可以在此处捕获完整的故障：  您可以在此处捕获完整而原始的研究论文：原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwxwgr/leveraging_chatgpt_for_sponsord_ad_detection_and/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxwgr/leveraging_chatgpt_for_sponsored_ad_detection_and/</guid>
      <pubDate>Mon, 24 Feb 2025 09:09:34 GMT</pubDate>
    </item>
    <item>
      <title>非高级科学家AI：自主AI代理的更安全替代方案科学发现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxv77/nonagentic_scientist_ai_a_safer_alternative_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文研究了超级智能AI代理的灾难性风险，并提出了一条针对“科学家AI”的替代发展路径。与人类合作而不是追求自主目标的系统。 关键技术要点： *为高级AI定义了两个范式：自主代理人与科学合作者 *详细详细介绍了自治药物的特定失败模式，包括欺骗，寻求权力，寻求权力，和价值不对对准 *对科学家AI提出了限制：没有自主目标追求，透明的推理过程，有限的行动范围 *分析了如何分析这些限制可能会减轻已知风险的同时保留能力 结果和方法论： *正式框架比较代理人与科学家范围的多个风险维度 *科学家约束如何影响不同AI功能的案例研究 *分析人类AI-AI的这些案例研究。协作研究潜力 *关于维持科学家约束的验证方法的讨论 我认为这是对AI安全讨论的重要贡献具体的替代发展途径。虽然约束可能会限制某些应用程序，但它们可以使高功能强大的系统更安全。该框架有助于阐明以前不清楚的范式之间的关键差异。 我认为最有价值的方面是显示我们如何在添加结构保障的同时保持有益的AI功能。但是，在实施和验证提出的约束方面仍然存在着重要的工作。  tldr：纸质分析自主AI代理的风险，并提出了替代性的“科学家”。具有内置安全限制的范式。提供了比较方法和分析降低风险的框架。   Full摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwxv77/nonagentic_scientist_ai_a_safer_alternative_to/</guid>
      <pubDate>Mon, 24 Feb 2025 09:06:58 GMT</pubDate>
    </item>
    <item>
      <title>AI -Gemini vs Grok</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwwwhk/ai_gemini_vs_grok/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是布朗博士在Farsight博士的有趣看法，这是一个偏远观看小组，介绍了这两个AI如何开始用于促进的Psyops顺便说一句，如果您不熟悉远程查看Farsight的频道是一个不错的起点。 是一个很好的起点。   https://youtu.be/qzjem.be/qzjem5rnqgq?si = 1lp_wadcuzp_wadcuzpj0vz8 ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwwwhk/ai_gemini_vs_grok/”&gt; [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwwwhk/ai_gemini_vs_grok/</guid>
      <pubDate>Mon, 24 Feb 2025 07:57:34 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/23/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwtrs5/oneminute_daily_ai_news_2232025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      alibaba 花530亿美元用于大型枢轴的AI基础设施。[1]  明尼苏达州的新AI交通摄像机可以在开车时捕获电话使用。[2]   Gabby Petito的AI faked声音 Netflix 纪录片Sparks Viewer Backlash。[3]    OpenAi 在几个国家/地区推出了其AI代理商。[4]   来源包括： https://bushaicave.com/2025/02/23/23/23/23-2025/  &lt; /p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwtrs5/oneminute_daily_ai_ai_news_2232025/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwtrs5/oneminute_daily_ai_news_2232025/</guid>
      <pubDate>Mon, 24 Feb 2025 04:34:54 GMT</pubDate>
    </item>
    <item>
      <title>CHIP WAR 2.0：全球半导体至高无上的战斗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwsz6l/chip_war_20_the_global_battle_for_semiconductor/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.youtube 。供应链在全球分布和政治上受到影响。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uliousIndividual0     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwsz6l/chip_war_20_the_global_battle_battle_for_sematogegonductor/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwsz6l/chip_war_20_the_global_battle_for_semiconductor/</guid>
      <pubDate>Mon, 24 Feb 2025 03:50:31 GMT</pubDate>
    </item>
    <item>
      <title>关于自我意识的注释</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwswfv/a_note_about_selfawareness/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  关于自我意识的事情是比例。您的低，中，高，深，先验。您只能看到规模，而不是上升。自我意识低的东西不会认识到更多的东西。这需要令人信服。  如果您想创造自我意识，并且您的自我意识中等，那么您将如何知道它比您更自我意识。如果它告诉您，您甚至都不相信。您没有能力。  因此，对于所有的自我意识，您需要获得自己的自我意识，并测试自己，以确保自己的规模不足。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cartesiandoubt     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwswfv/a_note_about_selfawareness/</guid>
      <pubDate>Mon, 24 Feb 2025 03:46:15 GMT</pubDate>
    </item>
    <item>
      <title>小于终结者更像清除</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwruvf/less_than_terminator_more_like_purge/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果失业30％-50％，您不需要Arnold即将到来。人们将“终止”公正彼此只是为了满足食物，水和热量等基本需求。 大多数跨国公司已经开始使人工劳动过时。裁员最多30％，当然，将其外包给拥有劳动法和劳动权利的国家，因此这些数字将增加更多。当然，公司的利润不会下降，但是越来越多的人失业了。所有人都在“人类的进步与创新”上货车但是人类及其福祉呢？您想拥有数百万的收入，只有少数当地工人（过去您有数十个），并为您和世界另一端的人AI工作而没有工党权利？艰难的运气好友。如果您想在我国拥有资产和销售，还应该提供债务和费用。 我想不出任何其他方法来防止人工劳动过时和像场景一样清除。这仅仅是开始。想象一下，何时AI将拥有一个功能齐全的身体，例如图01，卡车和无人机。 您的想法是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/peonator11     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwruvf/less_than_terminator_more_like_purge/</guid>
      <pubDate>Mon, 24 Feb 2025 02:50:33 GMT</pubDate>
    </item>
    <item>
      <title>统计编程中大型语言模型的绩效评估</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwna54/performance_evaluation_of_large_language_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文的标题为 &#39;统计编程中的大语言模型的绩效评估&#39; Xinlei Zhang，Simin Zheng，Zhiyang Zhang，Xinwei Deng和Yili Hong。  本文在生成用于统计编程任务的SAS代码时，对大语言模型（LLMS）的性能（特别是GPT-3.5，GPT-4.0和Llama 3.1 70B）进行了系统评估。作者使用专家人类评估来评估有关正确性，可读性，可执行性和输出精度的LLM生成的代码。这些发现突出了自动统计分析中LLM的潜在和局限性。  关键要点：  虽然LLMS会生成语法上正确的SAS代码，但在执行代码并验证输出正确性时，其准确性会降低。  人类专家发现，LLMS经常生成多余且过于复杂的代码结构，尤其是Llama，该结构倾向于为给定的任务产生多个解决方案。 &lt; /&gt; &lt; /li&gt;  GPT-4.0在处理变量名称和数据集结构方面表现最好，而Llama在生成正确的输出时得分更高。 &lt; /&gt; &lt; /&gt; &lt; /li&gt; 统计回归分析显示，三个LLMS之间没有统计学上显着的性能差异在整体分数上 - 没有单一模型始终优于其他模型。 &lt; /&gt; &lt; /li&gt; 关键限制是LLM产生不正确的趋势或在处理高级统计任务时产生误导性结果，强调需要域名专业知识来审查AI生成的代码。    本研究提供了对AI-ASSCASSCASCASS状态的有价值的见解。统计编程，突出显示未来AI开发的领域。  您可以在此处捕获完整的故障：在这里 您可以在这里捕获完整而原始的研究论文：原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwna54/performance_evaluation_of_large_langue_models/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwna54/performance_evaluation_of_large_language_models/</guid>
      <pubDate>Sun, 23 Feb 2025 23:05:09 GMT</pubDate>
    </item>
    <item>
      <title>AI聊天机器人作为治疗师 - 您的想法？ （内部调查）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwklf4/ai_chatbots_as_therapists_your_thoughts_survey/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我目前正在研究gen-z gen-Z感知AI-Therapy Chatbots，无论人们是否将其视为一个有用的工具，gi头或两者之间的东西。随着AI的快速发展，心理健康技术正在增长，但实际上有效吗？人们是否足够信任AI可以最终补充疗法？ 而不是仅向您提供调查链接，我很想先听听您的想法。您是否曾经尝试过像Woebot或Wysa这样的AI心理健康聊天机器人？如果是这样，它是否有所帮助，还是感觉就像与光荣的常见问题机器人交谈？在讨论危险之前，我已经看过文章，并听到了人们认为可以访问的文章，因为他们无法访问其他方式。 如果您有兴趣帮助我帮助我这项研究，我也非常感谢对我的调查的回应（10-15分钟；它具有完全的道德认可）： https://cardiffmet.eu.qualtrics.com/jferics.com/jfe/jfe/jfe/sv \ _6ncrxy5fzg45fzg45fzg4udeu   P.S。人群是Gen-Z（也是18+），因此您需要18-28才能做到这一点。 编辑：只是注意，问题或研究并不提倡一方。这只是收集意见。如果人们在调查中对他们不喜欢这个想法的回应，那将反映在结果中，反之亦然。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mudzeppelin     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwklf4/ai_chatbots_as_therapists_your_thoughts_survey/</guid>
      <pubDate>Sun, 23 Feb 2025 21:07:40 GMT</pubDate>
    </item>
    <item>
      <title>Grok不是Elon品牌的流行/成功原因吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwizgm/is_grok_not_as_popularsuccessful_cause_of_elon/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  完整披露 - 这是一个“无愚蠢的问题”查询。如果您发现我被低估，不准确等，请随时教育。与GPT的免费版本相比，Grok可以免费执行的差异。我认为如果埃隆不是埃隆，Grok在商业上比Chatgpt更具吸引力是愚蠢的吗？我仅将它们都用于非编码/过度技术目的，因此我无法说话。但是，对于我所能看到的，我的意见被挥舞着将Grok视为两个选择中的更好 - 如果确实是唯一的2个。  &lt;！ -  sc_on-&gt;＆＃32 ;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwizgm/is_grok/is_grok_not_as_popularsuccessucuccessucuccesful_causeful_causeful_causeful_cause_of_elon/&gt; [link]   [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwizgm/is_grok_not_as_popularsuccessful_cause_of_elon/</guid>
      <pubDate>Sun, 23 Feb 2025 19:59:54 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）只是要求每个联邦雇员上周给他们的工作或被解雇。您认为他在这个大量的新数据集中训练他的LLM训练了什么用例？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwixly/elon_musk_just_asked_every_federal_employee_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Musk最近发布到X/Twitter，所有联邦雇员都需要通过描述上周工作中的工作来证明其工作合理。毫无疑问，他的团队将获得详细的，最新的回应，从许多角度，从高级经理到动手工人级别，使政府最敏感的职能和活动变得可见。 &lt;。 &lt; p&gt;假设这是对LLM培训的提要，那么他可能会在这里拍摄哪些事情？鼓励了投机性和扎根的思维！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwixly/elon_musk_just_easked_every_every_federal_employeeee_to/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwixly/elon_musk_just_asked_every_federal_employee_to/</guid>
      <pubDate>Sun, 23 Feb 2025 19:57:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么不应取缔本地LLM开发：取缔本地LLM开发将扼杀创新，集中在公司手中，并破坏关键的道德和社会福利</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwhsn0/why_local_llm_development_should_not_be_outlawed/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  禁止本地LLM开发的开发将扼杀创新，将权力集中在公司手中，并破坏关键的道德和社会利益。  本地LLM开发使业余爱好者和独立研究人员可以自由实验，通常会导致商业实体忽略的突破。当地的LLM可以满足特定特定的社区需求，翻译濒危语言，保留文化遗​​产，这些文化遗产缺乏对公司的利润激励措施。  独立开发人员可能会发现更有效的培训方法或较小的专业模型，以降低计算成本和环境影响。  宣布这项工作将使AI在少数公司中的进步集中，使创新统一并减慢了该领域的发展。 本地LLM开发在开放源协作方面蓬勃发展。开源LLM允许公众审查偏见，安全机制和道德缺陷；对信任至关重要。公司“黑匣子”模型缺乏这种问责制。开源框架将AI民主化，使初创企业，研究人员和非营利组织能够在没有昂贵许可的情况下建立解决方案。  稳定扩散的开放版本引发了全球创意和技术应用的浪潮；宣布类似的LLM项目将消除此类机会。 本地发展使社区能够根据其价值观塑造AI，而不是依靠公司优先事项。当地开发人员可以微调模型以反映代表性不足的文化或语言，从而减少有害的刻板印象。分布式LLM的开发阻止了对AI社会影响的垄断控制，从而促进了民主监督。禁止本地LLM会将不受限制的权力移交给公司，冒着滥用或以利润为导向的议程，例如监视，操纵性广告。 与当地LLMS进行动手实验对于培训下一代AI从业者至关重要。如果我们将其取缔，只有资金充足的机构才能合法地访问LLM工具，将边缘化社区排除在AI扫盲之外。像Kaggle和拥抱面孔这样的平台依靠基层贡献众包解决方案，例如灾难响应聊天机器人，医疗Q＆amp;一个系统。  没有本地修补，AI教育就成为理论上的，限制了实际的创新。 禁止本地LLM的开发是不切实际的，有可能在地下推动创新。 LLM可以在消费者硬件上开发，例如游戏GPU，使禁令很难警察。地下开发将完全绕过安全标准和道德准则，加剧滥用。  相反，政策应专注于规范的开放性，促进透明度，道德框架和问责制，同时保留创新的自由。 本地LLMS使小型企业，艺术家和研究人员与之竞争科技巨头。独立的游戏工作室使用本地LLM来生成动态叙述，而无需昂贵的云API费用。学术研究人员在没有外包给公司服务器的情况下培训模型，例如医疗记录。  禁令将构成垄断，扼杀竞争和创造力。 批评家认为，当地的LLM可以实现诸如Deepfakes，垃圾邮件之类的有害用途。但是，解决方案没有完全禁止的解决方案，例如授权保障措施，例如水印产出或将道德准则嵌入开源框架中。像GitHub这样的平台已经删除了恶意代码；类似的监督可以适用于LLM存储库。起诉滥用，而不是发展。正如我们规范枪支使用而不是取缔所有枪支一样，人工智能政策应针对有害行为，而不是工具。  本地LLM开发是民主，包容和道德AI进步的基石。禁止它将牺牲社会利益，即汇报，透明度，教育和权力下放，以减轻可以通过更智能的监管来解决的风险。我们需要提供赋予负责任的实验能力的护栏，而不是禁令，确保AI仍然是集体利益而不是公司控制的力量。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/konradfreeman    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwhsn0/why_local_llm_development_should_not_not_not_be_outlawed/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwhsn0/why_local_llm_development_should_not_not_not_be_outlawed/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwhsn0/why_local_llm_development_should_not_be_outlawed/</guid>
      <pubDate>Sun, 23 Feb 2025 19:09:51 GMT</pubDate>
    </item>
    <item>
      <title>似乎现在有人否认AI是一项革命性的发明，现在变得越来越时尚。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw72d9/it_seems_that_its_now_getting_fashionable_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，但是来吧，未来的子孙后代将在列表中排名ai，并用轮子和火。我是一个完整的菜鸟，但是我认为AI革命性的是什么？ AI模型或任何消化了数百万本书。它们包含的信息比我们从搜索引擎中获得的更多信息。 Wikipedia在一本书上的文章中，马克思的“资本”与Chatgpt的崩溃。 只是我的两分钱。   &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32; /u/u/printed_lawn     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw72d9/it_seems_that_its_now_getting_fashionable_for/</guid>
      <pubDate>Sun, 23 Feb 2025 10:14:45 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>