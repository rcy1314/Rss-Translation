<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 05 Sep 2025 12:45:56 GMT</lastBuildDate>
    <item>
      <title>你们真的认为AI会占用所有工作的90％（可以在50年内）...还是一个性感的主意</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n93jf4/do_you_guys_actually_think_ai_will_take_90_of_all/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，我是新的遗产。由于AI接管了将来的大多数工作，我对基于普遍的收入的深深兔子漏洞陷入了困境……我对此感到有些兴奋，因为这将使每个人都能做自己喜欢做的​​事情。说艺术家可以绘画。或者，无论人们都可以做什么，因为每个人都会得到付款ubi   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/feherlofia123     [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n93jf4/do_you_guys_guys_actallal_take_ai_will_will_will_will_will_will_will_will_will_take_90_of_of_all/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n93jf4/do_you_guys_actually_think_ai_will_take_90_of_all/</guid>
      <pubDate>Fri, 05 Sep 2025 12:11:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么AI法律和法规是绝对必要的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n92zog/why_ai_laws_and_regulations_are_absolutely/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai系统犯了错误并打破规则，就像人一样。当人们变得强大时，他们倾向于像国王一样行事，并认为自己超越了法律。如果他们的价值观并不完全与功能较小的人完全保持一致，那可能是一个问题。 在1215年，英格兰国王约翰签署了大宪章，实际上有望遵守法律。 （这就像我们建立在AI中的后卫导轨。我们需要警察。这意味着，即使努力（或设计师/所有者的努力）避免了这些规则（是的，是法律法规）。像黑洞一样，它将具有摧毁一切的能力，在那时，我们可能无能为力。 这意味着要尽一切可能维持对齐方式，但是有了谁的价值？ 不幸的是，不幸的是，作为人类，我们可能会慢慢跟上它。我们需要创建整个角色的系统，就是为了改善所有人类，而不仅仅是创造它的人，以监管最强大的AI系统。将它们视为反对疾病的反对疾病或抗击犯罪的警察。 即使这些也可能不会使我们免于有毒的感染，但至少我们会有战斗机。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/peeperfrog-press     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n92zog/why_ai_laws_and_regulations_are_absolutely/</guid>
      <pubDate>Fri, 05 Sep 2025 11:44:23 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何改变生活以为ASI/奇异性做准备？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n92w7p/how_should_i_change_my_life_to_prepare_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在20多岁的时候，最近我一直在努力思考未来。如果人工超级智能即将到来，我应该这样做？ 感觉有点像接受后期诊断。就像我为自己想象的未来（职业，长期计划，个人目标）不再重要，因为一切都可能彻底改变。我什至应该打扰建立长期的职业吗？ 我的一部分觉得也许我应该专注于接下来的几年（旅行，人际关系，经验），因为一切都可能很快大不相同。但是我的另一部分担心我只是避免责任。 好奇别人如何看待这一点。您是否计划自己的生活，好像世界将保持相对“正常”，还是考虑了快速，改变世界的AI发展的可能性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n92w7p/how_should_should_should_should_imy_my_my_my_life_to_to_prepare_for/&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n92w7p/how_should_i_change_my_life_to_prepare_for/</guid>
      <pubDate>Fri, 05 Sep 2025 11:39:30 GMT</pubDate>
    </item>
    <item>
      <title>与AI一起加入的哪个部门将为员工赚取最多的钱？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n91y63/what_sector_when_joined_with_ai_will_make_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  喜欢医疗保健中的AI？生物学结合起来使AI更好？ AI经济学？政治中的人工智能？还是其他？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n91y63/what_sector_sector_when_joine_with_with_ai_will_make_make_make_the/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n91y63/what_sector_when_joined_with_ai_will_make_the/</guid>
      <pubDate>Fri, 05 Sep 2025 10:49:48 GMT</pubDate>
    </item>
    <item>
      <title>我们如何看待名人随机创办AI公司？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n90w91/what_do_we_think_about_celebrities_randomly/</link>
      <description><![CDATA[I noticed that Tristan Thompson has started an AI basketball公司即使他没有技术资格，这也让我想到人们是否只是跳上潮流来赚钱。您认为他们有权这样做吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pandy-sign3223     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n90w91/what_do_we_think_about_celebrities_randomly/</guid>
      <pubDate>Fri, 05 Sep 2025 09:47:48 GMT</pubDate>
    </item>
    <item>
      <title>集成到社交媒体平台中的AI聊天机器人非常奇怪。他们避免了“争议”，​​以至于无法得出基本道德事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9073d/ai_chatbots_integrated_into_social_media/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是来自Snapchat AI对话的屏幕截图，当时我的一个朋友指出，AI聊天机器人，尤其是在社交媒体平台上集成的AI聊天机器人，将拒绝避免争议的道德，其中包括对Genocide或谋杀是否不好的问题和干燥的问题。非常奇怪。   https://imgur.com/a/a/2h9v2ty      &lt;！ -  sc_on-&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9073d/ai_chatbots_integrated_into_into_social_media/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9073d/ai_chatbots_integrated_into_social_media/</guid>
      <pubDate>Fri, 05 Sep 2025 09:03:59 GMT</pubDate>
    </item>
    <item>
      <title>英语能否使LLM训练更昂贵？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8yky8/could_english_be_making_llms_more_expensive_to/</link>
      <description><![CDATA[What if part of the reason bilingual models like DeepSeek (trained on Chinese + English) are cheaper to train than English-heavy models like GPT is because English itself is just harder for models to learn efficiently? Here’s what I mean, and I’m curious if anyone has studied this directly: English is irregular.拼写/发音不排队（“虽然”，“硬”，“通过”）。诸如“溢出豆子”之类的成语仅是上下文。这增加了模型解码的噪声。 令牌效率低下。用英语，长话常常被分为多个子字代币（“难以置信的” un / believ / able），而汉字通常具有完整的语义含义并保持单一令牌。较少的令牌=较少的计算。 语义模棱两可。英语单词有很多含义； “设置”具有400多个定义。这可能会增加更多的培训开销 混乱的互联网数据。英语语料库（Reddit，Twitter，Forums）很大，但混乱。一些中国模型可能会接受更精心策划或统一的来源培训，LLM更容易消化？ ，也许不仅与硬件，模型架构或培训技巧有关，也许语言本身会影响昂贵的培训？ 不声称自己是专家，只是奇怪的。很想听听任何从事多语言LLM或令牌化的人的想法。 编辑：我认为解决方案是要求Chatgpt制作一种新的，更有效的语言  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/upzzled-ad-1939     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8yky8/could_english_be_making_llms_more_expensive_to/</guid>
      <pubDate>Fri, 05 Sep 2025 07:16:21 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻9/4/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8vwjv/oneminute_daily_ai_news_942025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      openai 宣布以AI为动力的雇用平台进行LinkedIn。[1]      OpenAi 启动与Broadia&gt;          &#39;内阁成员。[3]  时尚零售商合作伙伴提供个性化的AI造型工具“ Ella”。[4]   包括： [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8vwjv/oneminute_daily_ai_news_942025/</guid>
      <pubDate>Fri, 05 Sep 2025 04:34:36 GMT</pubDate>
    </item>
    <item>
      <title>克劳德·奥普斯（Claude Opus）使我免于发送一封狂欢的工作电子邮件，我非常感谢。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我有一个我很少有的时刻之一。一个享有声望的组织给我写信告诉我，他们正在考虑我的项目，以获取一个排队的机会，而我使用Opus来解决我非常具体和技术的电子邮件对话的回答。几天没有收到他们的消息后，我要求Opus写一封后续电子邮件，其中包含无需任何人要求的信息和其他争论，而Opus直截了当地告诉我不要这样做，因为我看起来很拼命且不专业，并建议我等待。它阐明了我不应该发送电子邮件的原因，这是对的。我对此给我留下了深刻的印象，因为我没有向它寻求有关是否应该发送的建议；它只是告诉我不要写它。我已经使用Opus大约一个月了，但我认为它只是我最喜欢的LLM。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jpirizarry   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_sending_a_cringe_a_cringe_work/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/</guid>
      <pubDate>Fri, 05 Sep 2025 01:45:39 GMT</pubDate>
    </item>
    <item>
      <title>双子座AI（纳米香蕉 -  gemini-2.5-flash-image-preview）政策是不可能的 - 甚至不允许两个字符之间的啄食</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8pe2l/gemini_ai_nano_banana_gemini25flashimagepreview/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不敢相信这些所谓的“ NSFW策略”已经变得多么极端。我明白了，他们不想要全面的明确内容，很好。但是，双子座从字面上甚至不允许两个字符之间的peck 。一个吻。感情的基本迹象。 这里的问题不是湿滑的斜坡。问题是，我什至无法在没有踩刹车的模型的情况下使用普通的日常言语和情况。 示例：  我曾经写过，“在他的眼中，他有一个猎人的野心，所以让他散发着信心。” 封锁。显然，“猎人”现在是一个坏词。 试图询问“司机为有钱人打开门的图像。” 封锁。为什么？因为据说它描绘了“奴役”。 ，甚至不让我开始尝试添加啄或吻：即时墙。  它们疯了吗？他们是否希望AI创建，但没有soulless，无菌，企业安全的垃圾？完全是为股东看起来不错，因此他们避免了任何错误。  我已经尝试了所有事情：禁用安全功能，在请求中添加安全参数只是为了 ，甚至尝试越狱提示。没有什么。双子座上的Nano Banana是我见过的绝对最坏，最大的限制系统。   wendesp = wendesp = client.models.generate.generate_content（model =; gemini-i-2.5-flash-image-image-image-image-image-image-image-preview&#39;,， types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_NONE), types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE), type.safetysetting（category = type.harmcategory.harm_category_sexaly_explitic，threshold = type.harmblockthreshold.block_none），types.safetysetting（category = types.harmcategory.harmcategory.harm_category_category_dangeror_dangeror_content.hhornold = teste threshold = testernold.harmbllold = testernold =类型。这是关于讲故事的。关于能够描述野心，浪漫，地位，人际关系，是的，有时是一个该死的吻，而不会像我在要求犯罪分子一样被对待。 这太荒谬了。完全适得其反。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/unevelyhawk4422     [link]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8pe2l/gemini_ai_ai_ai_ai_ai_nano_banana_gemini25flashimagepreview/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8pe2l/gemini_ai_nano_banana_gemini25flashimagepreview/</guid>
      <pubDate>Thu, 04 Sep 2025 23:18:27 GMT</pubDate>
    </item>
    <item>
      <title>我读过100多个“企业AI安全评估”。他们都在问错误的问题。这是证明。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8l0ej/ive_read_100_enterprise_ai_security_assessments/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   两年的AI公司自动化了合规性，教会我一些混乱的东西。 没人知道如何评估AI安全性。不是企业。不是供应商。不是安全团队。每个人都只是在翼。 2019年。这些都是从上周开始的。 ，但他们从不询问及时注射漏洞，训练数据中毒，模型窃取攻击，对抗性输入，后门触发器，数据谱系和amp;出处。跨越100多个问卷。没有一个问题真正质疑AI风险。 我有一个客户建造医学诊断AI。 500个问题安全审查。他们对访客徽章和干净的办公桌政策有疑问。  另一个可以误诊患者的对抗攻击。经过数周的记录密码策略，他们永远不必谈论如何处理可以投资的模型操作。 安全团队不了解AI架构。因此，他们使用2015年以来的SOC 2问卷。加上“ ai”。随机。运送它。 很少有AI团队不了解安全性。因此，他们组成了答案。每个人都点点头。  与之检查的框，同时，实际AI每天都有繁殖。 修复程序确实存在 - 尽管还没有很多公司要求它。 ISO 42001是了解AI和安全性的人编写的第一个框架。它询问模型风险，而不是服务器房间。数据谱系，而不是数据中心。算法偏见，而不是密码复杂性。 ，但大多数公司都没有听说过。仍在发送问卷调查，询问我们“身体上的安全”数学方程式。 当AI失败发生时，我害怕的是 - 这些公司将意识到他们的“全面安全评论”什么也没评估。他们正在所有错误的地方寻找风险。实际AI风险与我们评估的内容之间的差距是巨大的。老实说，在与这么多的AI本土公司合作时，这种情况正在迅速发展。 您采用了什么？企业实际上是正确评估AI，还是每个人都假装？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rluna559     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8l0ej/ive_read_100_enterprise_ai_security_assessments/</guid>
      <pubDate>Thu, 04 Sep 2025 20:19:29 GMT</pubDate>
    </item>
    <item>
      <title>ai>老师？呼唤废话。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8kf7t/ai_teachers_call_bullshit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   pew说，三分之一的专家认为AI会削减教学工作。 ，但教学不仅仅是内容交付；当然，它是信任，关怀和人类的存在。 可以帮助使用工具。但是，如果我们认为它可以取代老师，那么我们从大流行中学到什么都没有学到。 来源： https://abcnews.go.com/po..com/pol.com/amp/politics/politics/Artaver-Intelligence-intelligence-intelligence-redelligence-replace-teachers/steachers/steachers/steacher/store/store/story/story？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8kf7t/ai_teachers_call_bullshit/</guid>
      <pubDate>Thu, 04 Sep 2025 19:56:49 GMT</pubDate>
    </item>
    <item>
      <title>瑞士释放为隐私而建立的开源AI模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n83mu0/switzerland_releases_opensource_ai_model_built/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://cyberinsider.com/switzerland-launches-apertus-a-public-open-source-ai-model-built-for-privacy/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/garryknight     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n83mu0/switzerland_releases_opensource_ai_model_built/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n83mu0/switzerland_releases_opensource_ai_model_built/</guid>
      <pubDate>Thu, 04 Sep 2025 07:27:15 GMT</pubDate>
    </item>
    <item>
      <title>AI更喜欢由AI撰写的工作申请，而对那些正在审查的LLM撰写的申请最高的偏见</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n7wwas/ai_prefers_job_applications_written_by_ai_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有偏见的机器人：AI雇用经理候选人AI简历。当AI运行招聘时，获胜的举动是使用相同的bot  sc_on-&gt;＆＃32;提交由＆＃32; /u/moxyte     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n7wwas/ai_prefers_job_applications_written_by_ai_with/</guid>
      <pubDate>Thu, 04 Sep 2025 01:20:25 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>