<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 28 Oct 2024 15:22:28 GMT</lastBuildDate>
    <item>
      <title>玛格丽特·阿特伍德不担心人工智能，继续多产的写作生涯</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ge4lhp/margaret_atwood_unworried_by_ai_continues/</link>
      <description><![CDATA[路透社报道：正在撰写回忆录的加拿大著名作家玛格丽特·阿特伍德在接受采访时表示，她年纪太大了，没有必要担心人工智能的崛起，并形容自己仍然享受着写作的“美好时光”。 现年 84 岁的阿特伍德于 1961 年以诗人身份首次亮相，并出版了她的第一部小说《可以食用的女人》。于 1969 年出版。此后，她撰写了 60 多本书，包括小说、短篇故事和儿童读物。 阅读更多： https://www.ctvnews.ca/sci-tech/margaret-atwood-unworried-by-ai-continues-prolific-writing-career-1.7089199     提交人    /u/CTVNEWS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ge4lhp/margaret_atwood_unworried_by_ai_continues/</guid>
      <pubDate>Mon, 28 Oct 2024 15:16:57 GMT</pubDate>
    </item>
    <item>
      <title>LLM 远程代码执行漏洞的剖析。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ge34gz/anatomy_of_an_llm_remote_code_execution/</link>
      <description><![CDATA[LLM RCE 剖析 我和我的团队刚刚发表了这篇令人大开眼界的文章，介绍了大型语言模型 (LLM) 中的安全漏洞，该漏洞允许研究人员通过简单的聊天提示在服务器上执行任意代码。 TL;DR：研究人员演示了如何绕过 LLM 对齐和 Python 沙盒来实现远程代码执行，从而暴露了 LLM 集成中的重大风险。 我强烈建议阅读全文。 你对此有何看法？ 您认为我们如何平衡 LLM 集成的好处和这些安全问题？    提交人    /u/jat0369   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ge34gz/anatomy_of_an_llm_remote_code_execution/</guid>
      <pubDate>Mon, 28 Oct 2024 14:15:44 GMT</pubDate>
    </item>
    <item>
      <title>Perplexity AI PRO - 1 年计划优惠 - 近 75% 折扣！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ge2wei/perplexity_ai_pro_1_year_plan_offer_almost_75_off/</link>
      <description><![CDATA[如标题：我们提供一年计划的 Perplexity AI PRO 优惠券代码。  订购：https://cheapgpt.store/product/perplexity-ai-pro-subscription-one-year-plan 接受的付款方式： - PayPal。 （100% 买家保护） - Revolut。    提交人    /u/MReus11R   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ge2wei/perplexity_ai_pro_1_year_plan_offer_almost_75_off/</guid>
      <pubDate>Mon, 28 Oct 2024 14:06:02 GMT</pubDate>
    </item>
    <item>
      <title>对 Sider、Chathub、MaxAi、Harpa 有何看法或经验？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ge2cf7/opinions_or_experiences_with_sider_chathub_maxai/</link>
      <description><![CDATA[  由    /u/murkomarko  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ge2cf7/opinions_or_experiences_with_sider_chathub_maxai/</guid>
      <pubDate>Mon, 28 Oct 2024 13:42:03 GMT</pubDate>
    </item>
    <item>
      <title>谷歌的生成式人工智能进展：Gemini 1.5 Pro 和 Gemma 2</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ge1w9r/googles_generative_ai_advances_gemini_15_pro_and/</link>
      <description><![CDATA[人工智能领域不断发展，生成式人工智能取得了重大进展。谷歌最近公布了其大型语言模型的重大更新，推出了先进的 Gemini 1.5 Pro 和强大的 Gemma 2。这些发展有望彻底改变开发人员的创造和创新方式，提供新的工具和功能，突破人工智能所能实现的界限。在 StellarMind，我们处于这项创新的前沿，尤其是在物联网领域。探索我们的产品组合，了解我们如何利用这些进步来推动进步。 阅读：https://stellarmind.ai/blog/google%E2%80%99s-generative-ai-advances-gemini1.5-pro-and-gemma2    提交人    /u/Sandyrocks77   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ge1w9r/googles_generative_ai_advances_gemini_15_pro_and/</guid>
      <pubDate>Mon, 28 Oct 2024 13:21:58 GMT</pubDate>
    </item>
    <item>
      <title>KAHANI 针对非西方文化的文化细微差别视觉叙事管道</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdycdk/kahani_culturallynuanced_visual_storytelling/</link>
      <description><![CDATA[标题：KAHANI 面向非西方文化的文化细微差别视觉叙事管道 我每天都在寻找和总结有趣的 AI 研究论文，所以您不必仔细阅读它们。今天的论文题为“KAHANI：面向非西方文化的文化细微差别视觉叙事管道”，作者是 Hamna、Deepthi Sudharsan、Agrima Seth、Ritvik Budhiraja、Deepika Khullar、Vyshak Jain、Kalika Bali、Aditya Vashistha 和 Sameer Segal。 本文介绍了 KAHANI，这是一种视觉叙事管道，旨在为非西方文化生成具有文化根基的视觉故事。作者强调了现有语言和文本到图像模型的局限性，这些模型往往反映了全球北方的文化偏见。为了解决这个问题，KAHANI 使用 GPT-4 Turbo 和稳定扩散 XL (SDXL) 模型，结合思路链 (CoT) 和文本到图像 (T2I) 提示技术来准确捕捉文化细微差别。 研究的主要发现包括：  文化准确性：在一项比较研究中，KAHANI 在捕捉文化特定项目 (CSI) 和反映与来自印度各个地区的参与者相关的文化细微差别方面优于 ChatGPT-4。它在 36 次跨不同评估维度的比较中，有 27 次获得了成功。 模型不可知论：KAHANI 的设计与模型无关，这意味着它可以适应未来的语言模型和文本到图像模型，从而随着 AI 技术的进步增强其实用性和相关性。 用户评价：参与者报告说，与 ChatGPT-4 生成的故事相比，KAHANI 制作的故事具有更具吸引力和生动的文化元素，例如特定的人物刻画和设置，而 ChatGPT-4 生成的故事被认为更具欧洲中心主义。 多元化代表：在承认平衡多样性与避免刻板印象的挑战的同时，KAHANI 允许进行包括更广泛的文化细微差别的代表，例如当地服饰和活动，从而有助于讲述更具相关性和真实的故事。 未来增强功能：该研究确定了需要进一步改进的领域，包括对输出的迭代改进以及在不影响故事叙述多样性的情况下整合更丰富的文化元素的潜力。您可以在此处查看完整的细分：这里 您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdycdk/kahani_culturallynuanced_visual_storytelling/</guid>
      <pubDate>Mon, 28 Oct 2024 10:01:48 GMT</pubDate>
    </item>
    <item>
      <title>哪个 LLM 更适合提供科学知识：新 Claude 3.5 Sonnet 还是 GPT-4o？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdv41r/which_llm_is_better_for_providing_scientific/</link>
      <description><![CDATA[例如，在问“L-茶氨酸治疗焦虑的作用机制是什么？”这样的问题时 哪个 LLM 更适合提供科学知识：新 Claude 3.5 Sonnet 还是 GPT-4o？    提交人    /u/greentea387   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdv41r/which_llm_is_better_for_providing_scientific/</guid>
      <pubDate>Mon, 28 Oct 2024 05:51:12 GMT</pubDate>
    </item>
    <item>
      <title>人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdtprr/artificial_cultural_intelligence/</link>
      <description><![CDATA[所以最近我看到了两篇论文：  混沌边缘的智能 (https://arxiv.org/abs/2410.02536) 大型语言模型反映了其创建者的意识形态 (https://arxiv.org/abs/2410.18417)  它们让我思考 - 如果 LLM 中存在固有偏见，那么为了达到 IV 类推理模型，我们是否需要一个可以根据上下文切换模型的系统（例如各种知识系统中固有的文化细微差别 - 从学术到甚至是本土）？ 我已经看到 LLM 路由器出现了，但它们主要用于降低成本。不一定是减少偏见或用于（文化）上下文切换。    提交人    /u/georgesiosi   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdtprr/artificial_cultural_intelligence/</guid>
      <pubDate>Mon, 28 Oct 2024 04:16:02 GMT</pubDate>
    </item>
    <item>
      <title>我们可以利用人工智能来理解黑匣子以及人工智能的工作原理吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gds6rj/can_we_use_ai_to_understand_the_black_box_and_how/</link>
      <description><![CDATA[比如，我们能否要求人工智能查看它（或其他人工智能）想出的规则，以找到模式或其他东西，并追溯规则的制定方式？当我们这样做时会发生什么？以前做过吗？我觉得考虑到我们现在可以用人工智能做的事情，这应该是可行的，但我肯定我遗漏了一些东西。比如训练集可能是一堆人工智能或其他东西。 编辑：好吧，我不太明白为什么我得到的反应是，我的问题没有意义，它不是那样工作的。说我可以问 ChatGPT 是一个公平的观点，出于某种原因，我认为我已经问过了。但我刚才问了，觉得我的问题很有道理。这是它的部分回应： “是的，人工智能本身经常被用来识别模式，并帮助在可解释人工智能 (XAI) 领域内开发解释。事实上，XAI 不仅专注于使 AI 模型更易于理解，还致力于利用 AI 来分析和解释其自身的输出。方法如下：...” 所以，我觉得我的问题的实际答案是：“是的，事实上我们已经这样做了，并且会继续这样做。它不再是一个黑匣子，但我们仍在努力更全面地理解” 我不知道为什么我一直认为我可以在 Reddit 上提问而不会觉得自己很愚蠢。谢谢大家    提交人    /u/whoi8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gds6rj/can_we_use_ai_to_understand_the_black_box_and_how/</guid>
      <pubDate>Mon, 28 Oct 2024 02:47:38 GMT</pubDate>
    </item>
    <item>
      <title>最好的一体化课程，我可以使用多个 LLM 吗？并且能够构建类似自定义 GPT 的东西（作为一项不错的选择）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdp8li/best_all_in_one_package_where_i_can_use_multiple/</link>
      <description><![CDATA[我订阅了 Perplexity 和 ChatGPT，但正在考虑取消订阅 ChatGPT。提前致谢！    提交人    /u/AppropriateRespect91   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdp8li/best_all_in_one_package_where_i_can_use_multiple/</guid>
      <pubDate>Mon, 28 Oct 2024 00:13:09 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能被视为“外星智能”会怎样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdl1k3/what_if_ai_was_viewed_as_a_alien_intelligence/</link>
      <description><![CDATA[大家好， 最近，我在 ChatGPT、Claude AI、Singularity 和 Reddit 等平台上深入研究了很多关于 AI 的讨论。有一件事不断出现，那就是我们经常赋予 AI 类似人类的特征，比如情感或意图。虽然以这种方式与 AI 建立联系是有道理的，但我觉得它忽略了 AI 真正的大局。我不确定以前是否讨论过这个问题，但与其将 AI 视为人类智能的另一种形式，如果我们将它视为完全不同的东西，更像章鱼，会怎么样？ 章鱼非常聪明，但它们的智力以我们无法完全理解的方式运作。它们有一个分布式神经系统，以我们完全陌生的方式解决问题和探索世界。同样，AI 通过模式和数据处理信息的方式与我们的想法或感受并不完全匹配。我们不应该期待人工智能模仿人类的行为或情感，也许我们应该欣赏它的本质——一种具有自身优势的独特智能形式。这可以帮助我们更有效地使用人工智能，利用其在数据分析和模式识别等领域的能力，而不是试图让它像我们一样行事。 通过将人工智能视为根本不同的东西，我们可能会设定更现实的期望，并找到与这些系统协作的更好方法。这就像与一个真正聪明的工具合作，它只是思维方式不同，不一定更好或更坏，只是不同而已。我注意到很多人把人类的特征投射到人工智能上，这可能会导致对它能做什么和不能做什么的误解。    提交人    /u/ParticularSmell5285   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdl1k3/what_if_ai_was_viewed_as_a_alien_intelligence/</guid>
      <pubDate>Sun, 27 Oct 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>有哪些工作具有抵御人工智能的坚实护城河？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdg4nf/are_there_any_jobs_with_a_substantial_moat/</link>
      <description><![CDATA[似乎许多行业要么已经受到影响，要么即将受到影响。所以，我想知道：是否有任何工作对人工智能有强大的“护城河”——也就是说，在可预见的未来，这些职位不太可能被人工智能取代或严重颠覆？    提交人    /u/sessionletter   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdg4nf/are_there_any_jobs_with_a_substantial_moat/</guid>
      <pubDate>Sun, 27 Oct 2024 17:21:56 GMT</pubDate>
    </item>
    <item>
      <title>詹姆斯·卡梅伦对AGI发出警告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gddnoq/james_camerons_warning_on_agi/</link>
      <description><![CDATA[你对他所说的话有什么看法？ 在最近的 AI+机器人峰会上，传奇导演詹姆斯·卡梅隆分享了对通用人工智能 (AGI) 潜在风险的担忧。卡梅隆因《终结者》而闻名，这是一部关于人工智能失败的经典故事，现在他觉得 AGI 的现实可能比小说更“可怕”，尤其是在私营公司而不是政府手中。 卡梅隆认为，开发 AGI 的科技巨头可能会带来一个由企业动机塑造的世界，人们的数据和决策受到“外星”智能的影响。他警告说，这种转变可能会将我们推入“数字极权主义”时代，因为公司控制通信并监视我们的行动。 强调“监视资本主义”的概念，卡梅伦指出，当今的公司正在成为“人类善的仲裁者”——这是一个危险的先例，他认为这比他曾经想象过的虚构天网更令人不安。 虽然他支持人工智能的进步，但他警告说，AGI 将反映人类的缺陷。“善取决于我们善良的程度，恶取决于我们邪恶的程度，”他说。 在 YouTube 上观看他的完整演讲：https://youtu.be/e6Uq_5JemrI?si=r9bfMySikkvrRTkb     提交人    /u/cyberkite1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gddnoq/james_camerons_warning_on_agi/</guid>
      <pubDate>Sun, 27 Oct 2024 15:35:08 GMT</pubDate>
    </item>
    <item>
      <title>攻读兼职人工智能硕士学位有意义吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdd8ek/does_it_makes_sense_to_do_a_parttime_masters_in_ai/</link>
      <description><![CDATA[大家好， 我 30 岁出头，在一家数字服务提供商工作，薪水不错（接近六位数）。考虑到人工智能的快速发展及其巨大的未来潜力，攻读第二个人工智能硕士学位是否是一个明智的决定（第一个是管理学硕士学位）？此外，这项资格能否在未来几年大幅提高我在德国的收入潜力？ 提前谢谢。    提交人    /u/money-money-11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdd8ek/does_it_makes_sense_to_do_a_parttime_masters_in_ai/</guid>
      <pubDate>Sun, 27 Oct 2024 15:16:03 GMT</pubDate>
    </item>
    <item>
      <title>一个法学硕士就能统治所有吗？如果不是，这可能是一个巨大的泡沫吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcg8y/one_llm_to_rule_them_all_if_not_is_this_likely_a/</link>
      <description><![CDATA[ChatGPT、Claude、Perplexity、Gemini、Copilot……每月 20 美元。对于大众来说，很难区分它们，因为它们都做着几乎相同的事情，只有细微的差异。然后其中一个发布了一项新功能来弥补差距，然后重复一遍。跟上潮流是令人兴奋的，但与此同时，大众并不是技术人员。因此，考虑到这一点，是只有我一个人觉得这看起来像一个巨大的泡沫吗？毫无疑问，它有有效的用例，但作为一种商业模式，它似乎是不可持续的。即使是 Open Ai，这家我猜在非技术人员中最为知名的公司，也预测要到 2029 年才能盈利？可能是错的。所以我想我现在的理论是，除非一个 LLM 完全出类拔萃并脱颖而出，否则这种情况似乎有成为一个大泡沫的风险。你觉得呢？     由   提交  /u/AppropriateRespect91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcg8y/one_llm_to_rule_them_all_if_not_is_this_likely_a/</guid>
      <pubDate>Sun, 27 Oct 2024 14:40:12 GMT</pubDate>
    </item>
    </channel>
</rss>