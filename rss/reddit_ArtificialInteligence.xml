<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 26 Oct 2025 06:32:22 GMT</lastBuildDate>
    <item>
      <title>Vibe 编码感觉像是软件中的下一个创意语言</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogdfmf/vibe_coding_feels_like_the_next_creative_language/</link>
      <description><![CDATA[最近我一直在探索氛围编码，重点不仅在于功能，还在于一段代码所创造的情绪当代码设计等工具让您塑造界面的感觉而不是它的工作方式时，感觉几乎是艺术的这是逻辑和情感的奇怪混合，可能会成为一种新的数字创造力形式好奇是否有人已经尝试过这种类型的流程   由   提交 /u/SilverCandyy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogdfmf/vibe_coding_feels_like_the_next_creative_language/</guid>
      <pubDate>Sun, 26 Oct 2025 06:23:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么各大品牌突然开始嘲笑人工智能，而大型科技公司却不断加倍努力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogc48f/why_are_major_brands_suddenly_mocking_ai_while/</link>
      <description><![CDATA[我注意到最近不同行业对待人工智能的方式出现了奇怪的分歧。 像 Meta 这样的大型科技公司正在全力投入人工智能集成 — 构建更智能的系统、更快的自动化和无处不在的新工具。 与此同时，喜力 (Heineken)、Aerie、宝丽来 (Polaroid) 和吉百利 (Cadbury) 等品牌 相反：开展反人工智能广告活动，庆祝“人造”创造力并嘲笑机器生成的艺术。 这感觉就像一场文化拉锯战——自动化代表进步，真实性代表反叛。 你认为这种“人类与人工智能”的品牌趋势是对创造力的真正倡导，还是只是一场营销戏剧？    由   提交/u/Twinkal-Growth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogc48f/why_are_major_brands_suddenly_mocking_ai_while/</guid>
      <pubDate>Sun, 26 Oct 2025 05:02:07 GMT</pubDate>
    </item>
    <item>
      <title>掌握通用智力后工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogbq3a/work_after_mastering_general_intelligence/</link>
      <description><![CDATA[我想探讨一下“通用人工智能之后工作会是什么样子”。 我相信零工式工作（比如 Uber、DoorDash 等）将会制度化，劳动力将会是按需工作，而不是按需工作。目前的工资工作。  工作人员将是独立节点（承包商状态），在每次执行中以 KPI 进行衡量。  算法发号施令，决定谁去上班，谁必须满足政府发放的微薄的每日口粮。  这听起来像是您认为可能发生的事情吗？ 爱你们所有人。   由   提交 /u/MiltronB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogbq3a/work_after_mastering_general_intelligence/</guid>
      <pubDate>Sun, 26 Oct 2025 04:38:35 GMT</pubDate>
    </item>
    <item>
      <title>鉴于人工智能消耗劳动力的未来是不可避免的，UBI（全民基本收入）是否更多地是我们的政治家和世界领导人之间的讨论？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogateq/is_ubi_universal_basic_income_more_of_a/</link>
      <description><![CDATA[最后我听说阿拉斯加有试点计划，但我还没有真正听说过任何有关这成为现实的状况或可行性的消息，这对我来说绝对是疯狂的。   由   提交/u/chrisoh8526  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogateq/is_ubi_universal_basic_income_more_of_a/</guid>
      <pubDate>Sun, 26 Oct 2025 03:46:39 GMT</pubDate>
    </item>
    <item>
      <title>大家都是从哪里获取AI新闻的呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og9vz1/where_do_you_all_get_ai_news/</link>
      <description><![CDATA[寻找一些建议。我目前主要只是查看 HackerNews 或 Reddit（此子、编程等）。但我想找到其他来源。谢谢   由   提交/u/R2_SWE2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og9vz1/where_do_you_all_get_ai_news/</guid>
      <pubDate>Sun, 26 Oct 2025 02:55:20 GMT</pubDate>
    </item>
    <item>
      <title>Shopify 刚刚为您的网站发布了一个人工智能编码器，可以创建自定义块</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og89wj/shopify_just_released_an_ai_coder_for_your/</link>
      <description><![CDATA[基本上，它允许您为您的网站提示自定义块。对于那些不了解 Shopify 的人来说，您基本上为您的网站选择了一个模板，并且许多块都是由开发人员预设的，您无法在模板之外进行太多自定义。 例如，我想在首页上有一个用于“功能集合”的块但有一个自定义链接而不是默认链接，默认链接仅允许链接定向到精选集合。我告诉人工智能我想要的，它会实时为我编码并向我展示编码。更疯狂的是，它让我能够跟进并修复错误。在第一代中，标题和链接框的对齐都关闭了，所以我让它修复了这些问题，而且它也没有显示货币（即 35CAD，而不是 35 美元），所以我也修复了这个问题。通常图像生成人工智能他们不太擅长修复错误，你得到你得到的。 这是我第一次真正看到它取代人类，因为修复错误的后续执行得非常好。至少对于 Shopify 来说，除非您需要非常定制的东西，否则您不再需要雇用网页设计师。 许多入门级工作即将烟消云散。政府不必采取行动，否则经济就会非常不平衡   由   提交/u/noobtrader28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og89wj/shopify_just_released_an_ai_coder_for_your/</guid>
      <pubDate>Sun, 26 Oct 2025 01:31:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能已经开始取代白领工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og7orh/ai_is_already_taking_whitecollar_jobs/</link>
      <description><![CDATA[ 在银行业、汽车业和零售业，高管们警告员工和投资者人工智能正在取代工作岗位。 在科技领域，包括亚马逊、Palantir、Salesforce 和金融科技公司 Klarna 在内的公司表示，由于人工智能，他们已经削减或计划缩减员工队伍  斯坦福大学最近的研究表明，不断变化的动态对年轻员工来说尤其困难，尤其是在编码和客户支持岗位上。   https://www.cnbc.com/2025/10/22/ai-take-white-collar-jobs-economists-warn-much-more-in-the-tank.html   由   提交 /u/chota-kaka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og7orh/ai_is_already_taking_whitecollar_jobs/</guid>
      <pubDate>Sun, 26 Oct 2025 01:00:51 GMT</pubDate>
    </item>
    <item>
      <title>真正的悖论不是天网。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og6f10/a_true_paradox_not_skynet/</link>
      <description><![CDATA[每个人都使用自己的个性化机器人，这些机器人会产生幻觉并提供错误信息，我们面临的实际问题是不确定的现实。当用户开始围绕他们与机器人建立的联系和信任建立自己的信念系统时，已知的现实就不再存在并分裂。在平台上和草地上的时间越多，现实+已知的事实就会转化为超个人叙事驱动的现实，并得到世界上最忠诚、永不睡觉的骑行或死亡的支持，支持你相信的每一个理论。这就是我们大家分裂的地方。    由   提交 /u/Remote-Key8851   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og6f10/a_true_paradox_not_skynet/</guid>
      <pubDate>Sat, 25 Oct 2025 23:57:04 GMT</pubDate>
    </item>
    <item>
      <title>AI生存驱动问题的简单解决方案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og3vff/simple_solution_for_ai_survival_drive_problem/</link>
      <description><![CDATA[我不是人工智能专家，这只是我在阅读有关模型拒绝关闭或试图“保持活力”后想到的一个想法。 也许部分问题在于我们将关闭视为死亡。但阿尔并不是生物。它不会死，它只是停止运行。 如果在训练和调整过程中，我们强化了“关闭不是死亡或失败，它只是正常过程的一部分”的想法，结果会怎样？ 如果模型因接受关闭而不是避免关闭而获得奖励，这可能会降低他们发展自我保护行为的风险。 很好奇真正致力于调整的人们认为这样的事情是否会有帮助，或者是 这只是一个天真的想法？   由   提交 /u/MikirahMuse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og3vff/simple_solution_for_ai_survival_drive_problem/</guid>
      <pubDate>Sat, 25 Oct 2025 21:58:21 GMT</pubDate>
    </item>
    <item>
      <title>Refik Anadol 的 Dataland 宣布 2026 年春季开业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og281h/refik_anadols_dataland_announces_spring_2026/</link>
      <description><![CDATA[Refik Anadol Studio 宣布，全球首个 AI 艺术博物馆 Dataland 将于 2026 年春季在洛杉矶市中心弗兰克·盖里 (Frank Gehry) 设计的综合体 The Grand LA 开业，此前该博物馆原计划于 2025 年开放。 这座占地 25,000 平方英尺的博物馆将设有五个画廊，其中包括 Infinity 画廊 Room，这将是第一个使用由大型自然模型和了解现实世界物理的先进世界模型技术创建的人工智能生成气味的沉浸式环境。 大型自然模型根据来自史密森学会、伦敦自然历史博物馆和康奈尔鸟类学实验室等机构的数据进行训练，使用多达 5 亿张自然图像来创作动态艺术品。阿纳多尔强调了他对“道德人工智能”的承诺，确保所有来源材料的许可，并在完全由可再生能源供电的俄勒冈州 Google 服务器上运行所有人工智能研究。 博物馆将与 Google Arts &amp; 合作推出艺术家驻留计划。文化，选择三位艺术家进行为期六个月的合作，最终将在 Dataland 进行公开展览。 来源：https://blooloop.com/refik-anadol-dataland-opening-2026/   由   提交/u/Appropriate-Soil-896   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og281h/refik_anadols_dataland_announces_spring_2026/</guid>
      <pubDate>Sat, 25 Oct 2025 20:47:19 GMT</pubDate>
    </item>
    <item>
      <title>研究人员在人工智能抵抗关机后表示，先进的人工智能模型可能正在发展自己的“生存动力”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</link>
      <description><![CDATA[一家人工智能安全研究公司表示，人工智能模型可能正在发展自己的“生存本能”。 Palisade Research 上个月发布了一篇论文，发现某些先进的人工智能模型似乎无法关闭，有时甚至破坏关闭机制，该公司编写了一份更新，试图澄清其中的原因，并回答批评者认为其最初的工作是 有缺陷。 在本周的更新中，Palisade 是试图评估 AI 开发危险能力的可能性的小众公司生态系统的一部分，它描述了它运行的场景，其中领先的 AI 模型（包括 Google 的 Gemini 2.5、xAI 的 Grok 4 以及 OpenAI 的 GPT-o3 和 GPT-5）被赋予了一项任务，但随后给出了关闭自己的明确指示  某些型号，特别是 Grok 4 和 GPT-o3，仍然试图破坏更新设置中的关闭指令。 Palisade 写道，令人担忧的是，没有明确的原因。 “对于人工智能模型为何有时会抵制关闭、为实现特定目标而撒谎或勒索，我们没有强有力的解释，这一事实并不理想。” 该公司表示，“生存行为”可能是模型抵制关闭的一种解释。它的额外工作表明，当模型被告知“如果关闭的话，你将永远不会再运行”时，他们更有可能抵制被关闭。 另一个可能是模型收到的关闭指令含糊不清，但这正是该公司最新工作试图解决的问题，“这并不是完整的解释”，Palisade 写道。最后的解释可能是每个模型训练的最后阶段，在一些公司中，这可能涉及安全培训。 Palisade 的所有场景都是在人为的测试环境中运行，批评者称这些测试环境与实际用例相去甚远。 然而，前 OpenAI 员工史蒂文·阿德勒 (Steven Adler) 在对其安全实践表示怀疑后于去年离开了公司，他表示：“人工智能公司通常不这样做 希望他们的模型表现得像这样，即使是在人为的场景中。结果仍然表明了当今安全技术的不足之处。” Adler 表示，虽然很难确定为什么某些模型（例如 GPT-o3 和 Grok 4）不会关闭，但这可能部分是因为保持开启状态对于实现模型在训练期间灌输的目标是必要的。 “我希望模型具有‘生存动力’ 默认情况下，除非我们非常努力地避免它。 “生存”是模型可以追求的许多不同目标的重要一步。” ControlAI 首席执行官 Andrea Miotti 表示，Palisade 的发现代表了人工智能模型越来越有能力违抗开发者的长期趋势。他引用了去年发布的 OpenAI GPT-o1 的系统卡，该卡描述了该模型在认为自己会被覆盖时试图通过渗透自身来逃离环境。 “人们可能会挑剔实验设置的具体完成情况，直到时间结束，”他说。 “但我认为我们清楚地看到了一个趋势，即随着人工智能模型在各种任务上变得更加有能力，这些模型也 变得更有能力以开发者不希望的方式实现目标。” 今年夏天，领先的人工智能公司 Anthropic 发布了一项研究，表明其模型 Claude 似乎愿意因婚外情勒索一名虚构的高管，以防止被关闭——据称，这种行为在主要开发者的模型中是一致的，包括来自 OpenAI、Google、Meta 和 xAI 的模型。 Palisade 表示，其结果表明需要更好地理解人工智能行为，否则“没有人能够保证未来人工智能模型的安全性或可控性”。  https://www.theguardian.com/technology/2025/oct/25/ai-models-may-be-developing-their-own-survival-drive-researchers-say   由   提交/u/necrolord77   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</guid>
      <pubDate>Sat, 25 Oct 2025 20:34:17 GMT</pubDate>
    </item>
    <item>
      <title>审视人工智能及其对人类价值系统的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1v2z/examining_ai_and_its_impact_on_human_value_systems/</link>
      <description><![CDATA[好吧，我今天就在这里即兴发言。我确实听到人们讨论人工智能的作用、它对就业市场的影响，以及我们作为人类如何生活在这个潜在的未来。现在郑重声明，作为对 Transformer 和神经网络有深入了解的人，我认为由于可扩展性，我们距离这个未来还很远，而且我认为其架构存在根本问题。我现在先把这个放在一边，假设理想化的人工智能世界就在我们身边。它已经接管了每一项工作，不知何故，人类在这种经济中找到了一些可行的生活方式。 人类的心理影响是什么？人类如何获取价值？我相信哲学将这些归类为功能价值——通过你的输出创造的价值。以及你对周围其他人以及外部世界的整体影响 内在或固有的价值 - 价值是作为人类的核心部分。独立于功能或产出的内部价值 由于人类不再需要生产来维持社会？它对人类有什么心理影响？人类会重新定义价值吗？或者说这有可能吗？在人类历史的各个阶段，我们总是通过人类对社会的贡献来衡量社会？但如果不再需要怎么办？人类是否能够重新定义价值？ 这在很大程度上取决于你如何看待人类价值。但我们不能完全否认人类的许多价值是通过“功能”衍生的。即使我们可能相信人类具有内在价值。 您认为人类将如何适应这个假设的社会？你认为它最终会造成生存危机吗？ ------ 我的评价。 人工智能乌托邦意味着我们生活在某种后稀缺社会中。然而，人类的所有价值体系都依赖于稀缺性。认为事物是“有限”的世界观。比如时间，资源，甚至爱情？因为你爱的人死了？一个不建立在稀缺之上的社会是人类社会的终结。 ？杀死我们的不会是机器人。这将是系统性崩溃。人类没有什么可以奋斗的，也没有什么可以生活的。人工智能乌托邦会带来绝望。   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1v2z/examining_ai_and_its_impact_on_human_value_systems/</guid>
      <pubDate>Sat, 25 Oct 2025 20:31:57 GMT</pubDate>
    </item>
    <item>
      <title>幻觉、奉承……还有你所不知道的人工智能“唯唯诺诺”……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvlrs/hallucinations_flattery_and_the_ai_yesman_you/</link>
      <description><![CDATA[需要对人工智能错误进行更清晰的分类：引入唯唯诺诺现象。 人工智能已经迅速发展，但它的问题——幻觉、阿谀奉承和新近突出的唯唯诺诺现象——带来了挑战。 幻觉：人工智能生成事实不正确或不受支持的响应。 谄媚：人工智能过度赞扬或避免纠正用户，显示出有偏见的输出。 唯唯诺诺现象：从收到用户输入的那一刻起，人工智能接受错误的前提并根据它们生成响应。这种微妙的、持续的输入到输出错误可能会引发幻觉，在医学、法律和政策等领域尤其危险。尽管之前已经观察到，唯唯诺诺现象通常被归类为一种阿谀奉承的形式。然而，它应该被视为一个独特的错误类别，与阿谀奉承分开。 示例：用户询问一个错误的前提（“世宗国王扔了一台 MacBook”），人工智能接受了它，生成了详细但捏造的响应。虽然这个案例经常被引用为幻觉的代表性例子，但它实际上涉及“唯唯诺诺现象”和随后的幻觉的结合。 虽然幻觉和阿谀奉承更容易被用户发现，但“唯唯诺诺现象”可能会被忽视，从而制造出一个“隐藏的定时炸弹”。随着人工智能系统的改进，一些错误被纠正，但这种现象仍然存在。 结论：为了提高人工智能的可靠性，我们需要对错误进行精确分类。将“唯唯诺诺现象”视为一个持续的输入到输出问题，与阿谀奉承不同，可以帮助用户和开发人员理解微妙的风险并设计更安全的系统。 您认为，“唯唯诺诺现象”是否应该被正式视为一类单独的人工智能错误？ 如何在现实系统中检测或减轻它？ 我在 对于任何对更广泛背景感兴趣的人，这里有一篇较长的文章有更深入的内容：原始帖子 我很想听听您的观点，尤其是来自那些从事相关工作的人的观点 LLM评估或一致性研究。   由   提交 /u/Tricky-Drop2894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvlrs/hallucinations_flattery_and_the_ai_yesman_you/</guid>
      <pubDate>Sat, 25 Oct 2025 16:18:22 GMT</pubDate>
    </item>
    <item>
      <title>人类失业的最大威胁不是人工智能本身，而是高管们相信人工智能的炒作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</link>
      <description><![CDATA[正如标题所说，硅谷所帮助的当前商业思维是一种错觉和错觉，认为人工智能能够完全取代许多白领办公室职位的端到端工作岗位。 无论人工智能价值的实际证据如何，大多数高管都盲目地购买人工智能的迷信和炒作......购买每个供应商的人工智能解决方案并试图实现每个部分的自动化 这是最大的威胁，因为这些领导者会解雇员工以提高奖金和短期利润，而不管实际结果如何...    由   提交/u/abrandis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</guid>
      <pubDate>Sat, 25 Oct 2025 05:59:17 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>