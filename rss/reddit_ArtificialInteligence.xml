<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 10 Jan 2025 01:40:00 GMT</lastBuildDate>
    <item>
      <title>对于那些在人工智能兴起之前就读的学生来说，人工智能实际上如何帮助你？你能注意到差异吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxranb/for_those_currently_in_school_who_were_in_school/</link>
      <description><![CDATA[我去年写过这篇文章：抓住时机：为什么现在是重返校园的最佳时机。所以我想我应该弄清楚这到底是怎么回事，看看它是否真的有帮助。 https://medium.com/@olimiemma/seize-the-moment-why-now-is-the-perfect-time-to-go-back-to-school-041275bfebab    提交人    /u/Pay-Me-No-Mind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxranb/for_those_currently_in_school_who_were_in_school/</guid>
      <pubDate>Fri, 10 Jan 2025 00:05:14 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以自我训练吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxqsvd/can_ai_train_itself/</link>
      <description><![CDATA[当 AI 聊天机器人生成输出时，AI 是否会根据其创建的输出数据进行自我训练？如果没有，为什么它不能这样做？这似乎是它获取训练数据的一种非常简单的方法。另一方面，它确实似乎是循环的。    提交人    /u/DontTread76   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxqsvd/can_ai_train_itself/</guid>
      <pubDate>Thu, 09 Jan 2025 23:42:03 GMT</pubDate>
    </item>
    <item>
      <title>虚拟细胞是科学的“圣杯”。它正在越来越接近。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxn5tn/a_virtual_cell_is_a_holy_grail_of_science_its/</link>
      <description><![CDATA[Matteo Wong：“加快细胞研究可以为人类带来巨大的成果——新药和疫苗、癌症治疗，甚至只是对塑造我们生活的基本过程的更深入了解。而且这已经开始发生了。科学家们现在正在设计计算机程序，这些程序可能会解锁模拟人类细胞的能力，使研究人员能够预测药物、突变、病毒或身体中任何其他变化的影响，从而使物理实验更有针对性，更有可能成功。卡内基梅隆大学计算机科学家、阿拉伯联合酋长国穆罕默德·本·扎耶德人工智能大学校长 Eric Xing 告诉我，受 ChatGPT 等大型语言模型的启发，人们希望生成式人工智能能够“解码生物语言，然后说出生物语言”。 https://theatln.tc/NUbo5zTi “就像聊天机器人可以从大量书面语言中辨别风格甚至含义，然后用它来构建类似人类的散文一样，人工智能理论上也可以接受大量生物数据的训练，以提取有关细胞甚至整个生物体的关键信息。这将使研究人员能够创建体内许多细胞的虚拟模型，并对其采取行动。斯坦福大学细胞生物学家 Emma Lundberg 告诉我：“这是生物学的圣杯。” “人们多年来一直梦想着它。” “这些夸张的说法——关于生成式人工智能这种模糊且有争议的技术——听起来可能与技术高管的自私预言非常相似：OpenAI 的 Sam Altman、Google DeepMind 的 Demis Hassabis 和 Anthropic 的 Dario Amodei 都宣称他们的人工智能产品将很快彻底改变医学。 “然而，如果生成式人工智能确实实现了这些愿景，那么结果可能看起来就像 Xing、Lundberg 和其他人一直致力于实现的虚拟细胞……即使在早期——科学家告诉我，这种方法如果被证明可行，可能需要 10 年或 100 年才能完全实现——这表明该技术的最终好处可能不是来自聊天机器人，而是来自更雄心勃勃的东西。” 在此处阅读更多信息：https://theatln.tc/NUbo5zTi    由    /u/theatlantic  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxn5tn/a_virtual_cell_is_a_holy_grail_of_science_its/</guid>
      <pubDate>Thu, 09 Jan 2025 21:01:42 GMT</pubDate>
    </item>
    <item>
      <title>利用可解释的人工智能进行 LLM 文本归因分析，区分人工撰写的文本和多个 LLM-G 文本</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmzp3/leveraging_explainable_ai_for_llm_text/</link>
      <description><![CDATA[我每天都会查找和总结有趣的 AI 研究论文，这样您就不必费力地浏览所有论文。今天的论文题为“利用可解释的 AI 进行 LLM 文本归因：区分人工编写的文本和多个 LLM 生成的文本”，作者是 Ayat Najjar、Huthaifa I. Ashqar、Omar Darwish 和 Eman Hammad。 本文解决了文本来源识别方面的重大挑战，区分了人工编写的文本和由各种大型语言模型 (LLM) 生成的文章。它阐明了随着人工智能生成的文本的兴起，辨别和归因内容的迫切需要，这对学术诚信和内容原创性具有影响。 主要亮点包括：  双相分类：该方法涉及二元分类以区分人类编写的文本和人工智能生成的文本，然后进行多类分类以区分由五个不同的 LLM 生成的文本：ChatGPT、LLaMA、Google Bard、Claude 和 Perplexity。 准确性和性能：所提出的模型实现了极高的准确率，超越了 GPTZero 等现有模型。论文报告的准确率为 98.5%，而 GPTZero 的准确率为 78.3%，表明在识别完整数据集方面有了显着的改善。 可解释的 AI 集成：使用可解释的 AI (XAI) 技术，研究人员增强了模型透明度，有助于理解决定文本归因的重要特征。该方法有助于创建详细的作者资料，这对于强大的抄袭检测至关重要。 数据集管理：研究中的一个关键步骤是开发一个包含人工编写和 LLM 生成的文本的综合数据集，这有助于测试和改进模型。 抄袭检测：该研究通过强调特定 LLM 工具独有的风格和结构元素，提供了更准确的抄袭检测途径，增强了内容原创性的验证。  这项研究为日益依赖人工智能的世界中内容归属日益严峻的挑战提出了有效的解决方案，为更准确的文本来源验证铺平了道路。 您可以在此处查看完整细分：这里您可以在此处获取完整的原始研究论文：原始论文    提交人    /u/steves1189   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmzp3/leveraging_explainable_ai_for_llm_text/</guid>
      <pubDate>Thu, 09 Jan 2025 20:54:27 GMT</pubDate>
    </item>
    <item>
      <title>人工智能辅助路线规划调查</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmni5/survey_on_ai_assisted_routing/</link>
      <description><![CDATA[大家好， 我想请你们帮帮我。我目前正在学习和撰写一篇关于人工智能辅助路线的论文。为了完成这篇论文，我需要进行一项调查。这项调查非常简单、匿名，最多需要 15 分钟才能填写完毕。如果你们能帮助我，我会非常高兴。这是调查的链接 https://wiwigoettingen.eu.qualtrics.com/jfe/form/SV_8i7Lokn6cV5ToUe    提交人    /u/Fair_Dirt_7169   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmni5/survey_on_ai_assisted_routing/</guid>
      <pubDate>Thu, 09 Jan 2025 20:40:03 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人在研究这个想法吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmgoe/is_anyone_else_working_on_this_idea/</link>
      <description><![CDATA[我曾有这个想法，使用逆向强化学习来为法学硕士 (LLM) 检测用户的目标，然后帮助他们实现所检测到的目标。这个想法似乎太简单、太重要了，其他人不应该不研究它。我在 Google Scholar 中查找，我能找到的最接近的东西是协作逆向强化学习。还有其他人在研究这个吗？ 这个想法对我来说非常重要，我打算在写完这篇文章后练习为我的爷爷写一份推销材料。我不认为我具备研究技能来迭代这个想法的细节，所以我能做的最好的事情就是让其他人研究它。希望你们开始研究它，或者也许我会发现已经有一群人在研究它了。我只是认为这是让人工智能帮助人类的最重要和最直接的一步，因为它的奖励功能实际上是为他人服务。 我认为已经有足够的研究来让这个想法发挥作用，但我希望看到开发的一个想法是如何使用视频源之类的东西对多个代理进行逆向强化学习。想到这些想法真的很重要，而我却认为我有足够的脑力来拼凑研究论文，而不是提出原创研究，这让我很痛苦。 从字面上看，它的奖励功能就是为他人服务。为什么这么简单的想法没有引起任何关注？！ 编辑：这是我写的简短销售宣传： 想象一下，一个人工智能会不遗余力地问你喜欢什么，而不是等你告诉它。想象一下，一个人工智能会用最甜蜜、最有爱心和最友好的方式与你交谈，而不是一些公司商务用语。想象一下，一个人工智能会从你对它的回应方式中检测出你最微妙的偏好。想象一下，即使你目光短浅，无法抵挡诱惑，人工智能也会将你的最大利益放在心上。 有一种更简单的方法来实现它，即让所有用户更加相爱。我想还有一种更难实现的方法，即让用户不加区别地更加爱护每个人。 这不仅仅是幻想。它基于非常具体的逆向强化学习理念。    提交人    /u/NeuroPyrox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmgoe/is_anyone_else_working_on_this_idea/</guid>
      <pubDate>Thu, 09 Jan 2025 20:31:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Leonardo AI：利用 Leonardo AI 掌握 AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmbr0/how_to_use_leonardo_ai_mastering_ai_with_leonardo/</link>
      <description><![CDATA[想要创作令人惊叹的 AI 生成艺术作品？在本视频中，我将向您展示如何使用 Leonardo AI，这是一款功能强大的 AI 工具，只需单击几下即可生成令人惊叹、逼真的艺术作品。  无论您是初学者还是经验丰富的数字艺术家，本教程都将引导您了解基本功能、分步说明和创意技巧，以帮助您充分发挥 AI 的艺术潜力。 https://youtu.be/fnRcNrhnXeQ    提交人    /u/Chisom1998_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmbr0/how_to_use_leonardo_ai_mastering_ai_with_leonardo/</guid>
      <pubDate>Thu, 09 Jan 2025 20:26:08 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek v3 的思路链为何如此有效？看示例</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxltnt/how_does_deepseek_v3s_chain_of_thought_work_so/</link>
      <description><![CDATA[我尝试了 DeepSeek v3 的思维链推理，基于树的思维链具有回溯其步骤的能力，让我措手不及。 有人有过类似的经历吗？或者任何其他模型？老实说，我没有使用过 O1 Pro，但最初的 o1-preview 和 Gemini 2 的 COT 并不那么复杂。 有什么线索可以说明他们是如何做到的？就 COT 而言，当前的 SOTA 是什么？ 在评论中添加实际的想法。它很庞大，因为它思考了 88 秒并给出了深思熟虑的答案。 COT 要点链接：https://gist.github.com/rajatady/11dbf4c65046c4bb4688c1c4b07122b0    提交人    /u/Consistent_Yak6765   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxltnt/how_does_deepseek_v3s_chain_of_thought_work_so/</guid>
      <pubDate>Thu, 09 Jan 2025 20:04:45 GMT</pubDate>
    </item>
    <item>
      <title>个人人工智能克隆：仅仅经过 2 小时的对话，谷歌就能创造出你个性的数字版本——我不知道对此该作何感想......</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxkp9a/personal_ai_clones_after_just_2_hours_of/</link>
      <description><![CDATA[刚刚阅读了谷歌/斯坦福关于人工智能个性复制的最新研究，它既令人印象深刻又令人担忧。他们开发了一个系统，可以通过一次两小时的采访以 85%（无论这到底意味着什么）的准确率模拟个人决策模式。 技术方法是可靠的：1,052 名参与者，结构化访谈，根据 GSS 和 BFI 框架进行验证。每次采访产生约 6.5k 个单词，足以训练个性化人工智能模型。有趣的是，经济决策游戏中的准确率下降到 66%，这表明当前的建模能力存在局限性。 影响重大：对研究和政策测试很有价值，但对安全性令人担忧。当前的深度伪造骗局已经存在问题——加上个性复制，社会工程学将变得更加危险。 很想听听科技界其他人的想法。我们应该推动哪些保障措施？我们如何在研究实用性和隐私问题之间划清界限？ https://gizmodo.com/google-researchers-can-create-an-ai-that-thinks-a-lot-like-you-after-just-a-two-hour-interview-2000547704    提交人    /u/iamkrulliam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxkp9a/personal_ai_clones_after_just_2_hours_of/</guid>
      <pubDate>Thu, 09 Jan 2025 19:17:52 GMT</pubDate>
    </item>
    <item>
      <title>人工智能如何避免从错误信息中“学习”？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxk3sd/how_does_ai_avoid_learning_from_misinformation/</link>
      <description><![CDATA[人工智能基本上是在“互联网”这个数据集上进行“训练”的。互联网包含错误信息，也包含事实。那么“训练过程”如何避免受到错误信息的影响？ 进一步思考，互联网充满了虚构、喜剧、讽刺等。人工智能的学习过程如何避免受到这些内容的影响？    提交人    /u/Steerpike58   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxk3sd/how_does_ai_avoid_learning_from_misinformation/</guid>
      <pubDate>Thu, 09 Jan 2025 18:52:57 GMT</pubDate>
    </item>
    <item>
      <title>加州警报：人工智能在加州野火扑灭中冲锋在前线</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxcbk5/alert_california_ai_takes_the_frontline_in/</link>
      <description><![CDATA[关键要点  南加州消防员使用 ALERT California 等 AI 系统快速探测野火； ALERT California 的 1,000 个摄像头网络使用机器学习来监控和标记火灾风险； 全天候团队审查 AI 标记的镜头，以通知消防机构潜在火灾。  来源：https://www.bitdegree.org/crypto/news/alert-california-ai-takes-the-frontline-in-battling-californias-wildfires?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=r-ai-takes-the-frontline-in-battling-wildfires    提交人    /u/webbs3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxcbk5/alert_california_ai_takes_the_frontline_in/</guid>
      <pubDate>Thu, 09 Jan 2025 13:03:16 GMT</pubDate>
    </item>
    <item>
      <title>如果我们希望人工智能取得成功，我们就需要人工智能的这一传奇失败并结束</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hx9sk4/if_we_want_ai_to_succeed_we_need_this_saga_of_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hx9sk4/if_we_want_ai_to_succeed_we_need_this_saga_of_ai/</guid>
      <pubDate>Thu, 09 Jan 2025 10:18:50 GMT</pubDate>
    </item>
    <item>
      <title>什么是情报？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hx8vd2/what_is_intelligence/</link>
      <description><![CDATA[牛津高阶英汉双解词典将智能定义为学习、理解和逻辑思考事物的能力。 但从根本上讲，这到底意味着什么？ 业界似乎高度专注于迭代预先训练的 LLM，这些 LLM 可在数据集中找到模式，并根据训练生成输出。但这真的是智能吗？ 这些模型本身并不理解任何东西。它们接受输入、识别模式并产生与训练期间看到的场景最相似的输出。这与我对智能的理解不一致 - 感觉更像是复杂的模式匹配。 我探索了许多兔子洞，从使用传统 AI 构建交易机器人到映射数据集中的预定义关系模式以获得真正的商业智能（业内人士称之为 BI）。而我不断回到同一个基本事实： 智能不是关于反刍 - 而是关于关系。它是关于理解数据之间的固有关系，并观察这些关系在从不同角度或上下文来看时如何演变。 现有的强力张量训练无法提供透明度或对决策的真正洞察。它只是提供与其训练/测试参数“最接近匹配”的输出。没有真正的理解感，没有深度。 那么，我问你：你如何定义智能？你认为我们目前的方法缺少什么？ xoxo    提交人    /u/Internal_Vibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hx8vd2/what_is_intelligence/</guid>
      <pubDate>Thu, 09 Jan 2025 09:08:03 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>