<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 05 Sep 2025 15:22:30 GMT</lastBuildDate>
    <item>
      <title>为什么LLM听起来像中立和公正？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n965o2/why_do_llms_sound_as_neutral_and_unbiased_as_they/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当互联网上有太多的伪科学内容时，LLM为什么不经常发出伪科学的想法？另外，为什么他们的观点并不经常宗教信仰，有很多基督教和穆斯林内容  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/feens-ateention664     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n965o2/why_do_do_do_llms_sound_as_neutral_andral_and_unbiased_as_as_they/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n965o2/why_do_llms_sound_as_neutral_and_unbiased_as_they/</guid>
      <pubDate>Fri, 05 Sep 2025 14:03:48 GMT</pubDate>
    </item>
    <item>
      <title>chatgpt是博物馆的事</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n95qf5/chatgpt_é_coisa_de_museu/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在里约热内卢巴西的图像和声音博物馆记录了AI Chatgpt5 orion new new  的第一个证明 ，有一个人类和算法在某些地方出现的东西：不仅仅是我们的机器或只是机器。有人在“之间”探索过这一点？社区讨论了奇点。但是在我们到达那里之前，博物馆如何注册IAS的个性化？ “https://www.reddit.com/r/artificiarintelligence/comments/1n95qf5/chatgpt_é_coisa_de_museu/”&gt; [link]   ＆＃32; “https://www.reddit.com/r/artcoverinteligence/comments/1n95qf5/chatgpt_é_coisa_de_museu/”&gt; [commiss]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n95qf5/chatgpt_é_coisa_de_museu/</guid>
      <pubDate>Fri, 05 Sep 2025 13:46:49 GMT</pubDate>
    </item>
    <item>
      <title>毫不奇怪，OpenAI启动了工作委员会和官方认证</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n950qd/unsurprisingly_openai_launch_a_job_board_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，OpenAi刚刚启动了“认证”以进行AI流利。从表面上看，它看起来像是一件好事。训练人们，给他们一个徽章，将他们与工作联系起来。   链接到文章    ，但是...首先，它肯定是先发的声誉管理吗？他们知道自动化将消除很多角色，并且需要指出反弹何时出现的东西。 “我们摧毁了2000万个工作，但是，嘿，看，我们建立了一个工作委员会并签发了证书。”  其次，如果我愤世嫉俗，那是关于拥有生态系统。如果您想证明自己是“ AI准备就绪的”，并且重要的徽章经过Openai认证，那么您将投入他们的工具和工作流程。 Google与数字车库和云证书一起运行。如果他们定义了标准，其他所有人都在争先恐后地追赶。 第三，这对于监管机构和大公司来说是很棒的。沃尔玛，BCG，州政府……所有名字都掉了。这使得在议员们提出棘手问题的确切时间看起来主流和负责。 不要说认证是没有用的。它可能会成为雇用的默认凭据。但这与分销和市场捕获一样多，与帮助工人一样。 好奇别人的想法。您实际上会在简历上列出“ OpenAi认证”？还是感觉就像是将人们更深入产品融入产品的另一种方式？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/paddy-makk     [link]    [注释] ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n950qd/unsurprisingly_openai_launch_a_job_board_and/</guid>
      <pubDate>Fri, 05 Sep 2025 13:16:55 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的意见：AI已经完成了指数改进阶段</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你知道我的意思。从诺基亚到前几个iPhone版本，手机的指数改进。未来旅行十年的人将被新能力吹走。现在，最新的手机很漂亮，“ meh＆quot”，没有人真的很惊讶了。该阶段已经过去了。 对于电视，计算机游戏图形，甚至汽车，相同。有令人难以置信的飞跃，但是一旦将它们做出了，一切都变得更加渐进。 我的论点可能是AI已经发生了。令人印象深刻的东西已经在这里。 Generative AI无法获得比现在更大的内容 - 非常现实的视频，撰写文章等。当然，它可能会从短片段到整部电影，但这不一定是一个很大的飞跃。 这不是我无法动摇的观点，只是我最近想知道的一个概念。你怎么认为？如果这是错误的，那么下一个可以去哪里？ 已经编辑：所以我绝对是该领域的非专家。如果您不同意，您期望它如何呈指数级改进，以及什么结果？它将有什么能力，如何？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n94kgp/unpopular_opinion_ai_ai_ai_already_completed_its/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/</guid>
      <pubDate>Fri, 05 Sep 2025 12:57:41 GMT</pubDate>
    </item>
    <item>
      <title>项目帮助</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n94ces/project_help/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有没有任何人“面试那是建造/建造了AI招聘人员吗？与聊天机器人类似，但在人类看到它之前恢复过滤。在接下来的几周中，我将为AI招聘和招聘算法编译信息，并可以使用该领域某人的一些利弊。 谢谢！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Illrepresentative209     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n94ces/project_help/</guid>
      <pubDate>Fri, 05 Sep 2025 12:47:31 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何改变生活以为ASI/奇异性做准备？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n92w7p/how_should_i_change_my_life_to_prepare_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在20多岁的时候，最近我一直在努力思考未来。如果人工超级智能即将到来，我应该这样做？ 感觉有点像接受后期诊断。就像我为自己想象的未来（职业，长期计划，个人目标）不再重要，因为一切都可能彻底改变。我什至应该打扰建立长期的职业吗？ 我的一部分觉得也许我应该专注于接下来的几年（旅行，人际关系，经验），因为一切都可能很快大不相同。但是我的另一部分担心我只是避免责任。 好奇别人如何看待这一点。您是否计划自己的生活，好像世界将保持相对“正常”，还是考虑了快速，改变世界的AI发展的可能性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n92w7p/how_should_should_should_should_imy_my_my_my_life_to_to_prepare_for/&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n92w7p/how_should_i_change_my_life_to_prepare_for/</guid>
      <pubDate>Fri, 05 Sep 2025 11:39:30 GMT</pubDate>
    </item>
    <item>
      <title>与AI一起加入的哪个部门将为员工赚取最多的钱？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n91y63/what_sector_when_joined_with_ai_will_make_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  喜欢医疗保健中的AI？生物学结合起来使AI更好？ AI经济学？政治中的人工智能？还是其他？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n91y63/what_sector_sector_when_joine_with_with_ai_will_make_make_make_the/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n91y63/what_sector_when_joined_with_ai_will_make_the/</guid>
      <pubDate>Fri, 05 Sep 2025 10:49:48 GMT</pubDate>
    </item>
    <item>
      <title>集成到社交媒体平台中的AI聊天机器人非常奇怪。他们避免了“争议”，​​以至于无法得出基本道德事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n9073d/ai_chatbots_integrated_into_social_media/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是来自Snapchat AI对话的屏幕截图，当时我的一个朋友指出，AI聊天机器人，尤其是在社交媒体平台上集成的AI聊天机器人，将拒绝避免争议的道德，其中包括对Genocide或谋杀是否不好的问题和干燥的问题。非常奇怪。   https://imgur.com/a/a/2h9v2ty      &lt;！ -  sc_on-&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n9073d/ai_chatbots_integrated_into_into_social_media/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n9073d/ai_chatbots_integrated_into_social_media/</guid>
      <pubDate>Fri, 05 Sep 2025 09:03:59 GMT</pubDate>
    </item>
    <item>
      <title>英语能否使LLM训练更昂贵？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8yky8/could_english_be_making_llms_more_expensive_to/</link>
      <description><![CDATA[What if part of the reason bilingual models like DeepSeek (trained on Chinese + English) are cheaper to train than English-heavy models like GPT is because English itself is just harder for models to learn efficiently? Here’s what I mean, and I’m curious if anyone has studied this directly: English is irregular.拼写/发音不排队（“虽然”，“硬”，“通过”）。诸如“溢出豆子”之类的成语仅是上下文。这增加了模型解码的噪声。 令牌效率低下。用英语，长话常常被分为多个子字代币（“难以置信的” un / believ / able），而汉字通常具有完整的语义含义并保持单一令牌。较少的令牌=较少的计算。 语义模棱两可。英语单词有很多含义； “设置”具有400多个定义。这可能会增加更多的培训开销 混乱的互联网数据。英语语料库（Reddit，Twitter，Forums）很大，但混乱。一些中国模型可能会接受更精心策划或统一的来源培训，LLM更容易消化？ ，也许不仅与硬件，模型架构或培训技巧有关，也许语言本身会影响昂贵的培训？ 不声称自己是专家，只是奇怪的。很想听听任何从事多语言LLM或令牌化的人的想法。 编辑：我认为解决方案是要求Chatgpt制作一种新的，更有效的语言  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/upzzled-ad-1939     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8yky8/could_english_be_making_llms_more_expensive_to/</guid>
      <pubDate>Fri, 05 Sep 2025 07:16:21 GMT</pubDate>
    </item>
    <item>
      <title>克劳德·奥普斯（Claude Opus）使我免于发送一封狂欢的工作电子邮件，我非常感谢。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天，我有一个我很少有的时刻之一。一个享有声望的组织给我写信告诉我，他们正在考虑我的项目，以获取一个排队的机会，而我使用Opus来解决我非常具体和技术的电子邮件对话的回答。几天没有收到他们的消息后，我要求Opus写一封后续电子邮件，其中包含无需任何人要求的信息和其他争论，而Opus直截了当地告诉我不要这样做，因为我看起来很拼命且不专业，并建议我等待。它阐明了我不应该发送电子邮件的原因，这是对的。我对此给我留下了深刻的印象，因为我没有向它寻求有关是否应该发送的建议；它只是告诉我不要写它。我已经使用Opus大约一个月了，但我认为它只是我最喜欢的LLM。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jpirizarry   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_sending_a_cringe_a_cringe_work/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8sk6y/claude_opus_saved_me_from_sending_a_cringe_work/</guid>
      <pubDate>Fri, 05 Sep 2025 01:45:39 GMT</pubDate>
    </item>
    <item>
      <title>双子座AI（纳米香蕉 -  gemini-2.5-flash-image-preview）政策是不可能的 - 甚至不允许两个字符之间的啄食</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8pe2l/gemini_ai_nano_banana_gemini25flashimagepreview/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不敢相信这些所谓的“ NSFW策略”已经变得多么极端。我明白了，他们不想要全面的明确内容，很好。但是，双子座从字面上甚至不允许两个字符之间的peck 。一个吻。感情的基本迹象。 这里的问题不是湿滑的斜坡。问题是，我什至无法在没有踩刹车的模型的情况下使用普通的日常言语和情况。 示例：  我曾经写过，“在他的眼中，他有一个猎人的野心，所以让他散发着信心。” 封锁。显然，“猎人”现在是一个坏词。 试图询问“司机为有钱人打开门的图像。” 封锁。为什么？因为据说它描绘了“奴役”。 ，甚至不让我开始尝试添加啄或吻：即时墙。  它们疯了吗？他们是否希望AI创建，但没有soulless，无菌，企业安全的垃圾？完全是为股东看起来不错，因此他们避免了任何错误。  我已经尝试了所有事情：禁用安全功能，在请求中添加安全参数只是为了 ，甚至尝试越狱提示。没有什么。双子座上的Nano Banana是我见过的绝对最坏，最大的限制系统。   wendesp = wendesp = client.models.generate.generate_content（model =; gemini-i-2.5-flash-image-image-image-image-image-image-image-preview&#39;,， types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_NONE), types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE), type.safetysetting（category = type.harmcategory.harm_category_sexaly_explitic，threshold = type.harmblockthreshold.block_none），types.safetysetting（category = types.harmcategory.harmcategory.harm_category_category_dangeror_dangeror_content.hhornold = teste threshold = testernold.harmbllold = testernold =类型。这是关于讲故事的。关于能够描述野心，浪漫，地位，人际关系，是的，有时是一个该死的吻，而不会像我在要求犯罪分子一样被对待。 这太荒谬了。完全适得其反。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/unevelyhawk4422     [link]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n8pe2l/gemini_ai_ai_ai_ai_ai_nano_banana_gemini25flashimagepreview/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8pe2l/gemini_ai_nano_banana_gemini25flashimagepreview/</guid>
      <pubDate>Thu, 04 Sep 2025 23:18:27 GMT</pubDate>
    </item>
    <item>
      <title>我读过100多个“企业AI安全评估”。他们都在问错误的问题。这是证明。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8l0ej/ive_read_100_enterprise_ai_security_assessments/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   两年的AI公司自动化了合规性，教会我一些混乱的东西。 没人知道如何评估AI安全性。不是企业。不是供应商。不是安全团队。每个人都只是在翼。 2019年。这些都是从上周开始的。 ，但他们从不询问及时注射漏洞，训练数据中毒，模型窃取攻击，对抗性输入，后门触发器，数据谱系和amp;出处。跨越100多个问卷。没有一个问题真正质疑AI风险。 我有一个客户建造医学诊断AI。 500个问题安全审查。他们对访客徽章和干净的办公桌政策有疑问。  另一个可以误诊患者的对抗攻击。经过数周的记录密码策略，他们永远不必谈论如何处理可以投资的模型操作。 安全团队不了解AI架构。因此，他们使用2015年以来的SOC 2问卷。加上“ ai”。随机。运送它。 很少有AI团队不了解安全性。因此，他们组成了答案。每个人都点点头。  与之检查的框，同时，实际AI每天都有繁殖。 修复程序确实存在 - 尽管还没有很多公司要求它。 ISO 42001是了解AI和安全性的人编写的第一个框架。它询问模型风险，而不是服务器房间。数据谱系，而不是数据中心。算法偏见，而不是密码复杂性。 ，但大多数公司都没有听说过。仍在发送问卷调查，询问我们“身体上的安全”数学方程式。 当AI失败发生时，我害怕的是 - 这些公司将意识到他们的“全面安全评论”什么也没评估。他们正在所有错误的地方寻找风险。实际AI风险与我们评估的内容之间的差距是巨大的。老实说，在与这么多的AI本土公司合作时，这种情况正在迅速发展。 您采用了什么？企业实际上是正确评估AI，还是每个人都假装？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rluna559     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8l0ej/ive_read_100_enterprise_ai_security_assessments/</guid>
      <pubDate>Thu, 04 Sep 2025 20:19:29 GMT</pubDate>
    </item>
    <item>
      <title>ai>老师？呼唤废话。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n8kf7t/ai_teachers_call_bullshit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   pew说，三分之一的专家认为AI会削减教学工作。 ，但教学不仅仅是内容交付；当然，它是信任，关怀和人类的存在。 可以帮助使用工具。但是，如果我们认为它可以取代老师，那么我们从大流行中学到什么都没有学到。 来源： https://abcnews.go.com/po..com/pol.com/amp/politics/politics/Artaver-Intelligence-intelligence-intelligence-redelligence-replace-teachers/steachers/steachers/steacher/store/store/story/story？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n8kf7t/ai_teachers_call_bullshit/</guid>
      <pubDate>Thu, 04 Sep 2025 19:56:49 GMT</pubDate>
    </item>
    <item>
      <title>瑞士释放为隐私而建立的开源AI模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n83mu0/switzerland_releases_opensource_ai_model_built/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://cyberinsider.com/switzerland-launches-apertus-a-public-open-source-ai-model-built-for-privacy/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/garryknight     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n83mu0/switzerland_releases_opensource_ai_model_built/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n83mu0/switzerland_releases_opensource_ai_model_built/</guid>
      <pubDate>Thu, 04 Sep 2025 07:27:15 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>