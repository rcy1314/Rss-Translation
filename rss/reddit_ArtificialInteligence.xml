<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 20 Dec 2024 21:18:10 GMT</lastBuildDate>
    <item>
      <title>Open AI 的 o3 模型在 ARC-AGI 基准上得分为 87.5%</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hitny3/open_ais_o3_model_scores_875_on_the_arcagi/</link>
      <description><![CDATA[https://arstechnica.com/information-technology/2024/12/openai-announces-o3-and-o3-mini-its-next-simulated-reasoning-models/ 这非常重要。   据 OpenAI 称，o3 模型在 ARC-AGI 基准测试中获得了破纪录的分数，ARC-AGI 是一个视觉推理基准测试，自 2019 年创建以来一直无人能及。在低计算场景中，o3 得分为 75.7%，而在高计算测试中，它达到了 87.5%——与人类在 85% 的门槛下的表现相当。 在直播中，ARC 奖基金会主席表示：“当我看到这些结果时，我需要改变我对人工智能能做什么和它能做什么的世界观。” OpenAI 还报告称，o3 在 2024 年美国邀请赛数学考试中的得分为 96.7%，只错过了一道题。该模型在 GPQA Diamond 上也达到了 87.7%，其中包含研究生级别的生物学、物理学和化学问题。在 EpochAI 的 Frontier Math 基准测试中，o3 解决了 25.2% 的问题，而其他模型都没有超过 2%。     提交人    /u/Pmang6   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hitny3/open_ais_o3_model_scores_875_on_the_arcagi/</guid>
      <pubDate>Fri, 20 Dec 2024 21:01:26 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 是否能看到全局，还是只能逐个像素地拼凑起来？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hitis1/do_llms_see_the_big_picture_or_just_piece_it/</link>
      <description><![CDATA[大家好，我一直在想：当谈到大型语言模型时，它们是否像我们人类一样，一次性以整体的方式“看到”所有概念？还是它们更像机器，一点一点地处理所有事情，慢慢地添加细节，直到得出结论？ 例如，当我看一个苹果时，我不会分析每个像素然后确定它是一个苹果——它会立即点击。法学硕士是否在做类似的事情，或者他们基本上是在处理微观层面的数据后再给出答案？他们的流程与我们自己的“即时”理解有何不同？    提交人    /u/gizia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hitis1/do_llms_see_the_big_picture_or_just_piece_it/</guid>
      <pubDate>Fri, 20 Dec 2024 20:54:54 GMT</pubDate>
    </item>
    <item>
      <title>Instruct — 类似于 Microsoft Guidance，但是用 Ruby 编写</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hit4q3/instruct_similar_to_microsoft_guidance_but_in_ruby/</link>
      <description><![CDATA[https://github.com/instruct-rb/instruct Instruct 的灵感来自微软指导，它自然地交织了代码和 LLM 完成，但它具有 Ruby 风格和自己独特的功能。  这只是一个关于如何使用 instruct 轻松创建多轮代理对话的示例。  ```ruby # 创建两个代理：Noel Gallagher 和一个带有系统提示的面试官。 noel = p.system{&quot;你是 Noel Gallagher。回答面试官的问题。&quot;} interviewer = p.system{&quot;您是一位熟练的面试官，正在向 Noel Gallagher 提问。&quot; # 我们通过启动 # 面试代理并捕获 :reply 键下的响应来与面试官开始动态问答循环。 interviewer &lt;&lt; p.user{&quot;Noel 坐在您面前。&quot;} + gen.capture(:reply) puts interviewer.captured(:reply) # =&gt; &quot;您好 Noel，今天感觉怎么样？&quot; 5.times do # 向 Noel 发送 :reply 键下面试官记录中捕获的最后一个值。# 类似地，我们为 Noel 生成响应并将其捕获到 :reply 键下。noel &lt;&lt; p.user{&quot;&lt;%= interviewer.captured(:reply) %&gt;&quot;} + gen.capture(:reply, list: :replies) # Noel 捕获的回复现在发送给面试官，面试官以相同的方式捕获它。 面试官 &lt;&lt; p.user{&quot;&lt;%= noel.captured(:reply) %&gt;&quot;} + gen.capture(:reply, list: :replies)  end # 对话结束后，我们可以访问从两个代理捕获的回复列表 noel_said = noel.captured(:replies).map{ |r| &quot;noel: #{r}&quot; } interviewer_said = interviewer.captured(:replies).map{ |r| &quot;interviewer: #{r}&quot;  puts interviwer_said.zip(noel_said).flatten.join(&quot;\n\n&quot;) # =&gt; &gt; &quot;noel: ... \n\n interviewer: ..., ...&quot; ``` 我已经利用业余时间研究这个 gem 几个月了。API 尚未完全稳定，因此除了实验之外我不建议使用它。尽管如此，我的公司仍在生产中使用它（截至今天 :)），所以现在似乎是分享的好时机。 那么我为什么要编写另一个 LLM 提示库呢？ 我发现现有的 Ruby 库要么太抽象 - 将 LLM 的功能隐藏在看不见的提示后面，太低级 - 让我的课程难以理解，并且充斥着管理提示和响应的样板，要么使用类级抽象 - 迫使我在我不想创建类时创建类。 在阅读 Obie Fernandez 的《使用 AI 进行应用程序开发模式》的早期版本并使用 Obie 的库 raix 后，我感到很受启发。这本书有很多很棒的模式，raix 的成绩单管理和工具管理是我用过的第一个感觉像 ruby​​ 的库。同时，python 社区中的库（如指导、DSPy、LangSmith 和 TEXTGRAD）引起了我的注意。我也喜欢跨平台 BAML 的功能。我不喜欢代码生成和免费增值方面。 在积极性高涨的情况下，我开始构建一个有主见的 gem 库，以改善我的 Ruby（和 Rails）LLM 开发人员体验。 第一个 gem 是 instruct。它是其他 gem 构建的灵活基础。虽然 API 与指导类似，但它具有基于属性字符串和中间件的不同架构，这启用了一些独特的功能（如异步防护栏、内容过滤器、自我修复、自动延续和本机多模式支持）。 我目前正在开发一个希望优雅的 API，它使请求和处理流式结构化输出变得容易（从 BAML 中汲取灵感，但如果 API 支持，则自动升级到 json 模式）。除此之外，我还在开发一个对话记忆中间件，它会自动修剪对话记录中不相关的历史部分。我希望这能让模型更具可操作性，但不会丢失关键细节。 提前感谢您的关注并提供任何建设性的反馈或想法。最后，如果您有兴趣做出贡献，请给我留言。    提交人    /u/mackross   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hit4q3/instruct_similar_to_microsoft_guidance_but_in_ruby/</guid>
      <pubDate>Fri, 20 Dec 2024 20:37:15 GMT</pubDate>
    </item>
    <item>
      <title>臭氧价格</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hirxjp/o3_price/</link>
      <description><![CDATA[O3 在 AGI-arc 测试中表现出色，但有趣的是他们公布了计算成本。因此，为了在 100 个问题中获得 75% 的分数，他们花费了 2000 美元的零售成本。而为了获得 82% 的分数，他们花费了 172 倍的计算成本，并要求不公布成本。但对于一堆合乎逻辑的问题来说，这似乎是一大笔钱，不是吗？ 来源  https://arcprize.org/blog/oai-o3-pub-breakthrough    提交人    /u/NoWeather1702   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hirxjp/o3_price/</guid>
      <pubDate>Fri, 20 Dec 2024 19:43:15 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI o3 和 o3-mini 发布</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hirhk2/openai_o3_and_o3mini_annouced/</link>
      <description><![CDATA[因此，OpenAI 发布了 o3 和 o3-mini，它们在编码和数学任务上表现出色。Arc AGI 数字看起来很疯狂！查看此帖子中总结的所有详细信息：https://youtu.be/E4wbiMWG1tg?si=lCJLMxo1qWeKrX7c    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hirhk2/openai_o3_and_o3mini_annouced/</guid>
      <pubDate>Fri, 20 Dec 2024 19:22:59 GMT</pubDate>
    </item>
    <item>
      <title>探索安全、合作的人工智能之路</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hionut/exploring_the_path_to_safe_cooperative_ai/</link>
      <description><![CDATA[研究研讨会视频提醒 奇怪的嵌入、模糊的预言以及通往安全、合作的人工智能的道路 在 2024 年 12 月宾大 ASSET 人工智能中心系列上发表 今天早上，我将本月早些时候发表的研讨会演讲发布到了 YouTube 上。演讲涵盖了我在 Voxel51 和密歇根大学的团队最近在建模和构建人机协作功能方面所做的工作。完整摘要如下！ ...正好赶上您在假期的扶手椅上观看！ 视频链接：https://youtu.be/Ck3ma6L4lug 此 YouTube 版本经过清理，包括问题答案、事实核查和更好的音频。 下面是演讲详情。 标题：奇妙的嵌入、模糊的预言和通往安​​全、合作的人工智能之路 摘要：通过安全和值得信赖的沟通和互动进行合作是人类团队完成复杂任务的基础。然而，尽管人工智能取得了重大的——有时是革命性的——进步，但我们才刚刚开始释放安全、合作的人工智能的潜力。这可能源于我们对多模态、大规模人工智能模型如何运作的有限理解、当代全监督人工智能方法的片面性，或对人机合作的社会担忧。在本次演讲中，我将深入探讨这些层面的问题，首先从原则性探索大规模基础模型中的嵌入揭示了什么有关潜在问题和数据的信息，包括将样本大小与贝叶斯误差和决策边界复杂性区分开来的新结果。然后，我将介绍人类合作者作为“模糊的神谕”的概念——一个会犯错的合作伙伴，而不是无所不知的信息来源——并建立一个框架来对合作过程中人类提供的错误进行建模。基于这些基础见解，我将最终应用这些想法来促进健康科学领域安全有效的人机合作。    提交人    /u/ProfJasonCorso   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hionut/exploring_the_path_to_safe_cooperative_ai/</guid>
      <pubDate>Fri, 20 Dec 2024 17:17:57 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hinu6g/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：Instagram 预告编辑 AI 工具 (来源：TechCrunch、The Verge)  Sam Altman 曾通过 Sequoia 持有 OpenAI 的部分股权。 (来源：TechCrunch) 据报道，Perplexity 已完成一轮 5 亿美元的融资。 (来源：TechCrunch) Boon 筹集 2050 万美元，为舰队打造代理 AI 工具。 (来源：TechCrunch) 前 Twitch 首席执行官 Emmett Shear 正在创立一家由 a16z 支持的 AI 初创公司。 （来源：TechCrunch） TuSimple 从自动驾驶转向 AI 动画，CreateAI 品牌重塑圆满完成（来源：TechCrunch） 在短短 4 个月内，AI 编码助手 Cursor 在 Thrive 领投下以 25 亿美元的估值再融资 1 亿美元（来源：TechCrunch） Waymo 填补了 Cruise 的海外空白，向偶像 Jean Jennings 致敬（来源：TechCrunch）  如果您想及时了解 AI 新闻，请首先在此处发布。，其中包含所有来源和文章的完整摘要    提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hinu6g/heres_whats_making_news_in_ai/</guid>
      <pubDate>Fri, 20 Dec 2024 16:42:23 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 刚刚发布了伊隆·马斯克的一些爆炸性文字：“你不能通过起诉来实现通用人工智能”。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hinfg1/openai_just_unleashed_some_explosive_texts_from/</link>
      <description><![CDATA[伊隆·马斯克和 OpenAI 之间的法律纠纷愈演愈烈，OpenAI 刚刚通过一篇博客文章反击马斯克的指控，捍卫自己的立场。这篇文章包括一些非常有趣的短信，这些短信是联合创始人 Ilya Sutskever、Greg Brockman 和 Sam Altman 等关键人物以及伊隆·马斯克本人和前董事会成员 Shivon Zilis 之间交换的。 OpenAI 的博客文章直接谈到了马斯​​克的诉讼，称“你不能通过诉讼来实现 AGI”（指通用人工智能，Altman 预测它很快就会出现）。他们表达了对马斯克过去贡献的尊重，但建议他应该专注于市场竞争，而不是法庭竞争。帖文强调了美国保持人工智能领导地位的重要性，重申了 OpenAI 确保 AGI 惠及每个人的使命，表示希望马斯克也能认同这一目标以及推动他自身成功的创新和自由市场竞争原则。 https://www.liquidocelot.com/index.php/2024/12/20/openai-just-unleashed-some-explosive-texts-from-elon-musk-you-cant-sue-your-way-to-artificial-general-intelligence/   由    /u/liquidocelotYT  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hinfg1/openai_just_unleashed_some_explosive_texts_from/</guid>
      <pubDate>Fri, 20 Dec 2024 16:23:37 GMT</pubDate>
    </item>
    <item>
      <title>更快的推理：torch.compile 与 TensorRT</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1himc85/faster_inference_torchcompile_vs_tensorrt/</link>
      <description><![CDATA[在我们对 LLama-7b、LLama-3-8b、mistral-v0.1、phi-3 和 phi-2 等模型的测试中，torch.compile 在易用性和性能方面优于 TensorRT。除非您需要 TensorRT 特定的功能或专门在 NVIDIA 的生态系统中工作，否则 torch.compile 是优化 PyTorch 模型的更好选择。 https://www.collabora.com/news-and-blog/blog/2024/12/19/faster-inference-torch.compile-vs-tensorrt/   由    /u/mfilion  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1himc85/faster_inference_torchcompile_vs_tensorrt/</guid>
      <pubDate>Fri, 20 Dec 2024 15:34:21 GMT</pubDate>
    </item>
    <item>
      <title>不会有 UBI，地球只会变得极度荒芜</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hiizzu/there_will_not_be_ubi_the_earth_will_just_be/</link>
      <description><![CDATA[老实说，我为那些期待失业后每月从政府领取支票的人感到遗憾，这将使他们（在精英眼中）成为一张没有生产力的嘴。 我根本不认为这有效果。我所观察到和看到的一切都告诉我，不，我们不会得到 UBI，是的，精英会让我们挨饿。我说的是字面意思。一旦人们找不到工作，我们就会饿死在街头。精英不再需要我们工作，也不需要我们购买他们的产品（机器人/人工智能将采购一切）或文化（AGI 将产生它）。他们真的没有理由让我们留在身边，我们只会成为资源消耗者和无用的污染者。所以他们会通过大规模饥荒杀死我们所有人，然后独霸世界。 几个月来我没有听到过任何反驳的声音，所以请证明我错了。    提交人    /u/Phoenix5869   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hiizzu/there_will_not_be_ubi_the_earth_will_just_be/</guid>
      <pubDate>Fri, 20 Dec 2024 12:43:41 GMT</pubDate>
    </item>
    <item>
      <title>在向无就业社会转型的过程中，我们应该逐步缩短工作时间，而不是让人们失业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hihv2a/during_the_transition_to_a_mainly_jobless_society/</link>
      <description><![CDATA[当然是保持相同的工资。不同意这一点的公司应该支付比留住工人更昂贵的自动化税。 盈利的公司将由于人工智能比以前生产更多而增加收入。 人们将有时间调整他们的心态，并在工作之外寻找其他东西来形成他们身份的花瓶。 经济可以继续照常运转。作为奖励，消费者有更多的时间，并且会消费更多。    提交人    /u/dom-dos-modz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hihv2a/during_the_transition_to_a_mainly_jobless_society/</guid>
      <pubDate>Fri, 20 Dec 2024 11:31:27 GMT</pubDate>
    </item>
    <item>
      <title>我们是否都有使用各种超参数调整过的 LLM 的不同版本？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hihkok/are_we_all_different_versions_of_llms_tuned_with/</link>
      <description><![CDATA[这是我和几个朋友前几天讨论的话题。随着所有 LLM 都趋向于人类智能，模仿人类大脑，如果我们反转这个思想实验会怎么样？ 如果我们所有人实际上都是具有不同超参数（即不同温度、topK、topP、上下文窗口、领域知识等）的 AI 的一种或另一种形式，会怎么样？我们在特定领域接受的训练越多，我们就会变得越好，变得越专业。是的，我们所有的神经网络都有一个初始配置（原始智能），但随着时间的推移，根据我们训练它的数据集（体育、编码、法律），我们会做得更好。 我们称之为创造性的小习惯或行为只是我们被烘烤的不同温度设置。更有创造力的人会产生更多幻觉，这与 LLM 在较高温度下发生的情况相同。 我们的讨论陷入僵局的地方是意识问题。我们还不知道意识在哪里，我们如何模仿意识？我的意思是真正的 AGI 不是 LLM 能够解决 NP 难题或胜过 PhD 级数学家，而是它能够真正感受到。    提交人    /u/Top-Victory3188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hihkok/are_we_all_different_versions_of_llms_tuned_with/</guid>
      <pubDate>Fri, 20 Dec 2024 11:11:02 GMT</pubDate>
    </item>
    <item>
      <title>我提取了 Microsoft Copilot 的系统指令——这里的东西太疯狂了。它被指示说谎，让微软看起来不错，而且充满了令人尴尬的企业联盟。以下是分析的关键部分和整个提示本身。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hhyt1y/i_extracted_microsoft_copilots_system/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hhyt1y/i_extracted_microsoft_copilots_system/</guid>
      <pubDate>Thu, 19 Dec 2024 17:58:37 GMT</pubDate>
    </item>
    <item>
      <title>每周自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hhuszb/weekly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hhuszb/weekly_self_promotion_post/</guid>
      <pubDate>Thu, 19 Dec 2024 15:03:09 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hgcnpp/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hgcnpp/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 17 Dec 2024 15:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>