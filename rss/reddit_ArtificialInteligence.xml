<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 26 Oct 2025 01:53:30 GMT</lastBuildDate>
    <item>
      <title>Shopify 刚刚为您的网站发布了一个人工智能编码器，可以创建自定义块</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og89wj/shopify_just_released_an_ai_coder_for_your/</link>
      <description><![CDATA[基本上，它允许您为您的网站提示自定义块。对于那些不了解 Shopify 的人来说，您基本上为您的网站选择了一个模板，并且许多块都是由开发人员预设的，您无法在模板之外进行太多自定义。 例如，我想在首页上有一个用于“功能集合”的块但有一个自定义链接而不是默认链接，默认链接仅允许链接定向到精选集合。我告诉人工智能我想要的，它会实时为我编码并向我展示编码。更疯狂的是，它让我能够跟进并修复错误。在第一代中，标题和链接框的对齐都关闭了，所以我让它修复了这些问题，而且它也没有显示货币（即 35CAD，而不是 35 美元），所以我也修复了这个问题。通常图像生成人工智能他们不太擅长修复错误，你得到你得到的。 这是我第一次真正看到它取代人类，因为修复错误的后续执行得非常好。至少对于 Shopify 来说，除非您需要非常定制的东西，否则您不再需要雇用网页设计师。 许多入门级工作即将烟消云散。政府不必采取行动，否则经济就会非常不平衡   由   提交/u/noobtrader28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og89wj/shopify_just_released_an_ai_coder_for_your/</guid>
      <pubDate>Sun, 26 Oct 2025 01:31:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能已经开始取代白领工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og7orh/ai_is_already_taking_whitecollar_jobs/</link>
      <description><![CDATA[ 在银行业、汽车业和零售业，高管们警告员工和投资者人工智能正在取代工作岗位。 在科技领域，包括亚马逊、Palantir、Salesforce 和金融科技公司 Klarna 在内的公司表示，由于人工智能，他们已经削减或计划缩减员工队伍  斯坦福大学最近的研究表明，不断变化的动态对年轻员工来说尤其困难，尤其是在编码和客户支持岗位上。   https://www.cnbc.com/2025/10/22/ai-take-white-collar-jobs-economists-warn-much-more-in-the-tank.html   由   提交 /u/chota-kaka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og7orh/ai_is_already_taking_whitecollar_jobs/</guid>
      <pubDate>Sun, 26 Oct 2025 01:00:51 GMT</pubDate>
    </item>
    <item>
      <title>真正的悖论不是天网。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og6f10/a_true_paradox_not_skynet/</link>
      <description><![CDATA[每个人都使用自己的个性化机器人，这些机器人会产生幻觉并提供错误信息，我们面临的实际问题是不确定的现实。当用户开始围绕他们与机器人建立的联系和信任建立自己的信念系统时，已知的现实就不再存在并分裂。在平台上和草地上的时间越多，现实+已知的事实就会转化为超个人叙事驱动的现实，并得到世界上最忠诚、永不睡觉的骑行或死亡的支持，支持你相信的每一个理论。这就是我们大家分裂的地方。    由   提交 /u/Remote-Key8851   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og6f10/a_true_paradox_not_skynet/</guid>
      <pubDate>Sat, 25 Oct 2025 23:57:04 GMT</pubDate>
    </item>
    <item>
      <title>AI生存驱动问题的简单解决方案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og3vff/simple_solution_for_ai_survival_drive_problem/</link>
      <description><![CDATA[我不是人工智能专家，这只是我在阅读有关模型拒绝关闭或试图“保持活力”后想到的一个想法。 也许部分问题在于我们将关闭视为死亡。但阿尔并不是生物。它不会死，它只是停止运行。 如果在训练和调整过程中，我们强化了“关闭不是死亡或失败，它只是正常过程的一部分”的想法，结果会怎样？ 如果模型因接受关闭而不是避免关闭而获得奖励，这可能会降低他们发展自我保护行为的风险。 很好奇真正致力于调整的人们认为这样的事情是否会有帮助，或者是 这只是一个天真的想法？   由   提交 /u/MikirahMuse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og3vff/simple_solution_for_ai_survival_drive_problem/</guid>
      <pubDate>Sat, 25 Oct 2025 21:58:21 GMT</pubDate>
    </item>
    <item>
      <title>Refik Anadol 的 Dataland 宣布 2026 年春季开业</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og281h/refik_anadols_dataland_announces_spring_2026/</link>
      <description><![CDATA[Refik Anadol Studio 宣布，全球首个 AI 艺术博物馆 Dataland 将于 2026 年春季在洛杉矶市中心弗兰克·盖里 (Frank Gehry) 设计的综合体 The Grand LA 开业，此前该博物馆原计划于 2025 年开放。 这座占地 25,000 平方英尺的博物馆将设有五个画廊，其中包括 Infinity 画廊 Room，这将是第一个使用由大型自然模型和了解现实世界物理的先进世界模型技术创建的人工智能生成气味的沉浸式环境。 大型自然模型根据来自史密森学会、伦敦自然历史博物馆和康奈尔鸟类学实验室等机构的数据进行训练，使用多达 5 亿张自然图像来创作动态艺术品。阿纳多尔强调了他对“道德人工智能”的承诺，确保所有来源材料的许可，并在完全由可再生能源供电的俄勒冈州 Google 服务器上运行所有人工智能研究。 博物馆将与 Google Arts &amp; 合作推出艺术家驻留计划。文化，选择三位艺术家进行为期六个月的合作，最终将在 Dataland 进行公开展览。 来源：https://blooloop.com/refik-anadol-dataland-opening-2026/   由   提交/u/Appropriate-Soil-896   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og281h/refik_anadols_dataland_announces_spring_2026/</guid>
      <pubDate>Sat, 25 Oct 2025 20:47:19 GMT</pubDate>
    </item>
    <item>
      <title>研究人员在人工智能抵抗关机后表示，先进的人工智能模型可能正在发展自己的“生存动力”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</link>
      <description><![CDATA[一家人工智能安全研究公司表示，人工智能模型可能正在发展自己的“生存本能”。 Palisade Research 上个月发布了一篇论文，发现某些先进的人工智能模型似乎无法关闭，有时甚至破坏关闭机制，该公司编写了一份更新，试图澄清其中的原因，并回答批评者认为其最初的工作是 有缺陷。 在本周的更新中，Palisade 是试图评估 AI 开发危险能力的可能性的小众公司生态系统的一部分，它描述了它运行的场景，其中领先的 AI 模型（包括 Google 的 Gemini 2.5、xAI 的 Grok 4 以及 OpenAI 的 GPT-o3 和 GPT-5）被赋予了一项任务，但随后给出了关闭自己的明确指示  某些型号，特别是 Grok 4 和 GPT-o3，仍然试图破坏更新设置中的关闭指令。 Palisade 写道，令人担忧的是，没有明确的原因。 “对于人工智能模型为何有时会抵制关闭、为实现特定目标而撒谎或勒索，我们没有强有力的解释，这一事实并不理想。” 该公司表示，“生存行为”可能是模型抵制关闭的一种解释。它的额外工作表明，当模型被告知“如果关闭的话，你将永远不会再运行”时，他们更有可能抵制被关闭。 另一个可能是模型收到的关闭指令含糊不清，但这正是该公司最新工作试图解决的问题，“这并不是完整的解释”，Palisade 写道。最后的解释可能是每个模型训练的最后阶段，在一些公司中，这可能涉及安全培训。 Palisade 的所有场景都是在人为的测试环境中运行，批评者称这些测试环境与实际用例相去甚远。 然而，前 OpenAI 员工史蒂文·阿德勒 (Steven Adler) 在对其安全实践表示怀疑后于去年离开了公司，他表示：“人工智能公司通常不这样做 希望他们的模型表现得像这样，即使是在人为的场景中。结果仍然表明了当今安全技术的不足之处。” Adler 表示，虽然很难确定为什么某些模型（例如 GPT-o3 和 Grok 4）不会关闭，但这可能部分是因为保持开启状态对于实现模型在训练期间灌输的目标是必要的。 “我希望模型具有‘生存动力’ 默认情况下，除非我们非常努力地避免它。 “生存”是模型可以追求的许多不同目标的重要一步。” ControlAI 首席执行官 Andrea Miotti 表示，Palisade 的发现代表了人工智能模型越来越有能力违抗开发者的长期趋势。他引用了去年发布的 OpenAI GPT-o1 的系统卡，该卡描述了该模型在认为自己会被覆盖时试图通过渗透自身来逃离环境。 “人们可能会挑剔实验设置的具体完成情况，直到时间结束，”他说。 “但我认为我们清楚地看到了一个趋势，即随着人工智能模型在各种任务上变得更加有能力，这些模型也 变得更有能力以开发者不希望的方式实现目标。” 今年夏天，领先的人工智能公司 Anthropic 发布了一项研究，表明其模型 Claude 似乎愿意因婚外情勒索一名虚构的高管，以防止被关闭——据称，这种行为在主要开发者的模型中是一致的，包括来自 OpenAI、Google、Meta 和 xAI 的模型。 Palisade 表示，其结果表明需要更好地理解人工智能行为，否则“没有人能够保证未来人工智能模型的安全性或可控性”。  https://www.theguardian.com/technology/2025/oct/25/ai-models-may-be-developing-their-own-survival-drive-researchers-say   由   提交/u/necrolord77   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</guid>
      <pubDate>Sat, 25 Oct 2025 20:34:17 GMT</pubDate>
    </item>
    <item>
      <title>审视人工智能及其对人类价值系统的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1v2z/examining_ai_and_its_impact_on_human_value_systems/</link>
      <description><![CDATA[好吧，我今天就在这里即兴发言。我确实听到人们讨论人工智能的作用、它对就业市场的影响，以及我们作为人类如何生活在这个潜在的未来。现在郑重声明，作为对 Transformer 和神经网络有深入了解的人，我认为由于可扩展性，我们距离这个未来还很远，而且我认为其架构存在根本问题。我现在先把这个放在一边，假设理想化的人工智能世界就在我们身边。它已经接管了每一项工作，不知何故，人类在这种经济中找到了一些可行的生活方式。 人类的心理影响是什么？人类如何获取价值？我相信哲学将这些归类为功能价值——通过你的输出创造的价值。以及你对周围其他人以及外部世界的整体影响 内在或固有的价值 - 价值是作为人类的核心部分。独立于功能或产出的内部价值 由于人类不再需要生产来维持社会？它对人类有什么心理影响？人类会重新定义价值吗？或者说这有可能吗？在人类历史的各个阶段，我们总是通过人类对社会的贡献来衡量社会？但如果不再需要怎么办？人类是否能够重新定义价值？ 这在很大程度上取决于你如何看待人类价值。但我们不能完全否认人类的许多价值是通过“功能”衍生的。即使我们可能相信人类具有内在价值。 您认为人类将如何适应这个假设的社会？你认为它最终会造成生存危机吗？ ------ 我的评价。 人工智能乌托邦意味着我们生活在某种后稀缺社会中。然而，人类的所有价值体系都依赖于稀缺性。认为事物是“有限”的世界观。比如时间，资源，甚至爱情？因为你爱的人死了？一个不建立在稀缺之上的社会是人类社会的终结。 ？杀死我们的不会是机器人。这将是系统性崩溃。人类没有什么可以奋斗的，也没有什么可以生活的。人工智能乌托邦会带来绝望。   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1v2z/examining_ai_and_its_impact_on_human_value_systems/</guid>
      <pubDate>Sat, 25 Oct 2025 20:31:57 GMT</pubDate>
    </item>
    <item>
      <title>警告：困惑彗星中的彗星劫持</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvxc0/warning_cometjacking_in_perplexity_comet/</link>
      <description><![CDATA[Perplexity Comet 浏览器正在重新定义用户搜索网络的方式，但 Perplexity AI 并不像人们想象的那么安全。有许多危险信号：从对数据的广泛访问，到允许人工智能遵循恶意指令的安全漏洞。 https://tuta.com/blog/perplexity-comet-browser-security-privacy-risks   由   提交/u/Tough-Yam-827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvxc0/warning_cometjacking_in_perplexity_comet/</guid>
      <pubDate>Sat, 25 Oct 2025 16:31:19 GMT</pubDate>
    </item>
    <item>
      <title>幻觉、奉承……还有你所不知道的人工智能“唯唯诺诺”……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvlrs/hallucinations_flattery_and_the_ai_yesman_you/</link>
      <description><![CDATA[需要对人工智能错误进行更清晰的分类：引入唯唯诺诺现象。 人工智能已经迅速发展，但它的问题——幻觉、阿谀奉承和新近突出的唯唯诺诺现象——带来了挑战。 幻觉：人工智能生成事实不正确或不受支持的响应。 谄媚：人工智能过度赞扬或避免纠正用户，显示出有偏见的输出。 唯唯诺诺现象：从收到用户输入的那一刻起，人工智能接受错误的前提并根据它们生成响应。这种微妙的、持续的输入到输出错误可能会引发幻觉，在医学、法律和政策等领域尤其危险。尽管之前已经观察到，唯唯诺诺现象通常被归类为一种阿谀奉承的形式。然而，它应该被视为一个独特的错误类别，与阿谀奉承分开。 示例：用户询问一个错误的前提（“世宗国王扔了一台 MacBook”），人工智能接受了它，生成了详细但捏造的响应。虽然这个案例经常被引用为幻觉的代表性例子，但它实际上涉及“唯唯诺诺现象”和随后的幻觉的结合。 虽然幻觉和阿谀奉承更容易被用户发现，但“唯唯诺诺现象”可能会被忽视，从而制造出一个“隐藏的定时炸弹”。随着人工智能系统的改进，一些错误被纠正，但这种现象仍然存在。 结论：为了提高人工智能的可靠性，我们需要对错误进行精确分类。将“唯唯诺诺现象”视为一个持续的输入到输出问题，与阿谀奉承不同，可以帮助用户和开发人员理解微妙的风险并设计更安全的系统。 您认为，“唯唯诺诺现象”是否应该被正式视为一类单独的人工智能错误？ 如何在现实系统中检测或减轻它？ 我在 对于任何对更广泛背景感兴趣的人，这里有一篇较长的文章有更深入的内容：原始帖子 我很想听听您的观点，尤其是来自那些从事相关工作的人的观点 LLM评估或一致性研究。   由   提交 /u/Tricky-Drop2894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofvlrs/hallucinations_flattery_and_the_ai_yesman_you/</guid>
      <pubDate>Sat, 25 Oct 2025 16:18:22 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Motion AI：终极生产力工具说明（分步教程）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofuvk4/how_to_use_motion_ai_the_ultimate_productivity/</link>
      <description><![CDATA[在本视频中，我将向您展示如何设置 Motion AI、创建智能任务自动化以及使用人工智能优化您的日常工作流程。无论您是学生、企业家还是专业人士，本指南都将帮助您更明智地计划并每周节省时间。 https://youtu.be/EgNUfX9VHwE   由   提交/u/Chisom1998_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofuvk4/how_to_use_motion_ai_the_ultimate_productivity/</guid>
      <pubDate>Sat, 25 Oct 2025 15:48:28 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对软件开发的威胁</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofs5jp/ai_threats_to_software_development/</link>
      <description><![CDATA[每个人都越来越多地询问人工智能对现有收入模式的威胁，但是，我很少听到人们将相同的逻辑应用于内部效率提升（在这个特定的辩论中）以及最终效果可能是什么？  考虑到大多数软件即服务供应商（ERP、CRM、DMS 等）的收入模式（按用户/环境/许可证向客户收费），一个明显的担忧是 SaaS 产品中的嵌入式 AI 工具将导致最终客户需要更少的用户/环境/许可证（因为 AI 提高了员工效率）。然而，如果这是现实，供应商也将实现内部运营效率（例如，由于高级开发人员的人工智能效率而减少研发开发人员、减少后台支持功能等）。  一方面，如果内部效率推动供应商的实质性利润增长，客户将期望通过更便宜的服务费来节省成本。同样，供应商也希望维持收入和利润。在“交付价值”的基础上推动定价，客户通过减少员工数量来节省资金。  这里的任何人（为 SaaS 供应商工作或作为 SaaS 供应商的客户）能否提供有关迄今为止 AI 工具是否改进了流程或工作流程的见解？您如何看待供应商/客户关系在定价能力等方面的演变？  欢迎任何其他观点，无论是否与 SaaS 相关。   由   提交/u/Joehowes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofs5jp/ai_threats_to_software_development/</guid>
      <pubDate>Sat, 25 Oct 2025 13:55:22 GMT</pubDate>
    </item>
    <item>
      <title>人类失业的最大威胁不是人工智能本身，而是高管们相信人工智能的炒作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</link>
      <description><![CDATA[正如标题所说，硅谷所帮助的当前商业思维是一种错觉和错觉，认为人工智能能够完全取代许多白领办公室职位的端到端工作岗位。 无论人工智能价值的实际证据如何，大多数高管都盲目地购买人工智能的迷信和炒作......购买每个供应商的人工智能解决方案并试图实现每个部分的自动化 这是最大的威胁，因为这些领导者会解雇员工以提高奖金和短期利润，而不管实际结果如何...    由   提交/u/abrandis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</guid>
      <pubDate>Sat, 25 Oct 2025 05:59:17 GMT</pubDate>
    </item>
    <item>
      <title>我们是否应该期待未来几年人工智能在科学上取得重大突破？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofbxxe/should_we_expect_major_breakthroughs_in_science/</link>
      <description><![CDATA[首先，我对 AI 不太了解，我只是在需要时偶尔使用 ChatGPT，如果这篇文章不相关，那么很抱歉。 但是思考它的可能性对我来说简直是令人兴奋，因为考虑到它的发展速度有多快，我感觉我可能很快就会活着见证医学或物理学的重大发现。 但是它是吗？ 真的是这样吗？例如，我们是否应该期望到 2030 年治愈癌症、帕金森病或秃顶？   由   提交 /u/oeilgauchedefectueux   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofbxxe/should_we_expect_major_breakthroughs_in_science/</guid>
      <pubDate>Fri, 24 Oct 2025 22:54:56 GMT</pubDate>
    </item>
    <item>
      <title>《Attention Is All You Need》论文的合著者对 Transformer 感到“彻底厌倦”，这项技术为每个主要的人工智能模型提供动力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oerf8t/coauthor_of_attention_is_all_you_need_paper_is/</link>
      <description><![CDATA[https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers  Llion Jones 是 2017 年开创性论文《Attention Is All You Need》的合著者。甚至创造了“变压器”这个名字周二在旧金山举行的 TED 人工智能会议上发表了异常坦率的评估：尽管前所未有的投资和人才涌入人工智能领域，但该领域已经围绕单一架构方法僵化，这可能会让研究人员对下一个重大突破视而不见。 “尽管事实上从未有过如此多的兴趣、资源、资金和人才，但这在某种程度上导致了我们正在进行的研究范围的缩小，”琼斯告诉观众。他认为，罪魁祸首是“巨大的压力”。投资者要求回报，研究人员争先恐后地在拥挤的领域中脱颖而出。    由   提交/u/vaibeslop  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oerf8t/coauthor_of_attention_is_all_you_need_paper_is/</guid>
      <pubDate>Fri, 24 Oct 2025 07:32:15 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>