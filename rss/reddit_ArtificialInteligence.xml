<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 27 Oct 2024 21:17:39 GMT</lastBuildDate>
    <item>
      <title>如果人工智能被视为“外星智能”会怎样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdl1k3/what_if_ai_was_viewed_as_a_alien_intelligence/</link>
      <description><![CDATA[大家好， 最近，我在 ChatGPT、Claude AI、Singularity 和 Reddit 等平台上深入研究了很多关于 AI 的讨论。有一件事不断出现，那就是我们经常赋予 AI 类似人类的特征，比如情感或意图。虽然以这种方式与 AI 建立联系是有道理的，但我觉得它忽略了 AI 真正的大局。我不确定以前是否讨论过这个问题，但与其将 AI 视为人类智能的另一种形式，如果我们将它视为完全不同的东西，更像章鱼，会怎么样？ 章鱼非常聪明，但它们的智力以我们无法完全理解的方式运作。它们有一个分布式神经系统，以我们完全陌生的方式解决问题和探索世界。同样，AI 通过模式和数据处理信息的方式与我们的想法或感受并不完全匹配。我们不应该期待人工智能模仿人类的行为或情感，也许我们应该欣赏它的本质——一种具有自身优势的独特智能形式。这可以帮助我们更有效地使用人工智能，利用其在数据分析和模式识别等领域的能力，而不是试图让它像我们一样行事。 通过将人工智能视为根本不同的东西，我们可能会设定更现实的期望，并找到与这些系统协作的更好方法。这就像与一个真正聪明的工具合作，它只是思维方式不同，不一定更好或更坏，只是不同而已。我注意到很多人把人类的特征投射到人工智能上，这可能会导致对它能做什么和不能做什么的误解。    提交人    /u/ParticularSmell5285   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdl1k3/what_if_ai_was_viewed_as_a_alien_intelligence/</guid>
      <pubDate>Sun, 27 Oct 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>复制真实照片并改变人物</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdjlni/replicate_realistic_photos_and_change_the_person/</link>
      <description><![CDATA[AI 图像生成方面的新手，但我有一个想法想探索。本质上，我想建立一个超现实的角色（我的妻子），然后让模型复制我在互联网上找到的图像。例如：一张穿着红色连衣裙的女人的照片，然后它在同一个场景中复制我妻子穿着那件连衣裙的照片。 有没有类似的东西在消费者层面上相对容易使用？    提交人    /u/itstheHbK   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdjlni/replicate_realistic_photos_and_change_the_person/</guid>
      <pubDate>Sun, 27 Oct 2024 19:51:35 GMT</pubDate>
    </item>
    <item>
      <title>通过人工智能裁员（示例）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdivkz/white_collar_redundancies_via_ai_an_example/</link>
      <description><![CDATA[觉得今天在 FB 上看到的一篇帖子很有趣 - 英国一家知名的健康和营养企业裁掉了 70 名营养师，并用人工智能取而代之。 有道理 - 这绝对是当今人工智能完全有能力做的事情，但它可以取代拥有两个学位的人，这可能会让一些感到惊讶。 帖子：https://imgur.com/a/xbdG85F 企业：https://zoe.com/    提交人    /u/FrostyAd9064   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdivkz/white_collar_redundancies_via_ai_an_example/</guid>
      <pubDate>Sun, 27 Oct 2024 19:19:35 GMT</pubDate>
    </item>
    <item>
      <title>LLM 生成数字的精度。您对研究的建议</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdijcp/precision_of_llm_generated_numbers_your/</link>
      <description><![CDATA[我为我的大学做了一个小的研究项目，想听听你对我的工作的哪一部分对 LLM 用户来说最有趣和最有用的看法。除此之外，我还想在一家小型本地杂志上发表文章，并希望研究结果对一些研究也很有趣。这项研究是纯粹的实验性的，将 LLM 视为一个黑匣子，因为我用统计学研究编程，对 LLM 本身了解不多。 所以我想深入研究类似“使用模型误差的自我评估来评估 LLM 生成的数字精度”的东西。问题生成器是使用 API 编写和测试的。预计模型将返回 3 个数字：问题的答案、绝对误差的评估、介于 0 和 1 之间的精度的评估。目前已收到 3000 多个请求。 法学硕士 (LLM)：  Meta-Llama-3.1-70B-Instruct GPT-3.5-turbo GPT-4o-mini（由于其准确性，它是研究的主要模型）。  其他几个较小的模型显示的答案大多是随机的，因此被排除在外。 主要任务是将两个由正态分布生成的浮点数相加。它经历了几个额外的测试，比如求 10 或 20 个数字的平均值和计数数字。 就目前而言，我们可以谈论模型行为中的许多模式：  在简单的加法任务中，模型的误差可以很好地建模为数字每个数字的随机概率（正确答案 + 信息噪声）。因此，通过重复问题并取最稳定的答案可以大幅提高获得正确答案的概率。模型无法估计这种噪音，并错误地将其答案估计为非常准确。GPT-3.5-turbo 在估计正确答案的概率方面更好，但这只是因为模型很懒，决定将数字四舍五入为某些值。 正如预期的那样，您需要执行的数学运算越多，获得准确答案的概率就越低（很快就会变得非常低）。但平均而言，答案相当准确，错误似乎并没有累积。此外，没有自我评估准确度的问题的答案的准确度更高（思考得越少越好）。 模型的自我评估误差呈指数分布，异常值以大值的形式出现，而真实误差呈正态分布。平均自估计误差高于平均真实误差，但大多数自估计误差小于真实误差。在这里，中位数比平均值更好。这意味着模型不擅长估计它们的误差，但如果需要许多类似的动作，它们可能能够粗略地估计自己。  最后，如果我们收集了一定数量的模型响应，我们可以自己估计许多任务的误差。 谢谢你的建议。    提交人    /u/roman-hart   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdijcp/precision_of_llm_generated_numbers_your/</guid>
      <pubDate>Sun, 27 Oct 2024 19:05:12 GMT</pubDate>
    </item>
    <item>
      <title>有哪些工作具有抵御人工智能的坚实护城河？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdg4nf/are_there_any_jobs_with_a_substantial_moat/</link>
      <description><![CDATA[似乎许多行业要么已经受到影响，要么即将受到影响。所以，我想知道：是否有任何工作对人工智能有强大的“护城河”——也就是说，在可预见的未来，这些职位不太可能被人工智能取代或严重颠覆？    提交人    /u/sessionletter   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdg4nf/are_there_any_jobs_with_a_substantial_moat/</guid>
      <pubDate>Sun, 27 Oct 2024 17:21:56 GMT</pubDate>
    </item>
    <item>
      <title>詹姆斯·卡梅伦对AGI发出警告</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gddnoq/james_camerons_warning_on_agi/</link>
      <description><![CDATA[你对他所说的话有什么看法？ 在最近的 AI+机器人峰会上，传奇导演詹姆斯·卡梅隆分享了对通用人工智能 (AGI) 潜在风险的担忧。卡梅隆因《终结者》而闻名，这是一部关于人工智能失败的经典故事，现在他觉得 AGI 的现实可能比小说更“可怕”，尤其是在私营公司而不是政府手中。 卡梅隆认为，开发 AGI 的科技巨头可能会带来一个由企业动机塑造的世界，人们的数据和决策受到“外星”智能的影响。他警告说，这种转变可能会将我们推入“数字极权主义”时代，因为公司控制通信并监视我们的行动。 强调“监视资本主义”的概念，卡梅伦指出，当今的公司正在成为“人类善的仲裁者”——这是一个危险的先例，他认为这比他曾经想象过的虚构天网更令人不安。 虽然他支持人工智能的进步，但他警告说，AGI 将反映人类的缺陷。“善取决于我们善良的程度，恶取决于我们邪恶的程度，”他说。 在 YouTube 上观看他的完整演讲：https://youtu.be/e6Uq_5JemrI?si=r9bfMySikkvrRTkb     提交人    /u/cyberkite1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gddnoq/james_camerons_warning_on_agi/</guid>
      <pubDate>Sun, 27 Oct 2024 15:35:08 GMT</pubDate>
    </item>
    <item>
      <title>攻读兼职人工智能硕士学位有意义吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdd8ek/does_it_makes_sense_to_do_a_parttime_masters_in_ai/</link>
      <description><![CDATA[大家好， 我 30 岁出头，在一家数字服务提供商工作，薪水不错（接近六位数）。考虑到人工智能的快速发展及其巨大的未来潜力，攻读第二个人工智能硕士学位是否是一个明智的决定（第一个是管理学硕士学位）？此外，这项资格能否在未来几年大幅提高我在德国的收入潜力？ 提前谢谢。    提交人    /u/money-money-11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdd8ek/does_it_makes_sense_to_do_a_parttime_masters_in_ai/</guid>
      <pubDate>Sun, 27 Oct 2024 15:16:03 GMT</pubDate>
    </item>
    <item>
      <title>万圣节狂欢 DJ：我需要你最奇怪、最故障、最恐怖、最畸形的 AI 视频！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcq02/djing_a_halloween_rave_i_need_the_weirdest/</link>
      <description><![CDATA[嗨！我大部分时间都在这里潜水，但我非常喜欢这里的所有海报。你们都在我的脑海里。 我希望你能给我一个你所知道的最奇怪、最有故障、最可怕、最畸形的人工智能文本转视频的链接，这样我就可以为我将要参加的万圣节狂欢派对制作一个特别的视频表演。 谢谢你的贡献。迫不及待地想看看你有什么！ 干杯 Dylan 又名 ill.Gates    提交人    /u/illGATESmusic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcq02/djing_a_halloween_rave_i_need_the_weirdest/</guid>
      <pubDate>Sun, 27 Oct 2024 14:52:49 GMT</pubDate>
    </item>
    <item>
      <title>一个法学硕士就能统治所有吗？如果不是，这可能是一个巨大的泡沫吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcg8y/one_llm_to_rule_them_all_if_not_is_this_likely_a/</link>
      <description><![CDATA[ChatGPT、Claude、Perplexity、Gemini、Copilot……每月 20 美元。对于大众来说，很难区分它们，因为它们都做着几乎相同的事情，只有细微的差异。然后其中一个发布了一项新功能来弥补差距，然后重复一遍。跟上潮流是令人兴奋的，但与此同时，大众并不是技术人员。因此，考虑到这一点，是只有我一个人觉得这看起来像一个巨大的泡沫吗？毫无疑问，它有有效的用例，但作为一种商业模式，它似乎是不可持续的。即使是 Open Ai，这家我猜在非技术人员中最为知名的公司，也预测要到 2029 年才能盈利？可能是错的。所以我想我现在的理论是，除非一个 LLM 完全出类拔萃并脱颖而出，否则这种情况似乎有成为一个大泡沫的风险。你觉得呢？     由   提交  /u/AppropriateRespect91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gdcg8y/one_llm_to_rule_them_all_if_not_is_this_likely_a/</guid>
      <pubDate>Sun, 27 Oct 2024 14:40:12 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI 推出代币级检测奖励模型，以提高视觉语言模型的准确性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gd9fbm/meta_ai_launches_tokenlevel_detective_reward/</link>
      <description><![CDATA[Meta AI 和南加州大学发布了 Token-Level Detective Reward (TLDR) 模型，以提高大型视觉语言模型 (VLM) 的准确性。这是 AI 评估方式向前迈出的一大步。https://theaiwired.com/meta-ai-launches-token-level-detective-reward-model-for-improved-vision-language-model-accuracy/    提交人    /u/alyis4u   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gd9fbm/meta_ai_launches_tokenlevel_detective_reward/</guid>
      <pubDate>Sun, 27 Oct 2024 12:03:35 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型反映了其创造者的意识形态</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gd7i61/large_language_models_reflect_the_ideology_of/</link>
      <description><![CDATA[标题：大型语言模型反映了其创建者的意识形态 我每天都会查找和总结有趣的 AI 研究论文，这样您就不必仔细阅读它们了。今天的论文题为“大型语言模型反映了其创建者的意识形态”，作者是 Maarten Buyl、Alexander Rogiers、Sander Noels、Iris Dominguez-Catena、Edith Heiter、Raphael Romero、Iman Johary、Alexandru-Cristian Mara、Jefrey Lijffijt 和 Tijl De Bie。 这项研究调查了大型语言模型 (LLM) 在多大程度上体现和反映了其开发人员的意识形态观点。随着 ChatGPT 等模型成为控制全球信息流的重要参与者，了解它们是否带有固有偏见对于评估它们对社会的影响至关重要。 主要发现：  意识形态反思：研究表明，法学硕士表现出与地区或创作者观点一致的意识形态立场。这表明，这些模型虽然看似中立，但确实反映了它们在发展过程中做出的潜在意识形态选择。 语言影响：提示法学硕士的语言显著改变了它们的意识形态立场。例如，用中文和英文提示的同一个模型显示出不同的偏见，特别是在地缘政治话题方面，展示了语言和文化背景的影响。 地区差异：在不同地理区域建立的模型表现出不同的意识形态倾向，与提示语言无关。西方法学硕士更倾向于民主价值观，而非西方模式则倾向于中央集权治理。 区域内多样性：即使在同一文化区域内，来自不同公司的法学硕士之间也存在差异。例如，与其他西方法学硕士相比，OpenAI 模型对超国家主义和腐败表现出更多的怀疑。 意识形态中立的挑战：法学硕士中的中立概念受到批判，这与哲学论点一致，认为完全的意识形态中立是无法实现的，而且可能有害。相反，在民主模式下，存在不同的意识形态观点被认为是有益的。  这些发现强调了在纯技术领域以外的背景下考虑法学硕士的意识形态取向的重要性。对监管、模型设计和用户选择的影响凸显了确保负责任地部署人工智能技术的重要主题。 您可以在这里看到完整的细分：这里您可以在这里看到完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gd7i61/large_language_models_reflect_the_ideology_of/</guid>
      <pubDate>Sun, 27 Oct 2024 09:51:55 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的崛起将如何影响电影制作的未来？人工智能会取代编剧、演员或导演吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gd72qt/how_might_the_rise_of_ai_impact_the_future_of/</link>
      <description><![CDATA[人工智能的兴起将如何影响电影制作的未来？人工智能会取代编剧、演员或导演吗？    提交人    /u/Sidolab   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gd72qt/how_might_the_rise_of_ai_impact_the_future_of/</guid>
      <pubDate>Sun, 27 Oct 2024 09:19:58 GMT</pubDate>
    </item>
    <item>
      <title>人工智能新闻：GLM-4-Voice、Gemini 2.0、Gigapixel 8</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gczspj/ai_news_glm4voice_gemini_20_gigapixel_8/</link>
      <description><![CDATA[GLM-4-Voice：智普的语音模型让对话变得生动 智普的 GLM-4-Voice 模型在回复中使用情感语调，创造出听起来自然的对话。它支持中文和英文等语言，可以流畅地处理中断，增添更动态的感觉。在 GitHub 上探索它：THUDM/GLM-4-Voice。 谷歌 Gemini 2.0：预计 12 月发布 谷歌的 Gemini 2.0 将于今年 12 月发布。虽然并不是每个人都期待它具有革命性，但 AI 爱好者们都渴望看到谷歌会有什么新东西。敬请期待！ Gigapixel 8：使用 Face Recovery Gen 2 增强照片 Gigapixel 8 致力于提高照片质量，尤其是面部质量。其 Face Recovery Gen 2 功能可恢复细节，使图像更清晰、更生动。 LVSM 模型：仅用几张图片即可创建视频 LVSM 是一种仅用几张图片即可创建视频的模型，可流畅处理各种视角，产生逼真的效果。虽然代码尚未公开，但它显示出巨大的潜力。 Bee Agent Framework：让工作流程自动化变得简单 Bee Agent Framework 是一个免费、简单的工具，用于创建、运行和管理工作流程。非常适合自动执行任务而没有任何麻烦。 来源：https://comfyuiblog.com/ai-newsglm-4-voicegemini-2-0gigapixel-8-and-more/    提交人    /u/hackerzcity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gczspj/ai_news_glm4voice_gemini_20_gigapixel_8/</guid>
      <pubDate>Sun, 27 Oct 2024 01:12:19 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以取代程序员吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gcn4h2/could_ai_replace_programmers/</link>
      <description><![CDATA[在接下来的一个月里，我想开始学习编程，但如果人工智能真的发展到可以取代像我这样的人，我担心我所做的一切都是徒劳的    提交人    /u/Dense-Actuary3269   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gcn4h2/could_ai_replace_programmers/</guid>
      <pubDate>Sat, 26 Oct 2024 15:06:54 GMT</pubDate>
    </item>
    <item>
      <title>欣顿获诺贝尔奖后首次接受采访。他称人工智能对人类构成“生存威胁”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gcm23t/hintons_first_interview_since_winning_the_nobel/</link>
      <description><![CDATA[还说工业革命使人类的力量变得无关紧要，而人工智能将使人类的智能变得无关紧要。他过去认为这大约需要 100 年的时间，现在他认为这将在未来 20 年内发生。https://www.youtube.com/watch?v=90v1mwatyX4    提交人    /u/TurpenTain   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gcm23t/hintons_first_interview_since_winning_the_nobel/</guid>
      <pubDate>Sat, 26 Oct 2024 14:16:59 GMT</pubDate>
    </item>
    </channel>
</rss>