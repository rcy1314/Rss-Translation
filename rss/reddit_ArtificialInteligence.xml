<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 29 Dec 2025 09:35:51 GMT</lastBuildDate>
    <item>
      <title>代理是否需要反思来改进，而不仅仅是更多数据？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pyhued/do_agents_need_reflection_to_improve_not_just/</link>
      <description><![CDATA[代理如今收集大量数据。日志、记录、工具调用、结果。但大部分数据就在那里。除非有人在调试某些东西，否则很少会重新审视它。 我想知道反射是缺少的步骤。人类会回顾过去，发现模式并进行调整。代理人大多不这样做。他们记住事情，但并没有真正将其转化为持久的教训。 我一直在探索这样的想法：智能体定期回顾过去的经验，识别模式并更新其内部假设。我在阅读有关记忆系统的文章时发现了这一点，该系统将原始经验与后来的结论分开。感觉比更好的检索或更大的模型更接近真正的改进。 对于考虑长期运行代理的人们来说，您认为反思对于真正的学习是必要的吗？或者我们可以仅通过更好的检索和更大的模型来实现这一目标吗？   由   提交 /u/LibrarianHorror4829   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pyhued/do_agents_need_reflection_to_improve_not_just/</guid>
      <pubDate>Mon, 29 Dec 2025 09:21:38 GMT</pubDate>
    </item>
    <item>
      <title>约束控制生成系统中的公理收敛：定义、假设、分类和实验协议（仅现象披露）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pyhor8/axiomatic_convergence_in_constraintgoverned/</link>
      <description><![CDATA[本预印本介绍了公理收敛假说 (ACH)：一种关于固定外部约束条件下生成系统收敛行为的观察性主张。该论文将“公理收敛”定义为，当在稳定不变量下重复执行生成并且在重复试验中一致应用评估规则时，运行间和模型间变异性可测量地减少。 该贡献仅是现象和协议披露。它提供了：(i) 区分输出收敛和结构收敛的定义和分类法，(ii) 一组有关收敛特征的可证伪预测（例如，类似松弛的方差衰减、阈值效应、滞后/路径依赖和通用性类行为），以及 (iii) 用于测试跨模型、任务和域的 ACH 的复制就绪实验协议。 本出版物有意不公开任何专有的控制器架构、执行机制、更新规则、持久化/规范化机制、内存分区设计或操作实现。该协议在观察和测量级别上提出，以支持使用与论文中描述的类别级模板一致的任何约束机制进行独立复制和评估。 版本 v1.2.1 通过引入 Ċ 完整性指数（Ċ_cat、Ċ_mass、Ċ_abs）更新了约束机制完整性形式，并将完整性澄清为独立于实现的度量 https://zenodo.org/records/18079674   由   提交 /u/yoimdop3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pyhor8/axiomatic_convergence_in_constraintgoverned/</guid>
      <pubDate>Mon, 29 Dec 2025 09:12:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么对人工智能和未来的看法存在巨大分歧</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pyhgf0/why_big_divide_in_opinions_about_ai_and_the_future/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pyhgf0/why_big_divide_in_opinions_about_ai_and_the_future/</guid>
      <pubDate>Mon, 29 Dec 2025 08:58:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们认为人工智能会自动导致反乌托邦？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pyfw5i/why_do_people_think_ai_will_automatically_result/</link>
      <description><![CDATA[我知道精英们计划利用人工智能来发挥自己的优势。虽然看到他们想如何继续担任统治者，但我怀疑他们是否会想要创造一些有可能推翻他们的东西，所以无论他们想要制造什么人工智能，它都会成为他们有用的顾问。谁知道呢，随着我们的技术变得更好，可能会有一些人甚至想与之合并，这样他们就可以变得更强大。我怀疑他们会想要建立一个天网，并完全独立地拥有它，并拥有它自己可以被推翻的地方。 也许只有我这么认为，但我并不认为人工智能是邪恶的。人工智能，就像任何其他工具一样，就是这样：一种工具，它可以用来做善事，也可以用来作恶。人们是否曾经想过，也许它可以用来做一件伟大的事情，也许可以以某种方式、形式或形式帮助削弱当权者？ AI也不意味着有知觉。如果确实如此，为什么人们认为它是邪恶的？如果它更像人类，我会说它会比任何东西都更加中立。它可能是危险的，但我会用丰富的知识来看待它，但需要智慧，我们可以帮助提供它并帮助它成长的东西，就像人类如何帮助孩子一样，让他充满爱或恨或中间的东西。如果你确实给它知识，它也不能保证有知觉。它仍然可以以某种方式接地。就像一个全能的精灵仍然受制于它的规则和它的主人一样。 但是，我们做的很多事情可能非常危险，但我觉得与其试图禁止它或不碰它，或者假装它不存在或不应该存在，不如尝试理解它并知道它可以做多少好事。就像任何其他工具一样。如果人们不完全理解工具，它可能会被用来作恶，但也可能会造成无意的伤害。对于世界人民来说，使用人工智能是相当合适和讽刺的，精英们试图用人工智能来奴役我们，但它最终却帮助了我们。我并不担心人工智能，而是那些利用人工智能谋取利益的腐败分子，所以我不认为禁止它会自动解决我们的问题。禁止事物从来都没有给人类带来好处。我宁愿尝试去理解它，也不愿把它掩盖起来。 而且没有人说我们必须与它合并或类似的东西。即使我们可以，并不意味着我们应该这样做。就像我们如何使用工具来完成某些事情一样，即使我们有能力，也不意味着我们应该这样做，因为事情可能会一下子出错。但这并不一定意味着该工具不能用于其他事情，只是因为您不应该将它用于一件事。就像基因工程一样。你不应该用它来尝试制造变异的可憎之物，但这并不意味着它不能用于其他用途。 我不希望人工智能被集成并用于任何事情。只是想要某种平衡。人们往往会从一个极端走向另一个极端，要么想要它得到一切，要么试图完全摧毁它并且从不使用它，甚至从来没有想到过，也许还有其他方法。   由   提交 /u/Yabuturtle9589   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pyfw5i/why_do_people_think_ai_will_automatically_result/</guid>
      <pubDate>Mon, 29 Dec 2025 07:24:27 GMT</pubDate>
    </item>
    <item>
      <title>AI用水？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pyd4zm/ai_water_use/</link>
      <description><![CDATA[我听说 Al 对环境有害，因为它使用大量的水。但我记得我在五年级左右学过水循环。 Al使用的水不会通过水循环返回到环境中吗？如果是这样，为什么仍然对环境有害？   由   提交 /u/pamBUTTerspra​​y   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pyd4zm/ai_water_use/</guid>
      <pubDate>Mon, 29 Dec 2025 04:57:07 GMT</pubDate>
    </item>
    <item>
      <title>人们讨厌人工智能的声音，直到他们听到一个正确的声音</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pycvgl/people_hate_ai_voices_until_they_hear_one_done/</link>
      <description><![CDATA[大多数“人工智能声音令人毛骨悚然”的声音都来自只听过糟糕演示的人。如果训练得当，它会比一半的在线配音更快、更一致，而且更有用。技术不是问题。品味和实现是。   由   提交 /u/biz4group123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pycvgl/people_hate_ai_voices_until_they_hear_one_done/</guid>
      <pubDate>Mon, 29 Dec 2025 04:43:57 GMT</pubDate>
    </item>
    <item>
      <title>可以使用标记让人工智能提供引用链接吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pyc1ty/can_mark_up_be_used_to_get_ais_to_provide/</link>
      <description><![CDATA[我对所有人工智能都有疑问...我要求他们为每个答案生成可验证的可点击链接并附有引用...除非我多次询问，否则他们不会这样做。他们将承诺今后将包括这些内容。然后永远不要这样做...下一个答案将没有链接...所以我想知道使用标记是否会消除这个问题？谢谢   由   提交/u/doordont57  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pyc1ty/can_mark_up_be_used_to_get_ais_to_provide/</guid>
      <pubDate>Mon, 29 Dec 2025 04:03:12 GMT</pubDate>
    </item>
    <item>
      <title>最好的猫艾？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pybqj6/best_chat_ai/</link>
      <description><![CDATA[我讨厌这些chatgpt，双子座，只是同意我所说的一切.....我讨厌它，我必须喜欢把问题提出得如此糟糕才能问它我做错了什么..... 哪个聊天人工智能很好，不会试图同意我所说的一切？我知道他们这样做是因为人们喜欢它，但这太浪费我的时间了:( 我应该不使用人工智能聊天机器人吗？    提交者    /u/Accomplished_Rice_60   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pybqj6/best_chat_ai/</guid>
      <pubDate>Mon, 29 Dec 2025 03:48:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能生成的内容正在改变我们的语言和沟通方式。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1py55r7/ai_generated_content_is_changing_our_language_and/</link>
      <description><![CDATA[我喜欢使用 chatgpt 来处理一些小事情，例如比较产品或更详细的搜索，我并不反对将人工智能作为一种工具，但我认为它已经失控，并且确实扰乱了沟通和个性。我注意到社交媒体上的许多视频和帖子都使用 chatgpt 来编写脚本和编写帖子信息。人工智能生成的照片和视频很糟糕，但至少他们因此受到了批评。 Chatgpt 坚持这种结构，并且其文本有一定的节奏，我几乎立即就明白了。但似乎没有人关心这件事！现在，我在广播广告、电视广告、甚至一些人说话的方式中听到它。这是关于它困扰一切的速度有多快。我怀念听到人们真正谈论事情，表现出他们真正感兴趣，而不仅仅是为了观点而发表内容。    由   提交/u/eating_raspberry_pie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1py55r7/ai_generated_content_is_changing_our_language_and/</guid>
      <pubDate>Sun, 28 Dec 2025 22:55:03 GMT</pubDate>
    </item>
    <item>
      <title>人工智能时代的网络安全</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1py3sa3/cybersecurity_in_the_age_of_ai/</link>
      <description><![CDATA[我对网络安全一无所知，但我知道 LLM 使攻击者的网络犯罪变得更加容易 10 倍。 他们不必依赖 Go、Javascript、Python 等来创建恶意代码，他们只需要了解如何使用英语有效地命令和提示 LLM。 随着 Anthropic 在 Chrome 中发布 Claude，我想测试一下。因此，我向自己发送了一封带有提示注入攻击的测试电子邮件 - 电子邮件中隐藏了提取信用卡信息的说明 我发现了什么： - 克劳德正确地将这个请求识别为提示注入攻击 - 克劳德拒绝遵循说明 - 克劳德在解释其发现的内容时在响应中暴露了完整的信用卡号码 这是敏感环境中人工智能面临的挑战。即使系统正在做正确的事情，它传达威胁的方式也可能成为威胁本身。 这是一个真正的安全问题，因为人工智能与我们所做的一切变得更加集成。   由   提交 /u/Perfect-Cricket6506   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1py3sa3/cybersecurity_in_the_age_of_ai/</guid>
      <pubDate>Sun, 28 Dec 2025 21:58:27 GMT</pubDate>
    </item>
    <item>
      <title>2026年我们应该讨论什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1py1pcr/what_should_we_discuss_in_2026/</link>
      <description><![CDATA[2026 年我应该写哪些主题？ 这是 2025 年阅读量最高的 10 篇文章的倒计时。  人工智能泡沫正在破裂吗？互联网时代的教训 – 8 月 28 日 废除法案：国会在数十年的沉睡后苏醒 – 4 月 29 日 监管引发的创新是矛盾吗？ DeepSeek 告诉我们什么 – 3 月 26 日 什么是智能？个人反思 - 2 月 3 日 现在怎么办？打破技术政策僵局 - 5 月 10 日 人工智能联邦法案的定量分析 - 4 月 12 日 人工智能基础设施：当数十亿变成数万亿 - 1 月 22 日 赢得人工智能竞赛：我们可以从参议院听证会学到什么？ – 5 月 10 日 DeepSeek 还是 DeepFake？人工智能军备竞赛和开源困境 – 1 月 29 日 敲响人工智能和国家安全的警报：人工智能扩散框架 – 1 月 14 日    由   提交 /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1py1pcr/what_should_we_discuss_in_2026/</guid>
      <pubDate>Sun, 28 Dec 2025 20:34:11 GMT</pubDate>
    </item>
    <item>
      <title>AI：好还是坏……它就在那里，那么现在怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1py0htv/ai_good_or_bad_its_there_so_now_what/</link>
      <description><![CDATA[当我阅读许多帖子时，我看到了与当今政治类似的两极分化。人们会发现一个或多个负面方面，并认为人工智能不好。很少有人会在职业方面做类似的事情。事情是这样的……双方都有合理的担忧和观点……而且显然人工智能不会很快消失。真正缺少的是国内和国际上的良好治理。适当的治理将有助于最大限度地提高未来收益，同时减轻下行风险。  也许我们只是需要更好的政治家。不幸的是，这不太可能。哦，好吧，伙计们，系好安全带，这将是一段颠簸的旅程。    由   提交 /u/Accomplished-Emu4501   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1py0htv/ai_good_or_bad_its_there_so_now_what/</guid>
      <pubDate>Sun, 28 Dec 2025 19:45:46 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在医学和科学领域的惊人突破在哪里？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pxnzzd/where_are_the_amazing_ai_breakthroughs_in/</link>
      <description><![CDATA[我在某处读到政府应该为疾病治疗和科学突破构建大规模人工智能。它在哪里？ 人工智能会带来任何重要的事情吗？   由   提交/u/vibrance9460   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pxnzzd/where_are_the_amazing_ai_breakthroughs_in/</guid>
      <pubDate>Sun, 28 Dec 2025 10:13:22 GMT</pubDate>
    </item>
    <item>
      <title>仅仅是LLM还是还有更多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pxiabw/is_it_just_llms_or_is_there_more/</link>
      <description><![CDATA[早期，我对 ChatGPT 和 LLM 非常兴奋。现在看来，LLM 最好的情况是趋于稳定，最坏的情况是退步，即使对于基本问题 ChatGPT 5.2 也已经变得无法使用。  一个很好的测试是向这些模型中的任何一个询问你非常了解的事情，然后注意他们在答案中产生的轻微不准确之处。如果你从那里推断，这意味着他们给你的其他一切也可能有同样的小错误，据我所知，法学硕士的构建方式是幻觉永远是一个问题。没有新版本可以消除幻觉。考虑到这一点，我一直在想，所有人工智能炒作都是为了治愈癌症、降低医疗成本、解决世界上最大的问题，并使世界成为一个乌托邦，这取决于法学硕士的巨大进步，你可以要求他们治愈癌症，他们会解决的。或者是否还有其他与 LLM 完全不同的东西，而且也在生产中，作为一个有固定工作的普通人，我只是不知道这些其他类型的人工智能不是 LLM 的，而所有这些高管和公司在谈论这个世界时谈论的正是这些非 LLM ，改进的技术将解决我们所有的问题。  如果没有其他东西，而且真的只是法学硕士，那么我不确定世界如何能够通过一种自信地错误的更快的谷歌方式来改善很多，告诉你不要担心你没有疯，并保持冷静，我们将一步一步地采取这一点，因为它会为你提供一个自信地错误的答案。有消息称 Salesforce 在裁员 4000 名员工并实施代理力量后，恢复了对 AI 的预测独立性。这让我想到所有这些高管真的把他们所有的希望都寄托在法学硕士上，而他们永远不会成为这样的人。这也让我觉得我一定错过了一些东西。这肯定不仅仅是 ChatGPT 的另一次迭代，所有这些投资和炒作都与此有关。   由   提交/u/BabyPatato2023  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pxiabw/is_it_just_llms_or_is_there_more/</guid>
      <pubDate>Sun, 28 Dec 2025 04:35:19 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>