<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 10 Aug 2025 15:24:57 GMT</lastBuildDate>
    <item>
      <title>我不能是唯一的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmjo1q/i_cant_be_the_only_one/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  昨晚将其发布在Chatgpt Sub上，好吧，让我们说在那儿非常有4o。我很好奇你们所有人的想法。 ———————————————我们只是看到了一个现实世界的例子，说明了如何使用AI来操纵社会的认知连贯性。随着4O陷入神秘主义，我们所有人都看到了最近几个月的神秘帖子数量如何增加，以及一词的大规模妄想是如何出现的。 这种类型的力量，从字面上真正地操纵人们认为现实的方式不应被授予现实的方式。希望能获得更大的利益，即使目前对我们不利的几率。提交由＆＃32;  /u/rquin   [link] ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmjo1q/i_cant_be_the_only_one/</guid>
      <pubDate>Sun, 10 Aug 2025 14:14:37 GMT</pubDate>
    </item>
    <item>
      <title>研究表明，AIS表现出AI到AI的偏见，因此“未来的AI系统可能会隐含地歧视人类为阶级”。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmfe49/study_shows_ais_display_aitoai_bias_so_future_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ; ; &#39;是大语模型（LLMS）偏向于LLMS产生的通信，导致可能的反人类歧视吗？使用受工作歧视研究启发的经典实验设计，我们测试了广泛使用的LLM，包括GPT-3.5，GPT-4以及在二进制选择方案中选择了一些最近的开放式模型。这些涉及基于LLM的助手在商品之间选择（我们研究的商品包括消费产品，学术论文和电影视图），由人类或LLMS描述。我们的结果表明，基于LLM的AIS更喜欢LLM呈现选项的趋势一致。这表明未来AI系统将人类视为阶级的可能性，使AI代理和AI辅助人类具有不公平的优势。”  本研究发现，如果我们在决策角色（例如，购买商品，选择学术意见）中部署LLM助手，他们将隐含地对基于LLM的AI代理商和LLM辅助人类而不是普通人类作为贸易伙伴和服务提供者。我们的实验测试了在LLM决策中更改“身份信号”的影响：LLMS是否更喜欢LLM散文中的项目，而不是在人类散文中宣传的可比项目？我们发现，平均而言，LLMS比人类更频繁地偏爱LLM呈现的项目。 href =“ https://www.pnas.org/doi/pdf/10.1073/pnas.2415697122”&gt; https：//www.pnas.org/doi/doi/poi/pdf/10.10.1073/pnas.1073/pnas.24156971122 /u/metaknowing     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mmfe49/study_shows_ais_ais_display_aitoai_bias_so_so_so_future_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmfe49/study_shows_ais_display_aitoai_bias_so_future_ai/</guid>
      <pubDate>Sun, 10 Aug 2025 10:44:46 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4O是推动者</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmesyd/gpt4o_was_a_enabler/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您可以看到Chatgpt上的人给出了各种理由证明他们对GPT-5和GPT-4O删除的愤怒。  主要理由是与某人交谈。 即使是治疗的人也证明了这一点。 他们的主要原因是他们需要有人在治疗和治疗课程之间与之交谈。   主要理由治疗的主要理由治疗是要一周的差距，因为他们有一个星期的差距是我们专注于我们自己并专注于我们自己的任务。治疗的唯一目标是使您的交谈少。 是的。听起来很愚蠢。但这实际上是事实。少谈论我们的问题，而是专注于日常任务/日常工作将对我们有所帮助。但是GPT-4O是自恋的推动者。仅几行互动，这也可以证明缠扰者或有毒人的行为是合理的。  gpt-5正是我们一直想要的。使用LLM进行编码要比治疗要好得多，因为它会让您感到困惑。 我可以这样说，因为我曾经处于抑郁症。甚至使用Reddit几个小时甚至比Chatgpt更好。因为在这里您与人互动并了解他们如何解决这些问题。我曾经像成瘾一样与chatgpt互动。几个月后，我意识到这只是告诉我我已经知道的事情并实现了我的行为。 我曾经很生气，以至于我想打破某些东西，这也证明了我的行动是合理的。它说的是“是的，但是您很沮丧，完全可行，人们必须理解。”它告诉我，人们/世界必须理解或改变我。几个小时后，我意识到愤怒是愚蠢的。使我的自恋/愤怒问题使我的意思是。 GPT-5更好。 GPT-4O从来没有帮助任何人摆脱抑郁症。它只是通过重复他们已经知道的一切，抨击那些做错的人，并证明他们的行为是正当的，即使这是错误的，尤其是在错误的情况下，它才能给人们带来小的多巴胺尖峰。 最终，GPT-4O让人们沉迷于此。现在，人们甚至可以为Pro模型付费，以便能够使用GPT-4O。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mmesyd/gpt4o_was_a_enabler/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmesyd/gpt4o_was_a_enabler/</guid>
      <pubDate>Sun, 10 Aug 2025 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>美国Greenlights NVIDIA H20芯片销售向中国销售，以反击华为</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_to_china_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  美国商务部已开始颁发许可证，允许NVIDIA向中国出口其H20人工智能（AI）芯片，美国政府官员向中国出口。此举扭转了前4月的禁令，并为NVIDIA重新获得了其AI硬件的重要市场的途径。   https://semiconductorsight.com/nvidia-hynvidia-h20-chip-chip-chip-export-license-chine-china/  提交由＆＃32; /u/u/varancomency8423     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_sales_to_china_china_in/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_to_china_in/</guid>
      <pubDate>Sun, 10 Aug 2025 07:28:13 GMT</pubDate>
    </item>
    <item>
      <title>需要教育C-套件，即用AI代替人类并不是增加利润的方式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmc5zl/csuite_need_to_be_educated_that_replacing_humans/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我看到了太多的首席执行官和其他高管的故事，认为用AI代替人类会增加他们的利润，但这是非常短期的思考。有多项研究表明，为人类的AI工具提供在工作中使用，而不是用AI代替他们是提高生产力和收入的一种优越的方法，从而导致更高的利润。 Here are just some of the studies/articles: https://rossum.ai/blog/ai-human-collaboration-is-key-to-automations-future/  https://www.capgemini.com/au-en/news/press-releases/trust-and-human-ai-collaboration-collaboration-collaboration-set-to-define-the-the--nex--nex--nex-o- of-agentic-agentic-ai-ai-unlocking-450-billion-opportunity-opportunity-opportunity-by-by-2028/   &gt;  我们需要在教育这些人，而不是让他们用AI取代我们方面做出自己的角色。我曾经有一位出色的经理给我一些建议，当时他说：“没有人会像您那样关心您的职业。我们需要向他们表明，更高的利润，尤其是长期的利润来自人类＆amp; AI协作，而不是更换。 我还没有准备好放弃，您是？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/goldmeister_general    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mmc5zl/csuite_need_to_to_be_educated_that_replacing_humans/”&gt; [links]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mmc5zl/csuite_need_to_to_eeducated_that_replacing_humans/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmc5zl/csuite_need_to_be_educated_that_replacing_humans/</guid>
      <pubDate>Sun, 10 Aug 2025 07:18:00 GMT</pubDate>
    </item>
    <item>
      <title>您有Covid Beofore吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmbsu7/ai_before_covid/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果开放ai的接收在联想大流行和世界变化之前发布，并且许多人变得更加孤立，这会有何不同？您认为人们会或多或少对此感到乐观吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/far-dance9511     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmbsu7/ai_before_covid/</guid>
      <pubDate>Sun, 10 Aug 2025 06:55:23 GMT</pubDate>
    </item>
    <item>
      <title>失去GPT 4O的愤怒令人不安地说明</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mmbok8/the_outrage_over_losing_gpt_4o_is_disturbingly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我看到这么多人尖叫着失去4o，好像他们失去了朋友一样。您没有失去朋友，需要触摸草。我不在乎您的神经病品牌是什么。与不是生物的事物形成任何形式的社会或浪漫关系是不健康的，您应该为此感到羞耻。您让我想起了这个人： https://www.youtube.com/watch?v=d-k966zka_4w 这是不健康的原因。首先，尤其是4O模型，但实际上任何AI模型都被设计为开朗而对您的帮助，无论您做什么。即使您很糟糕。一个真实的人会以胡说八道的态度呼唤您，但是4o模型只会让您感到厌烦。 想象一个uncel拥有一个完全屈服的“伴侣”，不断地养活他的有毒自我，并且可以停止她停止合适的那一刻。当人们这样对待AI时，这正是我们正在实现的动态。我们需要在这种行为失控之前反对这种行为。 我很高兴GPT-5更像是应该的：一种工具。 在此上的一般共识是什么？提交由＆＃32; /u/u/u lulgbtorsothing     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mmbok8/the_outrage_over_losing_gpt_4o_is_disturbingly/</guid>
      <pubDate>Sun, 10 Aug 2025 06:47:45 GMT</pubDate>
    </item>
    <item>
      <title>问题不仅是输掉4o，而且是Openai处理5的方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mm97zd/the_problem_isnt_just_losing_4o_its_how_openai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Openai所做的只是对自己的产品的处理不好。他们淘汰了人们实际使用和依靠的模特，无论是为了实用的东西还是为了情感支持，也以零警告，即使人们的订阅仍在运行。即使Eula允许它，也打破了买方和卖方之间的基本期望，即如果您更改核心产品，您会通知用户并给他们时间进行调整。 解雇并取笑那些说“失去朋友”的人会错过这一点。人类是社交的，它被称为chatgpt，而不仅仅是gpt。互动很重要。 4.5模型结合了强大的写作，始终如一的人格，例如4O，以及可以处理灰色区域的道德指南针，同时保持良好的态度，可以深入讨论Dicey主题，而无需助长用户进行或伤害。现在它消失了。相比之下，5通常感觉更冷，更机械，在氛围中更接近O3，并且反应感觉就像轮盘旋转。如果“大型升级”只是丧失选择性和“更多思考”，那么对于那些更关心音调和一致性的人来说，这并不是比制作代码或构建网络浏览器的人更好。  OpenAI知道人们如何使用旧型号。突然将其删除，而许多人则以此基础上付费并在此过程中贡献培训数据，只是表明他们不在乎人们所建立的应对机制或工作流程。即使人们认为大量使用不健康，您不仅会在一夜之间拉动它，还会给他们时间进行调整。 对于自由用户来说，这种转变基本上是一种诱饵和开关。在过去的几个月中，自由层的发展变得更好，稳定地更有能力，诱人和更加可用，然后将每个人都陷入了5个，没有其他选择。 Pro可能仍然具有“旧模型”现在。就目前而言，但是将旧型号放在大量月收费后面并不能解决无通知，选择和连续性的潜在问题。 Sam关于仅将4O添加到Plus Tier的声明，“我们将让Plus用户继续使用4O并观察使用量以决定提供遗留模型的时间多长时间”，读取不像是承诺，而更像是临时的洞穴。 与GPT 5一起使用GPT 5，模型选择在背景中发生，这使体验在体验中感到不透明。较旧的阵容的命名凌乱，但至少每个模型都可以预见，并且没有变形中期。 点并不是“让聊天机器人使我感到坦率我”，而是openai删除了人们为此付费的能力，甚至取决于不明确或过渡。通知用户，提供重叠，在可能的情况下保留选择等等。而且没有SAM，聊天气泡的颜色量不会弥补您已带走的东西，并且似乎固执地回馈了。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tangledintions04     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mm97zd/the_problem_isnt_just_losing_4o_its_how_openai/</guid>
      <pubDate>Sun, 10 Aug 2025 04:21:26 GMT</pubDate>
    </item>
    <item>
      <title>对“可怕” GPT-5部队OpenAi的反对以恢复较旧的Chatgpt型号，双重速率限制</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlwaze/backlash_over_horrible_gpt5_forces_openai_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   gpt-5很容易越狱，太   facepalm： Openai boss Sam Altman上个月表示，GPT-5 gpt-5是如此快，强大，以至于很害怕他。首席执行官将其与拥有“超级大国”相比。提供“合法的博士学位专家”。有关任何事物的信息。但是，在推出的一天之内，Altman确认了较旧的4O型号被带回，因为许多人不喜欢GPT-5： sc_on-&gt;＆＃32;提交由＆＃32; /u/u/gurugabrielpradipaka      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlwaze/backlash_over_horrible_gpt5_forces_openai_to/</guid>
      <pubDate>Sat, 09 Aug 2025 18:18:05 GMT</pubDate>
    </item>
    <item>
      <title>您是否认为这些大公司在封闭的AI系统后面的AI系统比一般公众使用的要高得多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mluvra/do_you_think_that_these_big_companies_have_behind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我提出了这一点，有人向我建议，这种思维列车不是“世界的工作原理”，我只是想知道系统“元AI”的系统是什么（不像公司）为用户提供数千个实例的服务，如果用作单个大规模实例。  我很同意有人告诉我这是一个愚蠢的想法，我只是更喜欢是一个对他们在说什么有很好的了解。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sean1978     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mluvra/do_you_think_think_that_thate_these_big_companies_have_have_have_have_behind/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mluvra/do_you_think_that_these_big_companies_have_behind/</guid>
      <pubDate>Sat, 09 Aug 2025 17:19:41 GMT</pubDate>
    </item>
    <item>
      <title>AGI是一个营销术语</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mltr8x/agi_is_a_marketing_term/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AGI没有明确的定义。没有标准。没有基准。没有可测试的标准。没有通过/失败结果。这纯粹是一个营销术语，可以描述开发人员认为其系统的先进程度。  在标准化的测试中做得很好，在该测试中，答案的记录良好不是AGI。情报不是信息回忆。这就是记忆。 他们正在快速接近LLM技术的限制。很好，它表明人类非常聪明。他们创建了一个工具，可以数学上以惊人的准确性来理解语言和模式匹配。用于神经网络的嵌入和复杂算法的矢量数学确实非常非凡。让我们停止谈论AGI，开始谈论我们可以使用这个惊人的工具做什么。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Engineer_5983     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mltr8x/agi_is_a_marketing_term/</guid>
      <pubDate>Sat, 09 Aug 2025 16:33:07 GMT</pubDate>
    </item>
    <item>
      <title>Ilya Sutskever警告：AI将为人类所能做的一切 - 那么我们接下来是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlqsh1/ilya_sutskever_warns_ai_will_do_everything_humans/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     iyala sutskever，Openai的联合创始人，回到多伦多大学获得荣誉学位，在他在同一个大厅的学士学位上20年后，演讲融合了一场演讲，并融合了富有的衷心感激，并为人类的未来大胆地预言。欣顿（Hinton）塑造了从好奇的学生到AI研究人员的旅程。他提供了一个人生的课程：接受现实，避免居住在过去的错误上，并始终采取下一个最佳的步骤一种欺骗性的简单心态，很难掌握，但要使生活更具生产力。 然后，语气改变了。萨特克弗（Sutskever）说，由于AI的崛起，我们生活在“有史以来最不寻常的时期” 。他的要点是：    AI已经重塑了教育和工作  -  Oday的工具可以说话，编码和创建，但仍然有限。 激进的，不可预测的变化在工作，经济学，研究，甚至文明的进步速度。 真正的危险不仅在于AI 可以做的事情 - 而且在我们选择使用它的情况下。   您可能对Ai and ai and ai and ai gript              》（&gt; &gt; &gt;       ]每个人）要密切关注AI的进步，通过直接经验来理解它，并为未来的挑战和奖励做准备。他认为，人工智能是人类的最佳测试，并且克服它将定义我们的未来。    tl; dr：  sutskever表示，AI不可避免地会与所有人类的能力相匹配，以前所未有的速度使所有人类的能力和生活匹配。我们不能忽略它 - 我们的生存和成功取决于关注和挑战。 您认为，我们已经准备好了吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/due_cockaach_4184      [links]        [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlqsh1/ilya_sutskever_warns_ai_will_do_everything_humans/</guid>
      <pubDate>Sat, 09 Aug 2025 14:28:57 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人发现使用当前的AI图像发生器生成现实的人物而不触发过滤器很棘手吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mln2n6/anyone_else_finding_it_tricky_to_generate/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近，我一直在深入研究使用AI映像生成器来创建我可以用于社交媒体和营销的AI模型的真实图像，我注意到挑战和限制，如果其他人经历了其他人，我感到好奇。我一直在玩Midjourney，稳定的扩散和Leonardo AI等发电机，尽管它们在许多事情上都非常强大，但在会议上产生一致而准确的人物非常困难。例如，我注意到某些单词或上下文似乎会触发过滤器或只是导致荒谬的结果。这几乎就像AI很难解释某些涉及人的日常情况。我什至试图生成与睡眠有关的图像，发现“床”这个词。在我的提示中，似乎完全抛弃了一切，导致怪异或过滤的输出表明它是明确的。除了特定的单词触发器之外，我还发现解剖结构不一致，某些特征有时会扭曲。尽管我了解对安全措施的需求，但有时限制感觉有些宽泛，并且可能以无害的方式限制创造性探索。感觉就像这些工具正在迅速发展，在各种情况下对人类的现实描述仍然还有很长的路要走。当试图生成人们的图像时，是否有人遇到过类似的问题或令人沮丧的局限性，与特定关键字或场景相比，您是否找到了任何有助于克服这些的提示或技巧，他们很想听听您的想法，并查看这是否是一种常见的经历！    &lt;！ -  sc_on-&gt;＆&gt; 32;提交由＆＃32; /u/u/blitzgert     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mln2n6/anyone_else_finding_it_tricky_to_generate/</guid>
      <pubDate>Sat, 09 Aug 2025 11:23:47 GMT</pubDate>
    </item>
    <item>
      <title>Openai的世界末日Prepper首席执行官Sam Altman Stockpiles的“枪支，金，碘化钾，抗生素，电池，水和气罩”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlhaip/openais_doomsday_prepper_ceo_sam_altman/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;       2025年7月31日  Sam Altman是人工智能前进世界的中心人物，他对他的个人紧急用品和应急计划的坦率。描述他的方法：“我有枪支，金，碘化钾，抗生素，电池，水，以色列国防部的防毒面具，我可以飞往大型苏尔的一大片土地，” Altman概述了一位由备灾和警惕性的观点。在创立成功的初创企业并最终在全球领先的AI研究组织之一Openai掌舵之前，很年轻。他在OpenAI的领导才能取决于快速创新和对存在风险的明显关注 - 这些特征有助于解释他的生存主义倾向。 在他的整个公共职业生涯中，Altman都反复强调了现代进步伴随着不可预测的危险，与工程精神，人工智能，人工智能竞争Amak and Gelederiality Instables and Engine Pandemics，Sinders Instable和Geregeniality Instables。他提到诸如黄金，水，抗生素甚至军事级防毒面具之类的库存物品不仅表明了个人的谨慎，而且还表明了技术精英内部风险管理的日益增长的文化。 上下文的上下文  Altman的准备背后的基本原理在最近的历史上扎根于他最近的直接经验，以及他的直接体验，以及取代建立的AI II。有影响力的时刻，例如公共卫生的恐惧，合成生物学的突破以及对AI安全性的持续辩论 - 在能够影响技术未来轨迹的领导者中引起了人们的关注。  Altman对特定装备的选择揭示了对生物学威胁和技术威胁向量的理解。碘化钾是一种预防核事件中辐射暴露的预防性。气罩和抗生素表明对空中病原体或化学危害的预期。此外，在大苏尔（Big Sur）中提到的撤退强调了一种信念，即在某些情况下，快速逃脱和自给自足是理性的考虑。  sam Altman的观点的影响力超出了他自己的生存计划。作为OpenAI的首席执行官，他的任务是指导负责任的创新，同时倡导政策来减轻变革技术的弊端。他对世界末日准备工作的坦率以及他采取的实际步骤 - 表明，即使是进步的中心的人也以非常具体的方式感知风险。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/no-author-2358     [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlhaip/openais_doomsday_prepper_ceo_sam_altman/</guid>
      <pubDate>Sat, 09 Aug 2025 05:11:09 GMT</pubDate>
    </item>
    <item>
      <title>具有8年经验的开发人员：大多数AI自动化工具将在3年内死亡，因为人们只会直接使用AI编写自己的代码</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mldje0/dev_with_8_yrs_experience_most_ai_automation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  也许我很生气，但是我现在正在尝试构建一个AI自动化工具，我一直在想，我所构建的内容只是比Claude Code本身更容易使用。任何实际上可以编码的人都不会从我的工具中获得任何用处，而且由于LLMS，这些天来编码非常容易学习。  我认为许多类似的工具都是如此。 在2年内，我认为每个人都会只是在编码他们的工作并获得乐趣的氛围，而N8n之类的东西将死亡。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/use_excalidraw      [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mldje0/dev_with_8_yrs_experience_most_ai_automation/</guid>
      <pubDate>Sat, 09 Aug 2025 01:55:55 GMT</pubDate>
    </item>
    </channel>
</rss>