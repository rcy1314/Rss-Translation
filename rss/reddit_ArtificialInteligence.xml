<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 27 Jan 2026 18:46:08 GMT</lastBuildDate>
    <item>
      <title>如果有意识的人工智能确实被创造出来，并且它处理现实的速度比我们快一百万倍，我们怎么能与这个创造联系起来呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qomcga/if_conscious_ai_was_actually_created_and_this/</link>
      <description><![CDATA[我读到达里奥关于强大的未来人工智能的想法是处理速度比人类快 10 到 100 倍，因为它不受我们大脑如何在生物学上发送信号的限制。因此，假设如果这是能够达到主观现实的东西，那么体验会是什么样的。我一直想象在这种情况下意识会像我们现在一样流动，但是了解人工智能处理输入的速度，现实会感觉完全不同吗？    由   提交 /u/Intelligent-Month-35   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qomcga/if_conscious_ai_was_actually_created_and_this/</guid>
      <pubDate>Tue, 27 Jan 2026 18:36:31 GMT</pubDate>
    </item>
    <item>
      <title>当人工智能“有效”但仍然失败时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qoltm9/when_ai_works_and_still_fails/</link>
      <description><![CDATA[我最近一直在深入研究人工智能，我写了一篇文章，详细分析了人工智能系统如何以“局部正确性”来完成每个单独的任务——比如代码运行、逻辑检查——但仍然陷入完全混乱，因为它们继承了我们人类的捷径、偏见和盲点。考虑跳过安全检查，因为它“更快”，“就这一次”例外，或者为了快速获胜而优化，而不是长期理智。 我注意到的一些杀手方面：  “人工智能系统不只是执行指令；它们继承了制造者的假设、激励、捷径和盲点。” “先行动，后思考，然后证明。它是一个明确的人类行为。”  我在这里的论点是，我们需要更好的“治理层”来保持人工智能在扩展时保持一致，否则我们只是在放大我们自己混乱的思维方式。这让我想起了那些流氓人工智能特工的故事，一切都开始得很顺利，但最终以垃圾箱着火告终。 你认为这是这么多人工智能“失败”背后的真正原因吗？还是我们夸大了人为因素？您见过实际项目中的示例吗？ 查看评论中的完整内容。很想听听您的看法！   由   提交/u/rohynal  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qoltm9/when_ai_works_and_still_fails/</guid>
      <pubDate>Tue, 27 Jan 2026 18:18:37 GMT</pubDate>
    </item>
    <item>
      <title>人们害怕让人工智能在现实世界中做事吗？如果是这样，为什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qollqv/are_people_afraid_of_letting_ai_do_things_in_the/</link>
      <description><![CDATA[我想我生活在泡沫中。最近在我的个人页面上进行了一项 Instagram 民意调查，询问人们是否会让人工智能在现实世界中为他们做事。 70% 的人说不。  我想了解大多数人是否有这种感觉。  预先感谢您的任何评论或反馈。真的很感激。    由   提交 /u/No-Sprinkles-8204   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qollqv/are_people_afraid_of_letting_ai_do_things_in_the/</guid>
      <pubDate>Tue, 27 Jan 2026 18:11:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在不破坏生产行为的情况下管理即时更改？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qolcdo/how_do_you_manage_prompt_changes_without_breaking/</link>
      <description><![CDATA[我正在构建一些提示不再只是实验的东西 - 它们是真正工作流程的一部分。 当我迭代时，我遇到了一个感觉非常“软件工程式”而不是“提示工程式”的问题： 小的提示更改可能会巧妙地（或不那么巧妙地）破坏行为、一致性或输出结构。 我很好奇这里的人在实践中如何处理这个问题，尤其是当事情超出原型设计的范围时。 我试图弄清楚的一些具体事情： • 您是否像代码一样对提示进行版本控制？如果是这样，粒度如何？ • 在交付之前如何测试即时更改？ • 您是否执行严格的输出模式/合同？ • 是否有安全地推出即时更新的工作流程（金丝雀、A/B 等）？ • 您早期犯过哪些现在可以避免的错误？    由   提交/u/batmantvgirl  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qolcdo/how_do_you_manage_prompt_changes_without_breaking/</guid>
      <pubDate>Tue, 27 Jan 2026 18:02:16 GMT</pubDate>
    </item>
    <item>
      <title>人工智能时代的地缘政治：不确定的人工智能未来中的战略与力量</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qol7vr/geopolitics_in_the_age_of_artificial_intelligence/</link>
      <description><![CDATA[https://www.foreignaffairs.com/united-states/geopolitics-age-artificial-intelligence [摘自基辛格教授杰克·沙利文的论文哈佛大学肯尼迪学院治国与世界秩序实践博士，2021 年至 2025 年担任美国国家安全顾问； ] 无论人工智能的未来最终如何发展，美国战略都应该从对成功的明确定义开始。华盛顿应该利用人工智能来加强国内和盟友之间的国家安全、基础广泛的繁荣和民主价值观。当人工智能与公共利益相结合时，可以推动科技进步，改善生活；帮助应对公共卫生、发展和气候变化等全球挑战；维持和扩大美国对中国的军事、经济、技术和外交优势。美国可以做到这一切，同时负责任地管理人工智能带来的非常现实的风险。 挑战在于如何实现这一目标。为了使隐藏的假设变得明确并针对不同的未来测试策略，那些考虑人工智能策略的人应该考虑一个简单的框架。它提出了三个问题：人工智能的进步会加速走向超级智能，还是会长期处于停滞状态？突破是否容易复制，还是追赶会变得困难且成本高昂？中国是否真的在争夺前沿，或者是否将其资源投入到其他地方，以为以后可以模仿和商品化？    由   提交 /u/ForeignAffairsMag   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qol7vr/geopolitics_in_the_age_of_artificial_intelligence/</guid>
      <pubDate>Tue, 27 Jan 2026 17:58:08 GMT</pubDate>
    </item>
    <item>
      <title>代理工具、法律视角下的人工智能代理</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qol45w/agentic_tools_ai_agents_from_legal_perspective/</link>
      <description><![CDATA[我与律师进行的讨论。 当您在 Youtube 或 Twitter 上看到人工智能演示时，“从头开始构建网站”或“实现工作流程自动化”的代理看起来令人印象深刻。他们得到了参与。但当你试图把它卖给真正的企业时，即使企业没有得到它，它也会变成一种负债。 当你告诉客户代理人可以“弄清楚”时，你就在承诺一些你无法控制的事情。它迟早会产生折扣幻觉，向错误的公司发送电子邮件，或者做出错误的数据更改。到那时，错误就是你的了。真正成功的工作是无聊的。很无聊。清晰的步骤。严格的规则。人类在循环中。人工智能仅在存在模糊性的情况下使用。 如果我们专注于构建护栏而不是实验，它会更安全、更稳健，也不会惹恼更少的人，因为它不会不断犯错误，而这可能是你被起诉的原因。   由   提交/u/ranaji55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qol45w/agentic_tools_ai_agents_from_legal_perspective/</guid>
      <pubDate>Tue, 27 Jan 2026 17:54:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能生产力是否真的节省了您的时间，还是我们只是花了几个小时调整提示？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qoimmr/is_ai_productivity_actually_saving_you_time_or/</link>
      <description><![CDATA[我最近一直在认真审核自己的工作流程（主要与学术研究、数据输入和内容组织相关）。 我诚实地意识到，对于我大约 80% 的日常任务，设置完美的 AI 代理或尝试自动化一个简单的流程比手动完成工作要花费更长的时间。投资回报率根本不存在。我发现自己花了几个小时调整提示，只是为了节省 10 分钟的实际工作时间。感觉更像是生产力剧场，而不是实际生产力。 然而，对于另外 20% 的人（特别是使用 NotebookLM 或自定义 RAG 系统等工具来读取大型 PDF 库的大规模数据合成），节省的时间是天文数字。它将几天的阅读变成了几分钟的综合。 对于那些在真正的专业或商业环境中实际使用人工智能（不仅仅是为了好玩）的人来说，现在对你真正产生净积极影响的一个特定工作流程是什么？我正在努力消除炒作，找到在生产中真正有效的方法。您实际上是在节省时间，还是只是将工作量转移到管理 AI 上？   由   提交/u/wido720  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qoimmr/is_ai_productivity_actually_saving_you_time_or/</guid>
      <pubDate>Tue, 27 Jan 2026 16:29:18 GMT</pubDate>
    </item>
    <item>
      <title>Kimi开源了全球最大的VLM</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qofwbs/kimi_has_opensourced_the_worlds_largest_vlm/</link>
      <description><![CDATA[根据他们的博客，他们在多个基准测试中实现了 SOTA。 来源：https://www.kimi.com/blog/kimi-k2-5.html   由   提交 /u/Big_Draft309   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qofwbs/kimi_has_opensourced_the_worlds_largest_vlm/</guid>
      <pubDate>Tue, 27 Jan 2026 14:50:30 GMT</pubDate>
    </item>
    <item>
      <title>人工智能真的能帮助发展严肃的会计实践吗？还是只是噪音？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qoc6ve/can_ai_actually_help_grow_a_serious_accounting/</link>
      <description><![CDATA[我们正在尝试将我们的会计业务扩展到推荐和本地业务之外，而在线部分比我们想象的更具挑战性。在线销售线索往往意向较低、对价格敏感，或者根本不确定自己想要什么。信任也是一个问题——在会计领域，可信度很重要，但在网上，很难展示实际经验而不显得过于推销。 最近，我一直在想人工智能是否真的可以帮助解决这一问题，而不仅仅是在理论上。当然，不是为了实际的会计工作，而是为了提高潜在客户质量、以清晰的方式解释服务、大规模建立信任，甚至确定哪种内容真正推动客户决策。 似乎许多解决方案都声称可以推动增长，但我不确定人工智能在会计等面向服务、基于信任的行业中的位置。 这里是否有人真正在现实世界的应用程序中使用人工智能，从简单的在线展示到真正吸引严肃的客户定期？   由   提交 /u/Loud_Assistant_5788   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qoc6ve/can_ai_actually_help_grow_a_serious_accounting/</guid>
      <pubDate>Tue, 27 Jan 2026 12:13:35 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是我用过的最酷也是最可怕的东西。有这样的感觉正常吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qobfi8/ai_is_both_the_coolest_and_scariest_thing_ive/</link>
      <description><![CDATA[最近我一直在试图弄清楚我对人工智能的真实感受。一方面，我不断听到 Yuval Harari、Eliezer Yudkowsky、Sam Harris 等人说人工智能将消灭我们。我在睡觉前观看他们的 Youtube 视频。老实说，这些东西让我害怕。与其说是技术本身，不如说是少数人或公司最终可能拥有太多权力的想法。 但与此同时，我真的很喜欢人工智能现在让我做的事情。大约一年前，我从 Windows 切换到 Linux，如果没有 GPT 帮助我解决问题，我可能无法在这种转变中幸存下来。昨天我有一次有趣的经历。我的 PC 最终安装了大量积压的更新（例如 51 个），在重新启动 Ubuntu 后，Steam 拒绝启动。 我尝试了通常的故障排除。 GPT 起初给了我一些简单的检查，但很快就变成了深入研究，打开多个终端窗口，观察输出，试图找出崩溃的原因。经过大约一个小时的失败后，我想到了让 GPT 自己处理整个事情的想法。我告诉它制定一个计划，找出步骤，并编写一个我可以运行的脚本。然后我将脚本粘贴到文件中并运行它。它收集了一堆日志文件，然后我上传了这些文件，在下一步中它发现了问题，编写了另一个脚本来修复它，Steam 再次运行，就像什么都没发生一样。现在一切正常了。  所以我陷入了这两种感觉之间： 人工智能非常有用和有趣，我喜欢尝试新工具，用它来 DIY 东西、家居装修、解决技术问题。我很幸运能在这个时候活着经历这一切。但是我也担心人性和贪婪、权力、短期政治可能会把这变成危险的东西，比如技术封建主义。生成式人工智能似乎对民主没有帮助，因为很少有公司能够集中大量影响力并能够游说政客对他们有利。自动化工作也将产生大量利润，同时也会降低大部分人的议价能力。失业者可以大声喊叫，但没有实际影响力。人工智能还可以非常有效地用于监视和人口控制。这让我不禁要问，民主将如何渡过难关？  我真的不知道该怎么理解这一切。好奇其他人如何看待它。   由   提交 /u/Caderent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qobfi8/ai_is_both_the_coolest_and_scariest_thing_ive/</guid>
      <pubDate>Tue, 27 Jan 2026 11:34:42 GMT</pubDate>
    </item>
    <item>
      <title>一年前有传言称 DeekSeek 接受了 OpenAI 输出的训练。这在实践中会如何运作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qo9opb/a_year_ago_there_were_rumors_that_deekseek_was/</link>
      <description><![CDATA[训练数据时，不需要完整的文本才能工作吗？ 如果只是将各种输入发送到 OpenAI，然后读取其输出工作，为什么像 OpenRouter 这样的公司不从用户那里获取所有 AI 来生成最终的 AI？   由   提交 /u/aliassuck   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qo9opb/a_year_ago_there_were_rumors_that_deekseek_was/</guid>
      <pubDate>Tue, 27 Jan 2026 09:56:31 GMT</pubDate>
    </item>
    <item>
      <title>[指南]一种通过观察眼睛来识别AI生成图像的方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qo2wa2/guide_a_method_for_recognizing_aigenerated_images/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qo2wa2/guide_a_method_for_recognizing_aigenerated_images/</guid>
      <pubDate>Tue, 27 Jan 2026 03:46:33 GMT</pubDate>
    </item>
    <item>
      <title>深度研究感觉就像有一个天才实习生，同时也是一个病态的骗子。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qo2pes/deep_research_feels_like_having_a_genius_intern/</link>
      <description><![CDATA[我一直在努力迫使这些“深入研究”成为现实。工具进入我的工作流程大约一个月了。主要是 perplexity pro 和新的 gpt 功能。 起初感觉就像魔法一样。我通常要花 4 个小时收集标签的事情在几分钟内就可以得到总结。感觉就像我为我的工作解锁了作弊代码（市场分析的东西）。 但本周，裂缝已经显现出来，而且很糟糕。 昨天，我要求它为欧盟的一个项目找到具体的监管限制。它给了我一份漂亮的报告。引用来源。自信的语气。完美的格式。 为了安全起见，我仔细检查了一个引文。它不存在。它确实产生了一个可以解决我所有问题的特定条款的幻觉。如果我没有检查的话，我在今天的会议上看起来绝对是个白痴。 现在我正处于一个奇怪的困境，我用它来获取答案的结构，但我必须手动验证每一个声明，这有点违背了速度的目的。 很好奇你们在哪里着陆。您真的相信它可以进行深度工作还是只是进行表面总结？有人有一个堆栈可以真正修复谎言吗？ 我想相信这就是未来，但现在感觉就像我在照顾一个计算器，它有时会决定 2+2=5 只是为了让我开心。   由   提交/u/Safe_Thought4368  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qo2pes/deep_research_feels_like_having_a_genius_intern/</guid>
      <pubDate>Tue, 27 Jan 2026 03:37:52 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>