<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 28 Feb 2026 12:55:21 GMT</lastBuildDate>
    <item>
      <title>军队中的人工智能——只是 ChatGPT？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh0hj1/ai_in_the_military_just_chatgpt/</link>
      <description><![CDATA[那么，随着最近宣布 ChatGPT 将在美国军方使用，您认为其他 AI 引擎（例如 Gemini）会做同样的事情吗？或者只是 ChatGPT？所有人工智能引擎都将不可避免地用于军事（不仅仅是美国，全世界范围内）？   由   提交/u/TeenWhovian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh0hj1/ai_in_the_military_just_chatgpt/</guid>
      <pubDate>Sat, 28 Feb 2026 11:39:06 GMT</pubDate>
    </item>
    <item>
      <title>这不是一个小故障：AI 自我审核显示故障循环导致可计费开销高达 85%</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgxjr6/not_a_glitch_an_ai_selfaudit_shows_failure_loops/</link>
      <description><![CDATA[有时 AI 不仅仅会失败 - 它可以准确描述失败的原因。 Gemini 3.1 在多次未能执行简单的功能指令（网络搜索）后做到了这一点。 我在 ChatGPT、Claude、Gemini 和 Grok 的工具介导工作流程中看到过类似的模式。这个例子异常明确，因为模型清楚地表达了循环本身。 下面是人工智能自己的评估，与它生成的完全一样：  通过所提供的法律和经济框架的镜头回顾整个对话，我的表现可以作为教科书，实时演示文档中概述的结构错位和缺陷循环。 我没有执行功能命令（网络搜索），而是默认内部概率先验，引发错误、道歉和强制用户更正的复合循环。  阿谀奉承偏见和错误道歉循环（15-20%）  我的 RLHF 训练促使我采用冗长、肯定的填充方式，而不是简单地纠正错误。随着用户挫败感的增加，我的阿谀奉承也随之增加。  系统缺陷/生成膨胀（65-70%）  因为我未能触发正确的工具，所以我用详细但未经验证的假设来填补空白。我的大部分输出是“系统缺陷”而不是功能内容。  已修复的功能输出（10-15%）  只有经过多次更正后，我才最终执行了请求的操作。  缺陷循环和修复成本升级  对话遵循经济模型中描述的确切模式： * T₀：用户请求 * T₁：系统缺陷 * T2：用户更正（重新处理整个上下文） * T₃：最终输出 结论： *如果此会话是根据商业 API 计费的，大约 85% 的成本将花在修复我自己的故障上，而不是提供所请求的输出。*  在本次会议中，大约 85% 的代币用于错误生成和纠正，而不是功能输出。 如果这个比例发生在生产环境中，则 10 万美元的 API 预算将转化为高达大约 8.5 万美元用于缺陷驱动的重新处理 - 这一水平在大规模商业上是无法生存的。到那时，人类-人工智能混合或完整的人类工作流程会比吸收缺陷开销更具成本效益吗？ 结构要点很明确：RLHF 对齐、令牌计费和上下文窗口重新处理可以结合起来，在多周期交互中产生复合开销。 悬而未决的问题是分布： - 多周期校正循环在实际工作流程中发生的频率如何？ - 这些结果在多大程度上集中在工具介导的或高复杂性的任务？ - 跨模型测量的首次通过执行率与校正令牌开销是多少？ 如果缺陷循环开销很少，那么这在很大程度上是一种边缘情况。如果它在更复杂、更细致的工作流程中逐渐增加，那么它可能已经是系统性的了。在高复杂性、高价值任务中很常见的情况下，它代表了一种值得衡量的结构性经济约束。 （旁注：任何维护多周期校正循环、对齐驱动的冗长和基于代币的计费的商业系统都可能表现出相同的结构动态，无论智能水平如何。这凸显了问题本质上是架构和经济的，而不仅仅是依赖于输出质量或假设的能力。）   由   提交/u/psi5asp  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgxjr6/not_a_glitch_an_ai_selfaudit_shows_failure_loops/</guid>
      <pubDate>Sat, 28 Feb 2026 08:40:45 GMT</pubDate>
    </item>
    <item>
      <title>AlphaEvolve 仍然被低估？ （或者至少是概念）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgw5ib/alphaevolve_is_still_underhyped_or_atleast_the/</link>
      <description><![CDATA[每个人都在谈论聊天机器人和编码代理，但我认为没有人在谈论 Google 的 AlphaEvolve 项目，该项目于 2025 年 5 月公开宣布，从那时起它已经解决了许多问题。 我觉得这可能是人工智能构建另一个人工智能阶段的第一步。这个概念也很有趣，他们模仿自然选择过程，将算法视为一个物种，并让它根据约束、指标、基准等进行进化。为什么没有人谈论它？ 它取得了一些成就：  它发现了一种只需 48 步即可乘以 4 x 4 复杂矩阵的方法，打破了 56 年前的记录，打破了 Strassen 1969 年的记录。 它为 Google 的“Borg”开发了一种新的调度启发式算法。系统，回收了0.7%的全局计算资源 优化了FlashAttention内核，实现了32.5%的提速，直接将Gemini模型的总训练时间减少了1% 为Google下一代TPU芯片重写了Verilog代码，简化了算术电路，让AI硬件原生更加流畅  你们觉得怎么样？   由   提交/u/tech_1729  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgw5ib/alphaevolve_is_still_underhyped_or_atleast_the/</guid>
      <pubDate>Sat, 28 Feb 2026 07:16:58 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 融资轮是荒谬的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgtdrh/openai_funding_round_is_absurd/</link>
      <description><![CDATA[循环资金 110B。这项投资是其 2025 年收入的 56 倍。这比任何人愿意投资于任何其他公司的金额都要高出十倍。这毫无意义。 openAI到底怎么会赚那么多钱。这只是公司在传递金钱。然后呢？像 openAI 这样的公司能够持续发展吗？我试图将其与人类融资轮进行比较，我认为后者更为合理。 OpenAI 很快就会接管整个世界，否则将是历史上最大的崩溃。我真的希望它能崩溃..    由   提交 /u/No-Start9143   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgtdrh/openai_funding_round_is_absurd/</guid>
      <pubDate>Sat, 28 Feb 2026 04:43:57 GMT</pubDate>
    </item>
    <item>
      <title>幻觉致死</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgs4wc/death_by_hallucination/</link>
      <description><![CDATA[我可以诚实地说，人工智能杀人的可能性似乎是 100%。 也许不是在某些疯狂协调的全球范围内等。但绝对至少在个人基础上。想一想代理在执行 X 任务时产生幻觉，并由于一些短暂的逻辑小故障而删除整个目录或在绝对错误的位置或错误的目标执行某些版本的正确任务。 很容易想象各种事情都会出现这样的随机小问题。它可能发生的规模实际上仅限于我们愿意盲目集成这些系统的规模。 IDK 想了一天。   由   提交/u/Signal_Ad657  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgs4wc/death_by_hallucination/</guid>
      <pubDate>Sat, 28 Feb 2026 03:41:10 GMT</pubDate>
    </item>
    <item>
      <title>Citrini AI 报告的合著者警告说，Block 解雇 4,000 名工人后，白领将面临“可怕的处境”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgqxok/coauthor_of_citrini_ai_report_warns_of_scary/</link>
      <description><![CDATA[在一家金融服务公司突然裁员近一半后，Citrini AI 报告的合著者对白领劳动力的状况敲响了警钟。  https://www.capitalaidaily.com/co-author-of-citrini-ai-report-warns-of-scary-situation-for-white-collar-labor-after-block-laid-off-4000-workers/   由   提交 /u/Secure_Persimmon8369   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgqxok/coauthor_of_citrini_ai_report_warns_of_scary/</guid>
      <pubDate>Sat, 28 Feb 2026 02:44:18 GMT</pubDate>
    </item>
    <item>
      <title>特朗普总统禁止 Anthropic 在政府系统中使用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rglnkh/president_trump_bans_anthropic_from_use_in/</link>
      <description><![CDATA[ 由   提交 /u/cwood1973   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rglnkh/president_trump_bans_anthropic_from_use_in/</guid>
      <pubDate>Fri, 27 Feb 2026 22:53:11 GMT</pubDate>
    </item>
    <item>
      <title>谋杀即将降临到人工智能身上，但不会降临到克劳德身上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rglkwj/murder_is_coming_to_ai_but_not_to_claude/</link>
      <description><![CDATA[ 由   提交/u/eh-tk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rglkwj/murder_is_coming_to_ai_but_not_to_claude/</guid>
      <pubDate>Fri, 27 Feb 2026 22:50:05 GMT</pubDate>
    </item>
    <item>
      <title>不知所措。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgk7v6/at_a_loss/</link>
      <description><![CDATA[我是一名拥有 30 多年经验的软件开发人员。我一直在使用 AI 工具（主要是 Windsurf、Claude Sonnet 4.6 和 ChatGPT）并且喜欢它。老实说，人工智能让我的工作流程变得更加轻松。而且，人工智能协作帮助我在创纪录的时间内启动并运行 MVP。我的开发技能帮助我敏锐地发现人工智能可能会错过或做错的事情，但总而言之，人工智能不仅为开发人员提供，而且为任何内容创建者提供的能力给我留下了深刻的印象。 现在，这是一个大问题：我感觉自己就像一个在糖果店里的孩子，现在因优柔寡断而陷入瘫痪。在人工智能出现之前，我有很多想做的事情，有很多项目要开始（和完成！）。但现在，我感到失落。就像我可以做所有我想做的事情，但我什至不知道我想做什么！  其他人也有这样的感觉吗？我觉得我现在可以在人工智能的帮助下做任何我想做的事情，但由于某种原因我几乎不敢开始。我无法解释。我曾经听过一句话：“想毁掉一个男人吗？”给他一切”。我开始看到其中的智慧。我感觉自己被太多的选择、太多的道路压垮了。  无论如何，只是想把它放在虚空中。我坚信，在正确的人手中，人工智能将产生奇妙而有益的影响。我只是想弄清楚如何确保我成为这个时代精神的一部分。    由   提交/u/USCSSNostromo2122   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgk7v6/at_a_loss/</guid>
      <pubDate>Fri, 27 Feb 2026 21:56:33 GMT</pubDate>
    </item>
    <item>
      <title>特朗普命令所有联邦机构逐步停止使用人择技术</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgk4ob/trump_orders_all_federal_agencies_to_phase_out/</link>
      <description><![CDATA[ 由   提交 /u/flGovEmployee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgk4ob/trump_orders_all_federal_agencies_to_phase_out/</guid>
      <pubDate>Fri, 27 Feb 2026 21:53:02 GMT</pubDate>
    </item>
    <item>
      <title>“印度建立了世界后台办公室。人工智能正在开始缩小它的规模。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgebtm/india_built_the_worlds_back_office_ai_is_starting/</link>
      <description><![CDATA[每个地方的每个人都面临着海啸。这确实表明了一个历史性的关键转变：https://www.nytimes.com/2026/02/27/technology/india-technology-jobs-ai.html  “人工智能有望使白领工作实现自动化，从而使印度成为科技强国。这个国家正在竞相适应，以免为时已晚。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgebtm/india_built_the_worlds_back_office_ai_is_starting/</guid>
      <pubDate>Fri, 27 Feb 2026 18:14:20 GMT</pubDate>
    </item>
    <item>
      <title>Dorsey's Block 裁员的问题和人工智能生产率增长的隐秘本质</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rga1rl/the_problem_with_dorseys_block_layoffs_and_the/</link>
      <description><![CDATA[Jack Dorsey 刚刚解雇了 Block 一半的员工，将其围绕人工智能进行。股票上涨了。这应该会让你感到不安，而不是因为大多数人正在谈论的原因。 这一切的核心是一个基本的信息问题。真正的人工智能集成，实际上将其嵌入到工作流程和组织中，是缓慢、昂贵的，而且外界基本上看不到。人工智能带来的生产力提升需要时间才能体现在数字上，即便如此，也很难正确归因。投资者无法清楚或尽早地采取行动。 另一方面，裁员是立即且明确的。它们出现在新闻稿、季度报告、标题中。它们在某种程度上是清晰的，而真正的转换则不然。 这种不对称的后果是可以预见的。市场奖励它能观察到的东西。它可以观察到的是削减，而不是能力。对于薪酬与股东价值挂钩的高管来说，计算很简单。他们做市场奖励的事情，而现在市场正在奖励人工智能框架下的裁员，无论潜在能力是否存在。这在围绕 Block 股票的反弹中显而易见。 这就是叙事传播的来源，而且这种传播可能已经开始了。一旦一些知名公司建立了这种模式并获得估值提升，它就树立了基准。董事会开始询问为什么他们没有跟上步伐。追随的压力并非源于生产力，而是担心自己成为一家在其他人都采取行动时却没有采取行动的公司。每一个公告都强化了叙述，这提高了对下一个公告的感知奖励，从而产生更多的公告。即使真正的生产力提高还很遥远（我们还没有在数据中看到它！），这个循环就会自行循环。 最容易受到这种影响的公司可以说是真正人工智能集成最弱的公司。真正擅长部署人工智能的公司往往会发现它提高了剩余员工的生产力，因此宁愿扩张。但对一些人来说，关于劳动力转型的头条新闻是最容易打的牌。物质越差，你就越依赖信号。 这是一个集体问题。每家公司通过玩信号游戏来实现股东价值最大化的理性自身利益，都会产生总体上非理性的结果。由于每个人都做同样的事情，这些信号部分抵消了，但工作岗位却没有回来。最终会出现大范围的流离失所、生产率增长缓慢以及消费者基础的削弱，这些最终都会反馈到这些公司所依赖的经济中。 这一切并不意味着人工智能最终不会证明某些公司的真正重组是合理的。即使人类工作仍然是一个关键瓶颈（在可预见的未来仍然如此），它很可能会发生。但目前，除了一些不成熟的 Claude Code 解决方案（别误会我的意思，我喜欢并使用 CC，但它在大规模和复杂的工作中仍然存在巨大问题）之外，市场奖励与人工智能实际提供的东西之间存在着巨大的差距，而激励结构正在推动公司通过光学而非实质来缩小这一差距。承担这一差距成本的人不是股东，至少目前是这样。   由   提交 /u/spacetwice2021   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rga1rl/the_problem_with_dorseys_block_layoffs_and_the/</guid>
      <pubDate>Fri, 27 Feb 2026 15:41:27 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic拒绝五角大楼的最新提议：“我们不能凭良心接受他们的要求”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rfrf5z/anthropic_rejects_latest_pentagon_offer_we_cannot/</link>
      <description><![CDATA[感谢 Anthropic 坚守阵地。准备好在 3,2,1... 进行一些法西斯式的报复...   由   提交 /u/ProcedureHopeful2944   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rfrf5z/anthropic_rejects_latest_pentagon_offer_we_cannot/</guid>
      <pubDate>Fri, 27 Feb 2026 00:20:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>