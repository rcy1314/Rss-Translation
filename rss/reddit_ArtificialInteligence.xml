<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 26 Dec 2024 01:36:29 GMT</lastBuildDate>
    <item>
      <title>我们真的需要一个去中心化的人工智能网络吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmdvr6/do_we_really_need_a_decentralized_ai_network/</link>
      <description><![CDATA[  由    /u/eqai_inc  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmdvr6/do_we_really_need_a_decentralized_ai_network/</guid>
      <pubDate>Thu, 26 Dec 2024 01:34:13 GMT</pubDate>
    </item>
    <item>
      <title>不要只关注人类能做什么而人工智能不能做什么，而要关注人工智能能做什么而人类不能做什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmd51r/stop_seeing_what_humans_can_do_and_ai_cant_and/</link>
      <description><![CDATA[无论我们喜欢与否，人工智能都会到来——只是它何时到来以及它将对各个领域产生何种影响的问题。从医疗保健和教育到艺术、工程和农业，人工智能已经产生了巨大的影响。它可以处理无聊的任务，处理大量数据，并给我们提供我们自己永远无法弄清楚的见解。即使是那些不信任人工智能的人最终也会使用它，因为它太有用了，不容忽视。随着人工智能不断进步，它不仅会帮助我们更快地完成任务——它还会改变我们的思维、工作和创造方式。    提交人    /u/TheLogiqueViper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmd51r/stop_seeing_what_humans_can_do_and_ai_cant_and/</guid>
      <pubDate>Thu, 26 Dec 2024 00:52:19 GMT</pubDate>
    </item>
    <item>
      <title>我添加了专业人士的天赋</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</link>
      <description><![CDATA[由于最近对专业内容更加突出的兴趣，我认为一个好的开始是了解用户的哪些答案来自真正了解他们所谈论内容的人。 因此，我通过 mods 使经过验证的专业标签仅可分配。如果您想要该标签，您必须证明您在该领域工作。我把这留给您，我不在乎您的数据，并在看到后删除所有内容。如果您获得了标签，结果发现您对自己的职业撒了谎，无论出于何种原因，您都将被永久禁止，并且无法上诉。 一旦我们拥有足够多的人，我们还可以允许用户将某些帖子限制为仅供那些用户进行更专业的讨论。 让我知道您的想法    提交人    /u/ILikeBubblyWater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</guid>
      <pubDate>Wed, 25 Dec 2024 23:49:53 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型面临的新安全挑战</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmahfn/emerging_security_challenges_of_large_language/</link>
      <description><![CDATA[标题：大型语言模型的新兴安全挑战 我每天都会查找和总结有趣的 AI 研究论文，这样您就不必全部浏览了。今天的论文题为“大型语言模型的新兴安全挑战”，由 Herve Debar、Sven Dietrich、Pavel Laskov、Emil C. Lupu 和 Eirini Ntoutsi 撰写。 本文深入探讨了大型语言模型 (LLM) 带来的独特安全挑战，例如基于转换器架构的模型，这些模型越来越多地用于教育和医疗保健等不同领域。尽管这些模型具有广泛的适用性，但它们面临着与传统机器学习模型不同的重大安全风险。 要点和发现：  对抗性漏洞：由于 LLM 在大规模、多样化的数据集上进行通用训练，因此特别容易受到对抗性攻击。这些攻击可以利用提示的构造或 LLM 的概率性质等功能，导致幻觉等现象 - 模型生成误导性或无意义的输出。 数据中毒和后门攻击：用于训练 LLM 的大量数据集容易受到中毒，恶意行为者会引入可能影响模型行为的数据。鉴于数据集的庞大规模，精确投毒可能具有挑战性，但有针对性的攻击仍然是可行的。 供应链的复杂性：从数据采购到模型部署的链条错综复杂，为攻击者创造了机会。令人担忧的问题包括预训练模型的来源、用于微调的数据以及透明度问题——每个问题都可能增加引入漏洞的风险。 安全风险评估中的挑战：LLM 的不透明和多面性使安全评估变得复杂。因素包括培训和架构缺乏透明度、广泛的应用环境和自适应学习机制，所有这些都使全面的安全评估变得困难。 防御攻击本文还强调了系统防御的必要性，因为现有策略主要侧重于查明漏洞。它要求在保持模型实用性和防范各种形式的攻击之间取得平衡，呼吁更深入地了解系统性漏洞。  本文强调，人工智能社区迫切需要优先开发强大的防御机制，以抵御威胁 LLM 可靠性和完整性的各种攻击。 您可以在此处查看完整的细分：这里您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmahfn/emerging_security_challenges_of_large_language/</guid>
      <pubDate>Wed, 25 Dec 2024 22:25:23 GMT</pubDate>
    </item>
    <item>
      <title>Gemini-exp 的视野真好！远远超过了 GPT-4o。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hm4wbd/geminiexp_has_so_great_vision_far_exceeding_that/</link>
      <description><![CDATA[当被要求转录此屏幕截图中的文本时，它进行了绝对精确的转录，最多可达任何单个字符，包括遗留符号。 https://i.sstatic.net/ElizK.png 这里是文字记录： ``` 我很高兴向您展示您期待已久的产品：ANDOS V 3.30。此版本实现：  使用 63 个设备（硬盘分区） “合并”功能将多个硬盘驱动器分区合并为一个，并使用链接方便地从一个磁盘转换到另一个磁盘 在所有可用的硬盘驱动器分区上按掩码搜索文件 子目录的图形树 &lt; li&gt;编辑文本文件 屏幕保存模式（星号） 计算器 从 shell 进行系统设置（许多 M 文件是内置的） 计算器李&gt; 在外壳被破坏时无需重新启动即可恢复 文件管理器的速度显着提高 也许您期望更多，但不幸的是，我现在几乎没有在 BKshka 上工作的机会，这个版本几乎完全是在没有我参与的情况下创建的：EMT36 拦截器 或 DOS（根据你的喜好）仍然存在没有任何更改（原则上新版本 4.0 已经存在 - 它是我在 1995 年夏天编写的，但您不太可能再次看到它）。 1995 年春天，Sergey Koptev 改进了他的 Disk Master shell，添加了使用硬盘驱动器的功能。在这种形式下，ANDOS V3.11 收到了轻微的未经批准的````  这绝对是令人惊叹的！   由   提交 /u/Anuclano   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hm4wbd/geminiexp_has_so_great_vision_far_exceeding_that/</guid>
      <pubDate>Wed, 25 Dec 2024 17:28:13 GMT</pubDate>
    </item>
    <item>
      <title>如果您的医疗保健提供者依赖人工智能来为您提供医疗服务，您会感到舒服吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hm3ve9/would_you_be_comfortable_if_your_healthcare/</link>
      <description><![CDATA[大家好！我正在开展一项民意调查，作为探索人工智能如何影响医疗行业和患者看法的项目的一部分。我很想听听你的想法。请在民意调查中投票，并在评论中随意分享任何其他见解或经验。非常感谢您的参与！ 感谢您的时间！ 查看民意调查    由   提交 /u/MR_EP1C4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hm3ve9/would_you_be_comfortable_if_your_healthcare/</guid>
      <pubDate>Wed, 25 Dec 2024 16:34:31 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hm35wg/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：Sriram Krishnan 被任命为特朗普的人工智能高级政策顾问 (TechCrunch)  OpenAI“考虑”建造一个人形机器人。 （TechCrunch） Google 正在使用 Anthropic 的 Claude 来改进其 Gemini AI（TechCrunch） xAI 正在为其 Grok 聊天机器人测试独立的 iOS 应用程序（TechCrunch） Juniper Ventures 将投资气候合成生物学（TechCrunch） Swizzle Ventures 为首支致力于女性健康和财富的基金筹集了 500 万美元（TechCrunch） Coralogix 收购了 AI 可观察性平台 Aporia（TechCrunch）  如果您想及时了解 AI 新闻，它首先在这里发布。，其中包含所有来源和文章的完整摘要    由    /u/codeharman 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hm35wg/heres_whats_making_news_in_ai/</guid>
      <pubDate>Wed, 25 Dec 2024 15:55:53 GMT</pubDate>
    </item>
    <item>
      <title>谷歌正在利用 Anthropic 的 Claude 改进其 Gemini AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hm18sk/ai_google_is_using_anthropics_claude_to_improve/</link>
      <description><![CDATA[https://techcrunch.com/2024/12/24/google-is-using-anthropics-claude-to-improve-its-gemini-ai/ 老实说，对于通用或编码任务来说，Claude 是最好的商业上可用的 LLM，所以我明白为什么谷歌想要抄袭他们的作业。    提交人    /u/spacespacespapce   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hm18sk/ai_google_is_using_anthropics_claude_to_improve/</guid>
      <pubDate>Wed, 25 Dec 2024 14:01:38 GMT</pubDate>
    </item>
    <item>
      <title>有人记得这个 subreddit 曾经充满专家和计算机科学家吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlyvmg/does_anyone_remember_when_this_subreddit_was_full/</link>
      <description><![CDATA[现在看来，这里全是白痴，在没有任何数据科学、机器学习或人工智能背景或技术知识的情况下，发表近乎阴谋的愚蠢言论     提交人    /u/Alloy-Black   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlyvmg/does_anyone_remember_when_this_subreddit_was_full/</guid>
      <pubDate>Wed, 25 Dec 2024 11:10:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么AI相关的工作描述这么模糊？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlygvy/why_do_the_airelated_jobs_have_so_vague/</link>
      <description><![CDATA[我读了Coursera上的一些描述，但仍然不太明白我应该做什么。我喜欢机器学习工程师和数据科学家的职业，但我仍然不明白当我去工作时我到底应该做什么。    提交人    /u/Altruistic-Error-262   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlygvy/why_do_the_airelated_jobs_have_so_vague/</guid>
      <pubDate>Wed, 25 Dec 2024 10:37:51 GMT</pubDate>
    </item>
    <item>
      <title>对 OpenAI o3 的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlws9a/thoughts_on_openais_o3/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlws9a/thoughts_on_openais_o3/</guid>
      <pubDate>Wed, 25 Dec 2024 08:20:49 GMT</pubDate>
    </item>
    <item>
      <title>人们对人工智能的看法可能比它的能力更危险</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlq42x/the_way_people_perceive_ai_could_be_more/</link>
      <description><![CDATA[在我看来，人们忽视了人工智能的大量合法问题，而更倾向于好莱坞对人工智能的比喻。虽然随着技术的进步，我们应该认真对待这些比喻，但我们需要更好地理解人们对这些系统的看法如何影响他们对它们的使用，以及这种看法与现实不一致的潜在负面影响。 这是关于依赖技术的更广泛影响的讨论的一部分。我在研究生院学习的主题之一是人机交互/人为因素，航空事故可能是最常用的例子。大约 80% 的事故是人为失误的直接结果，而不是机械故障或飞行条件，其中大多数事故是由于飞机和飞行员之间的脱节造成的。 一个例子是大韩航空货运航班，自动驾驶系统补偿了飞行员不知情的姿态指示器故障。这掩盖了问题，当机组人员采取手动控制时，他们使用有故障的指示器将飞机撞向地面。机组人员对自动驾驶系统和姿态指示器的信任被归咎为事故的原因，以及在退出自动驾驶时将人带回控制环的过程（或缺乏控制）。法航 447 航班是另一个出现的例子。自动驾驶系统掩盖了飞机在湍流/结冰条件下飞行的一些行为。手动飞行时，飞行员会积极保持飞机水平并注意飞行条件，但在这种情况下，他们听从了自动驾驶仪的指示，并在自动驾驶仪意外交还控制权时失去了控制。大多数涉及自动化组件的事件都有一个共同点——人类没有完全处于控制环路中，要么误判情况，要么缺乏采取适当行动所需的信息。 在谈论人工智能代理时，谈论自动化的意外后果是个好主意——无论系统是否正常工作。自动化不仅仅是设计系统以正确完成任务，它还涉及使用系统的人的想法或期望。通常，在系统按照设计的方式工作的情况下，失败点是人。 我们需要记住哪些事情？我最大的担忧之一是人们对人工智能能做什么的关注程度与它不能做什么的关注程度相比如何。错误的期望通常是导致人员死亡的原因。    提交人    /u/Murky-Motor9856   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlq42x/the_way_people_perceive_ai_could_be_more/</guid>
      <pubDate>Wed, 25 Dec 2024 00:29:50 GMT</pubDate>
    </item>
    <item>
      <title>这是我的想法，还是大学真的严重缺乏有关人工智能代理的课程？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlofn1/its_just_me_or_are_universities_seriously_lacking/</link>
      <description><![CDATA[我专攻自动化生产工程，在我的整个学习过程中，我从未遇到过关于这个主题的任何课程。甚至没有关于无代码工具（如 n8n）的课程，而这在当今的自动化中基本上是基础。 也许只是我的大学。这里还有其他人专门上过关于 AI 代理或无代码开发的课程吗？我很好奇，想知道是否还有其他大学已经将 AGI/无代码整合到他们的课程中。    提交人    /u/Garraww   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlofn1/its_just_me_or_are_universities_seriously_lacking/</guid>
      <pubDate>Tue, 24 Dec 2024 22:50:51 GMT</pubDate>
    </item>
    <item>
      <title>刚刚获得人工智能基础知识认证</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlkoxm/just_got_my_artificial_intelligence_essentials/</link>
      <description><![CDATA[我刚刚完成了Google 人工智能基本认证，我想与大家分享一下，以防其他人也想开始使用 AI。本课程以易于理解的方式分解了人工智能和机器学习的基础知识，即使您没有太多经验。它还涉及如何在现实生活中使用人工智能以及负责任地使用它的重要性。如果您对人工智能感兴趣或只是想在简历中添加一些有价值的东西，我绝对会推荐它。如果您需要更多信息或有任何问题，请告诉我 - 很乐意为您提供帮助！    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlkoxm/just_got_my_artificial_intelligence_essentials/</guid>
      <pubDate>Tue, 24 Dec 2024 19:29:25 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 24 Dec 2024 15:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>