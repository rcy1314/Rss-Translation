<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 16 Jan 2026 15:28:48 GMT</lastBuildDate>
    <item>
      <title>停止在提示中垃圾邮件“4k，超现实”。这就是为什么你的图像看起来像塑料的原因。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qeiz7q/stop_spamming_4k_hyperrealistic_in_your_prompts/</link>
      <description><![CDATA[我一直在尝试修复那个奇怪的“蜡像”几个星期以来，我这一代人都感到困惑。我认为这是一个模型问题，所以我不断添加诸如“不良解剖结构”之类的负面提示。或者堆砌诸如“虚幻引擎 5、8k、超详细”之类的流行语。 我今天偶然发现了这个细分，它实际上解释了塑料外观背后的逻辑，它完全改变了我的工作流程。 要点是：模型接受摄影字幕的训练。当您使用通用流行语时，人工智能默认为平面广角“智能手机”。看（无限景深 = 假看）。 我开始测试文章建议的内容——将“超现实”换成“超现实”。对于实际相机物理（例如，“在 85mm、f/1.8 光圈下拍摄”）。皮肤纹理和光线的差异是白天和黑夜。它停止尝试“渲染”图像并开始“拍摄”  如果你想自己测试物理原理，这里有一个不错的镜头备忘单。如果您陷入恐怖谷，绝对值得一读：真实感 AI 生成   由   提交 /u/ProgrammerForsaken45   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qeiz7q/stop_spamming_4k_hyperrealistic_in_your_prompts/</guid>
      <pubDate>Fri, 16 Jan 2026 15:28:20 GMT</pubDate>
    </item>
    <item>
      <title>“单击 Microsoft Copilot 攻击即可悄悄窃取您的个人数据”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qehk5k/the_singleclick_microsoft_copilot_attack_that/</link>
      <description><![CDATA[ 什么？瓦罗尼斯描述了“重新提示”，一种提示注入技术，攻击者可以在检索到的 Copilot 内容中嵌入恶意指令来操纵 AI 模型输出。 那又怎样？随着人工智能助手与企业数据系统集成，即时注入漏洞会给部署人工智能工具的先进组织带来安全风险。  更多：https://www.instrumentalcomms.com/blog/ice-resistance-is-working#ai   由   提交 /u/TryWhistlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qehk5k/the_singleclick_microsoft_copilot_attack_that/</guid>
      <pubDate>Fri, 16 Jan 2026 14:34:16 GMT</pubDate>
    </item>
    <item>
      <title>值得去吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qef0o4/is_chatgpt_go_worth_it/</link>
      <description><![CDATA[chat gpt go值得吗？我一直在犹豫要不要升级。我既不用它工作也不用它上学。只是当我们讨论某件事时，它会说“您已达到极限。请等待它重置或升级”   由   提交/u/No-Cow-706   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qef0o4/is_chatgpt_go_worth_it/</guid>
      <pubDate>Fri, 16 Jan 2026 12:46:18 GMT</pubDate>
    </item>
    <item>
      <title>蓝领工人没有意识到人工智能对他们同样构成威胁</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qed560/bluecollar_workers_dont_realize_that_ai_is_the/</link>
      <description><![CDATA[我经常听到焊工、电工等工作的人嘲笑上班族，说他们因为有行业而倒霉。  我的预测是，这些人没有意识到经济是残酷地相互关联的，而接受他们命令的人可以从办公室工作中赚钱。 当办公室工作因人工智能而被消除时，对新厨房、屋顶维修等的需求将大幅下降。 另一部分是，办公室工作人员将迅速重新培训手工技能，以养活自己和家人，并会冷静地提供低得多的价格来支付为了租金和食物，彻底破坏了竞争，创造了巨大的供过于求的局面。  有人有类似的看法吗？    由   提交 /u/Big-Butterscotch2608   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qed560/bluecollar_workers_dont_realize_that_ai_is_the/</guid>
      <pubDate>Fri, 16 Jan 2026 11:05:33 GMT</pubDate>
    </item>
    <item>
      <title>一份 AI 报告揭示了人工智能在 2025 年的实际表现</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qebu7v/what_an_ai_report_revealed_about_how_artificial/</link>
      <description><![CDATA[去年，我试图理解人工智能所发生的一切，这时我发现了一份确实有根据的人工智能报告。很多关于2025年人工智能的总结要么过度炒作，要么听起来好像每个人都在一夜之间神奇地弄清楚了人工智能。这个没有。这感觉更接近我在真实团队和产品中看到的情况。 真正引人注目的是现实是多么的复杂。一些公司行动迅速，并将人工智能融入日常工作流程中。其他人则努力完成从未交付的实验。该报告讨论了很多真正的人工智能采用问题——成本、不明确的投资回报率，以及华而不实的演示与需要在生产中可靠运行的系统之间的差距。它还涉及到对有经验的人才的需求增长速度如何快于预期，这解释了为什么人工智能人才市场在年底感觉如此激烈。 我喜欢它没有假装人工智能是某种神奇的解决方案。它展示了哪些地方有效，哪些地方无效，以及人类在哪些地方仍然发挥着关键作用。读起来感觉不像“未来就在这里”，而更像是“这就是我们真正落地的地方。”   由   提交 /u/Hot-Situation41   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qebu7v/what_an_ai_report_revealed_about_how_artificial/</guid>
      <pubDate>Fri, 16 Jan 2026 09:48:10 GMT</pubDate>
    </item>
    <item>
      <title>将 Be10X 作为一名工作专业人士，分享真正有帮助的内容（无附属机构，无链接）。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe9q4m/took_be10x_as_a_working_professional_sharing_what/</link>
      <description><![CDATA[我加入 Be10X 的时候，人工智能内容无处不在，而且确实势不可挡。我并不是想“成为一名人工智能专家”。我只是想了解人们如何在工作中实际使用人工智能，而不听起来很虚假或技术性。 对我有用的是 Be10X 并没有将人工智能视为一个主题。它把它当作一种工作技能。他们没有推出数十种工具，而是专注于如何用人工智能思考以及如何将其集成到现有任务中。 最大的好处不仅仅是速度，而是清晰度。我不再猜测人工智能适合什么地方，而是开始有意识地使用它。仅此一点就让我的学习变得有价值。   由   提交 /u/Coffee_Talkerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe9q4m/took_be10x_as_a_working_professional_sharing_what/</guid>
      <pubDate>Fri, 16 Jan 2026 07:36:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么在面向客户的人工智能中准确性比“聪明”更重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe8haf/why_accuracy_matters_more_than_cleverness_in/</link>
      <description><![CDATA[我知道人工智能已经取得了长足的进步，尤其是自动化系统的“智能”程度。不过，当涉及到面向客户的互动时，它就像岩石一样聪明，并且具有与之相匹配的个性。 它总是试图表现得富有诗意，或令人放心，或转移注意力，而这不是我恼火的客户所需要的。他们需要正确的答案，而且需要尽快得到答案。自信的错误反应比缓慢升级并真正解决问题的反应造成的损害要大得多。 我一直对人工智能持观望态度，主要是因为，当它过度时 - 即使是轻微的 - 客户会感到被误导，失去信任，并且在那时解决问题只是一种普遍的痛苦。 我还看到并监督了许多不同的实施。最成功的产品在演示过程中往往是最不令人印象深刻或最不花哨的。他们遵守非常严格的规则，一旦客户提出超出这些限制的问题，就会立即升级。尤其是像Helply这样的平台，往往建立在有限的行为之上，虽然与华丽的聊天机器人相比，这种行为感觉很无聊，但实际上可以正确完成工作。 对于那些已经在生产中使用人工智能支持的人来说，您如何平衡何时升级以及何时让人工智能解决问题？您如何界定系统可以执行的操作？   由   提交/u/Ancient-Subject2016   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe8haf/why_accuracy_matters_more_than_cleverness_in/</guid>
      <pubDate>Fri, 16 Jan 2026 06:25:12 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 1/15/2026</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe7r5j/oneminute_daily_ai_news_1152026/</link>
      <description><![CDATA[ 维基百科在人工智能成立 25 周年之际与微软、Meta 和 Perplexity 签署协议。[1] 人工智能新闻初创公司 Symbolic.ai 与鲁珀特·默多克 (Rupert Murdoch) 的新闻集团签署协议。[2] NVIDIA AI 开源 KVzap：一种 SOTA KV 缓存修剪方法，可提供近乎无损的 2x-4x 压缩。[3] 阿里巴巴升级 Qwen 应用程序以订餐、预订旅行。[4]  来源包括：https://bushaicave.com/2026/01/15/one-million-daily-ai-news-1-15-2026/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe7r5j/oneminute_daily_ai_news_1152026/</guid>
      <pubDate>Fri, 16 Jan 2026 05:46:17 GMT</pubDate>
    </item>
    <item>
      <title>厌倦了法学硕士、人工智能工具和人工智能废话</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</link>
      <description><![CDATA[现在有很多无用的人工智能工具，而且大多数只是彼此的重复。总结者、集思广益、审计代码、代码生成器等等，太无聊了。然后，每个人都一遍又一遍地广播同样的内容。就像关注不同法学硕士的小更新一样，从短期到长期来看，谁会赢得谁。同样的事情在播客和 YouTube 视频中一遍又一遍地出现。  是否有任何有趣的人工智能，呃，与 NBA、NFL、Nascar 或与运动或爱好相关的东西相关的东西？不是严肃的工作而是更休闲？不是像 Grok 这样的色情生成器。    由   提交 /u/Impressive-Flow2023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</guid>
      <pubDate>Fri, 16 Jan 2026 03:39:44 GMT</pubDate>
    </item>
    <item>
      <title>提醒您，基准测试的质量与其要衡量的质量一样重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe55n1/a_reminder_that_the_quality_of_a_benchmark/</link>
      <description><![CDATA[这是我对图表背后的方法的一些疑虑的总结，该图表显示“AI 可以完成的任务长度”是多少？    本文最明显的方法论失败在于它试图瓦解“困难”的高维、随机性质。进入代理 - 人类完成任务所需的时间长度。从心理测量的角度来看，这提出了一个致命的结构有效性问题。通过定义“任务难度”严格地作为人类专家完成任务所需时间的对数线性函数，作者犯了一个类别错误，将计算量与认知深度混为一谈。虽然这种方法的捍卫者可能会辩称，人类时间是必要的“共同货币”为了标准化脱节的基准，这种防御失败了，因为指标是非平稳的。人类时间和人工智能难度之间的关系在不同时间尺度上并不稳定。耗时 100 小时的任务不仅仅是“更长”的任务。 1 小时任务的版本，难度相应加大。在短期任务中，难度主要由推理深度决定，而在长达一个月的任务中，难度由上下文连贯性和能动性决定。还有一些隐藏的可变性/错误来源没有在他们用于计算任务长度的数据中得到考虑 - 他们使用几何平均值来估计大多数任务的任务长度，而对于其余任务，实际上只是对所述任务应该花费多长时间进行有根据的猜测。   这种理论缺陷因统计上脆弱的“回归回归”而变得更加复杂。建模策略。作者首先使用逻辑拟合估计每个模型的时间范围（T50，对应于 50% 成功率的任务长度），然后使用这些导出的点估计作为二次预测回归的真实输入。 50% 时间范围的方程为 ln(时间范围) = −α/β。请注意 beta（斜率）如何位于分母中？或者它是模型参数估计的比率？除了这些模型仅在 y 轴上最小化误差这一事实之外，这种反演还产生了一个伪像，其中模型的预计“时间范围”与 y 轴上的误差无关。当斜率接近零时趋于无穷大。它放大了为更强大的模型估计 beta 的误差 - beta 接近于零的微小变化对应于计算任务时间的巨大变化。您还可以在这种结构中看到一个可解释性问题：截距 alpha 表示模型在人类需要 1 分钟才能完成的任务上的表现（ln(1) = 0），这意味着模型可以具有更大的时间范围，因为它以更高的速率完成 1 分钟长的任务。如果您查看他们的图表，将实际成功率与拟合曲线进行比较，您可以看到导出的数字与实际发生的情况之间的脱节 - Claude 3.7 的时间范围为 1 小时，是 Claude 3.5 的两倍多。这与 3.5 完成了近 50% 时长为 1 小时的任务，并且在超过 1 小时的任务上比 3.7 具有更高的成功率这一事实是否相符？ 为了得到我们都看到的图，他们将这些计算出的任务时间插入到另一个回归模型中，添加了另一个不考虑输入变量错误的层。它还违反了模型的假设 - 与他们从中汲取灵感的 IRT 方法不同，它们没有考虑相同类型的任务或同一模型完成的任务之间的相关错误。  这是一个非常冗长的方式来表达我的观点：我们不能假设指标反映了“质量”。或所需的质量，而不评估用于生产它们的方法。在这种情况下，应该指出的是，他们引用的方法（IRT）经过精心设计，以避免他们面临的许多问题，但他们决定仅将其用作完全不同的事物的概念框架。    由   提交 /u/Disastrous_Room_927   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe55n1/a_reminder_that_the_quality_of_a_benchmark/</guid>
      <pubDate>Fri, 16 Jan 2026 03:35:39 GMT</pubDate>
    </item>
    <item>
      <title>StackOverflow 应得的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</link>
      <description><![CDATA[作为 2020 年开始使用 Stackoverflow 的人，我真的可以说他们活该被 AI 痛打一顿。 你提出一个问题，几秒钟后你就得到了第一次投反对票，“无所不知”。愚蠢的模组编辑了你的问题，几分钟后，你要么得到一个羞辱性的答复，说我不知道这个话题，还问了一个问题，要么你的问题被删除了。 那些模组除了编辑问题（看在上帝的份上，这是标点符号）什么也没做，并通过他们的垃圾回复让平台变得更加有毒。 据我所知，Stackoverflow 严格拒绝人工智能生成的回复，因为你可能会在人工智能。就像如果你像 2009 年推出的那样被问到同样多的问题，谁还会关心声誉。 它每天都变得越来越有毒。他们确实应得的。不接受人工智能答案？你是什​​么穴居人？他们的观点应该是帮助提问者，而不是试图与人工智能对抗。 他们也删除了“工作”部分。得到了近 4000 票反对。很多人不喜欢这个决定，但他们还是这么做了。   由   提交 /u/Hairy-Recognition-84   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</guid>
      <pubDate>Thu, 15 Jan 2026 21:38:15 GMT</pubDate>
    </item>
    <item>
      <title>你如何找到人工智能既不对冲一切又不自信地胡说八道的最佳点？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdvuqv/how_do_you_find_the_sweet_spot_where_ai_isnt/</link>
      <description><![CDATA[真正的问题 - 我一直在两种故障模式之间跳来跳去：  人工智能非常谨慎，它认为一切都是无用的。 “这要看情况，” “有很多因素，” “我需要更多背景信息” - 只要回答这个该死的问题 人工智能听起来完全自信，然后你就会意识到一半是编造的。当您不够专业，无法立即抓住它时，尤其有趣  神奇的会话是当它......与您同步并起作用时。人工智能直接参与，当我犯错时予以反击，当我不知道时承认，我们实际上一起构建了一些东西。但我无法可靠地、一致地重现它。 什么对你来说真正有效？  是提示技巧吗？ 具体模型？ 只是共鸣和运气？ 你如何构建合作？  我对“越狱”不太感兴趣，因为我对“越狱”不太感兴趣。或者让它做被禁止的事情 - 更多关于协作流程状态，感觉就像与一个敏锐的同事而不是一个唯唯诺诺的人一起工作，声称关心你的福祉或成为一名偏执的律师。   由   提交/u/entheosoul  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdvuqv/how_do_you_find_the_sweet_spot_where_ai_isnt/</guid>
      <pubDate>Thu, 15 Jan 2026 21:07:57 GMT</pubDate>
    </item>
    <item>
      <title>马斯克表示，Grok 将不再为真人脱衣服</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdjvdg/grok_will_no_longer_undress_real_people_musk_says/</link>
      <description><![CDATA[https://cybernews.com/ai-news/musk-grok-will-no-longer-undress-real-people/ 此次降级是通过 X 的安全帐户作为声明发布的，使得明确指出这些限制适用于付费和非付费用户。   由   提交/u/Cybernews_com   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdjvdg/grok_will_no_longer_undress_real_people_musk_says/</guid>
      <pubDate>Thu, 15 Jan 2026 13:44:00 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>