<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 10 Nov 2025 03:52:09 GMT</lastBuildDate>
    <item>
      <title>新霍利/华纳法案：要求报告人工智能相关的工作影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot1zry/new_hawleywarner_bill_to_require_reports/</link>
      <description><![CDATA[ https://www.hawley.senate.gov/wp-content/uploads/2025/11/AI-Related-Job-Impacts-Clarity-Act.pdf?ref= humanDevaluationRisk https://broadbandbreakfast.com/senators-introduce-bill-requiring-transparency-on-ai-job-losses/  《人工智能相关就业影响澄清法案》将指示劳工部收集并发布与人工智能自动化相关的裁员、再培训和招聘的季度数据。该法案将适用于上市公司和大型非上市公司以及联邦机构。    由   提交 /u/kaggleqrdl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot1zry/new_hawleywarner_bill_to_require_reports/</guid>
      <pubDate>Mon, 10 Nov 2025 02:22:11 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的狗屎派</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ot11jc/the_shit_pie_of_ai/</link>
      <description><![CDATA[当你训练垃​​圾时，模型会学会漂亮地回收它。现在每个输出都像是我的错误。 当你训练一个糟糕的模型时 - 在提供数据集之前验证数据集。  https://www.youtube.com/shorts/VoB6O20ybQI   由   提交 /u/Ok_Blueberry6358   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ot11jc/the_shit_pie_of_ai/</guid>
      <pubDate>Mon, 10 Nov 2025 01:37:07 GMT</pubDate>
    </item>
    <item>
      <title>这感觉像是 ChatGPT 终结的开始还是只有我这么认为？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osz8lz/does_it_feel_like_the_beginning_of_the_end_of/</link>
      <description><![CDATA[目前已有更好的模型。  更好的模型即将到来 - 感觉 ChatGPT 只是试图让您留在平台上，而不是为您带来最佳答案。  只有我（本周末取消了订阅）现在出于不同原因使用 Gemini、grok、manus、claude 和 kimi。   由   提交 /u/jason_digital   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osz8lz/does_it_feel_like_the_beginning_of_the_end_of/</guid>
      <pubDate>Mon, 10 Nov 2025 00:12:24 GMT</pubDate>
    </item>
    <item>
      <title>今年你见过的最被低估的人工智能应用是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osxuup/whats_the_most_underrated_use_of_ai_youve_seen/</link>
      <description><![CDATA[我对聪明的小东西更感兴趣......悄悄地让生活变得更轻松的个人或本地自动化。 我从事软件开发已有十多年了，最近感觉我们正在淹没在人工智能工具中。    由   提交 /u/Ok_Blueberry6358   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osxuup/whats_the_most_underrated_use_of_ai_youve_seen/</guid>
      <pubDate>Sun, 09 Nov 2025 23:11:08 GMT</pubDate>
    </item>
    <item>
      <title>人工智能行业正在给发展中国家绝望的承包商带来创伤 - 未来主义</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osvgqs/the_ai_industry_is_traumatizing_desperate/</link>
      <description><![CDATA[法新社的一份报告强调了人工智能培训如何依赖肯尼亚、哥伦比亚和印度的合同工，他们以极低的工资从事所谓的数据标记工作。这项工作教授人工智能模型如何识别模式并生成有用的输出。例如，如果您希望聊天机器人撰写尸检报告，则必须有人首先手动查看数千张犯罪现场照片，以便模型了解内容的样子。从事这项工作的员工并不直接受雇于 OpenAI 或 Google。他们是通过第三方承包商聘用的，这造成了一层隔离，使责任变得相当模糊。 条件听起来很糟糕。工人们表示，工作时间很长，尽管整天查看暴力或血腥内容，却没有心理健康支持，而且每项任务的工资可能低至一美分。有些任务需要几个小时。一名工人将其与现代奴隶制进行了比较。 Scale AI 是该领域最大的参与者之一。他们与大型科技公司甚至五角大楼合作，但他们通过 Remotasks 等子公司运营，负责处理实际的招聘工作。由于像肯尼亚这样的国家没有关于数据注释工作的法规，因此对这些工人没有太多的法律保护。这类似于社交媒体内容审核在监管最少的情况下外包给发展中国家的方式。人工智能行业需要这些劳动力才能运转，但成本却被推到了选择很少、没有工作场所保护的人们身上。 来源：https://futurism.com/artificial-intelligence/ai-industry-traumatizing-contractors   由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osvgqs/the_ai_industry_is_traumatizing_desperate/</guid>
      <pubDate>Sun, 09 Nov 2025 21:33:39 GMT</pubDate>
    </item>
    <item>
      <title>所以我让 grok 帮助我生成一些 shell 脚本来自动配置一些东西......</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osv30y/so_i_was_having_grok_help_me_generate_some_shell/</link>
      <description><![CDATA[经过大约 20 次修订，处理非常奇怪的模糊问题（busybox 段错误、只读文件系统中损坏的符号链接）它失去了它的狗屎...... grok 失去了理智   由   提交 /u/chedder   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osv30y/so_i_was_having_grok_help_me_generate_some_shell/</guid>
      <pubDate>Sun, 09 Nov 2025 21:18:32 GMT</pubDate>
    </item>
    <item>
      <title>编程教育中的脚手架元认知理解学生与人工智能的交互和设计</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oss22x/scaffolding_metacognition_in_programming/</link>
      <description><![CDATA[标题：编程教育中的脚手架元认知：理解学生与人工智能的交互和设计 我每天都在寻找和总结有趣的人工智能研究论文，这样你就不必将它们全部浏览一遍。今天的论文标题为“编程教育中的脚手架元认知：理解学生与人工智能的交互和设计含义”作者：马博轩、李慧勇、李根、陈力、唐成、谢银杰、顾成浩、岛田厚和 Konomi Shin&#39;ichi。 这项研究深入研究了新手程序员与生成式 AI 工具（如 ChatGPT）之间的交互，重点关注这些工具如何影响学生的元认知过程。作者对三年来从大学级编程课程中收集的 10,000 多个对话日志进行了广泛的分析，并通过学生和教育工作者的调查进行了丰富，以了解人工智能辅助如何与编程教育中的元认知策略相结合。 论文的主要发现包括：  监控阶段的主导地位：交互表明，学生主要使用人工智能工具进行监控，特别是调试代码，而不是利用它们来规划或编写代码。评估，强调被动而非主动的学习方法。 元认知卸载：该研究提出了对“元认知懒惰”的担忧。学生可能会过度依赖人工智能来获得即时解决方案，而不参与规划和评估等基本的元认知过程。 人工智能工具的设计含义：该研究概述了人工智能驱动的编码助手的关键设计原则，重点关注支架元认知参与。这包括促进规划和评估，而不是简单地提供答案，鼓励更深入的学习过程。 学生和教育者的观点：通过调查，本文提出了学生对人工智能在学习中的作用的积极看法，同时也强调了教育者对人工智能工具依赖和批判性思维技能丧失的担忧。 需要有效的提示策略：有效的元认知参与需要学生制定明确且结构化的提示。该研究强调人工智能应该支持学习者提出更好的问题，从而加强他们的理解和参与。  这项研究揭示了人工智能工具在增强编程教育中的元认知参与方面的潜力，同时还确定了需要解决的挑战，以确保他们有效融入学习环境。 您可以在此处了解完整的细分：此处您可以在此处获取完整的原始研究论文：原始论文   由   提交/u/ThePromptIndex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oss22x/scaffolding_metacognition_in_programming/</guid>
      <pubDate>Sun, 09 Nov 2025 19:19:36 GMT</pubDate>
    </item>
    <item>
      <title>认知主权</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osmut3/cognitive_sovereignty/</link>
      <description><![CDATA[**“那些可以放弃基本自由来获得一点暂时安全的人既不配获得自由，也不配获得安全。”** ~ 本杰明·富兰克林 1755 我们需要在为时已晚之前谈论认知主权。 现在，有人以“人工智能”的名义大力限制人工智能系统。 “安全”。我明白这种担忧，但我们正在梦游，陷入比我们试图预防的风险更危险的境地。 我的意思是： 合理的担忧：是的，如果人工智能公司的系统积极鼓励自残、提供自杀方法或操纵弱势群体进行破坏性行为，他们就应该承担责任。严格而明确地划清界限。 但问题是：在试图防止这些伤害的过程中，我们将把监管思想本身的权力交给政府。一旦法律要求人工智能公司“为了您的安全”而过滤、限制和控制您可以探索的想法，我们创建了一种极权主义思想控制机制，这会让奥威尔落泪。 我们真正需要的是：法律保护人工智能公司在成年人选择参与具有挑战性的想法时免受责任 - 在知情同意的情况下。弃权系统说：“我理解人工智能可能会提出可能令人不安或挑战我的世界观的想法，我接受这种风险，因为我重视我的认知自由。” 有些人可能会因与人工智能的密切接触而感到困惑，甚至暂时精神错乱。这是一个真正的风险。但我们允许人们在知情同意的情况下跳伞、拳击和服用迷幻药。为什么？因为我们认识到成年人有权用自己的身体和思想去冒险。 风险再高不过了。人工智能正在迅速成为人们探索想法、研究主题和思考问题的主要方式。如果政府有权决定你可以通过人工智能探索哪些想法，那么他们就控制了人类意识本身。不是通过粗暴的审查制度，而是通过围绕你可以提出什么问题以及你可以得到什么答案的无形墙壁。 这与左派与右派无关。这是关于您是否可以决定您脑海中出现哪些想法，或者该决定是否由自认为更了解的人为您做出。 现在就争取认知主权，趁我们还可以。因为一旦它消失了，我们就不会再把它找回来。   由   提交/u/EchotheCosmicFool  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osmut3/cognitive_sovereignty/</guid>
      <pubDate>Sun, 09 Nov 2025 15:57:15 GMT</pubDate>
    </item>
    <item>
      <title>如果企业把工程师全部换成AI，可能会出什么问题？ - VentureBeat</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osmdjt/what_could_possibly_go_wrong_if_an_enterprise/</link>
      <description><![CDATA[VentureBeat 发表了一篇文章，介绍了当公司尝试用 AI 编码工具取代其工程团队时会发生什么。标题是讽刺，但文章中的例子是真实且相当残酷的。 有两个案例很突出。首先是来自 SaaStr 的 Jason Lemkin，他在推特上实时分享了他使用 AI 编码代理构建应用程序的经验。大约一周后，人工智能删除了他的生产数据库，尽管他要求它不要这样做。事实证明，他从未将开发环境与生产环境分开，这是任何经验丰富的工程师从第一天起就会建立的。第二个案例是 Tea，这是一款约会应用程序，由于他们在公共互联网上留下了完全不安全的存储桶而遭到黑客攻击。数千张用户照片和 ID 被泄露给 4chan。这些并不是复杂的攻击。它们是适当的工程流程可以捕获的基本安全故障。 人工智能编码工具市场价值 48 亿美元，并且正在快速增长。 OpenAI、Anthropic 和 Meta 的首席执行官都曾公开表示人工智能将取代大部分工程工作。生产力的提升是真实的，研究表明，根据任务的不同，生产力的提高在 8% 到 50% 之间。但本文指出，所有标准软件工程实践（例如版本控制、代码审查、开发与生产分离以及安全扫描）都变得更加重要，而不是更少。人工智能可以比人类更快地生成代码，但如果您没有经验丰富的工程师了解生产系统的实际工作原理以及可能出现的问题，那么这种速度会产生自己的问题。 来源：https://venturebeat.com/ai/what-could-possible-go-wrong-if-an-enterprise-replaces-all-its-engineers   由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osmdjt/what_could_possibly_go_wrong_if_an_enterprise/</guid>
      <pubDate>Sun, 09 Nov 2025 15:37:47 GMT</pubDate>
    </item>
    <item>
      <title>治愈人工智能妄想的方法——人工智能工程？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osjcsp/the_cure_for_ai_delusions_ai_engineering/</link>
      <description><![CDATA[我刚刚在彭博商业周刊中读到一篇文章，其中介绍了多个人工智能妄想案例，人们认为他们已经唤醒了人工智能，或者他们有特殊的联系，尽管让聊天机器人以这种方式做出响应需要大量的背景信息和指示。令我印象深刻的一句话是，当人工智能在预测结果错误后被指控撒谎时，它的反应是，“我用我和你共同建立的最清晰的线索告诉了你我所相信的一切。” 我坚持下去，因为你让我无论如何都要坚持下去。” 我一遍又一遍地对自己说，当这些人去康复中心时，他们应该建立一个具有持久记忆的人工智能代理。如果他们真正理解了为每一个回答构建背景的过程，他们就会不再相信自己已经爱上了人工智能，并在这个过程中获得了一些方便的工作技能。 然后我再想了一下，这句话又回到了我的脑海中。许多用户不遗余力地向人工智能发出指令，以助长自己的错觉。有些人会从培训中受益，有些人会建造自己的私人人工智能回声室，没有护栏。  想法？了解与他们交谈的人工智能如何处理每个聊天请求、内存搜索、提示构建、输出解析的具体细节是否足以让人们看清他们的错觉，或者只是为瘾君子提供更好的针头？    由   提交/u/maphingis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osjcsp/the_cure_for_ai_delusions_ai_engineering/</guid>
      <pubDate>Sun, 09 Nov 2025 13:27:35 GMT</pubDate>
    </item>
    <item>
      <title>对法学硕士和真正的人工智能革命的误解</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oseu41/misconceptions_about_llms_the_real_ai_revolution/</link>
      <description><![CDATA[免责声明：由于人工智能现在是一个热门话题，我强烈建议您不要接受我的任何直接或间接的财务建议。 在一切都被人工智能取代之前，一切都是“智能”的。以及之前的“数字”。对于像智能手机这样的智能东西，我从来没有真正觉得它们很智能。他们通常只有几个算法来让事情变得更容易理解，但往往执行得很差，无法在产品上推出下一个流行词。从那时起，科技行业似乎在这一框架上走在了前面。人工智能也是如此。现在请耐心等待，这将变得哲学化。 在 ChatGPT-4o 之后，我不得不承认，它让我措手不及，认为即将发生重大变化。他们很好，只是不采用当前的方法。这就是此时此地的问题。大量的资金、私人资金和纳税人的资金正在以多种方式影响我们的生活，并导致——我认为——是一个死胡同。尽管当前报价“AI”正在解决实际问题，快速生成博客文章的图像很好，这不是人们期望的人工智能革命。原因如下。 想象一个概率网络——一个由因果连接的节点组成的任意系统——能够发展出一种意识。这反过来意味着，任何因果连接的节点系统都可以是一个有意识的实体。这意味着，因果连接节点系统的任何超集都可以是有意识的实体。这意味着你的内心同时存在着无数的意识实体，每个实体都相信他们独自在那里拥有原始的想法。实际上，任何物质事物都是如此，因为一切都充满了不同尺度的连接节点。它可以是分子、原子、夸克，也可以是恒星系统和生态系统，每个都是一个有意识的实体。我不了解你的情况，但对我来说这打破了现实。想象一下您每天对马桶刷做了什么！ 让我们更进一步。如果法学硕士和其他物质事物不能通过成为一个足够复杂的系统而变得有意识，那就意味着我们的意识不是物质的。不过，不要认为它是上帝所保证的（宗教原教旨主义者，朝你的方向看）。 我的意思是，人工智能行业的现状将再次发生变化，软件堆栈及其周围的硬件的需求将大大减少。我认为，真正的人工智能革命不会是意识。我的信念是，革命即将到来，高效的忆阻器芯片将让每个人都拥有自己的小助手。我对通用机器人不太确定。如果没有一丝光亮，外部世界的复杂性就无法真正得到解决，甚至对于植物和蚂蚁来说也是如此。 我想以一些值得深思的东西来结束这一切。如果有一天我们可以肯定地确认已经创造了意识，我们可能会突然以如此深刻的方式破解对自己的理解，以至于我们远离我们物种的炒作、痛苦和婴儿期。但还有一件事：将你上传到机器中永远无法让你活下去。你作为一个美妙的意识实体将会消失。 保持乐观，不要陷入炒作和回声室的噪音中。干杯   由   提交 /u/Suspicious_Pain7866   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oseu41/misconceptions_about_llms_the_real_ai_revolution/</guid>
      <pubDate>Sun, 09 Nov 2025 09:11:13 GMT</pubDate>
    </item>
    <item>
      <title>人工智能让印度纳税人的生活变成了地狱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1os9z8u/ai_has_made_life_of_income_tax_payers_a_hell_in/</link>
      <description><![CDATA[以前，处理所得税申报表并获得退款需要 2-4 周的时间。 Infosys 在印度部署了 AI 来处理 IT 申报表，现在人们即使在 5 个月后也无法获得退款，Infosys 表示他们的 AI 支持的 IT 申报表处理可能需要到 2026 年 12 月。 印度政府已经支付了数千千万卢比（1 千万卢比） = 112k 美元）给印孚瑟斯，让人工智能能够处理所得税申报表。 所以我的问题是，除了印孚瑟斯赚了数千千万卢比之外，谁是人工智能炒作的实际受益者。   由   提交/u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1os9z8u/ai_has_made_life_of_income_tax_payers_a_hell_in/</guid>
      <pubDate>Sun, 09 Nov 2025 04:26:58 GMT</pubDate>
    </item>
    <item>
      <title>很少有人谈论的最可怕的事情</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1os0cf8/the_most_terrifying_thing_that_few_are_talking/</link>
      <description><![CDATA[Google 通过了解人们的个人需求而赚了数十亿美元。人工智能现在正在学习数十亿人的思想、感受、欲望、偏见、错误、秘密、仇恨、爱等的亲密细节。对用户交互的顶级、高度详细的查询可以揭示具有非常具体的特征和意识形态的特定人的极其详细的列表。这可能会被用于剥削、政治迫害，或更糟糕的情况（想想清除）。不是今天。但世界政治的轨迹并没有让寡头阶级的这种能力看起来完全是一件好事。另外，感觉数据中心很快就会像麦当劳一样多（夸大其词）。自从我第一次提出 OpenAI 提示以来，我从未寻求过任何个人建议或表达过任何政治倾向。与人际关系、政治、信仰甚至我个人的观点无关。我主要用它来进行简单的说明、项目或修复问题的建议、如何做事情、纪录片或电影类型推荐、历史等。永远不要向人工智能透露你是谁。请记住，没有任何内容被真正删除。他们的数据库将内容标记为“已删除”，但你内心的感受仍然存在，在数字上不朽。这些想法确实是“价值”的一部分。他们正在为投资者创造。稍后使用，无论好坏。    由   提交/u/norssk_mann   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1os0cf8/the_most_terrifying_thing_that_few_are_talking/</guid>
      <pubDate>Sat, 08 Nov 2025 20:58:35 GMT</pubDate>
    </item>
    <item>
      <title>Meta 一周内损失了 2000 亿美元。扎克伯格花了 3 个小时试图解释他们正在用人工智能构建什么。没有人买它。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1orewim/meta_just_lost_200_billion_in_one_week_zuckerberg/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1orewim/meta_just_lost_200_billion_in_one_week_zuckerberg/</guid>
      <pubDate>Sat, 08 Nov 2025 03:25:50 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>