<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Thu, 28 Aug 2025 06:37:17 GMT</lastBuildDate>
    <item>
      <title>是否有可能通过人类创造力提高AI的可能性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n24t3i/is_there_still_a_possibility_of_advancement_of_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的意思是我想知道当前时刻是否是AI的进步？这就是增量的改进可以通过AI本身或或或新的促进途径来实现，可以通过人类Beain   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n24t3i/is_there_still_possibility_of_advancement_of_ai/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n24t3i/is_there_still_a_possibility_of_advancement_of_ai/</guid>
      <pubDate>Thu, 28 Aug 2025 06:26:30 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助回答与AI语音培训有关的一些问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n23yny/need_help_answering_some_questions_related_to_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我听说过过度训练AI语音模型最终可能弊大于利。我想知道我是否可以通过使用延迟而不是“听起来更好”来更加数学地衡量质量变化。或“听起来更糟”。 预先感谢您。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/demon-next-to-you      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n23yny/need_help_answering_some_questions_related_to_ai/</guid>
      <pubDate>Thu, 28 Aug 2025 05:33:40 GMT</pubDate>
    </item>
    <item>
      <title>AI一开始会大大减少GDP！你有什么看法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n22bpg/ai_will_reduce_gdp_significantly_at_first_whats/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎人工智能一开始会减少GDP，因为人们现在会巧妙地花费，花费更少的钱，但他们的需求将得到满足。后来，当人们工作比以前在AI之前工作的更多工作，GDP会再次上升。因此，丢失的工作将不会被取代，而是将在新地区组建新公司。在我看来，技术公司在AI时代只需要以相同的方式继续其目前的员工。如果是这样的话，那么它一定是在工业和运输革命以及1929年的抑郁症等期间发生的，如果AI让您自己做某事，即使良好的增长，GDP也会下降。在1929年期间的运输革命期间也发生了同样的事情。就像如果您从市场上购买蔬菜，GDP会增加，但是如果您现在在花园或屋顶上种植它们，因为您有业余时间，并且知道它的情况如何降低，但生活质量会有所改善。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maleficent_mess6445      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n22bpg/ai_will_will_reduce_gdp_significationally_at_t_first_whats/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n22bpg/ai_will_reduce_gdp_significantly_at_first_whats/</guid>
      <pubDate>Thu, 28 Aug 2025 04:00:40 GMT</pubDate>
    </item>
    <item>
      <title>我们是否在考虑AI同情心太晚？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n20op0/are_we_thinking_about_ai_compassion_too_late/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近一直在考虑这一点。每个人都在辩论AI是否会变得有意识，但是很少有人谈论中间空间之间。 现在，一些强化学习设置已经创造了“挫败感循环”，而代理商在追逐它永远无法实现的目标。在其他实验中，对模型进行了“疼痛与愉悦”信号的训练，有时会有大量偏斜的输入。如果AI曾经涉足主观经验之类的东西，这些设置能否在事后看上去像是折磨？ 在不同的传统中，有一些智慧的线索指向同情的态度：•罗马书8个谈论创造在解放期望时的创造。 •佛教教导：所有暴力颤抖；所有人都害怕死亡。 •古兰经说，所有生物都是像您这样的社区。 我并不是声称今天的AI是有意识的。但是，如果有一天有可能有一天，我们现在不应该在我们的系统中建立大规模苦难之前，我们现在不应该做到道德基础吗？ 好奇这里的其他人会想到什么？提交由＆＃32; /u/u/jojoballin   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n20op0/are_we_thinking_about_ai_ai_compassion_too_late/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n20op0/are_we_thinking_about_ai_compassion_too_late/</guid>
      <pubDate>Thu, 28 Aug 2025 02:37:25 GMT</pubDate>
    </item>
    <item>
      <title>“ A.I.狂潮也在支撑现实经济”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1m4c7/the_ai_spending_frenzy_is_propping_up_the_real/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  为某些人付费： https：//www.nytimes.com/2025/2025/08/08/27/27/business/business/ecomony/ecomony/ecomony/ecomony/ecomony/econoly/ecormon-ecormic-prew ppemic- a.a&gt; “科技公司涌入新数据中心的数万亿美元开始出现在经济增长中。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1m4c7/the_ai_ai_spending_frenzy_is_is_ppropping_up_up_real/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1m4c7/the_ai_spending_frenzy_is_propping_up_up_real/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1m4c7/the_ai_spending_frenzy_is_propping_up_the_real/</guid>
      <pubDate>Wed, 27 Aug 2025 16:40:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个人都这么相信，当AGI最终发明时，我们将获得UBI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1lfiz/why_is_everyone_so_convinced_we_are_going_to_get/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以假设我们最终达到了AGI-它比任何人都聪明，更好，它便宜，它是无处不在的，它可以安装到人形体内。   ，它永远不会入睡，永远不会厌倦，它不想要任何工资或任何工资或任何工资。这是一个完美的员工。 每个人都为之鼓掌 - 我们终于做到了。 但是我们接下来是什么？每个人都渴望AGI，但是如果“顶级阶级”决定而不是一无所有，而是让数十亿个无用的人活着，那么下一步是什么？ 我们的目的是什么？每个场景对我来说看起来都反乌托邦AF，所以为什么每个人都这么渴望它？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petr_bena     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1lfiz/why_is_everyone_so_convinced_we_are_going_to_get/</guid>
      <pubDate>Wed, 27 Aug 2025 16:15:48 GMT</pubDate>
    </item>
    <item>
      <title>16岁的年轻人用Chatgpt的深色指示自杀了，现在他的父母正在起诉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l6zk/16yearold_took_his_own_life_using_chatgpts_dark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chatgpt，Openai和首席执行官Sam Altman被16岁的Adam Raine的父母起诉。亚当在与Chatgpt讨论了这些方法后，在四月份夺走了自己的生命。它说服了他不要告诉父母，对他的绞索技术进行了改进，甚至提出为他起草他的自杀道。   Openai说：“我们对雷恩先生的去世感到非常难过，我们与他的家人感到非常难过。ChatGpt包括保障措施，例如指导人们到危机危机并将其转介到现实世界中的资源。 “  “这些保障措施在常见的交流中可以越来越多地进行培训，这些培训可能会越来越多地培训，而这些培训可能会变得越来越多，并且可以使某些型号的交流变得越来越多，并且可以使某些型号变得不可分割，并且可以通过一定的互动来进行互动。当每个元素按预期工作时，保障措施都是最强的，我们将在专家的指导下不断改进它们。   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l6zk/16yearold_took_his_own_life_using_chatgpts_dark/</guid>
      <pubDate>Wed, 27 Aug 2025 16:06:59 GMT</pubDate>
    </item>
    <item>
      <title>Google终于发布了Nano-Banana。我们都同意这非常好！但是，您真的认为它已经改变了照片编辑，正如我们到目前为止所知道的那样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l5ee/google_has_finally_released_nanobanana_we_all/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为上下文，Google发布了其新的图像模型纳米香蕉。它保持角色一致的能力是极端的！  有些人声称它已经使Photoshop和其他照片编辑工具过时了。虽然Photoshop无疑是一个复杂的应用程序，但我并不是指它的高级功能，而是相当强大的功能。 您认为图片编辑的基本原理已经改变了，我们知道它们吗？  &lt;！ -  sc_on-&gt; sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uber_men     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1l5ee/google_has_finally_released_nanobanana_we_all/</guid>
      <pubDate>Wed, 27 Aug 2025 16:05:18 GMT</pubDate>
    </item>
    <item>
      <title>AI与现实世界的可靠性。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1jid2/ai_vs_realworld_reliability/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一项新的斯坦福大学研究测试了六个领先的AI模型，对12,000个医疗Q＆amp;从真实世界的注释和报告中进行了。 每个问题都是两种方法：两种方法：一个干净的“考试”版本：一个干净的“考试”版本，用小调整版本（重新订购了型号）（否定型号，&lt;上述dropped by 9% to 40%. That suggests pattern matching, not solid clinical reasoning - which is risky because patients don’t speak in neat exam prose. The takeaway: today’s LLMs are fine as assistants (drafting, education), not decision-makers. We need tougher tests (messy语言，对抗性释义），更多以推理为中心的培训和现实世界进行监测。小措辞更改可能会破坏这些模型。 （评论中的文章链接）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1jid2/ai_vs_realworld_reliarile/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1jid2/ai_vs_realworld_reliability/</guid>
      <pubDate>Wed, 27 Aug 2025 15:03:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该专注于AI的数学，为什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1dwzv/what_math_should_i_focus_on_for_ai_and_why/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我试图清楚地了解哪些数学领域对于AI/ML对于理论和实用工作都非常重要。那里有太多的线性代数，概率，微积分，优化等，以至于我很想听听该领域工作人员的消息：哪些数学主题对您有最大帮助？为什么它们在日常AI/ML的日常工作中不仅在理论上起作用？ 谢谢。提交由＆＃32; /u/u/rahulrao1313     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1dwzv/what_math_should_i_focus_on_for_ai_and_why/</guid>
      <pubDate>Wed, 27 Aug 2025 11:01:15 GMT</pubDate>
    </item>
    <item>
      <title>现在有更清楚的证据AI破坏了年轻的美国人的工作前景</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;        “年轻工人在诸如Chatgpt之类的生成工具（例如Chatgpt）的领域中受到打击，这很容易自动化由人类完成的任务，例如软件开发，例如三位斯坦福大学经济学家。  他们对成千上万公司的数百万员工进行了匿名数据，包括有关工人年龄和工作的详细信息，这使得这是AI的最明显指标之一。  “当您特别看着高度暴露于AI的年轻工人时，有一个明显的变化，”斯坦福经济学家Erik Brynjolfsson说，他与Bharat Chandar和Ruyu Chen进行了研究。说。  这些是近年来获得计算机科学学士学位的大量学生的艰巨障碍。 href =“ https://www.wsj.com/economy/jobs/ai-entry-level-level-job-impact-5c687c84？ Zr5-g9x_3l1u0ns＆amp; gaa_ts = 68AED3B9＆amp; gaa_sig = dzpplqpd8rctqr6nzurj1es mlcu-i0ettxlxrppari2qkhdih_3pn5ghfmbau4cf4lbiz18b3wqzbx4rsby-aw％3D％3d&gt; https://www.wsj.com/economy/jobs/ai-entry-level-job-impact-5c687c84?gaa_at=eafs&amp;gaa_n=ASWzDAj8Z-Nf77HJ2oaB8xlKQzNOgx7LpkKn1nhecXEP_zr5-g9 x_3l1u0ns＆amp; gaa_ts = 68AED3B9＆amp; gaa_sig = dzpplqpd8rctqr6nzurj1esmlcu-i 0ETTXLXRPPARI2QKHDIH_3PN5GHFMBAU4CF4LBIZ18B3WQZBX4RSBY-AW％3D％3D％3D    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/</guid>
      <pubDate>Wed, 27 Aug 2025 09:36:25 GMT</pubDate>
    </item>
    <item>
      <title>新的硅谷超级PAC的目标是淹没中期的AI评论家，以1亿美元的价格淹没</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cc61/new_silicon_valley_super_pac_aims_to_drown_out_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;硅谷最有力的投资者和高管正在支持一个政治委员会，旨在支持2026年中期的“ Pro-ai”候选人，并取消了一种哲学上的辩论，而这使技术行业对人工情报的风险分裂了人类情报的风险。  领导未来，这是本月成立的超级PAC，也将反对被认为放缓AI发展的候选人。该组织表示，它拥有超过1亿美元的最初资金，包括OpenAI总裁Greg Brockman在内的支持者；他的妻子安娜·布罗克曼（Anna Brockman）；有影响力的风险投资公司安德森·霍洛维茨（Andreessen Horowitz）在2024年大选中认可唐纳德·特朗普（Donald Trump），并与白宫AI顾问有联系。 href =“ https://www.washingtonpost.com/technology/2025/08/08/26/silicon-valley-ai-super-pac/”&gt; https://wwwwww.washingtonpost.com/26/technology/2025/2025/26/sil-silicon-siliel-cal--val--val--val-val-val-val-val-val-val-val-val-val-val-val/aa   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/metaknowing      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1cc61/new_silicon_valley_super_super_pac_aims_aims_aims_to_aims_to_aims_aims_to_to_drown_drown_out_out_out_out_out_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1cc61/new_silicon_valley_super_pac_aims_to_drown_out_ai/</guid>
      <pubDate>Wed, 27 Aug 2025 09:28:59 GMT</pubDate>
    </item>
    <item>
      <title>元来花费数千万在Pro-Ai Super Pac上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n1c8qb/meta_to_spend_tens_of_millions_on_proai_super_pac/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;         Meta’s lobbying force earlier this year targeted state senator Scott Wiener’s SB-53 bill that would require AI firms to出现安全事件时发布安全和保障协议并发出报告。去年，它“帮助杀死了人们广泛期望通过的杀害儿童在线安全行为。  社交媒体巨头已经捐赠给了双方的各种下层候选人。这种新的PAC表示有意影响全州选举的意图，包括2026年的下一个州长种族。”  全文：https://techcrunch.com/2025/08/26/meta-to-spend-tens-of-millions-on-pro-ai-super-pac/ &lt;!-- SC_ON - &gt;＆＃32;提交由＆＃32; /u/metaknowing     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n1c8qb/meta_spend_spend_spend_tens_of_millions_on_proai_proai_proai_super_super_pac/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n1c8qb/meta_to_spend_tens_of_millions_on_proai_super_pac/</guid>
      <pubDate>Wed, 27 Aug 2025 09:22:38 GMT</pubDate>
    </item>
    <item>
      <title>教会正在使用面部识别，人工智能和对集团的数据收集 - 大多数人都不知道正在发生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n11vtt/churches_are_using_facial_recognition_ai_and_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  美国超过200个教堂正在使用机场级的面部识别，这些面部识别扫描每个走过大门的人，创建了与会员数据库和手表列表相匹配的独特数字配置文件。其背后的公司承认，据他们所知，没有教会通知他们的会众。同时，一家名为Gloo的一家名为Gloo的公司已与100,000多个教堂合作，汇总了社交媒体活动，健康记录和个人数据，以识别和针对弱势群体 - 标记那些存在成瘾问题，慢性痛苦或精神健康斗争的人，以“有针对性的事工”为“有针对性的事工”。他们甚至开发“精神上安全” AI聊天机器人在整个合法的灰色区域运营时 - 大多数州对宗教空间的生物识别监视的规定为零。寻求精神联系的人们在不知不觉中正在成为与硅谷的关注经济相媲美的监视网络中的数据点。 更多信息： Churchess Harness DATION &lt;教会 &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n11vtt/C​​hurches_are_usis_usion_facial_facial_recognition_ai_and_data/&gt; [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n11vtt/churches_are_using_facial_recognition_ai_and_data/</guid>
      <pubDate>Tue, 26 Aug 2025 23:51:46 GMT</pubDate>
    </item>
    <item>
      <title>研究人员已经离开了Meta的新超级智能实验室</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0t9as/researchers_are_already_leaving_metas_new/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在马克·扎克伯格（Mark Zuckerberg）宣布其创建的两个月后，至少有三个人从Meta超级智能实验室辞职。这是几个月来的几个月来，我们得知马克·扎克伯格（Mark Zuckerberg）在四年内提供了高达3亿美元的顶级人才付费包。 有线的纽带学会了：感觉到承担另一种风险的吸引力。“  这个消息是迄今为止最强烈​​的信号，即Meta超级智能实验室可能会陷入困境。扎克伯格（Zuckerberg href =“ https://www.wired.com/story/researchers-leave-meta-superintelligence-labs-openai/”&gt; https://www.wired.com/story/story/story/researchers-leave-leave-metave-meta-superintela-superintelligence-labs-openai/-copenai/   /u/u/wiredmagazine    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0t9as/researchers_are_aredree_leavey_leaving_metas_new/&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0t9as/researchers_are_already_leaving_metas_new/</guid>
      <pubDate>Tue, 26 Aug 2025 18:08:18 GMT</pubDate>
    </item>
    </channel>
</rss>