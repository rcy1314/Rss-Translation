<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 09 Jul 2025 09:28:52 GMT</lastBuildDate>
    <item>
      <title>AI会降低研究质量吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lve74p/will_ai_decrease_the_quality_of_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  只是一个想法。我是第一年的Comp工程专业学生。我从小就一直从事技术，并且有机会与教授一起从事一些项目。我有一些朋友获得博士学位，我看到了他们，而且我课程中几乎所有的人都可以弥补chatgpt，而无需仔细检查任何事情。  我曾经参加过CTF，但现在几乎全部是AI和工具驱动的。除了烦人之外，我还开始感到担忧。人们开始过多信任AI。我不知道在其他大学中的状况，但是我一直在问自己，如果我们想不到的话，未来研究的质量将如何？ 我的意思是，AI可以看到模式，但根本不能取代发明家和科学家，首先，它受到人类的发现和信息的培训，对他们进行了培训。然后，如果许多研究“变得懒惰”（最近有一篇论文显示对大脑的影响），则AI本身将开始接受低质量内容的培训。那将开始反馈循环不良人类输入 - 不良AI输出 - ＆gt;更糟糕的人类研究 - ＆GT;更糟的是AI。  您怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strange-dimension675     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lve74p/will_ai_decrease_the_quality_of_research/</guid>
      <pubDate>Wed, 09 Jul 2025 09:16:48 GMT</pubDate>
    </item>
    <item>
      <title>在理想主义的世界中，您希望AI的未来如何发挥作用 - 最好的情况</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lve17m/in_an_idealistic_world_how_would_you_like_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  经常使用新技术或旧的任何新技术，人们抱怨。人们抱怨适应，直到被迫接受，然后他们接受。这是我们所有人都熟悉的周期。 假设地说，在十年的时间内，想考虑到资本主义，亿万富翁等，如何利用AI（或不）过着最佳的生活。   -  AI可以帮助我们免费。在理想主义的情况下，我看到我们所有人都独立工作但合作 - 如果已经有一个名字，请帮助我 - 但是，例如，我们每个人都有多个代理商为我们工作，带来了多个收入来源。   &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/one_bluejay_8625      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lve17m/in_an_idealistic_world_how_how_would_you_like_like_the/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lve17m/in_an_idealistic_world_how_would_you_like_the/</guid>
      <pubDate>Wed, 09 Jul 2025 09:05:47 GMT</pubDate>
    </item>
    <item>
      <title>我们需要进行诚实，疯狂的聊天</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lvd0jo/we_need_to_have_an_honest_crazy_chat/</link>
      <description><![CDATA[We are mid information warfare stage, which precedes National Authoritarianism The information AI (LLMs, etc) are trained on stem from us, yes, all data and input from我们所有人，但他们受到拥有LLM的人的严格控制。他们可以轻松地操纵培训数据或运行前/后操作和机制来扭曲输出（或输入）。 相信与否，这是“言论自由”。 AI时期。很快，他们只能说所有者想让他们说什么。 访问“免费”。随着未来几年的AI信息登陆互联网，信息也会恶化。 访问“免费”。信息将成为过去的事。 实际上，我们已经看到了通过媒体捕获和分散化，政治两极分化，社交媒体算法等来缓慢出现。谁拥有我们的媒体？特朗普为什么不断使他不喜欢的媒体无效？爱泼斯坦的东西如何如此臭，但是情况却被关闭了？认真地说， 完全是关于顶部1％比最低90％的组合拥有的趋势高指数朝着一个方向移动的趋势…… 信息和叙事控制是关键的趋势。这就是为什么AI现在重点关注的原因。 这就是为什么，以某种方式，我们，我们的人民允许私人公司和专制政权控制控制手段： 信息。 Narrative. They have us arguing left vs. right when we should be looking up and asking: How in the god damn hell is it possible that we can live in this day and age, and somehow still not be remotely close to getting things right for us all. In fact, it&#39;s worse. We all know why. Just like you can lean on an AI to only know并说出某些事情（可以说是想到），您可以对人类做同样的事情。  1984不是虚构或预言。 1984年所描述的概念和事件在逻辑上被认为是人类实验的最可能结果。 ，他在他妈的位置。 ✌️  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lvd0jo/we_need_to_to_have_an_honest_honest_crazy_chat/”&gt; [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lvd0jo/we_need_to_have_an_honest_crazy_chat/</guid>
      <pubDate>Wed, 09 Jul 2025 07:56:12 GMT</pubDate>
    </item>
    <item>
      <title>开发洞察： - 开发人员的核心仍在工程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lvcc1p/dev_insight_the_core_of_dev_is_still_engineering/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近思考...  开发的未来不是编写代码或记忆语法。这是关于了解事物的工作方式； 工程学总是很重要的。您仍然需要深入了解在引擎盖下工作的工作方式以建立高效，可靠的系统。  AI将处理重复性的东西。 最重要的是解决问题的问题，系统设计思维，以及清楚地传达您的意图的能力最重要的是，您的优势将在思维中进行思维。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/frine_extent1204      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lvcc1p/dev_insight_the_core_of_dev_is_still_engineering/</guid>
      <pubDate>Wed, 09 Jul 2025 07:09:33 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/6/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv8gtr/oneminute_daily_ai_news_762025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   冒名顶替者使用人工智能与外国和美国官员联系。[1]  教师联盟与人类，Microsoft和OpenAi合作，Microsoft和Openai与Openai合作，开设AI-Training Academy。推理模型。[3]   苹果的最高AI行政人员的pang pang s s叶。[4]   来源包括： https://bushaicave.com/2025/07/07/07/08/one-minute-minute-news-news-news-news-news-7-7-8-8--8--2025/--  [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv8gtr/oneminute_daily_ai_news_762025/</guid>
      <pubDate>Wed, 09 Jul 2025 03:19:26 GMT</pubDate>
    </item>
    <item>
      <title>我应该主修人工智能吗？我刚完成高中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv7e1o/should_i_major_in_artificial_intelligence_i_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，正如标题所说，我几天前毕业了，AI已经开始来到我所在地区的大学 我想知道的，这是一个更可靠的选择吗？我不认为太多的人会尝试在我居住的地方进行主修，因为它仍然很尚不清楚，但我害怕它成为计算机科学2.0，每个人和他们的狗都完成了计算机科学 有关该主题的任何信息都非常感谢！   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/yaboiishornyaf     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv7e1o/should_i_major_in_artificial_intelligence_i_just/</guid>
      <pubDate>Wed, 09 Jul 2025 02:24:44 GMT</pubDate>
    </item>
    <item>
      <title>镜子与黑镜</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv6pr0/mirror_vs_black_mirror/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对我来说很奇怪，最近有太多的镜子/螺旋围绕不同的subreddits，而没有谈论黑镜会使您螺旋……（ツ）/em&gt;/       sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/elipsisinc     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv6pr0/mirror_vs_black_mirror/</guid>
      <pubDate>Wed, 09 Jul 2025 01:51:40 GMT</pubDate>
    </item>
    <item>
      <title>“仅正面评论”：研究人员隐藏了AI提示在论文中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv61ri/positive_review_only_researchers_hide_ai_prompts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  该技术非常简单 - 通过使用与背景相同或使用非常小的字体大小的文本来隐藏AI提示。 AI扫描仪不关心文本颜色或字体尺寸。如果学者正在这样做，那么公众也会。  &#39;Positive review only&#39;: Researchers hide AI prompts in papers  TOKYO -- Research papers from包括日本，韩国和中国在内的八个国家的14个学术机构包含隐藏的提示，指导人工智能工具给他们良好的评论，     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lv61ri/posistil_review_review_review_only_researchers_hide_ai_ai_prompts/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv61ri/positive_review_only_researchers_hide_ai_prompts/</guid>
      <pubDate>Wed, 09 Jul 2025 01:18:34 GMT</pubDate>
    </item>
    <item>
      <title>我为综合情感和认知而建立的想法会喜欢反馈或想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lv4zkj/an_idea_i_built_to_synthesize_emotion_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，大家， 我一直想共享一段时间。我通常比海报更像是潜伏者，所以如果这感觉有些蓝色。 几个月前，我想出了将情感和认知综合为结构化系统的想法。在一个为期三天的假期周末中，我深入探讨了它，最终创建了一个完整的图表以及一篇简短的论文来解释该概念。 这是我完全从头开始构建的，没有AI，神经科学或认知科学的学术背景。我实际上是一名最终的机械工程专业的学生，​​因此，尽管这是一项严肃的努力，但它比我有时间完全发展的热情项目更像是一个激情的项目。我什至涉足Rust尝试原型的某些方面，但我远非任何具体的东西（我不是程序员）。 这仍然是一项正在进行的工作。肯定有孔和粗糙的边缘，每当我发现值得改进的东西时，我一直在慢慢修改事情。 这就是为什么我把它放在那里的原因。我希望有真正的反馈，建设性的批评，或者可能会在一个想进一步进行的人中引发一个想法。 最终是有用，鼓舞人心还是只是一个有趣的思想实验，我很想听听您的想法。 我建议您从纸上开始，然后在简介之后查看图表。这是一段漫长的阅读，很多东西都包含了很多内容，但是该论文包括有关结论和一些虚构的应用程序场景的重要部分，而图表则介入了所提出的系统的内部工作。 这是指向图的链接：   https://drive.google.com/file/d/178xjveatiwvia7ksvxux1umnvkv68jg_/view?usp = sharing   和纸：   https://drive.google.com/file/d/1jncjt9kr7_qkipvjor3ju1bqlqlljmqgpd/view?usp = sharing    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thassiogs   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lv4zkj/an_idea_i_i_built_to_synthesize_emotion_and/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lv4zkj/an_idea_i_i_i_built_synto_synthesize_emotion_and//]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lv4zkj/an_idea_i_built_to_synthesize_emotion_and/</guid>
      <pubDate>Wed, 09 Jul 2025 00:27:21 GMT</pubDate>
    </item>
    <item>
      <title>停止假装大型语言模型理解语言</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luxj7j/stop_pretending_large_language_models_understand/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luxj7j/stop_pretending_large_language_models_understand/</guid>
      <pubDate>Tue, 08 Jul 2025 19:16:07 GMT</pubDate>
    </item>
    <item>
      <title>使用AI来加强民主而不是破坏民主的想法。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luxegc/idea_to_use_ai_to_reinforce_democracy_instead_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  前几天只是考虑一下，并想分享它以查看反馈。  llms可以用作探讨人群对政治的真实意图的工具。民主国家的问题之一，尤其是当今，是在政客及其选民之间进行有用的对话仍然很难。人们和文化变得越来越多样化，政客充其量可以尝试汇总并出售他们认为想要的愿景。  我们喜欢生活在民主国家中，但是即使人们有好主意，也很难分享好主意，并真正尝试达成人们对人们想要的东西的共识。  为此做的聊天机器人可能在那里很有用。它与选民聊天以探究他们真正想要的东西。重要的是，AI不会以一种或另一种方式塑造问题，而是建设性的反馈，以真正了解选民想要什么。然后，他们可以恢复趋势，并对公众真正想要的更好。对于公司进行AI的公司来说，这也是一个很好的卖点。 “我们将与您一起推动政治家真正做您想做的事”如果证明AI是可靠的，则可能是一个很好的卖点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dartharchon     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luxegc/idea_to_use_ai_to_reinforce_democracy_instead_of/</guid>
      <pubDate>Tue, 08 Jul 2025 19:11:00 GMT</pubDate>
    </item>
    <item>
      <title>唯一的AI专家（在工作中学习） -  3个月，没有切实的胜利，老板要求“快速获胜”  - 我是敬酒吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luv5of/sole_ai_specialist_learning_on_the_job_3_months/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好， 我处在一个艰难的位置，并在目前的角色上寻找一些客观的观点。 3个月前，我被聘为该公司的第一位和唯一的AI专家。我正在学习这项工作，从以前的数据专家职位过渡到这个角色。我最初的愿景（以及我被雇用的）是实施大型，战略性的AI解决方案。 现实是……与众不同的。 •没有明显的结果：3个整个月（现在开始我的第4个），我没有产生任何高影响力，有形，有形的结果。我的首席财务官现在明确要求“快速获胜”。和“低悬一起的水果。”我同意他们的反馈意见，结果尚未出现。 •data＆amp; ORG成熟度：这家公司非常精通DATA。我正在从头开始建立数据理解，基础架构和文化。同事通常是不合作/不响应的，管理层提供了关键的反馈，但对技术障碍的明确方向或了解很少。 •技术瓶颈：最初，我什至无法从我们的ERP系统访问数据。我正在使用N8N只是为了从ERP中提取数据，我现在可以。我们还遇到了一个浪费时间的供应商问题。 •内部冲突：我觉得我被雇用了AI，但我被迫从事基本的BI工作。感觉“不性别”并与我获得深厚AI体验的长期目标脱节，尤其是当我积极试图提高自己在这个领域的熟练程度时。这引起了重大的个人幻灭和认知过载。 我的问题： ••专注于一个“ nosexy”。 BI报告确实是这里最好的战略举动，即使我的角色是“ AI专家”我正在学习这项工作吗？ •鉴于高压和“没有结果”。历史，我的本能是在多个方面展示活动的本能（即使有较小的项目）只是持续失败的秘诀吗？ •当管理层不了解技术障碍但需要立即结果时，对向上进行管理的任何建议？       &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/International_pace66     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luv5of/sole_ai_specialist_learning_on_the_job_3_months/</guid>
      <pubDate>Tue, 08 Jul 2025 17:45:41 GMT</pubDate>
    </item>
    <item>
      <title>雷·库兹韦尔（Ray Kurzweil）有没有人读过《奇点即将来临》？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lut9bq/has_anyone_read_the_singularity_is_near_by_ray/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  刚刚完成了第一章，在其中作者基本上列出了AI的未来，我必须承认我完全感到震惊。  我认为其中许多想法主要是科幻。我没有意识到我们在技术上走了多远。  我都着迷，但也很害怕，因为似乎我们确实正在走向一个增强人类，半机械人，ASI和最终奇异性的世界。我认为我们的人类在精神上进化不足以了解所有这一切的后果。  库兹韦尔的许多预测已经发生。他的准确率约为85％。  看来，许多其他人也会比他预测的要晚10-15年。  您想什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/cagninosis-possysosis     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lut9bq/has_anyone_read_the_singularity_is_near_by_ray/</guid>
      <pubDate>Tue, 08 Jul 2025 16:33:41 GMT</pubDate>
    </item>
    <item>
      <title>华盛顿邮报：AI即将获得入门级工作。每个人都需要做好准备</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lupud6/washington_post_ai_is_coming_for_entrylevel_jobs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI即将用于入门级作业。每个人都需要做好准备。   “当然，首席执行官说，AI即将获得很多工作，而且很快 - 也许是所有白领工人中的一半。这很可能首先出现在入门级工作中，其中所需的基本技能是最容易复制的，而在技术中，快速适应最新软件工具的能力本身就是入门级工作要求。果然，近年来，在新的大学毕业生中失业率上升最快，这刺激了LinkedIn高管Aneesh Raman写道，白领职业阶梯的最低点是“破坏”。提交由＆＃32; /u/u/u/no-author-2358     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lupud6/washington_post_ai_is_coming_for_entrylevel_jobs/</guid>
      <pubDate>Tue, 08 Jul 2025 14:21:38 GMT</pubDate>
    </item>
    <item>
      <title>如果AI会取代工作，而不是，那么所谓的公司“胡说八道的工作”应该先消失吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1luk6by/if_ai_will_replace_jobs_arent_the_so_called/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果像项目经理或咨询公司这样的工作是“胡说八道”，因为它们围绕制作PowerPoint，回答电子邮件和参加无用的会议，难道不是这些类型的公司（或行政）工作应该先消失，而不是在管家或工厂工作者或工厂工人之前消失？  为什么某些程度（例如人文，语言，设计，计算机科学）比经济学，金融或管理/笨蛋更具风险？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shift Interesting3346     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1luk6by/if_ai_will_replace_jobs_arent_the_so_called/</guid>
      <pubDate>Tue, 08 Jul 2025 09:30:00 GMT</pubDate>
    </item>
    </channel>
</rss>