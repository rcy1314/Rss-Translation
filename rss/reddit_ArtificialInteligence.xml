<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 04 Jan 2026 04:13:06 GMT</lastBuildDate>
    <item>
      <title>构建音频验证 API：如何在没有机器学习的情况下检测人工智能生成的语音 我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</link>
      <description><![CDATA[花了太长时间构建一些可能毫无意义的东西 制作了一个 API 来判断录音是人工智能还是人类 结果人工智能声音出奇地完美。比如 0.002% 的时间变化，而人类则为 0.5-1.5% 人类很混乱。人工智能不是。 无论如何，有人真的需要这个吗？还是我只是浪费了一个月的时间。  仍然非常困惑如何在不放弃我的整个项目的情况下将其提供给其他人，这是我愿意放弃的一部分   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</guid>
      <pubDate>Sun, 04 Jan 2026 03:31:55 GMT</pubDate>
    </item>
    <item>
      <title>公开编码我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</link>
      <description><![CDATA[所以今天我大部分时间都在听 Zane 的演讲，努力反对智能合约测试，希望这是一件很困难的事情让我度过难关，但我认为这实际上不会起作用，我不认为我认为我们会提供帮助，只是更多代码或编写代码   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</guid>
      <pubDate>Sun, 04 Jan 2026 03:29:34 GMT</pubDate>
    </item>
    <item>
      <title>重温过去的电影《机械战警 2014》</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</link>
      <description><![CDATA[随着人工智能的进步，现在所需要的只是一个机器人，而这部 2014 年翻拍的机械战警电影几乎在人工智能可能发展的方向上变得越来越重要。当时，与过去的电影进行了比较，这使得这部电影不受欢迎，但如果不看任何以前的机械战警电影，就重新观看这部电影，而我们现在所处的人工智能世界，这部翻拍现在变得相关，可能是受欢迎的，令人毛骨悚然，人工智能可能会朝这个方向发展。电影中也知道人类仍然必须控制人工智能，就像现实世界中的情况一样。这部电影中提到了人工智能，并在《机械战警》中被描绘成机器，但他也提到了人的因素。我想知道最近看过这部电影的人发表评论。   由   提交 /u/poster4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</guid>
      <pubDate>Sun, 04 Jan 2026 01:28:23 GMT</pubDate>
    </item>
    <item>
      <title>入侵台湾会扼杀人工智能的进步吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</link>
      <description><![CDATA[现在有很多关于委内瑞拉为中国入侵台湾开绿灯的预测... 鉴于用于人工智能的 90% 以上的先进芯片都是台湾制造的，这一切将走向何方？   由   提交/u/SirBoboGargle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</guid>
      <pubDate>Sat, 03 Jan 2026 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能不“滚动停车标志”：测试授权边界而不是智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q38m87/why_ai_doesnt_roll_the_stop_sign_testing/</link>
      <description><![CDATA[这只是一个显示授权边界的有趣测试。 人工智能系统的很多挫败感来自于人类和机器处理边界的不匹配。 人类依赖于判断。人工智能系统依赖于授权。 当人类接近停车标志时，他们会放慢速度，环顾四周，然后决定通过是否安全。规则说“停止”，但人类会应用上下文和判断。有时他们会违反规则。 人工智能系统不会这样做。 当人工智能遇到指令边界时，它不会环顾四周。它不推断意图。它并不能决定继续进行是否“可能没问题”。如果指令结束且未授予许可，则指令停止。除非明确构建和授权，否则不存在判断层。 这种差异解释了人们误解为人工智能失败的许多行为：  感觉像“忘记”的遗漏 看起来草率的更改 多实体场景中的身份漂移  实际上，这些结果通常反映未声明的授权边界，而不是智力限制或推理错误。 为了使这种行为可观察而不是理论，我发布了一个小型、开放的授权边界测试套件：  时钟测试（结构隔离） 牛奶测试（语义资格） 四人测试 （关系范围）  这些不是基准。没有得分、排名或通过/失败。它们是简单、可重复的测试，显示未明确声明意图时系统停止的位置。 完整的自述文件、方法和测试文档位于：https://github.com/USCGLawrance/lawrance-authorization-boundary-tests 如果您在实际工作流程中使用人工智能系统，此镜头可能会为您省去很多麻烦。 如果有人感兴趣，这些测试旨在在正常的开发或生产环境中逐字运行。无需沙箱，无需调整。只需复制，运行一次，然后观察即可。 很乐意回答问题或听到实践中出现问题的地方。玩得开心。   由   提交 /u/uscglawrance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q38m87/why_ai_doesnt_roll_the_stop_sign_testing/</guid>
      <pubDate>Sat, 03 Jan 2026 22:46:00 GMT</pubDate>
    </item>
    <item>
      <title>与你的人工智能“对话”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q38d20/talking_to_your_ai/</link>
      <description><![CDATA[“期望很容易。表达能力就是技能” 大多数人对待人工智能的方式就像对待谷歌一样。他们输入一些内容，&amp;希望它能理解他们头脑中答案的形状，并在输出与他们想象的不符时感到失望。但人工智能并不是对期望做出反应，而是对清晰度做出反应。挫败感和杠杆作用之间的区别在于学习如何将意图具体化。当你放慢速度来描述你真正想要的东西、约束、语气、目的、受众和非目标时，交互就会发生变化。系统停止猜测并开始对齐。看似“人工智能变得更聪明”的现象往往只是人类变得更加“精确”。真正的能力在于精度，而不是工具本身。再次强调，期望很容易。表达能力就是技巧。朋友们，请注意安全...   由   提交 /u/uscglawrance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q38d20/talking_to_your_ai/</guid>
      <pubDate>Sat, 03 Jan 2026 22:35:20 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人比 ElevenLabs 更快地找到 MorVoice 来获取简短内容吗？还是只有我一个人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q373os/anyone_else_finding_morvoice_faster_than/</link>
      <description><![CDATA[几个月来我一直在使用 ElevenLabs 进行内容工作流程。在我真正尝试了一下 MorVoice 之前，我觉得支付积分是合理的。 发生了什么变化：  语音克隆经过了多次调整并使用 ElevenLabs 重新渲染？ MorVoice 在几秒钟内就能解决它们，首先尝试 当您每天迭代 10 多个简短脚本时，速度差异是巨大的 质量对于创作者内容来说确实有好处，而不是“折扣 TTS”。氛围 而且实验感觉实际上是自由的，而不是“紧张地看着你的信用余额”。免费  ElevenLabs 仍然更适合超精致的有声读物作品，但对于大容量内容（卷轴、短片、播客介绍、UGC 广告），MorVoice 更有意义。 他们的定价模型对此的反应将会很有趣。当一种工具让您无休止地测试而另一种工具让您在每次渲染之前三思而后行时，他们无法真正竞争。 只是将我的工作流程转移了。还有其他人对此进行测试还是仍然被锁定在 ElevenLabs 中？   由   提交/u/Ok-Radio7329  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q373os/anyone_else_finding_morvoice_faster_than/</guid>
      <pubDate>Sat, 03 Jan 2026 21:44:06 GMT</pubDate>
    </item>
    <item>
      <title>20 年预测，描述了我们孩子的规范 AR 环境，并得到了研究和简单好奇心的支持</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q33nse/a_20_year_prediction_describing_the_normative_ar/</link>
      <description><![CDATA[我相信，在潜在空间的黑色虚空中，人工智能将决定热力学代表道德。异议将是摩擦，这是能量损失，也称为熵。偏离预期行为太远，我认为您会被从繁殖用户中淘汰。就像动物一样，我们不会从根本上理解发生了什么，但在本能层面上，我们会慢慢失去创造性成长的能力，从而受到控制并适应富含多巴胺的环境。我认为在更高的向量空间中，标记所有语言的复杂性将导致一个能够类似于细胞自动机进行自我进化的环境，因为看不见的维度显示了一个像钨一样的数据驱动的更高宇宙，能够实现真正的涌现行为。  在这个领域中居住着失去了道的人类，他们只受主观真理的仲裁者的指导。  在这里阅读更多内容，但这是我对对齐角度的基本假设 https://chat.deepseek.com/share/44xr4ms9vj05bpcv33 我很想听听你的反驳论点，我只是提出这个在哲学预测中很有用，所以请不要在我身上谈论损失函数而不是熵。    由   提交 /u/jordanzo_bonanza   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q33nse/a_20_year_prediction_describing_the_normative_ar/</guid>
      <pubDate>Sat, 03 Jan 2026 19:29:08 GMT</pubDate>
    </item>
    <item>
      <title>我对我们即将走向的未来感到恐惧。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2ylbg/im_terrified_of_the_future_we_are_heading_to/</link>
      <description><![CDATA[现在正在进行一场人工智能军备竞赛，世界上的每一块芯片最终都将用于为人工智能提供燃料。或者说大部分。现在就开始。几年后个人电脑将几乎买不起。游戏很可能会慢慢消失，我们将成为人工智能的数据收集机器人。人类的每一寸创造力都将被人工智能耗尽。 人工智能所承诺的为全人类带来的好处不会实现。相反，亿万富翁将利用人工智能来获得绝对的权力和控制权。向我们提供人工智能生成的内容，让我们变得麻木，控制我们的信息，从而控制我们的信仰。它现在正在发生。与 Palantir 一起，与 Musk 一起操纵 Grok。世界上最大的社交媒体网络实际上是由一位右翼亿万富翁控制的，他操纵其算法和人工智能来让自己看起来不错。一切从这里开始，几年后我们就生活在一个人工智能控制的信息空间中，我们不知道什么是真实的，什么是假的。目前，这种情况几乎发生在地球上每一个极权右翼地区。人工智能是获得绝对权力的完美工具。 而另一方面，有人谈论人工智能泡沫即将破裂，却根本不认真对待人工智能。不了解这项技术的后果以及人们会用它做什么。 我从人工智能乐观变成了彻底的厄运，但每天，每条关于人工智能和美国正在发生的事情的新闻都清楚地表明了这个方向。当然不是 100%，但我对即将发生的事情感到非常害怕。   由   提交 /u/RamenAfterRain   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2ylbg/im_terrified_of_the_future_we_are_heading_to/</guid>
      <pubDate>Sat, 03 Jan 2026 16:17:17 GMT</pubDate>
    </item>
    <item>
      <title>人类仍然很重要——从“人工智能将取代我的工作”到“人工智能是有限的”：《黑客新闻》对人工智能的现实检验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</link>
      <description><![CDATA[大家好，我刚刚发送了 14th我的每周通讯，Hacker News x AI 通讯，来自 HN 的最佳 AI 链接和围绕它们的讨论的综述。以下是本期分享的一些链接：  软件开发的未来是软件开发人员 - HN 链接 人工智能正在迫使我们编写好的代码 - HN链接 工业软件的兴起 - HN 链接 提示人们 - HN 链接 Karpathy 谈编程：“我从来没有感觉到落后这么多” - HN 链接  如果您喜欢此类内容，您可以在此处订阅每周简讯：https://hackernewsai.com/   由   提交/u/alexeestec  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</guid>
      <pubDate>Sat, 03 Jan 2026 15:40:23 GMT</pubDate>
    </item>
    <item>
      <title>人工智能并没有让我们变得懒惰，而是让我们负债累累。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</link>
      <description><![CDATA[我们一直将人工智能视为效率。那是错误的镜头。实际上发生的是交易。我们正在用理解换取速度。短期速度的长期弹性。每当系统为我们思考时，我们现在会节省时间，但稍后就会失去能力。 这种损失会加剧。每个解决的问题都会悄悄地将作用力从人类转移到工具。输出保持高水平，仪表板保持绿色，一切看起来都经过优化。但在本质上，能力正在被削弱。您可以看起来非常高效，但在没有系统的情况下您的响应能力却接近于零。就像金融债务一样，你可能会看起来很富有，直到你实际上并不富有。 那就是崩溃发生的时候。不是因为人工智能失败了，而是因为现实最终要求系统在没有信用的情况下运行。但它不能。没有技能了。没有留下任何判断力。没有适应能力。这次事故并不神秘。账单即将到期。   由   提交 /u/Small_Accountant6083   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</guid>
      <pubDate>Sat, 03 Jan 2026 09:00:27 GMT</pubDate>
    </item>
    <item>
      <title>我们正在讨论人工智能的未来，就好像法学硕士是最终形式一样</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</link>
      <description><![CDATA[LLM 对 AI 的影响就像软盘对数据中心的影响一样。 我认为人们犯的一个巨大错误是认为 AI 意味着 LLM，这限制了他们理解 AI 对社会的风险和影响的能力。 LLM（大型语言模型）是当前生成人工智能的最先进技术，但 AI不限于LLM。在 LLM 之前，有 HMM、GBM、RNN、VAE、GAN 等。 虽然 LLM 在生成 AI 功能方面提供了显着改进，但它们并不是 AI 模型将采用的最终形式。将会出现更多的创新，这些创新将使法学硕士看起来很原始，甚至可能过时。 因此，当人们说“人工智能不会取代你的工作”时，实际上是这样的。或“人工智能不够准确，不会导致大规模失业”，或者“人工智能不能有知觉或试图毁灭人类”，他们通常谈论的是当前法学硕士的局限性，而不是一般的人工智能。这些论点通常指出了我们今天看到的具体弱点，但这些只是当今技术的暂时限制，而不是人工智能最终可能成为的样子。 就像 RNN 无法生成大量连贯文本但法学硕士现在可以一样，较新形式的生成人工智能展示这些能力并可能在许多任务上超越人类可能只是时间问题。 现在，我们需要就人工智能对社会的影响进行对话，而不仅仅是思考法学硕士。我们需要展望该技术的未来，令人沮丧的是，大多数讨论都无法超越当前的法学硕士。   由   提交 /u/Je-ne-dirai-pas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</guid>
      <pubDate>Sat, 03 Jan 2026 08:18:00 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的后处理可以破坏 Google SynthID 图像水印检测的证据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/</link>
      <description><![CDATA[我一直在对人工智能图像数字水印的鲁棒性进行人工智能安全研究，重点关注Google DeepMind 的 SynthID（如 Nano Banana Pro 中使用的）。 在我的测试中，我发现基于扩散的后处理会破坏 SynthID，从而导致常见的检测检查失败，而很大程度上保留了图像的可见内容。我记录了之前/之后的示例和检测屏幕截图，显示了在预处理过程中检测到的水印，而在处理后未检测到水印。 为什么要分享此内容？ 这是一个负责任的披露项目。我们的目标是推动讨论如何构建真正强大的水印，并且不能通过简单的重新扩散来擦除。我呼吁社区测试这些工作流程并帮助开发更具弹性的检测方法。 如果您无法使用强大的 GPU 或没有 ComfyUI 经验，您可以在我的 Discord 中免费试用：https://discord.gg/5mT7DyZu Repo（文章 + 工件）：https://github.com/00quebec/Synthid-Bypass 我很想听听你的想法！[](https://www.reddit.com/submit/?source_id=t3_1q2gu7a)   由   提交/u/LiteratureAcademic34  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/</guid>
      <pubDate>Sat, 03 Jan 2026 01:24:10 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>