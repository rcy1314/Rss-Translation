<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 11 Jan 2025 18:25:38 GMT</lastBuildDate>
    <item>
      <title>本周人工智能代理、法学硕士评估、快速工程十大法学硕士论文</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hz18r3/top_10_llm_papers_of_the_week_on_ai_agents_llm/</link>
      <description><![CDATA[  由    /u/Sam_Tech1  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hz18r3/top_10_llm_papers_of_the_week_on_ai_agents_llm/</guid>
      <pubDate>Sat, 11 Jan 2025 17:42:06 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助才能理解蓝色大脑</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hz0m9i/help_needed_to_understand_blue_brain/</link>
      <description><![CDATA[大家好，我是新来的！ 我迫切需要有关蓝色大脑项目的紧急信息 尽管我搜索过，但我还是无法真正理解：它只是老鼠大脑的制图，还是老鼠大脑的简化模拟，随着时间的推移，它能够真正将其转变为一个可以工作的人工智能？（类似于我们在某些黑镜剧集中看到的，人们的思想被复制到程序上，尽管被夸大了）    提交人    /u/Easy_Turn1988   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hz0m9i/help_needed_to_understand_blue_brain/</guid>
      <pubDate>Sat, 11 Jan 2025 17:14:45 GMT</pubDate>
    </item>
    <item>
      <title>我两次向 ChatGPT 提出相同的问题，得到了不同的答案。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyzrkn/i_set_chatgpt_the_same_problem_twice_and_got/</link>
      <description><![CDATA[所有内容都已在我的博客文章中进行了解释。我向 ChatGPT 提出了将 SQL 模式转换为 JSON 模式的问题。它做得很好。一天后，我要求它生成一个 TypeScript 模式，它正确地完成了任务。然后，为了更容易复制到第二篇博客文章中，我还要求它执行 JSON 模式，这与我前一天对 SQL 模式的要求完全相同。它看起来一样，但这次它将其中一个字段选为必填项，而前一天它没有这样做。 我问 ChatGPT 为什么它给了我一个不同的答案（第二个是正确的），它的回复就在博客文章中。有点长而且杂乱，但没有告诉我很多。 我也要求 Gemini 按照相同的顺序做同样的工作。先是 TypeScript，然后是 JSON。它也没有选择必填字段，但除此之外做得更好。 博客文章中有更多详细信息。AI 救援 - 第 2 部分。| Bob Browning 的博客    提交人    /u/Difficult-Sea-5924   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyzrkn/i_set_chatgpt_the_same_problem_twice_and_got/</guid>
      <pubDate>Sat, 11 Jan 2025 16:37:32 GMT</pubDate>
    </item>
    <item>
      <title>有没有关于特定编程语言的 LLM 的研究？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyzjm4/is_there_any_research_on/</link>
      <description><![CDATA[如今，许多 LLM 都可以生成 Python，我认为这是有道理的，因为 Python 是 AI 研究人员事实上的标准语言，而且在很多情况下它似乎运行得相当好。 现在，当谈到其他编程语言时，我的轶事测试表明情况并不那么乐观。例如，ChatGPT 很乐意产生错误的 Rust、C 或 C++ 幻觉。 有人知道受过训练的 LLM 可以使特定编程语言支持更好地工作吗？    提交人    /u/ImYoric   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyzjm4/is_there_any_research_on/</guid>
      <pubDate>Sat, 11 Jan 2025 16:28:00 GMT</pubDate>
    </item>
    <item>
      <title>我是一名 SDE，我热爱我的工作和工程……但我有点害怕</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyzbfw/i_am_a_sde_i_love_my_job_and_engineering_in/</link>
      <description><![CDATA[我大约一年前毕业，获得了计算机科学与工程学士学位... 8 个月前在一家软件公司找到了一份工作... 现在还在那里... 全栈... 但是现在很多人都在做前端...  我喜欢软件工程... 制作很酷的软件，甚至一些电子产品一直让我感兴趣....  但是随着人工智能的发展曲线... 我有点害怕我的未来....  我害怕它正是因为我知道它... 自从早期的 Andrew Ng 二元分类器教程时代以来，我一直对人工智能持乐观态度.... 我一直在学习人工智能概念... 使用各种工具... 用人工智能构建软件有一段时间了.... 但我还没有“下一件大事”的时刻，因为我有的想法.. 似乎总是有人已经做过了。 ... 所以现在这只是我的工作流程和爱好的一部分....  所以我知道这场 AI 实力竞赛的潜力......大规模裁员即将到来......虽然并不是因为 AI 在 SWE 方面更好，至少目前......只是 AI 公司和其他公司的经理已经同意“AI 员工在这里，比普通员工更好、更便宜”潮流......当然，人工智能从现在开始只会变得更好..所以你不能真的责怪他们..  我有一个家庭要养活...并且成为中下阶层..在一个低收入国家..没有丝毫的帮助...我能够勉强度日，用我现在的薪水还能剩下一些钱...但我不知道我以后是否会有工作...不是因为我对自己的技能没有信心...只是人工智能可能会做得更好.. 我一直在尝试多样化，同时保持我的兴趣....YouTube...内容创作...平面设计..动画...自由职业...等等，但我不知道...它只是行不通，因为感觉人工智能的手已经放在我的喉咙上了。. 我觉得我的目标感正在慢慢消失.....不知道是不是因为我没有从其他角度看问题.... 你怎么看？你的情况如何？... 只需说出你的想法..让我们谈谈     提交人    /u/CarzyForTech   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyzbfw/i_am_a_sde_i_love_my_job_and_engineering_in/</guid>
      <pubDate>Sat, 11 Jan 2025 16:17:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Agentic RAG 和文档分析增强大型推理模型以解决复杂问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyxjv0/enhancing_large_reasoning_models_with_agentic_rag/</link>
      <description><![CDATA[这里的关键进步是将 LLM 与迭代网络搜索相结合，以便根据推理需求自主细化搜索查询。系统不使用固定的检索模式，而是在复杂的推理任务中动态地决定何时搜索什么。 主要技术要点： - 双编码器架构将推理和搜索组件分开 - 使用迭代搜索细化，其中每个查询都基于以前的结果 - 实现自我反思机制来评估搜索结果质量 - 搜索行为无需经过明确的搜索策略训练即可出现 评估结果： - 在推理基准上比标准 RAG 模型提高了 8-15% - 幻觉/事实错误减少 45% - 不同模型大小的性能提升一致 - 搜索模式与人类的信息搜索行为相似 我认为这种方法对于构建更可靠的 AI 助手特别有影响。通过将 LLM 与动态网络搜索的优势相结合，我们得到了可以自我核实事实并收集支持证据的系统，而不是仅仅依靠训练有素的知识。自我反思组件似乎特别有希望提高准确性。 话虽如此，在广泛部署之前，仍有一些关于计算成本和搜索偏差的悬而未决的问题需要解决。我特别感兴趣的是看看如何将其扩展到包含网络搜索之外的结构化知识源。 TLDR：新系统将 LLM 与自主网络搜索功能相结合，通过迭代搜索细化和自我反思机制显着改善推理任务。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyxjv0/enhancing_large_reasoning_models_with_agentic_rag/</guid>
      <pubDate>Sat, 11 Jan 2025 14:55:11 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LLM 生成的文本通过 AI 检查？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyubx2/how_do_you_pass_ai_checkers_with_llm_generated/</link>
      <description><![CDATA[我正在编写一些代码，以便使用 ChatGPT 生成的文本通过 AI 检查器。查看了一些帖子，但它们都充斥着托儿，人们说“自己写”或关于 AI 检查器不准确的评论（无关紧要，因为它们无论如何都会被使用）。我只是想自己做个好玩的项目。 有谁可以提供有关 Undetectable 或 StealthGPT 等工具如何工作的见解？我知道它们并不完美，但它们似乎工作得很好！ 我的一些想法： - 使用同形异义词 - 引入轻微的拼写错误/语法错误 - 混合短句和长句 - 将不同的输出拼接在一起 那么，这些服务使用了哪些技术措施来使他们的文本无法检测到？    提交人    /u/h3llwaiver   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyubx2/how_do_you_pass_ai_checkers_with_llm_generated/</guid>
      <pubDate>Sat, 11 Jan 2025 11:53:20 GMT</pubDate>
    </item>
    <item>
      <title>LocalGLaDOS-在真正的 LLM 设备上运行</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyu7kw/localglados_running_on_a_real_llmrig/</link>
      <description><![CDATA[https://youtu.be/N-GHKTocDF0 上次我使用小型 8Gb RK3588 Raspberry Pi 5 Alternative 主板。延迟很大，还有 1B Llama3.2 型号。 此演示正好相反：双 RTX 4090 运行 Llama3.3 70B。这是超低延迟，感觉就像在与另一个人聊天。延迟低于 500ms 是一个神奇的数字。 亲自尝试！它应该可以在任何系统上运行，从 Pi 到 H100，具体取决于您选择的 LLM 模型！ https://github.com/dnhkng/GlaDOS 这也可以与任何聊天模型、Qwen 等等一起使用，只需：  ollama pull &lt;model\_name&gt; 编辑 glados_config.yml，并编辑模型：模型：“&lt;model\_name&gt;&quot;  这样，您可以选择适合您的 VRAM 的模型。我已经付出了很多努力来使语音功能高效运行，因此其余部分只有几百 Mb！ 在 GitHub 上支付 star！ 向 lawrenceakka 致敬，感谢他为 TUI 创建了 PR！    提交人    /u/Reddactor   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyu7kw/localglados_running_on_a_real_llmrig/</guid>
      <pubDate>Sat, 11 Jan 2025 11:44:54 GMT</pubDate>
    </item>
    <item>
      <title>逻辑思维框架的递归分解，用于高级推理和知识传播</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyrx6c/recursive_decomposition_of_logical_thoughts/</link>
      <description><![CDATA[我每天都会查找和总结有趣的 AI 研究论文，这样您就不必费力地浏览所有论文。今天的论文题为“逻辑思维的递归分解：大型语言模型中高级推理和知识传播的框架”，作者是 Kaleem Ullah Qasim、Jiashu Zhang、Tariq Alsahfi 和 Ateeq Ur Rehman Butt。 本文介绍了 RDoLT（逻辑思维的递归分解）提示框架，旨在增强大型语言模型 (LLM) 的推理能力。该方法依赖于三项创新：递归任务分解、复杂的思维选择机制和新颖的知识传播模块 (KPM)。在多个基准测试中，RDoLT 表现出优于现有最先进技术的卓越性能，证明了其在改进 AI 模型中的推理和知识传播方面的潜力。以下是他们研究的一些要点：  递归任务分解：RDoLT 将复杂的推理任务分为三个渐进级别：简单、中等和最终，与现有模型（如从最少到最多）相比，能够更有条理、更全面地探索任务复杂性。 思想评估与评分系统：RDoLT 在其思想评估过程中整合了逻辑有效性、连贯性、简单性和适应性，通过选择不仅正确而且适合上下文且灵活的想法，其表现优于传统方法。 知识传播模块 (KPM)：通过跟踪被选中和被拒绝的想法，KPM 有助于在后期重新审视被丢弃的想法，对抗先前模型中普遍存在的过早拒绝，并确保更动态的推理适应。 实证成功：RDoLT 已被证明比现有的 Chain-of-Thought 和 Least2Most 等技术具有显着提高性能，在使用 ChatGPT-4 的 GSM8K 上拥有 90.98% 的准确率，超过以前的最高分约 6%。 基准测试卓越表现：在各种推理基准测试中都表现出色，例如GSM8K、MultiArith 和高考 2023 数学。在所有测试场景中，RDoLT 始终胜过竞争性提示方法。  总之，RDoLT 代表了增强 LLM 推理能力的重要一步，允许更细致、更可靠、更灵活的问题解决方法。然而，该研究表明进一步探索特定领域的应用，并寻求最大限度地减少计算需求以实现更广泛的适用性。 您可以在此处查看完整的细分：这里 您可以在此处查看完整的原始研究论文：原始论文   由    /u/steves1189  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyrx6c/recursive_decomposition_of_logical_thoughts/</guid>
      <pubDate>Sat, 11 Jan 2025 08:54:13 GMT</pubDate>
    </item>
    <item>
      <title>Manimator：根据提示生成技术性 YouTube 视频</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyqgdw/manimator_technical_youtube_videos_generation/</link>
      <description><![CDATA[Manimator 基于 Manim（3blue1bro wn 使用）制作 YouTube 视频，使用附加的 AI 层在仅给出提示的情况下生成技术解释视频。该工具可在 HuggingFace 空间免费使用，演示可在此处查看：https://youtu.be/VV5SpLiUPO4?si=hMrMUcZXesRiCaxG    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyqgdw/manimator_technical_youtube_videos_generation/</guid>
      <pubDate>Sat, 11 Jan 2025 07:03:54 GMT</pubDate>
    </item>
    <item>
      <title>微软找到一种方法，让人工智能在数学推理方面实现强大的自我提升</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hync4l/microsoft_finds_a_way_to_have_ais_powerfully/</link>
      <description><![CDATA[如果他们可以在数学上做到这一点，为什么不能在一般推理上做到这一点？ https://youtu.be/Bhoy_arJvaE?si=OLomRfCVUguhx3rx    提交人    /u/Georgeo57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hync4l/microsoft_finds_a_way_to_have_ais_powerfully/</guid>
      <pubDate>Sat, 11 Jan 2025 03:50:10 GMT</pubDate>
    </item>
    <item>
      <title>我正在考虑成为一名水管工，考虑到 AI 的项目替代，这值得吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyiaav/im_thinking_about_becoming_a_plumber_worth_it/</link>
      <description><![CDATA[我觉得从现在起 1 年后 ChatGPT 将进入管道领域。我不想开始研究马桶，然后发现 AI 可以做得更好。有什么想法可以分析这个吗？    提交人    /u/Jebick   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyiaav/im_thinking_about_becoming_a_plumber_worth_it/</guid>
      <pubDate>Fri, 10 Jan 2025 23:32:46 GMT</pubDate>
    </item>
    <item>
      <title>我使用 Anthropic 的 Claude Computer-Use 让 OpenAI 的 o1-preview 使用计算机</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hyalld/i_made_openais_o1preview_use_a_computer_using/</link>
      <description><![CDATA[我建立了一个名为MarinaBox的开源项目，这是一个旨在简化为 AI 代理创建浏览器/计算机环境的工具包。为了扩展其功能，我最初开发了一个 Python SDK，可与 Anthropic 的 Claude Computer-Use 无缝集成。 本周，我探索了一个令人兴奋的想法：使 OpenAI 的 o1-preview 模型能够使用由 Langgraph 和 Marinabox 提供支持的 Claude Computer-Use 与计算机进行交互。 这是我写的文章， https://medium.com/@bayllama/make-openais-o1-preview-use-a-computer-using-anthropic-s-claude-computer-use-on-marinabox-caefeda20a31 此外，如果您喜欢阅读文章，请务必为我们的 repo 加注星标， https://github.com/marinabox/marinabox    提交人    /u/Severe_Expression754   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hyalld/i_made_openais_o1preview_use_a_computer_using/</guid>
      <pubDate>Fri, 10 Jan 2025 18:04:04 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>