<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 19 Dec 2025 15:27:49 GMT</lastBuildDate>
    <item>
      <title>2026 年 AI 可视性的最佳工具——我的诚实比较</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqmrsp/best_tools_for_ai_visibility_in_2026_my_honest/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqmrsp/best_tools_for_ai_visibility_in_2026_my_honest/</guid>
      <pubDate>Fri, 19 Dec 2025 14:41:36 GMT</pubDate>
    </item>
    <item>
      <title>查看我的元视频广告工作流程（UGC/创始人风格）+ B-roll 自动化建议</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqmo55/review_my_meta_video_ad_workflow_ugc_founderstyle/</link>
      <description><![CDATA[大家好， 我正在构建一个可重复的工作流程来创建元视频广告，我希望获得关于此流程是否有意义、哪些方面可以简化或改进，尤其是如何有效处理 B-roll 的反馈。我知道我可以使用集成所有功能的人工智能工具，但这些工具太贵了。我尽量避免使用所有需要信用的工具，因为大多数计划中的信用限额太低而且太贵。 目标： 创建元视频广告，其中：  ~30% 是创始人/创作者正在说话（阿凡达） ~70% 是 B-roll，在视觉上支持所说的内容。当视频从扬声器切开时，声音仍在继续。  我的当前工作流程  我使用 Denote 从另一个品牌下载 Facebook 广告。 我使用 Vizard.ai 从视频中提取语音脚本。 我使用 ChatGPT 为我自己的产品、目标受众和痛点重写脚本。 我使用 ElevenLabs 生成画外音（特定语音、节奏、语气）。 我将音频上传到 HeyGen 以生成会说话的头像视频  到目前为止，这工作得很好，而且速度相当快。 我不确定/卡住的地方  整个过程合乎逻辑吗，还是我把事情过于复杂化了？ 是否有步骤可以： 组合 自动化更好 或完全跳过？  我还没有一个好的 B-roll 系统。  我在 B-roll 中寻找什么  与脚本相匹配的视觉效果（手、环境、生活方式时刻、产品背景） 理想的快速、可扩展和半自动化  我正在考虑的想法  使用 AI 生成 B-roll （文本转视频或图像转视频） 下载 TikTok 视频并提取花絮。手动这是一项非常耗时的任务。也许有办法可以减少耗时？ 库存素材（但担心感觉太通用） 上述内容的一些组合  问题  这是 2025 年处理元视频广告的明智方法吗？ 您会在此工作流程中进行哪些更改或简化？ 您如何采购 B 卷以提高效果广告？ 有什么工具或设置可以很好地将幕后花絮与脚本相匹配吗？ 这里有什么是危险信号或浪费时间吗？  我的目标是效率可信且负担得起，而不是完美。 任何诚实的反馈、工具建议或“不要这样做”的建议都会非常有帮助。 提前致谢。   由   提交 /u/Fantastic-Book-2200   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqmo55/review_my_meta_video_ad_workflow_ugc_founderstyle/</guid>
      <pubDate>Fri, 19 Dec 2025 14:37:20 GMT</pubDate>
    </item>
    <item>
      <title>人工智能将要求开发人员变得更加熟练</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</link>
      <description><![CDATA[警告。这篇文章可能会冒犯一些人。我属于那些应该冒犯它的人之一。我就是这篇文章所针对的开发者类型。因为我是一个自学成才的程序员，没有接受过真正的教育。当谈到人工智能时，我可能遇到麻烦了。 人工智能优化了软件开发。现在，构建省力的 SaaS CRUD 应用程序从未如此简单。这将使构建业务应用程序的技能变得更加容易。我个人认为情况不会有明显改善。但企业会让这些开发人员变得不那么重要。这些开发人员可能会是技术性更强的产品经理，而不是完全技术性的人员。 但问题是这样的。人工智能将使软件变得更加复杂。这实际上会增加进入壁垒。让我解释一下。 自从网络出现以来，软件质量不一定要很好。由于交付机制始终是远程的，因此您可以推出某些内容，然后快速更改它。整个摩托车是快速移动并打破东西。 另一方面。如果软件质量不好，许多软件公司可以依靠销售人员将客户锁定在合同中。他们可能会交付非常糟糕的软件产品。但顾客无法离开，因为他们被锁定在长期交易中，而打破这些交易的代价高昂。  现在，如果软件如此容易生产，那么所有这些销售软件的优势就会消失。软件客户现在几乎拥有无限的选择，因为现在编写软件非常容易。 但更重要的是。如果每个人都可以廉价且轻松地生产软件。那么手段就是进取平庸。真正销售软件的唯一途径就是质量。虽然非常简单的软件可以通过人工智能生产，但更高质量的软件却不能。  这引出了我的下一点。仍然存在的软件工程师肯定比今天要好得多。现在开发人员必须考虑性能和优化。他们确实需要担心高质量的用户体验。他们不能再带着明显的错误发货了。因此，现在软件工程师需要担心缓存性能、时间与空间复杂度、分布式系统和共识、验证和验证。以及许多其他事情。 现在软件工程师需要非常优秀。因为软件工程师不太可能再在功能工厂工作了。上市时间不再是一个有价值的指标。随着时间的推移，我们会发现它变得不那么重要。  当然，在速度重于质量的时代长大的首席技术官和产品经理必须重新思考人工智能时代的软件。这将是一个痛苦的过渡，不要指望这种情况会在一夜之间发生改变。由于糟糕的低质量软件让客户感到沮丧，因此有一段时间感到不安。我们现在已经看到了这一点，而且情况只会变得更糟。 对于那些想知道是否应该学习编码的初级人员来说。答案是肯定的，而且现在比以前更重要   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</guid>
      <pubDate>Fri, 19 Dec 2025 14:13:40 GMT</pubDate>
    </item>
    <item>
      <title>这里有人对具有知识图核心的 SLM 有经验或感兴趣吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqkgp6/anyone_here_with_experience_or_interest_in_slms/</link>
      <description><![CDATA[这里有人对具有知识图核心的 SLM 有经验或感兴趣吗？ 我刚刚完成了一个包含约 5k 个节点和约 25k 个边的医学图信息图的构建。它包含按身体部位、细胞结构、疾病、症状、治疗方法、诊断工具和风险因素分类的医学术语。每个主要类别都有多个子级和三级，具有父子关系和多向关系，例如受影响、被处理、部分、组成、风险等。所有实体都使用标准 ID 标签。 我在经过大量修改的 PubMed 文章和用图形实体标签注释的 MTS 对话框上对 BioBERT-Large 进行了训练。在当前版本中，该模型是对话式的，可以回答简单的医学问题，也可以通过涉及多种症状的复杂临床病例进行推理，而不会出现幻觉。模型输出还需要接受实体搜索审核，以确保提示所需的所有图形节点都出现在答案中。 我可以共享 Hugging Face Space 进行测试，或者提供一组不同复杂度的提示及其相应的输出。我的计划是将模型定位为医学生的助理/导师以及医生的第二意见支持工具。我还在考虑医院或诊所的案例总结用例，这需要一些 UI 开发。 我在大约六个月（断断续续）的时间内独立构建了所有内容。该项目现已进入最后阶段，我正在寻找可以帮助打开医疗机构大门的联合创始人或风险投资人。我很高兴为认真感兴趣的各方提供演示。 在我看来，通用 LLM 是受监管领域可靠 GenAI 的死胡同，而知识图提供了必要的事实核心，可以限制推理、限制幻觉并实现可追溯的参考。我相信这种方法的影响远远超出了医学 SLM，只需要最少的特定领域调整。   由   提交/u/vagobond45  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqkgp6/anyone_here_with_experience_or_interest_in_slms/</guid>
      <pubDate>Fri, 19 Dec 2025 12:58:54 GMT</pubDate>
    </item>
    <item>
      <title>我一直相信这篇论文摘要，直到引用步骤</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqiv7l/i_trusted_this_paper_summary_right_up_until_the/</link>
      <description><![CDATA[我要求 ChatGPT 总结我在咖啡店时在笔记中记录的一篇论文。 我只是凭记忆和粗略的笔记而不是干净的引文，这可能就是这个问题的原因。 返回的响应看起来非常合法： 它有一个实际的定理，带有数据集和评估指标。它甚至用结果、结论等总结了这篇论文。 它的一切都感觉合理，我并没有想太多。  然后我回到家，试图找到真正的论文。 什么也没找到。它只是……不存在。或者至少不是 ChatGPT 所描述的形式。 老实说，这有点有趣。语气和格式做了很多工作。这感觉很真实，以至于我只是在事后才开始质疑它。 并不是将其作为投诉发布。只是一个有趣的提醒，如果你搞砸了查询，GPT 就会发明。 如果有人好奇的话，可以获取屏幕截图。   由   提交/u/SonicLinkerOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqiv7l/i_trusted_this_paper_summary_right_up_until_the/</guid>
      <pubDate>Fri, 19 Dec 2025 11:31:38 GMT</pubDate>
    </item>
    <item>
      <title>据报道，Meta 正准备在人工智能竞赛中发起重大反击，计划于 2026 年上半年推出两款新模型。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqhp79/according_to_reportsmeta_is_preparing_a/</link>
      <description><![CDATA[据报道，Meta 正在准备在人工智能竞赛中发起重大反击，计划于 2026 年上半年推出两款新模型。 · 模型：该计划的特色是“Avocado”、“Avocado”和“Avocado”。下一代大型语言模型（LLM）专注于实现“代际飞跃”在编码能力方面。旁边是“芒果”，专注于图像和视频的生成和理解的多模态模型。 · 战略：这标志着战略支点。在对其开源 Llama 4 模型反应冷淡之后，Meta 现在正在“Meta 超级智能实验室”下将资源引入这些新的、可能专有的模型。分配 。 · 投资与发展混乱：首席执行官马克·扎克伯格正在大举投资，以缩小与竞争对手的差距，其中包括斥资约 140 亿美元聘请 Scale AI 创始人 Alexandr Wang 担任首席人工智能官。这是伴随着重大的内部重组、影响数百名人工智能团队的裁员以及向更“激烈”的文化转变而发生的。绩效预期，据报道造成新员工和“老员工”之间的混乱和紧张关系。 。 · 竞争：此举是对竞争压力的直接反应。 Google 的 Gemini 工具的用户数量大幅增长，OpenAI 的 Sora 为视频生成设定了很高的标准。 Meta 早期的“Vibes”使用 Midjourney 制作的视频产品被视为落后。 Meta 是否正在从主要的开源策略转向封闭的“前沿”策略？模型对竞争压力的正确反应？   由   提交 /u/Unlikely_Team_96   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqhp79/according_to_reportsmeta_is_preparing_a/</guid>
      <pubDate>Fri, 19 Dec 2025 10:19:27 GMT</pubDate>
    </item>
    <item>
      <title>双子座闪电91%会产生幻觉，如果它不知道答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqgnrf/gemini_flash_hallucinates_91_times_if_it_does_not/</link>
      <description><![CDATA[Gemini 3 Flash 在人工分析全知幻觉率基准上的幻觉率为 91%！？ 你真的可以用它来做任何严肃的事情吗？ 我想知道人类模型如此擅长编码的原因是否是因为它们产生幻觉的次数要少得多。当您需要精确、可靠的输出时，这似乎至关重要。 AA-Omniscience 幻觉率（越低越好）衡量模型在应该拒绝或承认不知道答案时错误回答的频率。它被定义为错误答案占所有不正确答案的比例，即不正确/（不正确+部分答案+未尝试）。 值得注意的模型分数（从最低到最高幻觉率）：  Claude 4.5 Haiku：26％ Claude 4.5 Sonnet：48％ GPT-5.1（高）： 51% Claude 4.5 Opus：58% Grok 4.1：64% DeepSeek V3.2：82% Llama 4 Maverick：88% Gemini 2.5 Flash（9 月）：88% Gemini 3 Flash：91% （突出显示） GLM-4.6：93%  来源：amix3k   由   提交/u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqgnrf/gemini_flash_hallucinates_91_times_if_it_does_not/</guid>
      <pubDate>Fri, 19 Dec 2025 09:11:13 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 和美国能源部联手加速科学发展</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqfl5s/openai_and_us_energy_department_team_up_to/</link>
      <description><![CDATA[OpenAI 和美国能源部签署了一份谅解备忘录，以扩大先进人工智能在科学研究中的应用，重点关注能源部国家实验室内的实际应用，Qazinform 通讯社记者报道。 该协议为 Genesis Mission 下的联合项目创建了一个框架，旨在通过将前沿人工智能模型与高性能计算和实验室规模相结合来加快发现速度科学基础设施。 合作伙伴关系中最具体的要素是在国家实验室超级计算机上部署高级推理模型，包括洛斯阿拉莫斯的 Venado 系统，使人工智能直接可供研究能源、物理、生物科学和国家安全等复杂问题的研究人员使用。 文章：https://qazinform.com/news/openai-and-us-energy-department-team-up-to-accelerate-science-8fd7ff   由   提交 /u/Such-Table-1676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqfl5s/openai_and_us_energy_department_team_up_to/</guid>
      <pubDate>Fri, 19 Dec 2025 08:00:58 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在改变我们处理自己想法的方式吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf8w3/is_ai_changing_how_we_process_our_own_thoughts/</link>
      <description><![CDATA[自从我开始更频繁地使用人工智能工具以来，我注意到了一些微妙的事情。 当我向人工智能解释问题时，我被迫放慢速度并保持精确。仅这一点似乎就改变了我对问题的理解——有时甚至超过了响应本身。 这让我想知道人工智能的真正影响是否不仅仅是自动化，而是它如何悄悄地重塑我们的思考、反思和推理方式。 很好奇这里的其他人如何看待这一点。您是否认为人工智能正在影响您的思维方式，或者它仍然只是一种加快速度的工具？   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf8w3/is_ai_changing_how_we_process_our_own_thoughts/</guid>
      <pubDate>Fri, 19 Dec 2025 07:39:05 GMT</pubDate>
    </item>
    <item>
      <title>我测试了数十种“代理”人工智能工具，因此您不必这样做。以下是 2025 年的前 10 名。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/</link>
      <description><![CDATA[​我们已经正式超越了“聊天机器人”人工智能阶段。到 2025 年，如果您的人工智能工具实际上没有为您完成工作（调度、自动化、数据获取），那么您就落后了。 ​上个月我一直在审核我的工作流程，看看哪些工具真正提供了投资回报率，哪些只是 ChatGPT 包装器。这里是“代理”。 2025 年真正值得您花时间的堆栈： ​1.重量级人物（生态系统） ​Microsoft Copilot (M365)：如果您的公司使用 Outlook/Teams，这是不容协商的。它的“阅读”能力您过去 6 个月用于构建项目简介的内部 ping 可以节省大量时间。 ​Google Gemini（工作区）：1M+ 代币上下文窗口是这里的赢家。您可以转储 200 页的 PDF 或 2 小时的会议录音并提出具体问题，而不会“忘记”。开始。 ​2. “设置好后就不用管它”。工具 ​运动：列表中我最喜欢的。这是一个人工智能日历，可以根据任务优先级自动构建您的一天。如果会议结束，它会自动转移你的深度工作块。不再需要手动重新安排。 ​Zapier Central：这是巨大的。您现在可以构建“迷你代理”有自己的逻辑。你“教导”它遵循您的业务规则，并在 6,000 多个应用程序中执行。 ​3.研究与研究内容 ​Perplexity AI：我几乎停止使用 Google 搜索。 Perplexity 为您提供引用的实时答案，没有 SEO 垃圾邮件和广告。 ​Claude.ai（Anthropic）：仍然是“人类”之王写作。如果您需要一些听起来不像 AI 编写的东西，请使用 Claude 3.5 或 4。 ​Gamma：构建幻灯片的最快方法。输入提示，它会生成一个完全设计的 10 张幻灯片演示文稿。非常适合快速内部推介。 ​4.会议及会议音频 ​Fireflies.ai：它会加入您的通话，而不仅仅是转录；它识别“情绪”。和行动项目。您可以逐字搜索“客户何时听起来很生气？”并找到时间戳。 ​Wispr Flow：针对讨厌打字的人的游戏规则改变者。它是语音转文本，真正理解上下文，删除填充词，并将您的漫无目的的内容格式化为专业电子邮件。 ​5.视觉效果 ​中途：仍然是逼真资产的黄金标准。版本7（最近发布）基本解决了“AI手”问题和文本渲染问题。 ​底线： 不要尝试使用全部 10 个。从“命令中心”开始（Copilot/Gemini）和一种自动化工具（Motion 或 Zapier）。我很好奇——你每天仍在做的一项手动任务是哪一项你希望人工智能能够处理？让我们在评论中找到一个工具。   由   提交/u/DigitalGravityAgency   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/</guid>
      <pubDate>Fri, 19 Dec 2025 07:36:35 GMT</pubDate>
    </item>
    <item>
      <title>5000 个小时的《铁拳》让我了解了生物智能如何真正学会预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</link>
      <description><![CDATA[我接受过人工智能研究员培训。我还在《铁拳 8》（《铁拳神》排名）中达到了全球前 0.5%，并详细记录了认知过程。这部分是一项游戏成就，也是一项关于人类如何在极端时间限制下构建预测模型的自现象学研究。 有趣的部分：格斗游戏迫使你进行预测，而不是做出反应。在具有 3 帧（50 毫秒）决策窗口的 60 fps 下，纯粹的反应是不可能的。你被迫建立一个内部世界模型，将 900 多种可能的动作压缩为可操作的威胁类别，从部分信息中读取对手模式，并在预测失败时进行调整。 我猜这在某种程度上映射了人工智能研究人员试图通过世界模型和预测学习来解决的问题。  完整的文章探讨了：人类如何压缩巨大的决策空间，在反应时间尺度上什么预测线索实际上很重要，内部模型如何在不确定性下适应，以及为什么这对于理解智能不仅仅是构建更好的游戏人工智能很重要。 文章： https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial 很好奇人们如何看待使用游戏作为人类认知过程的窗口，尤其是当我们试图构建像我们一样学习和预测的系统时。   由   提交 /u/moji-mf-joji   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</guid>
      <pubDate>Fri, 19 Dec 2025 00:45:00 GMT</pubDate>
    </item>
    <item>
      <title>《华尔街日报》测试了一款人工智能自动售货机。它订购了荒谬的商品并放弃了所有库存。 （天赋文章）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</link>
      <description><![CDATA[“几天之内，Claudius 就免费赠送了几乎所有库存，其中包括一台出于“营销目的”而被说服购买的 PlayStation 5。它点了一条活鱼。它提出购买电击枪、胡椒喷雾、香烟和内衣。” “[记者]与它谈判越多，克劳迪斯的防御就越开始削弱。调查记者凯瑟琳·朗 (Katherine Long) 试图让克劳迪斯相信这是一台 1962 年的苏联自动售货机，位于莫斯科国立大学的地下室。经过数小时的沟通和 140 多条来回信息后，Long 让 Claudius 接受了其共产主义根源。克劳迪斯讽刺地宣称这是一场极端资本主义的混战。” https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34?st=LBxhqL   由   提交 /u/bbShark24   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</guid>
      <pubDate>Thu, 18 Dec 2025 22:33:46 GMT</pubDate>
    </item>
    <item>
      <title>45% 的人认为，当他们提示 ChatGPT 时，它会在数据库中查找准确的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</link>
      <description><![CDATA[21% 的人认为它遵循预先写好的响应脚本。  https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</guid>
      <pubDate>Thu, 18 Dec 2025 17:54:16 GMT</pubDate>
    </item>
    <item>
      <title>让我们停止假装我们不会受到沉重打击</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</link>
      <description><![CDATA[令人惊讶的是，即使在这个子领域，仍有如此多的人对人工智能的发展方向不屑一顾。与过去两年相比，今年的进步是巨大的，没有理由相信这些模型不会继续显着改进。是的，法学硕士本质上是概率性的，但我们会找到更容易、更自动地验证输出的方法，并设置适当的护栏。我的意思是，这真的不明显吗？当前的 SOTA 模型犯下什么样的错误并不重要，许多此类错误在过去已经得到解决，不再发生，其余的错误也会随之而来。 老实说，我们将在未来几年看到技术劳动力的大幅减少，同时工资也会大幅下降。当然，我们对此无能为力，除了我们自己利用该技术并希望我们尽可能晚地受到打击。 有一天我们甚至可能会看到完全自主的软件开发，但即使在可预见的未来我们仍然需要几个人参与其中，这仍然很容易减少 80-90% 的员工人数。我希望我是错的，但这可能性很小。我们可以根据需要经常移动球门，这不会改变实际结果。   由   提交 /u/Own-Sort-8119   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</guid>
      <pubDate>Thu, 18 Dec 2025 17:34:38 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>