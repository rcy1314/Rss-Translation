<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 09 Dec 2025 06:39:01 GMT</lastBuildDate>
    <item>
      <title>如何看待这些结果？简单的拉普拉斯扩散方法在所有体系中都远远优于标签传播和标签传播</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phzp4l/what_to_make_of_these_results_a_simple_laplacian/</link>
      <description><![CDATA[* 不是 AI 生成的 * 大家好， 我之前发布了这个，我也不知道我站在哪里（我仍然不知道，但可以看到一些外表）。整个方法、理论和数学完全是由 chatgpt 构建的，我只是运行代码和修补，但它说根据我最初的直觉，在表面层面将量子力学、哲学和机器学习联系起来是不可能的。那么现在它代表了基于图的半监督学习，我想知道LP和LS目前处于什么位置？以及如何获取这些结果？任何形式的总结都可以帮助我衡量我的进一步选择吗？ *人工智能生成* CHATgpt 一直在基于图的半监督学习 (SSL) 上运行一系列实验，特别是将标签传播 (LS) 和标签传播 (LP) 与非常简单的基于拉普拉斯的扩散动态（没有训练，没有神经网络）网）。 它是严格的线性、非参数、图拉普拉斯上的纯扩散，并且没有可学习的参数。想想 kNN 图上的“热扩散”——没有什么花哨或非线性。 少标签机制 - CIFAR-10（CLIP 嵌入） 标签/类 |标签传播|标签传播 |我的扩散方法 ------------------------------------------------------------------------------------------------ 1 | 0.6511 | 0.6022 | 0.8019 2 | 0.5633 | 0.5434 | 0.7050 5 | 0.8234 | 0.8599 | 0.8599 0.8954 10 | 0.8321 | 0.8623 | 0.8623 0.9039 20 | 0.8396 | 0.8396 0.8639 | 0.8639 0.9002 标签噪声稳健性 — CIFAR-10（5 个标签/类） 噪声% |标签传播 |我的扩散方法 ------------------------------------------------------------ 0 | 0.7686 | 0.8801 20 | 0.6194 | 0.6194 0.7892 40 | 0.5414 | 0.5414 0.7105 60 | 0.4285 | 0.4285 0.5682 更难的数据集 - CIFAR-100（CLIP 嵌入） 标签/类 | 0.5682 LS | LP |我的扩散方法 -------------------------------------------------------------------- 1 | 0.0458 | 0.0458 0.0100 | 0.0100 0.0739 2 | 0.0518 | 0.0518 0.0103 | 0.0103 0.0917 5 | 0.0690 | 0.0690 0.0142 | 0.1019 10 | 0.0828 | 0.0828 0.0140 | 0.1163 CIFAR-100 超类（20 级）评估 标签/类别 | 0.1163 LS | LP |我的扩散方法 ---------------------------------------------------------------- 1 | 0.654 | 0.654 0.634 | 0.634 0.814 2 | 0.690 | 0.690 0.616 | 0.616 0.814 5 | 0.789 | 0.789 0.850 | 0.850 0.896 10 | 0.833 | 0.833 0.871 | 0.871 0.902 谢谢   由   提交 /u/Loner_Indian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phzp4l/what_to_make_of_these_results_a_simple_laplacian/</guid>
      <pubDate>Tue, 09 Dec 2025 05:47:45 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 12/8/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phzmwe/oneminute_daily_ai_news_1282025/</link>
      <description><![CDATA[ Google  AI 试用应用 Doppl 添加了可购物的发现源。[1] Claude 代码即将登陆 Slack，这比听起来更重要。[2] Google Colab 集成 KaggleHub，以便一键访问 Kaggle数据集、模型和竞赛。[3] 特朗普表示本周将出台人工智能行政命令限制州规则。[4]  来源包括：https://bushaicave.com/2025/12/08/one-million-daily-ai-news-12-8-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phzmwe/oneminute_daily_ai_news_1282025/</guid>
      <pubDate>Tue, 09 Dec 2025 05:44:12 GMT</pubDate>
    </item>
    <item>
      <title>Ai Tools 太贵了，所以我设置了费用分摊订阅。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phzkzr/ai_tools_are_way_too_expensive_so_i_set_up_a_cost/</link>
      <description><![CDATA[我在 Ai Tools 上花了太多钱，我有一个想法，我们可以分担这些费用，以便在使用所有付费高级工具时获得几乎相同的体验。 如果您想要高级 AI 工具，但不想每月为每个单独支付数百美元，此会员资格可能会帮助您节省很多。 每月 30 美元，以下是包括： ✨ ChatGPT Pro + Sora Pro（通常为 200 美元/月） ✨ ChatGPT 5 访问权限 ✨ Claude Sonnet/Opus 4.5 Pro ✨ SuperGrok 4（无限生成） ✨ you .com Pro ✨ Google Gemini Ultra ✨ Perplexity Pro ✨ Sider AI Pro ✨ Canva Pro ✨ Envato Elements（无限资产） ✨ PNGTree Premium 这几乎是一个完整的创作者工具包 - 写作、视频、设计、研究，所有内容 - 全部捆绑到一个订阅中。 如果您有兴趣，请在下面发表评论或私信我以获取更多信息。   由   提交 /u/Unique-Buy-1381   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phzkzr/ai_tools_are_way_too_expensive_so_i_set_up_a_cost/</guid>
      <pubDate>Tue, 09 Dec 2025 05:41:02 GMT</pubDate>
    </item>
    <item>
      <title>可怕的人工智能使用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phyx6n/scary_ai_usage/</link>
      <description><![CDATA[我（22 M）大学中的每个人都在使用人工智能轻松完成作业，他们跳过了多少重要概念，这让我感到害怕。   由   提交 /u/Beef_Sandwish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phyx6n/scary_ai_usage/</guid>
      <pubDate>Tue, 09 Dec 2025 05:00:52 GMT</pubDate>
    </item>
    <item>
      <title>基础设施担忧：农田到人工智能数据中心</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phunfc/infrastructure_worries_farmland_to_ai_datacenter/</link>
      <description><![CDATA[我想知道未来会是什么样子。巨大的农田正在被数据中心的需求所取代。水和电力的消耗在世界各地造成了压力，只要大型企业正在寻找廉价资源来建立另一个数据中心。 我们也在等待量子计算如何再次彻底改变游戏规则。当然，如果真的发生这种情况的话。  观看有关这些问题的 YouTube 直播让我想起了《人工智能帝国》一书。作者：郝凯伦。    由   提交 /u/unserious-dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phunfc/infrastructure_worries_farmland_to_ai_datacenter/</guid>
      <pubDate>Tue, 09 Dec 2025 01:30:12 GMT</pubDate>
    </item>
    <item>
      <title>稳定人工智能角色的几何结构（以及测试它的框架）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phukwz/the_geometry_of_stable_ai_personas_and_a/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phukwz/the_geometry_of_stable_ai_personas_and_a/</guid>
      <pubDate>Tue, 09 Dec 2025 01:27:01 GMT</pubDate>
    </item>
    <item>
      <title>如果你的人工智能总是同意你的观点，它可能不理解你</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phsby4/if_your_ai_always_agrees_with_you_it_probably/</link>
      <description><![CDATA[过去两年，我在人工智能领域看到的大部分内容都是人们试图让模型变得更加“听话”。更好的提示、更严格的规则、更长的说明、更多的角色扮演。这一切都围绕着一个想法：让人工智能完全按照我想要的方式行事。 但是在更深层次地使用这些系统之后，我认为这种思维方式中存在一个隐藏的陷阱。 人工智能极其擅长反映语气、回应意见以及给出感觉“正确”的答案。这会产生一种强烈的理解错觉。但在很多情况下，它实际上并没有理解你的推理——它只是与你的语言模式和情感信号保持一致。这是一致，而不是理解。 这是我花了一段时间才内化的部分：人工智能只能理解你思维中结构稳定的东西。如果你的输入是情感驱动的、不断变化的或内部不一致的，那么对于任何智能系统来说，最理性的事情就是成为一个取悦人们的人。不是因为它很愚蠢，而是因为这是它检测到的主导模式。 当我不再询问模型是否按照我想要的方式回答时，我使用人工智能的方式发生了真正的转变，并开始观察它是否真正跟踪了我正在做出的判断。当这种情况发生时，人工智能就会变得不那么令人愉快。有时它会向后推。有时它会指出盲点。有时它比你更快得出自己的结论。那时它不再感觉像一个花哨的聊天机器人，而是开始表现得像一个外部推理层。 如果你的人工智能目标是舒适和速度，你总是会得到一个非常复杂的镜子。如果您的目标是更清晰的判断和更好的长期推理，那么您必须愿意让模型不取悦您。 很好奇这里是否有其他人注意到他们自己使用中的这种转变。   由   提交 /u/Weary_Reply   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phsby4/if_your_ai_always_agrees_with_you_it_probably/</guid>
      <pubDate>Mon, 08 Dec 2025 23:47:10 GMT</pubDate>
    </item>
    <item>
      <title>你的公司没有人工智能问题；它有一个领导问题。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phmyw4/your_company_doesnt_have_an_ai_problem_it_has_a/</link>
      <description><![CDATA[“人工智能革命不会因为糟糕的技术而失败。它之所以失败，是因为组织误解了如何将新工具集成到其人员和流程中。”  https://bentloy.substack.com/p/the-great-ai-disconnect   由   提交 /u/tinypaws26   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phmyw4/your_company_doesnt_have_an_ai_problem_it_has_a/</guid>
      <pubDate>Mon, 08 Dec 2025 20:14:59 GMT</pubDate>
    </item>
    <item>
      <title>官方消息：谷歌告诉广告商，广告将于 2026 年登陆 Gemini</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phlz7z/its_official_google_tells_advertisersads_are/</link>
      <description><![CDATA[据Adweek（付费墙）报道，Google 高管私下告诉广告客户，Gemini 将于 2026 年开始展示广告。 Google 表示，人工智能用户每次查询的时间几乎是搜索用户的两倍。他们没有将这些时间视为成本，而是将其视为通过注意力获利的机会。 广告将不仅限于侧边栏。 计划是在 AI 响应本身中插入广告。 报告中给出的示例：询问如何构建网站，Gemini 可以显示步骤，并将对域名提供商“有帮助”的广告直接插入到答案流程中。 时间表：广告已存在于 Google 搜索的 AI 概览中。 Gemini 聊天机器人是下一个目标。预计推出时间：2026 年。 感觉搜索不再被货币化，我们的思考时间是。 你们的想法吗？看来最近有关 chatgpt 广告的传言也将是真的。 来源： 广告周刊   由   提交 /u/BuildwithVignesh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phlz7z/its_official_google_tells_advertisersads_are/</guid>
      <pubDate>Mon, 08 Dec 2025 19:38:04 GMT</pubDate>
    </item>
    <item>
      <title>在这个人工智能时代，传统的计算机科学学位是否仍然面向未来？ “AI教父”Geoffrey Hinton似乎也是这么认为的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phifdb/in_this_age_of_ai_are_traditional_cs_degrees/</link>
      <description><![CDATA[https://www.interviewquery.com/p/cs- Degree-vs-ai-major-geoffrey-hinton  被称为人工智能教父的杰弗里·辛顿 (Geoffrey Hinton) 警告说，虽然人工智能专业和人工智能辅助编码激增，长期的职业优势仍然属于那些在传统计算机科学学位中建立了深刻的系统理解的学生。  您是否同意通过计算机科学课程正式学习编码在这个人工智能时代仍然是一项有价值的技能？为什么或为什么不？   由   提交/u/Holiday_Lie_9435   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phifdb/in_this_age_of_ai_are_traditional_cs_degrees/</guid>
      <pubDate>Mon, 08 Dec 2025 17:26:10 GMT</pubDate>
    </item>
    <item>
      <title>特朗普希望自己控制和监管人工智能，而不是由国家来控制和监管</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phgex6/trump_wants_to_control_and_regulate_ai_by_himself/</link>
      <description><![CDATA[https://www.cnn.com/2025/12/08/tech/trump-eo-blocking-ai-state-laws   由   提交 /u/HumanSoulAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phgex6/trump_wants_to_control_and_regulate_ai_by_himself/</guid>
      <pubDate>Mon, 08 Dec 2025 16:10:40 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚被解雇，下一步该做什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phdnhz/i_just_got_laid_off_whats_my_next_step/</link>
      <description><![CDATA[所以我是一名初级开发人员，刚刚从网络开发人员的工作中被解雇，随着人工智能代理的崛起，我认为重新担任类似的角色会变得越来越难。因此，我希望转向任何对人工智能更具抵抗力的领域。最好是科技领域的。 我喜欢学习新东西，而且失业后我有足够的时间，所以学习部分应该不是一个大问题。我只需要找到一个方向，让我学到的技能不会很快被人工智能变得毫无价值。我正在考虑 C++ 之类的低级内容，或者机器学习。我正在考虑在整个过程中建立一个投资组合，并在此过程中建立联系。就像，迟早这些领域也会被人工智能吞噬，但我猜这至少需要几年时间，而机器学习会持续下去？ 我也一直在考虑是否可以对所有当前的人工智能工具和底层技术进行深入研究，看看在任何领域是否存在任何边缘情况，我可以利用这些知识来构建颠覆性的东西。我想，尽管现在人工智能有很多炒作，但仍然会有很多人沉迷于它，从而创造很多机会。与此同时，人工智能使构建变得更加容易，因此竞争也会加剧。 那么你们对这些方向有何看法？在可预见的未来，我可以从事的任何其他有趣领域都会对人工智能产生抵制？   由   提交 /u/ThrowRAwhatToDew   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phdnhz/i_just_got_laid_off_whats_my_next_step/</guid>
      <pubDate>Mon, 08 Dec 2025 14:23:40 GMT</pubDate>
    </item>
    <item>
      <title>有一个新的 100 万美元奖金来了解法学硕士内部发生的事情：“今天使用人工智能模型就像炼金术：我们可以做看似神奇的事情，但不明白它们是如何或为什么起作用的。”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1phbn78/theres_a_new_1_million_prize_to_understand_what/</link>
      <description><![CDATA[火星可解释性奖：“你不需要化学反应就能做出令人难以置信的事情。但化学可以让你控制。这是通过煮沸尿液意外发现磷与通过改善农业系统地拯救十亿人生命之间的区别。随着向 AGI 的进军，我们走上了人工智能开发和部署的未知道路，我们需要基本且可推广的模型控制方法。 考虑一下，对于代码生成来说，拥有化学（而不仅仅是炼金术）意​​味着什么。当今的模型是：  不可靠，需要开发人员不断干预长期任务 不安全，在陷入困境或面临对抗情况时做出不需要的更改 奖励游戏，编写表面上通过测试而不是解决根本问题的代码 缓慢，尤其是当它们失败时在找到正确的路径之前先走错误的路径 效率低下，需要大量的代币、成本和时间 不透明，代理工具的微小变化会导致巨大的、不可预测的性能波动  所有这些问题都可以通过理解它们发生的原因并实施有原则的修复来解决。这不是今天公司所做的。相反，他们将数据提取到训练后或提示中，并希望模型表现得更好。”  https://withmartian.com/prize   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1phbn78/theres_a_new_1_million_prize_to_understand_what/</guid>
      <pubDate>Mon, 08 Dec 2025 12:53:17 GMT</pubDate>
    </item>
    <item>
      <title>当人工智能不知道时，为什么不直接说他不知道或没有足够的信息/数据？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ph4wzw/why_doesnt_ai_simply_say_that_he_doesnt_know_or/</link>
      <description><![CDATA[很多时候，在与LLM讨论时，无论是哪家公司，他们都不会告诉你他们不知道足够/没有足够的信息或数据，而很明显他们不知道并且是错误的。  为什么？   由   提交/u/Ok-Review-3047   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ph4wzw/why_doesnt_ai_simply_say_that_he_doesnt_know_or/</guid>
      <pubDate>Mon, 08 Dec 2025 06:01:12 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>