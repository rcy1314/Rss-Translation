<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 26 Dec 2024 06:29:05 GMT</lastBuildDate>
    <item>
      <title>如果人工智能由政府而不是企业来管理，真的会更好吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmhyfd/would_ai_actually_be_better_in_the_hands_of/</link>
      <description><![CDATA[想想看，它会对我们的生活和一切产生如此大的影响，但我们没有像对政府那样对公司的投票权。 我看到有人在这里的某个地方提起这个……    提交人    /u/AImoneyhowto   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmhyfd/would_ai_actually_be_better_in_the_hands_of/</guid>
      <pubDate>Thu, 26 Dec 2024 05:41:58 GMT</pubDate>
    </item>
    <item>
      <title>这是印度人工智能/机器学习的一个被低估但非常实用的用例——将当地政府机构的回复翻译成当地语言</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmgway/heres_an_underrated_yet_really_practical_usecase/</link>
      <description><![CDATA[背景 - 印度有 14 多种国家语言，尽管英语和印地语是常见的“联系”语言，但印度许多州都规定地方政府官员只能用当地语言与公民交流。人们可以争论这些政策的优点，但事实是，这些政策是出于政治和实际原因 - 培育当地语言和文化，让当地公民能够轻松地以母语寻求政府服务。 鉴于全国各地的专业人士为了工作、学习或其他机会而大量迁移，这种“当地语言”政策可能会带来实际挑战。许多城市或州的新居民可能会发现很难用当地的“母语”交流，因为他们可能熟悉印地语或英语等其他语言，而不是卡纳达语、泰卢固语、马拉地语或泰米尔语。学习交谈是第一步，但熟练掌握当地语言阅读和写作所需的技能可能更难获得。  我住在班加罗尔，这里是东方的“硅谷”，来自全国各地的数百万印度人都移居于此。虽然我已经学会了用当地语言坎纳达语说话和交流，但我并不擅长用这种语言阅读和写作。因此，当当地政府官员用当地语言发送官方通知时，与他们打交道是一项挑战。 我已经开始使用“简单”的工具来帮助我应对这一挑战 - 我的经验    提交人    /u/desi_guy11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmgway/heres_an_underrated_yet_really_practical_usecase/</guid>
      <pubDate>Thu, 26 Dec 2024 04:34:33 GMT</pubDate>
    </item>
    <item>
      <title>IG 上有一个频道@brainrotindian，我喜欢他们克隆演员的声音并将视频与音频口型同步的方式。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmgewq/theres_a_channel_on_ig_brainrotindian_i_love_how/</link>
      <description><![CDATA[是否有任何教程或我遗漏的具体内容，我尝试在 yt 上查找，但他们只是简单地建议了 11 个实验室，但问题是帐户的制作方式非常真实并与电影基调相符。  请帮忙。    提交人    /u/Odd_Philosopher_6605   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmgewq/theres_a_channel_on_ig_brainrotindian_i_love_how/</guid>
      <pubDate>Thu, 26 Dec 2024 04:04:33 GMT</pubDate>
    </item>
    <item>
      <title>一体化AI产品</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmdxvk/all_in_one_ai_product/</link>
      <description><![CDATA[大家好， 您是否厌倦了为单独的 AI 音乐生成器付费？ 您是否对 AI 艺术生成器的荒谬成本感到沮丧？ 您是否有时想知道选择不同的 LLM（无论是 ChatGPT 还是 Claude）是否可以给您正确的答案？ 您是否还希望预算所有 AI 订阅？ 我建议您查看 ninjatools.ai。这是一个利用多个 API 的平台，例如 llama、Claude、perplexity 和 chatgpt。它可以花时间总结您的 pdf。如果您时间紧迫，您可以使用该平台观看总结 youtube 视频。它还包括音乐和艺术生成，成本比大多数其他平台更便宜。 https://ninjatools.ai    提交人    /u/imperialsheriff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmdxvk/all_in_one_ai_product/</guid>
      <pubDate>Thu, 26 Dec 2024 01:37:37 GMT</pubDate>
    </item>
    <item>
      <title>我们真的需要一个去中心化的人工智能网络吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmdvr6/do_we_really_need_a_decentralized_ai_network/</link>
      <description><![CDATA[  由    /u/eqai_inc  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmdvr6/do_we_really_need_a_decentralized_ai_network/</guid>
      <pubDate>Thu, 26 Dec 2024 01:34:13 GMT</pubDate>
    </item>
    <item>
      <title>不要只关注人类能做什么而人工智能不能做什么，而要关注人工智能能做什么而人类不能做什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmd51r/stop_seeing_what_humans_can_do_and_ai_cant_and/</link>
      <description><![CDATA[无论我们喜欢与否，人工智能都会到来——只是它何时到来以及它将对各个领域产生何种影响的问题。从医疗保健和教育到艺术、工程和农业，人工智能已经产生了巨大的影响。它可以处理无聊的任务，处理大量数据，并给我们提供我们自己永远无法弄清楚的见解。即使是那些不信任人工智能的人最终也会使用它，因为它太有用了，不容忽视。随着人工智能不断进步，它不仅会帮助我们更快地完成任务——它还会改变我们的思维、工作和创造方式。    提交人    /u/TheLogiqueViper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmd51r/stop_seeing_what_humans_can_do_and_ai_cant_and/</guid>
      <pubDate>Thu, 26 Dec 2024 00:52:19 GMT</pubDate>
    </item>
    <item>
      <title>我添加了专业人士的天赋</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</link>
      <description><![CDATA[由于最近对专业内容更加突出的兴趣，我认为一个好的开始是了解用户的哪些答案来自真正了解他们所谈论内容的人。 因此，我通过 mods 使经过验证的专业标签仅可分配。如果您想要该标签，您必须证明您在该领域工作。我把这留给您，我不在乎您的数据，并在看到后删除所有内容。如果您获得了标签，结果发现您对自己的职业撒了谎，无论出于何种原因，您都将被永久禁止，并且无法上诉。 一旦我们拥有足够多的人，我们还可以允许用户将某些帖子限制为仅供那些用户进行更专业的讨论。 让我知道您的想法    提交人    /u/ILikeBubblyWater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</guid>
      <pubDate>Wed, 25 Dec 2024 23:49:53 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型面临的新安全挑战</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmahfn/emerging_security_challenges_of_large_language/</link>
      <description><![CDATA[标题：大型语言模型的新兴安全挑战 我每天都会查找和总结有趣的 AI 研究论文，这样您就不必全部浏览了。今天的论文题为“大型语言模型的新兴安全挑战”，由 Herve Debar、Sven Dietrich、Pavel Laskov、Emil C. Lupu 和 Eirini Ntoutsi 撰写。 本文深入探讨了大型语言模型 (LLM) 带来的独特安全挑战，例如基于转换器架构的模型，这些模型越来越多地用于教育和医疗保健等不同领域。尽管这些模型具有广泛的适用性，但它们面临着与传统机器学习模型不同的重大安全风险。 要点和发现：  对抗性漏洞：由于 LLM 在大规模、多样化的数据集上进行通用训练，因此特别容易受到对抗性攻击。这些攻击可以利用提示的构造或 LLM 的概率性质等功能，导致幻觉等现象 - 模型生成误导性或无意义的输出。 数据中毒和后门攻击：用于训练 LLM 的大量数据集容易受到中毒，恶意行为者会引入可能影响模型行为的数据。鉴于数据集的庞大规模，精确投毒可能具有挑战性，但有针对性的攻击仍然是可行的。 供应链的复杂性：从数据采购到模型部署的链条错综复杂，为攻击者创造了机会。令人担忧的问题包括预训练模型的来源、用于微调的数据以及透明度问题——每个问题都可能增加引入漏洞的风险。 安全风险评估中的挑战：LLM 的不透明和多面性使安全评估变得复杂。因素包括培训和架构缺乏透明度、广泛的应用环境和自适应学习机制，所有这些都使全面的安全评估变得困难。 防御攻击本文还强调了系统防御的必要性，因为现有策略主要侧重于查明漏洞。它要求在保持模型实用性和防范各种形式的攻击之间取得平衡，呼吁更深入地了解系统性漏洞。  本文强调，人工智能社区迫切需要优先开发强大的防御机制，以抵御威胁 LLM 可靠性和完整性的各种攻击。 您可以在此处查看完整的细分：这里您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmahfn/emerging_security_challenges_of_large_language/</guid>
      <pubDate>Wed, 25 Dec 2024 22:25:23 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hm35wg/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：Sriram Krishnan 被任命为特朗普的 AI 高级政策顾问 (TechCrunch)  OpenAI“考虑”建造一个人形机器人。 （TechCrunch） Google 正在使用 Anthropic 的 Claude 来改进其 Gemini AI（TechCrunch） xAI 正在为其 Grok 聊天机器人测试独立的 iOS 应用程序（TechCrunch） Juniper Ventures 将投资气候合成生物学（TechCrunch） Swizzle Ventures 为首支致力于女性健康和财富的基金筹集了 500 万美元（TechCrunch） Coralogix 收购了 AI 可观察性平台 Aporia（TechCrunch）  如果您想及时了解 AI 新闻，它首先在这里发布。，其中包含所有来源和文章的完整摘要    由    /u/codeharman 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hm35wg/heres_whats_making_news_in_ai/</guid>
      <pubDate>Wed, 25 Dec 2024 15:55:53 GMT</pubDate>
    </item>
    <item>
      <title>谷歌正在利用 Anthropic 的 Claude 改进其 Gemini AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hm18sk/ai_google_is_using_anthropics_claude_to_improve/</link>
      <description><![CDATA[https://techcrunch.com/2024/12/24/google-is-using-anthropics-claude-to-improve-its-gemini-ai/ 老实说，对于通用或编码任务来说，Claude 是最好的商业上可用的 LLM，所以我明白为什么谷歌想要抄袭他们的作业。    提交人    /u/spacespacespapce   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hm18sk/ai_google_is_using_anthropics_claude_to_improve/</guid>
      <pubDate>Wed, 25 Dec 2024 14:01:38 GMT</pubDate>
    </item>
    <item>
      <title>有人记得这个 subreddit 曾经充满专家和计算机科学家吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlyvmg/does_anyone_remember_when_this_subreddit_was_full/</link>
      <description><![CDATA[现在看来，这里全是白痴，在没有任何数据科学、机器学习或人工智能背景或技术知识的情况下，发表近乎阴谋的愚蠢言论     提交人    /u/Alloy-Black   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlyvmg/does_anyone_remember_when_this_subreddit_was_full/</guid>
      <pubDate>Wed, 25 Dec 2024 11:10:21 GMT</pubDate>
    </item>
    <item>
      <title>对 OpenAI o3 的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlws9a/thoughts_on_openais_o3/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlws9a/thoughts_on_openais_o3/</guid>
      <pubDate>Wed, 25 Dec 2024 08:20:49 GMT</pubDate>
    </item>
    <item>
      <title>人们对人工智能的看法可能比它的能力更危险</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlq42x/the_way_people_perceive_ai_could_be_more/</link>
      <description><![CDATA[在我看来，人们忽视了人工智能的大量合法问题，而更倾向于好莱坞对人工智能的比喻。虽然随着技术的进步，我们应该认真对待这些比喻，但我们需要更好地理解人们对这些系统的看法如何影响他们对它们的使用，以及这种看法与现实不一致的潜在负面影响。 这是关于依赖技术的更广泛影响的讨论的一部分。我在研究生院学习的主题之一是人机交互/人为因素，航空事故可能是最常用的例子。大约 80% 的事故是人为失误的直接结果，而不是机械故障或飞行条件，其中大多数事故是由于飞机和飞行员之间的脱节造成的。 一个例子是大韩航空货运航班，自动驾驶系统补偿了飞行员不知情的姿态指示器故障。这掩盖了问题，当机组人员采取手动控制时，他们使用有故障的指示器将飞机撞向地面。机组人员对自动驾驶系统和姿态指示器的信任被归咎为事故的原因，以及在退出自动驾驶时将人带回控制环的过程（或缺乏控制）。法航 447 航班是另一个出现的例子。自动驾驶系统掩盖了飞机在湍流/结冰条件下飞行的一些行为。手动飞行时，飞行员会积极保持飞机水平并注意飞行条件，但在这种情况下，他们听从了自动驾驶仪的指示，并在自动驾驶仪意外交还控制权时失去了控制。大多数涉及自动化组件的事件都有一个共同点——人类没有完全处于控制环路中，要么误判情况，要么缺乏采取适当行动所需的信息。 在谈论人工智能代理时，谈论自动化的意外后果是个好主意——无论系统是否正常工作。自动化不仅仅是设计系统以正确完成任务，它还涉及使用系统的人的想法或期望。通常，在系统按照设计的方式工作的情况下，失败点是人。 我们需要记住哪些事情？我最大的担忧之一是人们对人工智能能做什么的关注程度与它不能做什么的关注程度相比如何。错误的期望通常是导致人员死亡的原因。    提交人    /u/Murky-Motor9856   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlq42x/the_way_people_perceive_ai_could_be_more/</guid>
      <pubDate>Wed, 25 Dec 2024 00:29:50 GMT</pubDate>
    </item>
    <item>
      <title>这是我的想法，还是大学真的严重缺乏有关人工智能代理的课程？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlofn1/its_just_me_or_are_universities_seriously_lacking/</link>
      <description><![CDATA[我专攻自动化生产工程，在我的整个学习过程中，我从未遇到过关于这个主题的任何课程。甚至没有关于无代码工具（如 n8n）的课程，而这在当今的自动化中基本上是基础。 也许只是我的大学。这里还有其他人专门上过关于 AI 代理或无代码开发的课程吗？我很好奇，想知道是否还有其他大学已经将 AGI/无代码整合到他们的课程中。    提交人    /u/Garraww   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlofn1/its_just_me_or_are_universities_seriously_lacking/</guid>
      <pubDate>Tue, 24 Dec 2024 22:50:51 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，除了此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 24 Dec 2024 15:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>