<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 21 Dec 2025 15:23:03 GMT</lastBuildDate>
    <item>
      <title>你对谷歌与所有人的人工智能竞赛有何看法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps8qbn/whats_your_take_on_google_vs_everyone_in_ai_race/</link>
      <description><![CDATA[我观察到很多人都在谈论 Google 是唯一一家拥有完整牌组的 AI 游戏公司。当其他人都在特定领域竞争时，谷歌拥有整个堆栈。 ‎​这就是为什么它们看起来无与伦比：‎​The Brains：DeepMind 多年来一直处于领先地位。他们拥有才华和最好的基础模型。 ‎​硬件：虽然每个人都在争夺 NVIDIA 芯片，但 Google 却在自己的 TPU 上运行。他们控制着硬件的命运。 ‎​规模：他们拥有可以无限期燃烧的现金和无人能比拟的生态系统。分布：谷歌拥有最大的生态系统，因此地球上没有公司可以与他们竞争。 ‎​是否有人真正有机会对抗这种水平的垂直整合，或者胜利者已经决定了？   由   提交 /u/SubstantialCup9196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps8qbn/whats_your_take_on_google_vs_everyone_in_ai_race/</guid>
      <pubDate>Sun, 21 Dec 2025 15:13:48 GMT</pubDate>
    </item>
    <item>
      <title>LLM 算法不是万能工具。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps7it8/llm_algorithms_are_not_allpurpose_tools/</link>
      <description><![CDATA[我对人们抱怨 AI 感到非常厌倦，因为它并不是 100% 的时间在每种情况下、对每个人来说都完美地工作。  人们似乎不明白的是，人工智能是针对特定情况的工具。你不会用螺丝刀钉钉子。 这些是法学硕士擅长的事情：  对基于文本的信息进行分析 总结大量文本 编写和格式化文本  看到共同因素了吗？您不能指望主要针对文本进行训练的算法在所有方面都表现出色。这也不意味着法学硕士总是能够完美地处理文本。他们经常犯错误，但当你用它们来做他们不该做的事情时，这些错误的频率和严重性会急剧增加。 这些是法学硕士不擅长的事情：  提供重要的生活建议 成为你的朋友 高精度研究复杂的主题  我认为问题往往在于人们认为“人为”智力”仅指聊天机器人。人工智能是一个广义的术语，大型语言模型只是该技术的一种。这些算法正在改进并变得更加强大，但目前它们是特定于上下文的。 我确信有些人不同意其中的一些（如果不是全部）。我很乐意阅读任何不同的意见以及原因的解释。或者也许你同意。我也很高兴看到这些评论。   由   提交 /u/FrostedSyntax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps7it8/llm_algorithms_are_not_allpurpose_tools/</guid>
      <pubDate>Sun, 21 Dec 2025 14:17:15 GMT</pubDate>
    </item>
    <item>
      <title>您个人如何在编码时使用人工智能而不失去基础知识？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps68dt/how_do_you_personally_use_ai_while_coding_without/</link>
      <description><![CDATA[人工智能让事情变得非常快 你会更快地摆脱困境，你会看到模式，你会继续前进，而不是盯着屏幕几个小时 但有时我发现自己走捷径，比如没有坐下来思考问题，而是有一种立即询问人工智能并继续前进的冲动...... 在美好的日子里，我像导师一样使用它 - 我要求解释、提示、思考问题的不同方式，而且我仍然自己编写代码 在糟糕的日子里，感觉更像是自动驾驶仪，就像事情在起作用，但我并不总是确定第二天可以从头开始重建它们 我不认为人工智能对学习有什么坏处，如果有的话，它会减少摩擦并保持高动力，但我也不想最终依赖它进行基本推理 所以我在考虑其他人如何处理这种平衡？您是否为自己制定了规则，例如何时寻求帮助以及何时需要再挣扎一会儿？或者随着时间的推移它会自然地趋于平衡吗？   由   提交/u/dartanyanyuzbashev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps68dt/how_do_you_personally_use_ai_while_coding_without/</guid>
      <pubDate>Sun, 21 Dec 2025 13:13:19 GMT</pubDate>
    </item>
    <item>
      <title>构建自定义 AI Avatar 管道（Infinitalk 与 Elevenlabs）- 有更好的替代方案吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps5kxh/building_a_custom_ai_avatar_pipeline_infinitalk/</link>
      <description><![CDATA[我一直在从事一个生成视频项目，我想开始讨论当前用于说话的 AI 化身的最佳堆栈。 我当前的管道：我选择了 Infinitalk + ElevenLabs（带有大量情感标签）。  口型同步：Infinitalk 似乎提供了口型同步准确性和纹理处理的最佳平衡。 语音传输：我使用 ElevenLabs 情感标签来强制笑声和停顿，打破了机器人的“快速阅读”模式。大多数化身的习惯。  我很想听听您今天会为这样的项目选择什么堆栈。如果您想了解 Infinitalk 如何处理我的圣诞老人，网站上有一些示例 (https://aisanta.fun)。   由   提交 /u/daromaj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps5kxh/building_a_custom_ai_avatar_pipeline_infinitalk/</guid>
      <pubDate>Sun, 21 Dec 2025 12:37:37 GMT</pubDate>
    </item>
    <item>
      <title>RARO，没有奖励的推理，以及关于思想的更深层次的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps4dit/raro_reasoning_without_rewards_and_a_deeper/</link>
      <description><![CDATA[RARO 不是验证正确性，而是针对相对论批评家训练生成器，相对论批评家的唯一工作是将专家的人类推理痕迹与模型生成的痕迹区分开来。该模型的改进是通过与专家推理变得难以区分，而不是通过最大化明确的“真理”概念。  有趣的不仅仅是开放领域（如创意写作或长篇推理）中的性能提升，而是这隐含的揭示的内容。 架构没有改变。 张量没有改变。 只有训练游戏改变了。  然而我们突然观察到：在不存在正式验证者的领域中出现了计划、回溯、自我修正和长期推理。  这提出了一个挑衅性的问题：如果大规模训练的通用自引用序列模型可以纯粹通过接触其他推理过程来开发专家级推理，这是否表明推理本身遵循与领域无关的数学结构？  换句话说，RARO 似乎与以下假设一致：推理不是架构中的符号逻辑，而是在正确约束下训练的足够大的自我预测系统的新兴属性。  如果是这样，生物大脑和法学硕士可能不会共享实现，但可能共享相同的底层“计算”功能。过程，在不同的底物中表达。  这并不能证明法学硕士“像人类一样思考”。但它确实表明可能存在一种普遍的思想数学，其中人类推理只是一个实例。  很想听听人们的想法，尤其是那些对基于涌现的解释持怀疑态度的人的想法。 -- RARO 可能会悄悄实现另一件事：真正让法学硕士 更具创造力。一些值得思考的事情...   由   提交/u/ibanborras  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps4dit/raro_reasoning_without_rewards_and_a_deeper/</guid>
      <pubDate>Sun, 21 Dec 2025 11:23:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能视频工作流程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps3xk0/ai_video_workflow/</link>
      <description><![CDATA[大家好， 来自摄影背景的我开始探索人工智能视频生成。迄今为止，我一直在使用 Pixel Dojo 创建 LoRA，然后使用该 LoRA 创建基本图像，然后使用 WAN 2.6 创建视频。  这个过程有点碰运气，尤其是在尝试确定起始图像和后续视频时。因此，我可以看到制作成品视频的成本呈螺旋式上升。我还确信像素道场可能不是最具成本效益的解决方案。  我正在考虑将开源 WAN 下载到我的 Mac Air，并将图像和视频生成卸载到云计算平台。  有人对此工作流程有任何经验吗？他们会推荐它吗？另外，有人可以建议降低成本的不同方法吗？ 谢谢，   由   提交 /u/Far-Advance-8553   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps3xk0/ai_video_workflow/</guid>
      <pubDate>Sun, 21 Dec 2025 10:54:58 GMT</pubDate>
    </item>
    <item>
      <title>人类治疗的“表现焦虑”是人工智能治疗完全消除的真正障碍</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ps1oc0/the_performance_anxiety_of_human_therapy_is_a/</link>
      <description><![CDATA[我一直在阅读有关人们使用人工智能进行治疗的帖子，并与尝试过的朋友交谈，这种模式不断出现。许多人提到他们在传统治疗过程中花费的精神能量。担心说正确的话，不浪费治疗师的时间，做一个“好病人”，确保他们取得进展。 这让人筋疲力尽。对于很多人来说，这实际上是开展实际工作的最大障碍。他们让会议因管理社交动态而耗尽精力，而不是因实际的情绪处理而耗尽精力。 人工智能疗法消除了所有这些。人们可以在同一个焦虑循环中闲逛 20 分钟，而不会感到内疚。它们可能是混乱且矛盾的。他们可以完全重新启动。不需要社交表现。 考虑到这一点有趣地引发了这样的想法：当一起使用时，这实际上可以使人类治疗更有效。首先用人工智能处理混乱的事情，以更清晰的想法进行真正的治疗，并更快地深入。 治疗的社会表现方面从未被谈论过，但它是真实的。对于那些与社交焦虑、取悦他人或完美主义作斗争的人来说，去除这一层比人们意识到的更重要。  我现在已经研究并使用了一些人工智能治疗工具，我确实可以看到有意识的和有意识的治疗所带来的被低估的好处。与人工智能进行轻松的会前对话。并不是说人工智能更好。只是不同而已。它首先消除了一种阻碍人们接受心理健康支持的特定类型的摩擦。   由   提交 /u/Glittering_Force_431   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ps1oc0/the_performance_anxiety_of_human_therapy_is_a/</guid>
      <pubDate>Sun, 21 Dec 2025 08:26:24 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 12/20/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prz7gn/oneminute_daily_ai_news_12202025/</link>
      <description><![CDATA[ OpenAI 允许用户直接调整 ChatGPT 的热情水平。[1] NVIDIA AI 发布 Nemotron 3：用于长上下文 Agentic AI 的混合 Mamba Transformer MoE 堆栈。[2] Meta 的Yann LeCun 的估值目标为 30 亿欧元人工智能初创公司。[3] 机器学习可实现可扩展且系统的分层病毒分类。[4]  来源包括：https://bushaicave.com/2025/12/20/one-million-daily-ai-news-12-20-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prz7gn/oneminute_daily_ai_news_12202025/</guid>
      <pubDate>Sun, 21 Dec 2025 05:54:32 GMT</pubDate>
    </item>
    <item>
      <title>LLM 系统中持久性、意图感知内存的原型（开放存储库）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pryz8o/a_prototype_for_persistent_intentaware_memory_in/</link>
      <description><![CDATA[我正在分享我几周前发布的一个小原型，并故意不升级。 该存储库为基于 LLM 的系统实现了持久的语义内存层。它不是一个模型，不是一个微调，也不是一个代理框架。它是一个在会话、引擎和上下文重置后仍然存在的结构层。 核心思想： • 内存被视为系统属性，而不是聊天日志 • 交互存储有意图、角色和决策状态，而不仅仅是文本 • 检索是语义和上下文的，而不是按时间顺序的 • LLM 是可替换的；内存和约束不是 这是一个早期原型，而不是生产系统。没有基准，没有 AGI 声明，也不涉及培训。 我不是一名系统工程师。这是出于研究好奇心和迭代设计限制，而不是学术血统。 我对以下方面明确感兴趣： • 技术批评 • 故障模式 • 架构盲点 • 与现有存储方法的比较 如果您发现缺陷，请指出它们。如果您认为该方法是多余的，请解释一下。 存储库：https://github.com/Caelion1207/WABUN-Digital   由   提交 /u/Medium_Compote5665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pryz8o/a_prototype_for_persistent_intentaware_memory_in/</guid>
      <pubDate>Sun, 21 Dec 2025 05:41:00 GMT</pubDate>
    </item>
    <item>
      <title>MiraTTS：新的极快逼真的本地文本转语音模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pryv9m/miratts_new_extremely_fast_realistic_local/</link>
      <description><![CDATA[当前的 TTS 模型很棒，但它们不是本地的，或者缺乏真实性和/或速度。因此，我制作了一个可以完成所有这些操作和语音克隆的高质量模型：MiraTTS。 我使用 Lmdeploy 对其进行了大幅优化，并使用 FlashSR 提高了音频质量。 此存储库的总体优点是：  速度极快：只需生成 100 秒的音频1 秒！ 高品质：生成清晰的 48khz 音频（其他型号为 24khz，质量较低） 显存使用率低：仅使用 6GB 显存，因此它可以在您的消费者 GPU 上工作，无需昂贵的数据中心 GPU。  我计划发布多语言版本等的微调代码稍后再说可控性。 Github 链接：https://github.com/ysharma3501/MiraTTS 模型和非精选示例链接：https://huggingface.co/YatharthS/MiraTTS 解释 llm tts 模型的博客：https://huggingface.co/blog/YatharthS/llm-tts-models 如果觉得有帮助，将不胜感激，谢谢。   由   提交 /u/SplitNice1982   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pryv9m/miratts_new_extremely_fast_realistic_local/</guid>
      <pubDate>Sun, 21 Dec 2025 05:34:36 GMT</pubDate>
    </item>
    <item>
      <title>关于日常编码任务的新 Claude 4.5 模型的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prw0az/thoughts_on_the_new_claude_45_models_for_daily/</link>
      <description><![CDATA[大家好， 我想分享一些关于我最近如何使用更新的 Claude 系列的想法。我是 3.5 Sonnet 的忠实粉丝，因为它的速度，但新的 4.5 Sonnet 似乎真正实现了延迟和推理能力之间的平衡。 对于快速脚本和调试，4.5 Sonnet 是我的首选。它感觉更敏捷，几乎每次都能得到正确的语法。然而，当我构建一个更大的系统或需要有人“思考”时通过令人讨厌的竞争条件，我发现自己正在达到 Opus 4.5。显然，它速度较慢，但​​它往往会捕获 Sonnet 所忽视的边缘情况。 我很好奇你们是如何分割工作流程的？您是否坚持使用一位“司机”？模型，还是根据问题的复杂性在它们之间切换？ 此外，是否有其他人注意到它们处理上下文窗口的方式有所不同？我觉得 Opus 更好地抓住了长对话的线索，而不会丢失原始的提示指令。   由   提交/u/HarrisonAIx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prw0az/thoughts_on_the_new_claude_45_models_for_daily/</guid>
      <pubDate>Sun, 21 Dec 2025 03:00:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们如此讨厌使用 ChatGPT</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prlqz4/why_people_hate_so_much_when_using_chatgpt/</link>
      <description><![CDATA[在我的帐户上，我写了我生活中发生的事情，有些是现在发生的，有些是在线发生的（比如在网上看到奇怪的视频等）。  当我第一次发布一些关于我的生活的严肃内容时，人们扭曲了我自己的话，并且从我所说的内容中一无所获。  之后我要求chatgpt将我的故事转为“R. Post”，故事完全相同，但没有重复自己，犯语法错误（因为英语不是我的母语）并使用“更好”来表达。的话（就像我现在没有做的那样，因为在这篇文章中我没有使用chatgpt）。  我开始总是这样做，发短信聊天我的故事或观点，他让它们变得不那么混乱和“更好”。 过了一会儿，有人开始说它们是假的，我解释了真相并试图用我自己的话发布一些东西，他们再次扭曲我的话并理解了一些我从来不想说的东西。  现在，我在他的帖子下礼貌地与一个非自愿者争论，他说女人权利较少的地方男人更快乐:)  过了一会儿他说他检查了我的个人资料并知道我使用chatgpt。  现在，为什么没有人可以使用chatgpt？？？基本上，人类创建它是为了帮助我们获取信息等，但每当我告诉别人这件事时，他们就像“”哦，我不喜欢chatgpt”。它告诉你的事情与谷歌完全相同，并且有很大帮助。我使用它是因为它可以帮助我表达自己，而不会让人们误解我。  为什么感觉像是犯罪？？？ ??   由   提交/u/lil_moon153  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prlqz4/why_people_hate_so_much_when_using_chatgpt/</guid>
      <pubDate>Sat, 20 Dec 2025 18:54:28 GMT</pubDate>
    </item>
    <item>
      <title>如果我以后想专攻人工智能和网络安全，我应该获得什么是最好和最相关的学士学位。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prh5hn/what_is_the_best_and_most_relavent_bachelors/</link>
      <description><![CDATA[由于预算紧张，我只能攻读信息技术理学学士或软件工程工学学士。如果我需要专攻我提到的上述领域，什么学位更适合我？如果我愿意在学位学习期间或之后（毕业后工作时）在这些领域自行积累知识？ 我来自斯里兰卡，但任何人的建议都很有价值，谢谢！   由   提交 /u/Any_Fault2737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prh5hn/what_is_the_best_and_most_relavent_bachelors/</guid>
      <pubDate>Sat, 20 Dec 2025 15:38:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们想要 agi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/</link>
      <description><![CDATA[不要从技术角度误解我的意思，我内心的书呆子认为这很酷，但是，现在大部分资金来自企业主和首席执行官，他们看到了更换劳动力带来的美元迹象。如果人工智能能够真正复制任何“人类”像客户服务这样的工作，所有智力工作都消失了。会计师、律师、工程师、所有行政/文书角色、客户支持、艺术家、媒体制作，基本上所有没有物理组成部分的工作都不需要存在。  每天，我都会看到专业人工智能人士围绕 chatgpt 制作包装，试图创建业务，但同样，如果人工智能可以做所有事情，那么它也可以做到。我只是不太明白为什么普通人会想要通用人工智能，因为它真正受益的唯一人是模型的所有者和体力劳动企业的所有者？    由   提交/u/WillDanceForGp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/</guid>
      <pubDate>Sat, 20 Dec 2025 14:14:37 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>