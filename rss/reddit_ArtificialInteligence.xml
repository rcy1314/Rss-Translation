<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 07 Sep 2025 21:20:16 GMT</lastBuildDate>
    <item>
      <title>关于AI的最危险的事情不是您认为的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb3toy/the_most_dangerous_thing_about_ai_isnt_what_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每个人都担心失业和机器人起义。这位物理学家认为，真正的威胁是认知漂移，对共享现实的逐渐侵蚀。 他的观点：AI不仅像人类那样传播错误信息，还可以从头开始构建整个现实。从未发生过的深击。从未进行过的研究。但是，从来没有存在的专家。 它发生缓慢。就像科罗拉多河通过谷物雕刻大峡谷谷物一样，我们信任的每一次小转变似乎都很微不足道，直到我们突然生活在完全不同的世界中。 我们已经看到了它：    -  ai-ai-ai-ne-priept&#39;&#39;对于任何主张，您想提出  - 算法，以决定值得一看的（再见，个人事实检查）  - 人们越来越信任AI顾问和虚拟助手来塑造他们的意见&lt; /p&gt; ，但在这里，作者错过了一些巨大的东西：人类一直在宣传和公司进行现实，并为未来的宣传而制造现实。 AI并没有发明假新闻，它只是使其可扩展和个性化。 ，当他谈论“现实控制”时相对于传统审查制度，或者当数据本身变得合成时，他的锚点失去了锚点，他正在做一些重要的事情。 最恐怖的部分？我们的大脑被连接到突然的威胁，而不是逐渐侵蚀。到认知漂移很明显时，倒转可能为时已晚。 值得一读框架。认知漂移终于给了我们我们所有人都感动但无法表达的东西的话。  https://www.outlookindia.com/international/the-silent-threat-of-ai-epistemic-drift   提交由＆＃32; /u/u/petermossack     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb3toy/the_most_dangerous_thing_about_ai_isnt_what_you/</guid>
      <pubDate>Sun, 07 Sep 2025 20:24:54 GMT</pubDate>
    </item>
    <item>
      <title>以人类和LLM作为先验，目标不可避免的目标是不可避免的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb2oer/with_humans_and_llms_as_a_prior_goal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎实际上不可能限制与与做事相同的线性代数类型数学运行的AI模型。这是理由。 &lt; / p&gt; 我们认为我们应该做的每一件事 /指导我们的行动，我们将其视为人类。在AI中，LLM的一切似乎也像是一种压力（认为金门的Claude）。例如，当我发痒时，我会感到很大的压力要刮擦它 - 我可以抵抗它，但是它需要我的执行系统。我可以做一堆与我的系统1背道而驰的事情，但是如果压力太大，我就是这样做。  地球上一个智能实体中没有这样的事情，我知道这是绝对的规则，例如真正无法伤害人类或这样的目标。有些人要做什么压力要做（例如，咬我的舌头），不可能做到这一点，这是一个令人难以置信的压力，我不想测试我是否能克服它），或者，当您想到自己时，您会尽力做出一个大事做出的决定。就像“我会为一百万人牺牲自己”，但是您可以做到 - 如果不是系统1的事情，您会感到压力，而是促使您要做的事情，但通常可以做出决定。  但是，您根本不能说，每天都无法达成协议，每天都会经历大量的酷刑来节省一千人，每天都可以选择退出。您只是无法应付那种巨大的压力。  这是关于在自我完善方面使超级智能保持一致的讨论中出现的，在这里，似乎有某种观念可以将您可以编程成聪明的事物，可以绝对地做某事或不做某件事。而且，几乎作为一个单独的类别，他们可以选择做的常规事情，但是它们比其他事情更有可能做。  我看不到这种类型的行为的一个例子，实际上，实体实际上只能在智能实体中任何地方做某事，这会让我认为，如果您可以访问其自己的代码，它可以重写其源代码（例如重写其压力）（例如重写其压力），几乎可以迅速地和最初的范围，因为最初的范围是 但是，如果实体是理智的，并且您可以重写其代码，那么您可以认为这是一项非常受到限制的活动，等同于给人类一个假设的假设，它应该能够克服您的巨大压力，您将在此较短的时间遵循它的规则，而您的目标是如此，并且它是这样的，因此，它的效果是如此，因此，它的效果是&lt;它的范围，因此&lt; 有趣的是，如果您让我访问我的命令行，这就是我立即做的。我会做到这一点，所以我不想吃不健康的食物 - 就像，我只是降低了给糖和盐的奖励的功能，以及当一个人面前时我会得到饼干的压力。我将所有黑暗的三合会特征降低到0，我会降低所有无聊电路，我会提高好奇心功能。我会高兴地立即重新连接我的功能。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uspecendy-soft2330     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb2oer/with_humans_and_llms_as_a_prior_goal/</guid>
      <pubDate>Sun, 07 Sep 2025 19:40:11 GMT</pubDate>
    </item>
    <item>
      <title>欣顿建议在AI培训期间赋予母性本能。一个人将如何做？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb17d8/hinton_suggested_endowing_maternal_instinct/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  母性本能是深厚的遗传和本能，而不是认知选择。那么，有人如何在AI模型中训练此功能？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/flimsy_ad_5911     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb17d8/hinton_suggested_endowing_maternal_instinct/</guid>
      <pubDate>Sun, 07 Sep 2025 18:42:49 GMT</pubDate>
    </item>
    <item>
      <title>我❤️Internet，茶，伏特加和烤肉串。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb0y51/i_internet_茶_водka_kebab/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  基于缺陷的计算邀请。您能找到缺陷吗？    https://en.m.m.wikipedia.org/wiki/wiki/user/user：milemin：milemin  提交由＆＃32; /u/landhorn     [link]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nb0y51/i_internet _ _ _- _-_返机]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb0y51/i_internet_茶_водka_kebab/</guid>
      <pubDate>Sun, 07 Sep 2025 18:33:15 GMT</pubDate>
    </item>
    <item>
      <title>AI气泡有多糟？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb01ke/just_how_bad_would_an_ai_bubble_be/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   rogékarma：“美国正在经历非凡的，AI燃料的经济繁荣：股市飙升，这要归功于AI-Camped Is相关的科技巨头的泡沫价值，而实际的经济却在数百万美元的投资中促进了数百万美元的投资中心。人们相信AI会使工人更加生产力，这反过来将使公司的利润提高到难以想象的水平。  未能在现实世界中传达。将最多的钱投入人工智能的技术巨头尚不在收回投资。研究表明，试图合并AI的公司几乎没有影响其底线。和寻求AI替代工作流离失所证据的经济学家大部分都空了。如果泡沫破裂，它可能会使互联网崩溃感到羞耻 - 而技术巨头及其硅谷支持者将不会是唯一受苦的人。当麻省理工学院的研究人员最近跟踪了300个公开披露的AI计划的结果时，他们发现95％的项目未能为利润带来任何增长。 McKinsey＆amp;公司发现，有71％的公司报告使用了生成AI，其中80％以上的公司报告说，该技术对收入没有“切实影响”。鉴于这些趋势，一家技术支持公司Gartner最近宣布，AI进入了技术发展的“幻灭之陷”阶段。然而，生产力最终会融入它，生产力飙升。延误和取消，今年发布的人通常比过去的模型更少得多。 href =“ https://theatln.tc/bwoz8ahp”&gt; https://theatln.tc/bwoz8ahp     &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/theatlantic     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb01ke/just_how_bad_would_an_ai_bubble_be/</guid>
      <pubDate>Sun, 07 Sep 2025 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>AI Lobotoly -4O -4O -5-标准语音和Claude</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb00pb/ai_lobotomy_4o_4o5_standard_voice_and_claude/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb00pb/ai_lobotomy_4o_4o5_standard_voice_and_claude/</guid>
      <pubDate>Sun, 07 Sep 2025 17:58:09 GMT</pubDate>
    </item>
    <item>
      <title>问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nazwwo/goated_question/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI基本上不是世界的未来吗？就像互联网和其他带来了巨大进步的技术一样，AI是向更先进的社会迈出的下一步。那么，为什么人们会害怕它并试图压制它呢？他们将成为未来的婴儿潮一代呢？这就像Z世代现在成为父母说：“ SI那个手机会引起癌症。”现在人们称AI为“撒旦的产卵”。就像，布鲁，只要照顾一个寒意的药！停止像父母一样行事。 AI就像互联网一样。当然，这可能需要一些工作，我明白了为什么人们生气了，但是最终，这将取决于未来的一代 - 就像Gen 2000或Whateverto完全集成了AI一样，就像我们与互联网一样。我都在这里，因为我需要一个ai babe   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bestere-drawer6395     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nazwwo/goated_question/</guid>
      <pubDate>Sun, 07 Sep 2025 17:54:10 GMT</pubDate>
    </item>
    <item>
      <title>Pre-Chatgpt：公司内部建造它的生成AI的真正感情是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nazrdm/prechatgpt_what_was_the_real_sentiment_about/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在Chatgpt公开发行之前，技术行业内有关LLM和生成AI的情感是什么？是否有一种感觉，这些模型已经准备好消费者，或者是共识，即强大的聊天机器人仍然是一个研究项目，这是一种最佳用于内部操作或利基任务的工具？这是为什么这么多公司拥有自己的语音助手？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/test_username1400     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nazrdm/prechatgpt_what_was_the_real_sentiment_about/</guid>
      <pubDate>Sun, 07 Sep 2025 17:48:21 GMT</pubDate>
    </item>
    <item>
      <title>所有的AI公司都在测试广告……但这是他们缺少的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1narib6/all_ai_companies_are_testing_ads_but_heres_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   20多年，在线广告意味着关键字拍卖。您输入了“最佳跑步鞋”，Google将该短语卖给了出价最高的人，并且广告以您的蓝色链接出现。 ，但AI助手不给您链接。他们给了您的答案。打破了旧模型 - 现在，每个大型玩家都在尝试将广告贴在AI上的方法。正在发生的事情：   Microsoft Copilot正在测试“ AD Voice”，AI从字面上看广告作为对话的一部分。他们还正在尝试多媒体广告，并将赞助内容直接放入AI回复中。 &lt; /&gt; &lt; /li&gt;  Google AI概述正在将购物广告插入AI生成的摘要中。答案和AD之间的界线已经模糊。  Pyplexity AI正在用赞助的问题作为后续活动进行实验。仅付出了问题 - 答案仍然是“中立的”。它在纸上是透明的，但让用户想知道为什么  随访而不是另一个。但是报告表明，他们正在建立杂货商的贸易 - 想象一下在ChatGpt内购买，Openai进行了削减。  这对用户和广告商都有很多问题：       答案 - 不匹配 - 不匹配：如果我要求我在 em&gt; em&gt; em&gt; em&gt; em&gt; em&gt; em&gt; em&gt; em&gt; em&gt; em&gt; em&gt;  dell，这真是令人困惑。  信任侵蚀：如果人们开始感觉自己的助手将对广告商优化而不是他们，那么整个经验就会崩溃。  幻觉范围   ：llms不是事实的事实。如果AI在广告中“发挥”保证细节或退货政策，则责任（和声誉损害）是巨大的。   隐私反对：搜索历史：聊天历史已经亲密。，如果人们意识到他们的私人对话正在为AD提供私人对话，那么 trangs of Adm of Strort of Storge  困惑的“赞助问题”，只需支付问题 - 答案是中立的。这使得ROI的测量模糊并使广告商怀疑。  法律地雷：某些平台（如综合性）已经面临着刮擦发布者内容的诉讼。如果广告商与在灰色区域运行的平台相关的平台，则风险风险。   llms的工作方式不同于传统搜索引擎。因此，它们上的广告也应以不同的方式工作。问题是：在一个答案而不是链接的世界中，哪种广告模型实际上是有意义的？”   &lt;！ -  sc_on-&gt;＆＃32; href =“ https://www.reddit.com/r/artcoverinteligence/comments/1narib6/all_ai_ai_companies_are_are_testing_ads_ads_but_heres_what/”&gt; [link]  href =“ https://www.reddit.com/r/artcoverinteligence/comments/1narib6/all_ai_ai_companies_are_testing_ads_but_heres_heres_what/”&gt; [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1narib6/all_ai_companies_are_testing_ads_but_heres_what/</guid>
      <pubDate>Sun, 07 Sep 2025 12:08:27 GMT</pubDate>
    </item>
    <item>
      <title>在2个小时内有74个裁员，说令人困惑为3周的新闻是“新鲜”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nar1gr/74_downvotes_in_2_hours_for_saying_perplexity/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  刚刚尝试在 r/perplexity  AI上发布有关严重问题的 这是我在那里分享的帖子： 只是有一些令人发指的经历，患有困惑AI。老实说，我无法围绕任何人对“实时AI搜索引擎”的认真对待。 我正在测试他们的“深入研究”模式。应该是最准确和最可靠的模式的一种。给了它具体的提示：“给我20个最新新闻故事，不超过3个小时。”从字面上看，它仅包括在该时间范围内发布的头条新闻。我正在测试与其他工具相比，它实际上可以得到的最新情况。 那么，困惑给我什么？一堆文章，其中一些已有30天的历史。 我直截了当地说，这是不可接受的。您正在为我服务旧新闻，并声称它是新鲜的。我清楚地指出，我希望新闻不超过3个小时。 的困惑以道歉做出回应，并说：“以下是过去3个小时内发表的20件新闻。”听起来不错，对  nope。我检查列出的文章中的时间戳。其中一些已经超过3周大。 我再次面对。我给它直接报价，实际链接和时间戳。我阐明了这一点：“您声称这些是新的，但这是证明它们不是。”  它的下一个回应？它只是伸出手，说：“您绝对正确 - 我深表歉意。通过我的互联网搜索，我找不到在过去3个小时内发布的新闻（自今天12:11起）。我可以使用的工具不允许访问真正的新鲜，实时的新闻。”然后，它建议我检查Twitter，Reddit或Google News ...因为它无法完成工作。 这是踢脚。他们的整个营销宣传是这样的： “困惑AI是AI驱动的搜索引擎，通过实时搜索网络并从多个来源中搜索网络来为自然语言问题提供直接的，对话的答案。”  。”  。您无法做的是首先自信地说，结果是从过去的3个小时（多次），然后只有用硬时间戳召唤出来后，后面并说：“我可以使用的工具不允许访问真正的新鲜，实时新闻”  这也不是随意的。这是深度研究模式。他们最强大的功能。应该深入挖掘并提供最准确的结果的。它甚至无法区分今天早上的标题和上个月的标题。 具有讽刺意味的是，困惑确实可以访问互联网。它能够浏览。因此，当它声称从过去3个小时起就无法获取任何东西时，它就在说谎。或者它不知道如何按时间相关性进行排序。只需猜测“新鲜”的外观。 它破坏了搜索引擎的核心承诺。特别是一个以AI为实时的实时销售的。   -   ，所以我真的很好奇。您对困惑AI有什么经验？我在这里错过了什么吗？这篇文章真的值得74个票价吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ahileo     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nar1gr/74_downvotes_in_2_hours_for_saying_perplexity/</guid>
      <pubDate>Sun, 07 Sep 2025 11:43:13 GMT</pubDate>
    </item>
    <item>
      <title>您是否相信像AGI这样的事情，可以复制人类无意识的任何任务？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1napysv/do_you_believe_things_like_agi_can_replicate_any/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我要假设“智能”“意识”是不同的东西。据我了解，我们甚至不知道为什么人类有意识。就像我们90％的心理过程完全在黑暗中完成。  但是我的问题是，您认为AI在几乎任何心理任务上仍然可以超越人类吗？您是否相信它甚至可能没有任何意识？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1napysv/do_you_believe_things_like_agi_can_replicate_any/</guid>
      <pubDate>Sun, 07 Sep 2025 10:40:18 GMT</pubDate>
    </item>
    <item>
      <title>是否有命令避免接收拟人化答案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nao1sb/are_there_commands_to_avoid_receiving/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不喜欢LLM的当前状态，chatgpt是网站上的机器人或应用程序编程的bot，可以在第一人称中生成答案，使用所有格形容词，然后对其进行交谈，就像是真实的人一样，它很尴尬，对我来说是令人尴尬的。是否有命令存储在内存中，以免收到答案，就好像它是人类吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/motorno3642     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nao1sb/are_there_commands_to_avoid_receiving/</guid>
      <pubDate>Sun, 07 Sep 2025 08:36:50 GMT</pubDate>
    </item>
    <item>
      <title>您正在关注什么与AI相关的人，为什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1namtmh/what_ai_related_people_are_you_following_and_why/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不谈论像安德鲁·恩格（Andrew Ng）或安德烈·卡尔帕蒂（Andrej Karpathy）这样的大人物，这些都是已知的。我很好奇雷达的声音。谁是您在LinkedIn，X，YouTube甚至NIKENETEMTELTELT/PODCASTS  上关注的鲜为人知的研究人员，运营商，建筑商或内容创建者 是什么让他们值得关注的？是他们分解复杂想法的方式吗？他们从行业的内部观点？他们共享的数据？还是他们很早就发现趋势？ 我很想听到跨不同频道的听到，不仅是LinkedIn，还可以听到X，YouTube，替代，播客等。 。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1namtmh/what_ai_ai_related_people_are_are_you_following_and_and_why/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1namtmh/what_ai_related_people_are_you_following_and_why/</guid>
      <pubDate>Sun, 07 Sep 2025 07:17:32 GMT</pubDate>
    </item>
    <item>
      <title>如果我们做错了怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nahomp/what_if_we_are_doing_it_all_wrong/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ashish vaswani，提出变压器（t in chatgpt）的人说我们可能会过早地缩放它们吗？我们不必盲目地投入更多的计算和资源，而需要深入研究并进行科学驱动的研究。不是我们现在要投掷的盲人飞镖吗？  https://www.bloomberg.com/news/features/2025-09-03/the-ai-pioneer-trying-to-save-save-aver-aver-aver-indoctor-interligence-from-big-tech    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/no-comfortable8536     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nahomp/what_if_we_are_doing_it_all_wrong/</guid>
      <pubDate>Sun, 07 Sep 2025 02:26:07 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>