<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 23 Jan 2026 15:31:48 GMT</lastBuildDate>
    <item>
      <title>众包如何快速行动而不被起诉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qktaoc/crowdsourcing_how_move_fast_without_getting_sued/</link>
      <description><![CDATA[本周早些时候我发布了一篇文章，内容是关于我如何因 PoC 未获通过而受到指责，尽管该 PoC 是一个特别狡猾的人。感谢所有回复的人。我回来尝试保持理智 在您的组织中，AI 和 GenAI 是否通过现有的第三方风险或供应商保证途径，或者团队是否完成专门的 AI 风险和影响评估表格？ PoC 与试点和生产是否受到不同的对待，或者它们是否经历相同的治理大门？ PoC 是否有正式的“绿灯”步骤，或者在扩展之前是否更加非正式？ 我在一个非常大的组织中，我们发现很难调整控制规模。为企业规模、面向客户的生产系统设计的治理要求正在应用于早期的 PoC 和价值证明。结果是，实验在某些领域被扼杀，而在其他领域，人们完全回避治理，因为它感觉缓慢、不明确或不一致。它还在交付团队和风险职能部门之间造成了很多摩擦，而且仍然无法可靠地揭示真正重要的风险。 如果您找到了在实践中有效的方法，我很乐意听到它们。例如，您是否使用阈值或分层模型、具有硬性“禁止”规则的自助服务护栏、具有明确升级触发器的 PoC 轻量级批准，或者完全是其他东西？我不是在寻找理论框架。我正在寻找日常中真正有效的方法，包括您尝试过但失败的方法以及最终坚持下来的方法。   由   提交 /u/Existing_Ad3299   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qktaoc/crowdsourcing_how_move_fast_without_getting_sued/</guid>
      <pubDate>Fri, 23 Jan 2026 15:08:50 GMT</pubDate>
    </item>
    <item>
      <title>没有坏人的失败模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkse5k/failure_modes_with_no_bad_actors/</link>
      <description><![CDATA[当我问 ChatGPT 人们应该关心什么时，我总是得到类似的答复。 它标志着人们总是会被激励将决策和责任交给自动化的风险。我们多年来慢慢地这样做。当问题出现时，我们忘记了如何有效地破坏系统。 最终，当我们外包责任时，人类失去了社会的影响力和权力，最终变得依赖。  这种依赖关系可能看起来像是母亲或主人的关系。默认是主人，除非人们能够集体同意限制。 技术转移权力，当权力移动时，责任也应该随之而来。因为失败模式可能是不可挽回的，而且人们在设定界限时通常会对伤害做出反应，所以很可能所有人类最终都会被排除在外，并陷入过度优化的境地。 所需要的只是一个像公司这样的系统，来提供激励 相当令人震惊的事情，但这是有道理的。好奇其他人是否有意见。    由   提交/u/cosmonaut_88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkse5k/failure_modes_with_no_bad_actors/</guid>
      <pubDate>Fri, 23 Jan 2026 14:33:58 GMT</pubDate>
    </item>
    <item>
      <title>我认为我们需要一个新的聊天界面</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkrkv9/i_think_we_need_a_new_chatting_interface/</link>
      <description><![CDATA[我在 Reddit 上看到很多帖子抱怨 ChatGPT 中烦人的模型重新路由、免费用户的 ChatGPT 应用程序中弃用 GPT-4o 和（很快）5.1、Gemini 的内存问题以及其他问题。 如果我们能够完全控制选择我们想要的任何模型，所有这些问题肯定会得到解决，这让我思考关于自己构建一个聊天网站/应用程序。 你觉得怎么样？我的逻辑有问题吗？   由   提交/u/aurora_ai_mazen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkrkv9/i_think_we_need_a_new_chatting_interface/</guid>
      <pubDate>Fri, 23 Jan 2026 14:01:20 GMT</pubDate>
    </item>
    <item>
      <title>一位AI新手的笔记</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkqoau/notes_from_an_ai_novice/</link>
      <description><![CDATA[好吧，新手可能会慷慨一些。如果有傻瓜人工智能，我现在还处于第一章。到目前为止，我已经尝试了三种服务，结果好坏参半。不过我只花了不到两周的时间。 按时间顺序排列： A) Media.IO。从好的方面来说，它有一个简单、直接的界面。作为第一天的初学者，我对它在没有音频的情况下将静态图像带入逼真的生活印象深刻。但从那里开始走下坡路。提示 Media.io 类似于与只能理解几个英语单词的人交谈。即使我使用他们更明确的“优化”提示，它也常常与我的提示相反。特征。很多时候，结果都是非常奇怪的（我的小故事背景中的一匹马转身面对镜头，除了它有一张公牛的脸。哎呀！！）大约四分之一的时间我设法获得令人满意的结果，但最终我感到沮丧，因为它的使用成本并不便宜。在成绩单上，我会给它一个“D-”。 B) Adob​​e Firefly：我只让它在 Chrome 上运行，而不是在 Firefox 上运行。不过，大多数情况下，等待几分钟处理后，就会出现“无法上传”的提示。出现消息。有一次它说“我们的服务器正在融化”或类似的东西。我的内容没有任何挑衅性，所以我不认为这是问题所在。无论如何，我在继续之前并没有在这项服务上浪费太多钱。对我来说，我会给它评分“F”。 C) Kling：到目前为止，我通过这项服务获得了最好的结果。它在命令提示符方面也很困难，但它比 media.io（一个低标准）要好得多，而且大多数时候，只要有耐心（并花费一些积分），我就能获得满意的结果。然而，我最大的抱怨是克林有一种莫名其妙的脱离现实主义的倾向，而且我对创作动漫风格内容的兴趣为零。这是一个奇怪的怪癖，因为它经常渲染逼真的运动场景，而有时看起来很僵硬，以前令人信服的逼真角色变成了看起来俗气的卡通。根据我自己有限的经验曲线，我对克林的满意度评价为“B-”。总的来说，我对定价结构最感到沮丧。我建议采用一种系统，对于未下载就删除的结果使用较少的积分或退款，这种情况发生在一半以上。 我尝试了一些据称“免费”的方法。服务（混元是最新的），但在强制会员之前只需要测试一次。也许我没有使用正确的协议来让这些工作。 我希望听到其他初学者，特别是更高级用户的建议和技巧。   由   提交/u/Doggyman1202  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkqoau/notes_from_an_ai_novice/</guid>
      <pubDate>Fri, 23 Jan 2026 13:22:39 GMT</pubDate>
    </item>
    <item>
      <title>中国人工智能正在悄然蚕食美国开发者的午餐，并暴露出“开放”人工智能的一些奇怪之处</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkq97p/chinese_ai_is_quietly_eating_us_developers_lunch/</link>
      <description><![CDATA[在观看最近的 cnbc 文章后一直在思考这个问题。 Zhipu AI（中国实验室，刚刚在香港首次公开募股）不得不限制其 GLM-4.7 编码模型的订阅，因为太多人在使用它。正常的故事吧？除了他们的用户群主要集中在美国和中国，然后是印度、日本、巴西、英国。 让我们明白这一点。美国开发者，那些有权访问 gpt、claude、copilot、cursor 的人，正在选择数量足够大的中国开源模型，足以让他们的服务器崩溃。 美国实验室：建立最好的模型 → 关闭它 → 收取溢价 → 保护知识产权 → 利润最大化 中国实验室：建立一个足够好的模型 → 开源 → 价格非常便宜 → 获得大规模采用 → ??? GLM-4.7 在代码竞技场排行榜上排名第 6。它是开源的。显然它已经足够好了，美国开发者实际上正在将它用于实际工作，而不仅仅是测试。 如果查看开源排行榜，前 10 名模型中有 7 个是中国的。这不是“追赶”不再了。他们在开源方面处于领先地位，而我们却变得更加封闭。 如果你能以 10% 的成本构建一个 90% 的解决方案，并将其开源以便任何人都可以定制它，那么专有的 100% 解决方案对于大多数用例来说还重要吗？ 中国的人工智能战略似乎是“实际应用超过前沿”。他们并不是试图构建 AGI 或赢得基准。他们正在构建运行良好的工具，为它们定价以便每个人都使用它们，并将它们集成到实际的生产工作流程中。 与此同时，美国公司正在进行这场奇怪的军备竞赛，以打造“最先进”的产品。模型，同时充电更多并将其锁定得更紧。然后当开发人员把目光投向其他地方时表现得惊讶哈哈 如果这种趋势继续下去，中国模型主导开源+实际上很好+美国开发人员采用它们，这对美国人工智能生态系统的长期发展意味着什么？ 我们最终会出现两极分化的人工智能开发吗： 消费者人工智能=封闭的美国模型（chatgpt，claude） 开发人员工具/生产系统=开放的中国模型（GLM，deepseek，等） 因为这就是现在所显示的使用模式。 这里有人真正使用 GLM-4.7 进行编码工作吗？不是基准，例如实际生产使用。它与您之前使用的相比如何？ 因为如果它确实足够好+更便宜+开源，似乎是合乎逻辑的选择，除非您锁定到现有堆栈。也许这就是重点。   由   提交 /u/BlueDolphinCute   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkq97p/chinese_ai_is_quietly_eating_us_developers_lunch/</guid>
      <pubDate>Fri, 23 Jan 2026 13:04:06 GMT</pubDate>
    </item>
    <item>
      <title>机器上的 AGI 会像《星际穿越》中的 TARS 吗？还是会像钢铁侠的套房一样？你怎么认为 。想知道大家的想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkov4k/will_agi_on_machines_look_like_tars_from/</link>
      <description><![CDATA[与标题相同。机器上的 AGI 会像《星际穿越》中的 TARS 吗？还是会像钢铁侠的套房一样？你觉得怎么样   由   提交 /u/Gloomy_Temporary2914   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkov4k/will_agi_on_machines_look_like_tars_from/</guid>
      <pubDate>Fri, 23 Jan 2026 11:56:30 GMT</pubDate>
    </item>
    <item>
      <title>AI能打败验证码吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkoepz/can_ai_beat_the_captcha/</link>
      <description><![CDATA[我正在注册一些东西，一个验证码来了，要求我拿起桥梁的图片，这让我想到这些仍然是人工智能时代检测人类物体的相关工具。 AI能通过测试吗？    由   提交/u/Johnyme98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkoepz/can_ai_beat_the_captcha/</guid>
      <pubDate>Fri, 23 Jan 2026 11:31:20 GMT</pubDate>
    </item>
    <item>
      <title>2026 年 MCP - 很复杂</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qknr2k/mcp_in_2026_its_complicated/</link>
      <description><![CDATA[MCP 已成为连接外部工具的默认方式，其速度比任何人预期的都要快，而且我认为比安全性跟上的速度还要快。我试图以技术狂热者的方式总结这些挑战，希望对于刚刚进入该领域的人来说仍然可以访问。 https://write.as/iain-harper/tooling-around-letting-agents-do-stuff-is-hard 这是对（更长）我几周前写的企业代理安全概述，因为只简要提到了 MCP： https://iain.so/security-for-product-ai-agents-in-2026 一如既往，我们非常感激您的任何想法、评论或批评。我构建机器学习部署和企业代理已经有大约七年了，我们正处于一个非常有趣的时刻，拥有所有这些技术和一些固定的方法；这确实感觉像是网络的早期。   由   提交 /u/iainrfharper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qknr2k/mcp_in_2026_its_complicated/</guid>
      <pubDate>Fri, 23 Jan 2026 10:53:17 GMT</pubDate>
    </item>
    <item>
      <title>你有大约 5 年的时间来摆脱 K 型经济的底部</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkn56i/you_have_5_years_to_escape_the_bottom_arm_of_the/</link>
      <description><![CDATA[我一直在思考这个人工智能的实际发展方向，但我一直有同样令人不安的想法： 我们正在进入 K 型经济，从一侧跳到另一侧的窗口正在快速关闭。 在上臂：拥有东西的人。企业、知识产权、发行、受众、股权等等。人工智能使他们提高生产力，降低成本，并让他们比以前更快地扩大规模。 最底层：那些用时间来解决问题的人。这是没有人真正愿意承认的部分 - 人工智能正在减少实际上需要人类解决的问题的数量。 不会减少到零。但较少。并且更具竞争力。 现在，您仍然可以在两者之间移动。你仍然可以构建一个小型 SaaS，控制一个利基工作流程，拥有一个受众，创造某种杠杆，而不仅仅是用时间换取金钱。 但我不认为这个窗口永远开放。 我的猜测是，未来 5 年左右的时间比人们意识到的要重要得多。此后，差距就会扩大。不是因为人们变得懒惰或停止尝试，而是因为人工智能将执行成本降至基本为零，资本和分配开始主宰一切，资产所有者只是继续复利，而其他人都在争夺废料。 这并不是什么厄运。这只是经济学101。 我并不是说每个人都需要成为亿万富翁。但从现在开始，纯粹依靠出卖时间的风险每年都在增加。 我对其他人如何看待这个问题很感兴趣。 K型是不可避免的吗？或者人工智能真的会长期重新开放流动性吗？如果您不同意，您认为对于那些不拥有资产的人来说，新价值从何而来？ 真诚地想听到反驳意见。   由   提交 /u/Genstellar_ai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkn56i/you_have_5_years_to_escape_the_bottom_arm_of_the/</guid>
      <pubDate>Fri, 23 Jan 2026 10:16:05 GMT</pubDate>
    </item>
    <item>
      <title>聊天盒范式正在成为复杂人工智能研究的瓶颈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkmvtd/the_chatbox_paradigm_is_becoming_a_bottleneck_for/</link>
      <description><![CDATA[过去两年我们一直在对待高维引擎，就像它们只是 Whatsapp 的更好版本一样。聊天界面是采用的一个很好的起点，但它正在成为任何试图建立真正知识库的人的巨大瓶颈。 问题在于线性。聊天线程是一维的，但向量嵌入是多维的。当您尝试综合 50 篇研究论文或一个月的会议记录时，您不需要可滚动的历史记录。你需要一张地图。 我一直在寻找真正试图解决空间问题的工具，而不是仅仅在侧边栏添加另一个聊天机器人。我最近开始使用 getrecall，新的图形视图更新是我第一次感觉到我实际上正在浏览我的数据。它按语义对源进行聚类，这样您就可以看到您在 12 月阅读的 pdf 与您昨天保存的 YouTube 视频之间的关系。 我觉得这将交互从搜索转变为导航。我可以看到围绕特定主题形成的集群，并激发了线性聊天线程永远不会出现的联系。 行业是否会朝着这种空间范式发展，还是我们会永远停留在聊天框上？这感觉就像是 rag 的自然演变，但我很好奇其他人是否认为可视化地图方法实际上适用于大量工作。   由   提交 /u/Significant_Capita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkmvtd/the_chatbox_paradigm_is_becoming_a_bottleneck_for/</guid>
      <pubDate>Fri, 23 Jan 2026 10:00:50 GMT</pubDate>
    </item>
    <item>
      <title>AI，是不是让实力较弱的同事看起来不错，却没有实质内容？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkxvp/ai_is_it_making_the_weaker_colleagues_look_good/</link>
      <description><![CDATA[我是那种把人工智能作为最后一步的人，我不希望自己失去研究事物的能力。我是一名 IT 工程师，我感到在我的任务中越来越多地采用它的压力，老实说我发现它令人窒息。我的工作很出色，不需要完全依赖它，所以我不确定为什么我必须尽可能多地使用它。无论如何，这不是我写这篇文章的原因，而是我有一个更弱的同事，他一直依赖人工智能来完成任务和帮助。在人工智能出现之前，他无法以务实的方式解决问题，我猜他从来没有学过。然而，我有一种感觉，因为它，他现在才能够完成他的工作。我想进行一次讨论，并找出你对此的想法......它有效地使工作中表现不佳的人看起来非常好，而实际上它是假的。我知道我的同事缺乏知识，但却依赖人工智能： 你的想法是什么？   由   提交/u/Necessary_Ad_1450   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkxvp/ai_is_it_making_the_weaker_colleagues_look_good/</guid>
      <pubDate>Fri, 23 Jan 2026 07:59:14 GMT</pubDate>
    </item>
    <item>
      <title>当大型模型接受越来越多的人工智能生成文本的训练时会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qjzdkd/what_happens_when_large_models_are_trained_on/</link>
      <description><![CDATA[我对这种方式思考得太多了，请有知识的人澄清一下这里实际上可能发生的情况。 现在越来越多的互联网是由人工智能编写的。 博客文章、文档、帮助文章、摘要、评论。 你读了它，它有意义，你继续前进。 这意味着未来的模型将根据早期模型的内容进行训练已经写过了。当 ChatGPT 以同样谨慎、对冲的语气解释截然不同的主题时，我已经注意到了这一点。 这不是一个循环吗？ 我还不太明白这一点，这可能就是它困扰我的原因。 我不断重复这样的问题：  随着时间的推移，某些写作模式会开始强化自己吗？ （看着你破折号） 商标中立、对冲的语言会一代又一代地堆积起来吗？ 解释是否开始转向最安全、最通用的版本，因为这就是生存的原因？ 数据中已经很少见的边缘案例、奇怪的想法或少数观点会发生什么？  我也开始怀疑一些即时的“最佳实践”是否会强化这一点，通过奖励安全、平均的输出，而不是风险较高的输出。 我知道当前的模型训练已经使用过滤、重复数据删除和加权来减少模型生成的上下文的影响。 我更好奇的是，如果人工智能编写的文本在统计上占主导地位，会发生什么。 这不是一篇“人工智能造成的世界末日”帖子。 而且它实际上与任何模型无关具体来说。所有大规模训练的大型模型似乎都暴露在这一点上。 我无法判断这最终是否会产生更清洁、稳定的系统，或者是否会趋向于礼貌、安全的声音，一切听起来都一样。 可能其中一件事情稍后会变得显而易见，但我不知道这对互联网上的内容意味着什么。 如果有人看过对此的可靠研究，或者从其他反馈循环系统中获得直觉，我会真的很喜欢听。   由   提交/u/SonicLinkerOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qjzdkd/what_happens_when_large_models_are_trained_on/</guid>
      <pubDate>Thu, 22 Jan 2026 16:37:53 GMT</pubDate>
    </item>
    <item>
      <title>如果你的国家不建立自己的人工智能模型，它将外包其文化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qjxdln/if_your_country_doesnt_build_its_own_ai_models_it/</link>
      <description><![CDATA[我最近在 WEF 上观看 Jensen Huang 和 Larry Fink 的演讲，他们谈到了一些大多数国家还没有准备好听到的残酷事实。 我们主要从生产力、就业或哪家公司“获胜”的角度来谈论人工智能。但有一件更安静的事情感觉同样重要： 如果一个国家不建立（或至少认真适应）自己的人工智能模型，它不仅仅是进口技术 - 它接受别人的世界观作为默认。 语言模型不只是生成文本。它们编码假设：  什么是正常或异常 如何处理分歧 如何解释法律、道德、社会规范 哪些背景被忽略  当今大多数前沿模型都是根据少数国家的数据、激励措施和世界观进行训练的。不是阴谋——只是训练数据和资金的运作方式。 这才是像欧洲和印度这样的地方真正重要的地方。 欧洲在科学、制造、监管、社会系统方面拥有深厚的实力——但如果完全依赖外部人工智能，这些系统就会受到其他人逻辑的调节。 印度拥有更独特的东西：巨大的语言多样性、文化差异、现实世界的复杂性。如果印度用户只与在其他地方训练的人工智能进行交互，那么“默认智能”就会消失。即使界面是本地化的，他们得到的也不会反映现实。 Jensen 提出了一个固定的观点：人工智能正在成为基础设施。每个国家都有道路和电力。人工智能正在进入同一类别。您可以导入它 - 但随后您还可以导入决策的制定方式。 问题是，这并不像以前那么难。借助开放模型、微调和本地数据，各国无需从头开始构建一切。但他们确实需要使用以下方式积极塑造人工智能：  当地语言和方言 法律和社会背景 文化边缘案例  否则，你得到的人工智能在技术上会说你的语言，但不会在你的世界中思考。 风险并不是一夜之间戏剧性地失去控制。它更加渐进：随着时间的推移，判断、解释、决策将通过并非由您的社会塑造的系统正常化。 其他人对此有何看法：人工智能主权是否与能源或数据主权一样重要 - 或者我是否高估了文化背景在人工智能中的实际重要性？   由   提交 /u/Genstellar_ai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qjxdln/if_your_country_doesnt_build_its_own_ai_models_it/</guid>
      <pubDate>Thu, 22 Jan 2026 15:23:53 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>