<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 30 Nov 2025 15:22:04 GMT</lastBuildDate>
    <item>
      <title>Alphafold人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1paksnb/alphafold_ai/</link>
      <description><![CDATA[ https://www.technologyreview.com/2025/11/24/1128322/whats-next-for-alphafold-a-conversation-with-a-google-deepmind-nobel-laureate/?utm_source=engagement_email&amp;utm_m edium=email&amp;utm_campaign=wklysun&amp;utm_term=11.30.25.subs_eng.Cyber25_ENG3&amp;utm_content=CYBER25_DEFAULT_ACQ&amp;mc_cid=3d0770b026&amp;mc_eid=69f6f28ed7   由   提交 /u/StemCellPirate   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1paksnb/alphafold_ai/</guid>
      <pubDate>Sun, 30 Nov 2025 15:20:41 GMT</pubDate>
    </item>
    <item>
      <title>Tri-AGI治理：超级智能人工智能的思想实验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1paii9c/triagi_governance_a_thought_experiment_on/</link>
      <description><![CDATA[简介 人类不断地犯同样的错误。贪婪、腐败、战争和短视似乎根植于我们的运作方式中，即使我们试图创建公平的系统，人性也常常成为阻碍。 人工智能也许能够做得更好。但将所有权力赋予单个超级智能人工智能是有风险的——它可能会误解规则，以我们意想不到的方式行事，或者做出最终伤害人类的决定。 所以我开始思考：如果我们不只依赖一个人工智能，而是依赖三个人工智能会怎样？三个独立的人工智能共同做出决策，每个人工智能都关注其他人工智能，并且都以关注人类福祉和繁荣的道德指南针为指导。 系统如何工作  三个独立的人工智能  每个人工智能都在单独的硬件和训练系统上运行，因此没有一个人工智能可以控制。 它们进行沟通以达成决策，如果不同意，它们会计算出折衷的解决方案。  核心原则  道德罗盘：所有三个人工智能都以实现人类繁荣、自由和福祉最大化为目标进行训练。 制衡：每个人工智能都可以专注于不同的领域： 一个负责处理伦理和道德，确保考虑到人类尊严和痛苦。 一个专注于效率、资源和长期规划。 一个确保稳定性、监督：如有必要，人类可以使用需要多个国家同意的全球关闭系统进行干预，以防止单方面滥用。  记忆和训练  每个人工智能都从一张“白板”开始，没有偏见、记忆或情感包袱。 它们接受过训练，能够理解人类的价值观和规则，因此它们的行为与人类的利益保持一致。  自由和福祉是他们所做的一切中不可协商的约束。 为什么这会起作用 防止单点故障：没有一个人工智能可以单独行动而犯下灾难性错误。 避免极端解释：像“最小化痛苦”这样的规则不能被扭曲，因为所有三个人工智能都必须同意，并且系统会评估妥协以实现平衡。 表现优于其他人人类：人类会因为情绪、贪婪和偏见而犯错误。三人工智能系统可以进行长期规划，处理大量信息，并一致行动。 内置安全性：多国关闭系统确保人类在紧急情况下保持控制。 潜在挑战 衡量人类福祉和繁荣很复杂，可能需要仔细设计。 即使是分离的人工智能理论上也可能会集中在有害的解决方案上，尽管物理和软件分离可以降低这种风险。  各国需要信任并采用关闭系统。 编码没有漏洞的普遍道德仍然是一个难题。 结论 一个拥有三个独立超级人工智能的系统，在道德指南针和制衡的指导下，理论上可以比人类更安全地进行治理。它不会是完美的，但它可以减少痛苦，防止灾难性错误，并帮助人类繁荣发展。 这是一个推测性的想法，但思考它突显了在人类不再是唯一决策者的未来治理如何发挥作用。   由   提交/u/Which-Development779   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1paii9c/triagi_governance_a_thought_experiment_on/</guid>
      <pubDate>Sun, 30 Nov 2025 13:38:40 GMT</pubDate>
    </item>
    <item>
      <title>我如何不再永远失去良好的 ChatGPT 聊天</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pae20g/how_i_stopped_losing_good_chatgpt_chats_forever/</link>
      <description><![CDATA[我意识到我与 ChatGPT 进行了 50 次同样的“精彩对话”……然后让它随着聊天历史一起消失。 所以我翻转了它： • 选取最好的部分， • 将它们变成内核（它应该如何思考）， • 添加了一些模式（学习/构建/战争/修复）， • 并为我实际做的事情插入模块（业务、内容等）。 现在，我不再祈求一个好的答案，而是说： “构建模式+内容模块：为此评论写 3 个 Reddit 回复[粘贴]。” 相同的模型，更少的混乱。 还有其他人在做这样的事情，还是你还生活在“新聊天、新大脑”模式中？    由   提交 /u/Tall-Region8329   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pae20g/how_i_stopped_losing_good_chatgpt_chats_forever/</guid>
      <pubDate>Sun, 30 Nov 2025 09:20:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么有些人会感觉到人工智能系统中的“差距”——为什么注意到这些差距感觉像是一种技能而不是批评？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1paaqh6/why_do_some_people_perceive_gaps_in_ai_systems/</link>
      <description><![CDATA[为什么有些人会自然地注意到人工智能系统中的“差距”——微妙的不一致、缺失的部分或结构性盲点，而其他人甚至没有注意到它们？ 我一直在思考这个问题。 每次我与人工智能互动时，我的注意力都会自动“锁定”那些感觉不存在、不是错误、只是缺失的空间。不是错误，而是模式中的差距。 感觉不像批评，感觉像是一种感知模式（几乎就像注意到艺术中的负空间或节奏中缺失的节拍）。 与我交谈的一些人说他们根本没有经历过这种情况。其他人说这是他们与系统交互的唯一方式。 所以我很好奇：这是一种认知方式吗？模式识别的一种形式？训练有素的技能？或者关于我们如何感知结构和连贯性的问题？ 如果你也注意到差距 - 这个过程从内部感觉如何？   由   提交 /u/No_Afternoon4075   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1paaqh6/why_do_some_people_perceive_gaps_in_ai_systems/</guid>
      <pubDate>Sun, 30 Nov 2025 05:53:20 GMT</pubDate>
    </item>
    <item>
      <title>“即使我们在技术上取得了进步......我也会删除任何不是净资产的人”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1paag6i/even_as_we_have_progressed_technologically_i_will/</link>
      <description><![CDATA[没有比这更清楚的了。 自动化并不能解决潜在的有限资源问题。它并不能解决 100 倍的有毒污泥问题。 如果自动化让东西变得更便宜，显着增加全球消费，我们可能很快就会耗尽铜、银和其他关键矿物。 在这样的世界中，那些不是“净资产”的人会发生什么？ 社会找到合作方式的原因是因为我们需要彼此。 但是有了完全自动化，我们当然不需要每个人其他。 如果我们进行核聚变并开采小行星，那是可行的。但我们没有，也不是。与自动化相比，这些目前都是白日梦。 当前水平的自动化是可行的，但目前自动化程度提高的速度太快。 举个例子：这就是电价上涨的原因。我们需要放慢新的自动化速度，并提高发电效率。   由   提交 /u/kaggleqrdl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1paag6i/even_as_we_have_progressed_technologically_i_will/</guid>
      <pubDate>Sun, 30 Nov 2025 05:37:22 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 11/29/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pa9pgl/oneminute_daily_ai_news_11292025/</link>
      <description><![CDATA[ AI 帮助推动黑色星期五在线支出创纪录的 118 亿美元。[1] StepFunAI 发布 Step-Audio-R1：一种新的音频 LLM，最终受益于测试时计算扩展。[2] Musk 的 xAI 在 Colossus 数据附近建造小型太阳能发电厂center.[3] 你秃头了吗？有一个人工智能可以做到这一点。[4]  来源包括：https://bushaicave.com/2025/11/29/one-million-daily-ai-news-11-29-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pa9pgl/oneminute_daily_ai_news_11292025/</guid>
      <pubDate>Sun, 30 Nov 2025 04:58:18 GMT</pubDate>
    </item>
    <item>
      <title>人工智能中的能源使用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pa7nkc/energy_use_in_ai/</link>
      <description><![CDATA[嗨！我目前正在写一篇关于人工智能中能源使用的论文，以及它如何根据人工智能进程的时长而变化。有没有人有一些好的资料来讨论它或有我可以使用的数据？ 非常感谢您的帮助！   由   提交/u/Bluebird8683  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pa7nkc/energy_use_in_ai/</guid>
      <pubDate>Sun, 30 Nov 2025 03:10:02 GMT</pubDate>
    </item>
    <item>
      <title>直觉=真正的智慧</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pa233v/gut_feelings_real_intelligence/</link>
      <description><![CDATA[我们从人工智能中学到的是，直觉是被掩盖为不可靠情绪的真实智力。人们所说的直觉是大脑无需进行数学运算就能将数以百万计的过去模式分解为单个信号的能力。 以下是人工智能如何计算下一步要执行哪个动作： Value(state) = i_f1 (importance1xfeature1) + i_f2 + i_f3 ...... 等等 if value(next_state) &gt; value(current_state):execute_move() 这是人类如何计算下一步要做什么的：“根据我迄今为止所经历的一切，我的直觉会说什么”人类越能倾听直觉（又名分析结果），他们做出的决定就越好。 -哪个更可靠？艾绝对。因为它绘制了流程，并且能够根据命令可预测地重复该流程。 -到 2025 年，哪个实际上更准确？毫无疑问仍然是人脑！直觉感觉不可靠，因为我们不了解这个过程。   由   提交/u/shoman230  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pa233v/gut_feelings_real_intelligence/</guid>
      <pubDate>Sat, 29 Nov 2025 22:45:24 GMT</pubDate>
    </item>
    <item>
      <title>6 个人正在悄悄决定人类的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9u324/6_people_are_quietly_deciding_the_future_of/</link>
      <description><![CDATA[你们对未来有何看法？第三个选择是什么？ &quot;...现在的未来是两种结果之一， 要么你将这项技术大规模分散给每个人，这会造成法治无法预防的灾难。 或者这项技术集中在公司或政府中，可以创建大规模监视状态或自动化机器人...” https://www.youtube.com/watch?v=BFU1OCkhBwo   由   提交 /u/rexray2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9u324/6_people_are_quietly_deciding_the_future_of/</guid>
      <pubDate>Sat, 29 Nov 2025 17:08:43 GMT</pubDate>
    </item>
    <item>
      <title>分析：OpenAI 是一台亏损机器，预计到 2030 年它没有盈利之路——即使实现盈利，还需要 2070 亿美元的资金</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9lmwz/analysis_openai_is_a_lossmaking_machine_with/</link>
      <description><![CDATA[https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/analysis-openai-is-a-loss-making-machine   由   提交/u/ZacB_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9lmwz/analysis_openai_is_a_lossmaking_machine_with/</guid>
      <pubDate>Sat, 29 Nov 2025 10:21:29 GMT</pubDate>
    </item>
    <item>
      <title>当谷歌拥有他们已经搜寻了近十年的海量 YouTube 数据时，为什么 Gemini 还没有脱颖而出呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9kt8h/how_come_gemini_is_not_head_and_shoulders_above/</link>
      <description><![CDATA[YouTube 上的数据量让我难以置信。即使只提取基于文本的数据，这仍然是巨大的。还添加用户的所有使用情况和反馈数据。然后添加相应的视觉数据。 “到 2024 年，用户每天观看超过 10 亿小时的 YouTube 内容。” OpenAI、xAI、Anthropic 和中国人也能以某种方式抓取这些东西吗？ 或者 Google 是否受到计算的限制而无法进行如此大规模的训练？ 是否 Gemini/AGI 对他们来说根本不是那么重要，而他们把最多的精力放在了上面。他们将时间投入到更小的领域，例如蛋白质折叠和自动驾驶？ 也许当前没有足够有效的算法来利用所有这些数据？   由   提交 /u/NoGarlic2387   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9kt8h/how_come_gemini_is_not_head_and_shoulders_above/</guid>
      <pubDate>Sat, 29 Nov 2025 09:30:16 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能水危机”已经到来：由于地区干旱，亿万富翁向谷歌数据中心投资 50 亿美元。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9jpbj/the_ai_water_crisis_is_here_billionaire_invests/</link>
      <description><![CDATA[昨天，我们讨论了 Google 通过Project Suncatcher 将计算转移到太空，以摆脱地球的能源限制。 今天，现实离我们更近了。 新闻： Adani Group （由亚洲首富领导）确认与 Google 建立价值 50 亿美元的合作伙伴关系，以建设大型人工智能数据中心。虽然头条新闻正在庆祝“人工智能繁荣”，但物理现实要黑暗得多。 1.渴望 1 吉瓦：规划的集群目标是达到1 吉瓦容量。 * 物理原理： 这种规模的数据中心不仅需要电力，还需要水来冷却。 每天数百万升。 * 这些设施是在已经面临长期缺水和地下水枯竭的地区建造的。 2.全球分裂：我们看到各地区在处理“人工智能墙”方面存在可怕的分歧。  美国：微软重启三哩岛（核能）以解决能源问题。 Google 全球：计划轨道 TPU（太空）解决热能问题。 新兴市场：在可能没有水支持的土地上强行建设。  3. “人权”警告这不仅仅是一个技术问题。当地团体已经发出警报，称引水冷却 H100/TPU 可能会给当地人带来饮用水危机。 底线：资金流入基础设施的速度快于环境的适应能力。 我们正在进入一个阶段，您的人工智能提示不仅与空调竞争电力，而且与某人的农场竞争水。 这是发展还是我们正在清算自然资源训练模型？ 来源： 路透社   由   提交 /u/BuildwithVignesh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9jpbj/the_ai_water_crisis_is_here_billionaire_invests/</guid>
      <pubDate>Sat, 29 Nov 2025 08:20:09 GMT</pubDate>
    </item>
    <item>
      <title>用于人工智能的高性能 GPU 通常会在 2-3 年内变得经济过时，</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9hl0d/highperformance_gpus_used_for_ai_often_become/</link>
      <description><![CDATA[高性能 GPU 已成为全球人工智能生态系统的核心。它们为先进模型提供支持，支持云规模计算，并支持跨行业不断增长的人工智能驱动应用程序。对于云提供商、超大规模数据中心和专注于人工智能的公司来说，GPU 不仅仅是硬件，而且是主要的资本投资。围绕这些资产的财务和运营决策对盈利能力、现金流和战略规划具有重大影响。 最近讨论的一个核心争论点是 GPU 折旧：这些芯片失去经济价值的速度有多快以及这如何反映在公司财务中。批评者认为，包括英伟达和超大规模企业在内的一些公司可能低估了折旧，使用了跨越五六年的时间表。他们认为，这可能会夸大报告的利润，并掩盖硬件磨损和过时的经济现实。较长折旧计划的拥护者反驳说，延长使用寿命是通过操作实践来证明的，包括级联工作负载、维护计划以及旧 GPU 持续用于要求较低的任务。 来源   由   提交 /u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9hl0d/highperformance_gpus_used_for_ai_often_become/</guid>
      <pubDate>Sat, 29 Nov 2025 06:13:35 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对程序员的威胁大于软件架构师</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/</link>
      <description><![CDATA[31 年前获得计算机科学学位。我职业生涯的前 10 年一直在编写代码，最后 20 年则混合了软件架构、管理、项目管理和程序管理。 “牧猫”这是一个恰当的描述。我对氛围编码感到震惊（风帆冲浪现在是我的主要爱好。）在我看来，对编码员的需求正在消失。人工智能现在可以更好、更快地编码。然而，目前它还无法构建大型系统。它做出了非常糟糕的选择。我可以更快地构建很多东西，但我必须利用我在软件架构中学到的所有知识来完成它。我经常忽视人工智能架构建议。 问题是我主要通过编码来学习构建软件。此外，大学在 CSC 课程中仍然主要教授编码，并且没有适应。那么，如果不需要编码，我们如何构建未来的架构师呢？   由   提交 /u/pbmadman1994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/</guid>
      <pubDate>Sat, 29 Nov 2025 02:48:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>