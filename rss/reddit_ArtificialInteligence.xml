<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 12 Feb 2026 15:57:27 GMT</lastBuildDate>
    <item>
      <title>帮助工作的人工智能工具 - 可搜索的知识中心、结构化数据和跟踪</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wzwn/ai_tool_to_help_with_work_searchable_knowledge/</link>
      <description><![CDATA[嗨。我是一名医疗账单员/编码员，还负责认证、一般团队支持和一些实践管理。我正在尝试为我的日常工作构建一个更有组织性、人工智能辅助的工作流程和数据库。 现在，所有内容都分布在文件夹、PDF（LCD、NCD、付款人手册、编码指南、计划福利文档等）和多个电子表格中。我花了很多时间一遍又一遍地搜索相同的信息，例如及时提交限制、上诉截止日期、事先授权要求以及计划的一般承保规则。我需要在 3 个屏幕上工作，并打开数十个选项卡。我有一个简单的任务管理器，但我发现更多地使用笔和纸或快速记事本笔记，因为它更快。 我希望找到一个工具（最好免费或低于 20 美元/月），它可以让我上传所有保险手册、我现有的笔记、电子表格和任何相关文档，然后使用人工智能自动提取关键规则并将它们组织到结构化表格/数据库中。例如，如果我上传付款人手册，它会识别诸如索赔及时提交、更正的索赔限额、上诉提交截止日期、身份验证要求等内容，并将其填充到特定的数据库字段中。然后，我可以轻松地查看并排比较所有付款人和计划的表格，而不必每次都翻阅 PDF 和表格。 我还希望同一个系统能够兼作跟踪器（即凭证和合同），在其中我可以跟踪哪些提供商与哪些付款人处于网络中、提交凭证的时间、预期审核时间表、后续提醒、合同续签日期等。 并且还有一个聊天式任务处理程序，我可以在其中添加快速注释并让人工智能组织这些注释，或者设置提醒。 理想情况下有一个聊天界面，这样我就可以提出一些快速问题，例如“X 计划是否需要 CPT Y 的身份验证？”或“如何及时针对 X 计划提出上诉？”并让它从文档或结构化数据库中提取答案。 我会避免存储任何 PHI，但如果平台安全且符合 HIPAA，那就更好了。我对在线平台或本地运行感到满意。我听说过 Airtable 和 Notion，但我从未使用过它们，所以不确定它们是否合适。如果我也可以合并的话，我已经订阅了 ChatGPT Plus。 有人知道执行此操作的可靠方法或现有平台吗？   由   提交 /u/magnumpl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wzwn/ai_tool_to_help_with_work_searchable_knowledge/</guid>
      <pubDate>Thu, 12 Feb 2026 15:51:24 GMT</pubDate>
    </item>
    <item>
      <title>Opus 4.6 上下文检索与大型存储库的 GPT-5.3</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wwm6/opus_46_context_retrieval_vs_gpt53_for_large_repos/</link>
      <description><![CDATA[我一直在针对我正在重构的相当混乱的遗留存储库运行新的 Opus 和 GPT-5.3。 Opus 上的 1M 上下文实际上在依赖项跟踪方面比我预期的要好 - 它发现了我错过了三次的循环导入。 GPT-5.3 似乎在为新模块生成样板文件方面更快，但昨天它两次删除了全局类型文件上的上下文。 Opus 速度较慢，但​​对于深层架构而言感觉更稳定。 还有其他人看到这种差异吗？或者我只是运气好，看到了 Opus 提示？   由   提交 /u/HarrisonAIx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wwm6/opus_46_context_retrieval_vs_gpt53_for_large_repos/</guid>
      <pubDate>Thu, 12 Feb 2026 15:47:43 GMT</pubDate>
    </item>
    <item>
      <title>Claude Code Agent Teams：您现在是 AI 开发团队的首席执行官（感觉就像一场游戏）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wudf/claude_code_agent_teams_youre_now_the_ceo_of_an/</link>
      <description><![CDATA[ https://preview.redd.it/7u4lv4lw33jg1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=5b1aa2bde5f7b33709ca7992222ce07eb7961da1 Claude Code 刚刚推出了 Agent Teams，它改变了游戏规则。 您现在可以并行运行多个 AI 代理，每个代理都在自己的窗格中，同时处理项目的不同部分。他们相互沟通，协调任务，你可以在任务中与他们中的任何一个互动。 它基本上将 Claude Code 从单个 AI 开发人员转变为你实时管理的完整小队。您分配角色，分发任务，然后观察它们的执行，就像您自己的人工智能工程团队的领导一样。 让我惊讶的是，您可以在代理工作时向他们发送消息。真正的实时协作。需要代理 B 等待代理 A 的输出吗？他们明白了。想在构建中期改变方向吗？只要告诉他们即可。 这个功能让人工智能编码感觉像是一个真正的新范式。不是“更好的自动完成”，而是实际的并行团队协调。 如果您使用 Claude Code，强烈建议您尝试一下。   由   提交 /u/Delicious_Air_737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wudf/claude_code_agent_teams_youre_now_the_ceo_of_an/</guid>
      <pubDate>Thu, 12 Feb 2026 15:45:21 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能夺走了我们的工作（大多数人失去了工作），为什么我们认为拥有土地的人会让我们免费住在那里，拥有土地和生产食物的农民会让我们免费吃饭，工厂主会免费为我们生产东西，即使政府试图帮助失业者。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wjyl/if_ai_takes_our_jobs_majority_of_people_lose/</link>
      <description><![CDATA[如果人工智能夺走了我们的工作（大多数人失去了工作），为什么我们认为拥有土地的人会让我们免费住在那里，拥有土地并生产食物的农民会让我们免费吃饭，工厂主会免费为我们生产东西，...，即使政府试图帮助我们，为什么拥有东西的人会遵守。   由   提交 /u/Ok_Platform_7864   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2wjyl/if_ai_takes_our_jobs_majority_of_people_lose/</guid>
      <pubDate>Thu, 12 Feb 2026 15:33:56 GMT</pubDate>
    </item>
    <item>
      <title>帮我解决一下？懒惰行为</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2td2h/help_me_fix_lazy_behaviors/</link>
      <description><![CDATA[我在使用 Ai（使用张开爪）准确完成工作时遇到一些困难。无论我尝试哪种模型或非常明确的提示，似乎需要重复任务或耐心或双重检查的事情都很少能正确完成。我有最近任务中的两个例子： 学术幻灯片： - 我让人工智能提出了一个幻灯片的规范和计划，并为每个任务协调子代理。它适当地进行了公开搜索，审查了文件，提出了摘要和大纲。当需要下载所需的 pdf 和图表时（这需要从不同网页手动下载最多 50 个图表），它总是无法完成任务。当它说已完成时，通常带有未保存的数字和占位符。我尝试给出明确的提示，更改为昂贵的模型，要求谷歌通过 cli 执行，要求它仔细检查等，但没有任何解决办法，以便它实际上会坚持工作，直到获得所有数字。  任务 2：我要求它根据包含我所有交易的 pdf 文件对我的股票投资组合进行分析。它再次创建了规范和计划。它似乎很好地跟踪了我的交易，但最终结果总是失败。我尝试了 opus、gpt、sonnet 和 Gemini 等所有内容，但数字仍然不一致。我让他们去调查、审计，他们也想不出来。我最终手动返回，发现他们在搜索当前价格时始终为某些股票分配了错误的值（例如克劳德随机给许多股票分配了 25 美元的价格 - 我假设在网上搜索价格时 NA 后）。令人沮丧的是，因为我多次询问它以确保所分析的所有股票都有正确更新的市场价格，但显然它只是跳过了很多股票。这真的令人愤怒，因为它所做的其他事情都令人惊叹。分析的结果超出了输入值，但不知何故，由于懒惰（一致）而弄乱了输入，这意味着任务永远无法完成。    由   提交 /u/oikk01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2td2h/help_me_fix_lazy_behaviors/</guid>
      <pubDate>Thu, 12 Feb 2026 13:25:58 GMT</pubDate>
    </item>
    <item>
      <title>2026 年大规模处理 GenAI 政策执行、信任和安全的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2sqks/best_ways_to_handle_genai_policy_enforcement_and/</link>
      <description><![CDATA[扩展我们的 GenAI 和 UGC 平台使政策执行成为一个持续令人头痛的问题。规则最终分散在不同的团队和工具中，审计变成了日志和手动检查的混乱组合，监管机构要求更快地回答欧盟人工智能法案或州级要求等合规性问题。不一致会被忽视，特别是在多模式内容或新出现的危害中，而被动地修复问题会消耗我们所没有的工程周期。 我们已经开始探索信任和安全服务以及人工智能合规解决方案，这些解决方案提供集中执行、自适应策略、针对有害或不合规交互的实时护栏，以及在风险升级之前更好地捕捉风险的可观察性。目标是在文本、图像、视频和 GenAI 提示中实现一致的规则应用，而不会过度审查或减慢发布速度。 对于构建或运行 GenAI 应用程序和 UGC 平台的团队，是否有人破解了可扩展的策略执行，而不会成为供应商或运营商的噩梦？喜欢真实的体验   由   提交 /u/PlantainEasy3726   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2sqks/best_ways_to_handle_genai_policy_enforcement_and/</guid>
      <pubDate>Thu, 12 Feb 2026 12:57:56 GMT</pubDate>
    </item>
    <item>
      <title>如果我是一家大型人工智能公司，我会雇佣一名人工智能安全人员来做一份工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2ps6t/if_i_was_a_big_ai_company_i_would_hire_an_ai/</link>
      <description><![CDATA[退出，然后告诉大家 AGI 即将到来，公司将向这个世界释放一些东西。有了钱 这会让投资者相信人工智能公司实际上正在做艰苦的工作   由   提交 /u/Moneysaver04   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2ps6t/if_i_was_a_big_ai_company_i_would_hire_an_ai/</guid>
      <pubDate>Thu, 12 Feb 2026 10:16:33 GMT</pubDate>
    </item>
    <item>
      <title>到 2026 年，人工智能医疗抄写员可能会如何评估？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2lvxm/how_ai_medical_scribes_will_likely_be_evaluated/</link>
      <description><![CDATA[几年后，我认为人工智能抄写员的评判标准不会是它能否转录。 这将是基线，真正的区别将是它能适应你的写作方式吗？访问前、访问期间和访问后是否有帮助？是否确实减轻了精神负担？   由   提交 /u/Severe_Part_5120   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2lvxm/how_ai_medical_scribes_will_likely_be_evaluated/</guid>
      <pubDate>Thu, 12 Feb 2026 06:13:15 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 和 OpenAI 相隔 20 分钟放弃了他们的编码模型。这场竞争愈演愈烈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2lvqe/anthropic_and_openai_dropped_their_coding_models/</link>
      <description><![CDATA[上周，Anthropic 发布了 Claude Opus 4.6，而 OpenAI 则通过 GPT-5.3 Codex 进行了反击。两者实际上都安排在同一时间（太平洋标准时间上午 10 点），但 Anthropic 将他们的时间提前了 15 分钟，率先出发。小气？是的。我喜欢它吗？也是的。 老实说，整个星期都很混乱。 OpenAI 周二挖走了一名 Anthropic 安全研究员。然后 Anthropic 投放了超级碗广告，嘲笑 OpenAI 在 ChatGPT 中投放广告。萨姆·奥尔特曼 (Sam Altman) 在 X 上猛烈咆哮，称人类为“独裁者”。然后，周四，双方在一小时内相继放弃了各自最好的模特。感觉就像看着两个孩子在课间休息时试图比拼。 有趣的是，这些模型正朝着完全不同的方向发展。 Opus 4.6 是深度思考者：1M 代币背景，更擅长法律和财务推理，捕捉其他模型错过的边缘情况。但速度较慢。 GPT-5.3 Codex 是速度恶魔，速度提高了 25%，令牌更少，碾压了编码基准。哦，OpenAI 表示该模型在训练期间有助于自我调试。这要么真的很酷，要么真的令人不安，取决于你如何看待它。 让我印象深刻的数字：OpenAI 的企业市场份额在两年内从 62% 下降到 53%，而 Anthropic 从 14% 增长到 18%。差距正在缩小。 那么，你会选择 Team Claude 还是 Team Codex？或者你只是同时使用两者并让他们战斗？   由   提交/u/Deep_Ladder_4679   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2lvqe/anthropic_and_openai_dropped_their_coding_models/</guid>
      <pubDate>Thu, 12 Feb 2026 06:12:56 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 承诺承担其数据中心造成的电价上涨</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r2atip/anthropic_promises_to_cover_the_electricity_price/</link>
      <description><![CDATA[具体来说，他们将：  承担电网基础设施成本。我们将支付互连数据中心所需的 100% 电网升级费用... 采购新电力并保护消费者免受价格上涨的影响。我们将努力实现全新发电，以满足我们数据中心的电力需求…… 减少电网压力。我们正在投资限电系统，以在需求高峰期间减少数据中心的用电量... 投资当地社区。我们当前的数据中心项目将创造数百个永久性工作岗位和数千个建筑工作岗位...  纳德拉最近警告说，如果全社会不能广泛感受到人工智能的好处，那么像微软和 Anthropic 这样的公司将失去“社会许可”。消耗如此多的资源。 这看起来是 Anthropic 朝着正确方向迈出的一步。但这就足够了吗？   由   提交/u/jim-ben  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r2atip/anthropic_promises_to_cover_the_electricity_price/</guid>
      <pubDate>Wed, 11 Feb 2026 21:51:34 GMT</pubDate>
    </item>
    <item>
      <title>人工智能带来的就业灾难即将来临，您认为情况有多糟糕？严肃的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r26jw5/impending_jobs_apocalypse_due_to_ai_how_bad_do/</link>
      <description><![CDATA[仅就作品而言，就像每个人一样，我很担心。我不想担心，但当它每天出现在你面前，每个人都在营销这将需要白领工作时，你就会受到影响   由   提交 /u/Imnotneeded   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r26jw5/impending_jobs_apocalypse_due_to_ai_how_bad_do/</guid>
      <pubDate>Wed, 11 Feb 2026 19:11:53 GMT</pubDate>
    </item>
    <item>
      <title>马特·舒默：大事正在发生</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r235ch/matt_shumer_something_big_is_happening/</link>
      <description><![CDATA[https://shumer.dev/something-big-is-happening 在上面链接的文章中，Matt Shumer 声称：“但最让我震惊的是上周发布的模型 (GPT-5.3 Codex)。这不仅仅是执行我的指示。它正在做出明智的决定。它第一次给人一种判断的感觉。喜欢味道。人们总是说人工智能永远不会有一种莫名其妙的感觉，那就是知道什么是正确的选择。这个模型有它，或者足够接近以至于区别开始不重要。” 这是真的，还是只是 AI 粉丝的炒作？ 已编辑格式。   由   提交 /u/squeezyflit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r235ch/matt_shumer_something_big_is_happening/</guid>
      <pubDate>Wed, 11 Feb 2026 17:11:17 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 正在犯 Facebook 所犯的错误。我不干了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1r1zfpj/openai_is_making_the_mistakes_facebook_made_i_quit/</link>
      <description><![CDATA[“本周，OpenAI 开始在 ChatGPT 上测试广告。在担任研究员两年后，我也从公司辞职，帮助制定人工智能模型的构建和定价方式，并在标准确定之前指导早期安全政策，”Zoë Hitzig 在 Times Opinion 的客座文章中写道。 “我曾经相信我可以帮助构建人工智能的人们解决人工智能所带来的问题。本周我慢慢意识到，OpenAI 似乎已经不再提出我加入来帮助回答的问题了。”  Zoë 继续说道：  多年来，ChatGPT 用户已经生成了史无前例的人类坦诚档案，部分原因是人们相信他们正在谈论的事情没有别有用心的目的。用户正在与自适应的对话声音进行交互，他们可以通过这种声音透露自己最私密的想法。人们告诉聊天机器人他们的医疗恐惧、人际关系问题、对上帝和来世的信仰。基于该档案的广告有可能以我们没有工具可以理解的方式操纵用户，更不用说阻止了。   许多人都将人工智能的资助问题归结为一个问题。两害相权取其轻：将变革性技术的使用限制在有钱有钱的特定人群中，或者接受广告，即使这意味着利用用户最深的恐惧和向他们出售产品的愿望。我相信这是一个错误的选择。科技公司可以寻求一些选择，使这些工具保持广泛可用，同时限制任何公司监视、分析和操纵其用户的动机。 阅读全文 这里，免费，，即使没有《纽约时报》订阅。   由   提交 /u/nytopinion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1r1zfpj/openai_is_making_the_mistakes_facebook_made_i_quit/</guid>
      <pubDate>Wed, 11 Feb 2026 14:52:41 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>