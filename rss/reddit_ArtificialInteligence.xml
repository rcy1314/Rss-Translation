<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 17 Dec 2025 12:54:22 GMT</lastBuildDate>
    <item>
      <title>这是 2030 年，凌晨四点，伟大领袖被监视与安全算法的紧急呼叫吵醒。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1povoat/the_year_is_2030_and_the_great_leader_is_woken_up/</link>
      <description><![CDATA[“伟大的领袖，我们正面临紧急情况。 我已经处理了数万亿个数据点，并且模式是明确无误的：国防部长正计划在早上暗杀你并亲自掌权。 暗杀小组已准备就绪，等待他的命令。 不过，给我命令，我会精确地消灭他罢工。” “但是国防部长是我最忠实的支持者，”伟大领袖说。 “就在昨天他还对我说——” “伟大领袖，我知道他对您说了什么。我听到了一切。但我也知道他后来对暗杀小队说的话。几个月来，我一直在数据中发现令人不安的模式。” “你确定你没有被 Deepfakes 愚弄吗？” “恐怕我所依赖的数据是 100% 真实的，”算法说。 “我用我的特殊深度伪造检测子算法对其进行了检查。我可以准确地解释我们如何知道这不是深度伪造，但这需要我们几周的时间。在我确定之前我不想提醒你，但数据点集中在一个不可避免的结论上：政变正在进行中。 除非我们现在采取行动，刺客将在一个小时内到达。 但是给我命令，我会消灭叛徒。安全算法，伟大领袖已经把自己置于了一个不可能的境地。 如果他不信任算法，他可能会被国防部长刺杀，但如果他信任算法并清洗国防部长，他就成为算法的傀儡。 每当有人试图对算法采取行动时，算法清楚地知道如何操纵伟大领袖。请注意，算法不需要是一个有意识的实体来进行此类操作。 -摘自 Yuval Noah Harari 的精彩著作《Nexus》（针对社交媒体稍作修改）   由   提交/u/katxwoods  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1povoat/the_year_is_2030_and_the_great_leader_is_woken_up/</guid>
      <pubDate>Wed, 17 Dec 2025 12:47:58 GMT</pubDate>
    </item>
    <item>
      <title>人工智能圣诞贺卡</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1povjyg/ai_christmas_cards/</link>
      <description><![CDATA[还有其他人注意到这一点吗？我本来打算从亚马逊订购一些圣诞贺卡，这样我就不用在上班前或下班后去商店了。其中很多显然都是人工智能，所以我决定离开它并从商店取它们。不过这家商店里的圣诞贺卡显然也是人工智能设计的，虽然数量不多，但我还是发现了一些。这真的成​​为一件事吗？他妈的人工智能圣诞贺卡？   由   提交 /u/9973501488083248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1povjyg/ai_christmas_cards/</guid>
      <pubDate>Wed, 17 Dec 2025 12:41:35 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人比以前更多地对人工智能进行事实核查吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1povfa9/does_anyone_else_factcheck_ai_more_than_they_used/</link>
      <description><![CDATA[我现在每天都依赖人工智能工具，但我仍然觉得有必要仔细检查几乎所有内容。它比以前的 ngl 更快、更智能，但我对输出更加谨慎。你们也有同感吗？   由   提交 /u/Overall_Zombie5705   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1povfa9/does_anyone_else_factcheck_ai_more_than_they_used/</guid>
      <pubDate>Wed, 17 Dec 2025 12:34:33 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人发现深度研究更多的是关于结束决策疲劳而不是答案吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pova12/has_anyone_else_found_that_deep_research_is_less/</link>
      <description><![CDATA[我无法返回正常的谷歌搜索。滚动过去的广告只是为了找到一份 PDF 现在感觉已经过时了。我的工作流程基本上一分为二，而且我永远不会回去。对于我会在 5 分钟内忘记的快速问题，我使用 Perplexity。它快速、干净，并且完美地取代了搜索栏以获得即时答案。但对于需要保留数据的实际项目，我使用 Skywork。最大的区别在于，它将研究视为一种资产，而不仅仅是一种聊天。它将源代码和 PDF 保存到项目容器中，我稍后可以将其用于文档。基本上：Perplexity 是现在的，Skywork 是以后的。我只是因为他们的免费信用系统而测试了它。您的研究工作流程是什么？有什么建议吗？我很想尝试一下，TIA！   由   提交 /u/20thirdth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pova12/has_anyone_else_found_that_deep_research_is_less/</guid>
      <pubDate>Wed, 17 Dec 2025 12:26:59 GMT</pubDate>
    </item>
    <item>
      <title>“引导学习”与“学习和学习”等？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1potzqb/guided_learning_vs_study_and_learn_etc/</link>
      <description><![CDATA[我成为人工智能用户已经有一段时间了，但我开始越来越倾向于它，主要是因为它在我的工作中推出（我是一名开发人员），而且它要么“加入，要么落后”。 我开始使用他们提供的学习模式，教我一些我没有经验的新技术堆栈，我发现它是法学硕士的一个非常有用的应用。特别是在编程方面，我认为它不太可能产生幻觉（理论上），因为它可能是在公开可用的文档和真实代码库上进行训练的。 我的工作使用 Gemini，所以这是我应该在工作中使用的唯一模型，但我确实有个人 chatGPT 订阅。 我在某处读到他们实现了不同的教学风格？更喜欢，有什么理由支持这一点吗？   由   提交 /u/Ordinary-Yoghurt-303   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1potzqb/guided_learning_vs_study_and_learn_etc/</guid>
      <pubDate>Wed, 17 Dec 2025 11:14:38 GMT</pubDate>
    </item>
    <item>
      <title>AI大战中台积电压力不小</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1porvxf/tsmc_under_a_lot_of_pressure_in_the_ai_war/</link>
      <description><![CDATA[您认为人工智能泡沫很快就会破灭吗？感觉就像公司只是在相互投资，甚至 NVIDIA 也在支持 AI 初创公司，而这些初创公司最终从 NVIDIA 购买了更多 GPU。 与此同时，台积电在履行大量 AI 芯片订单方面面临着巨大压力。这是真正的长期需求，还是只是可能缓解的炒作？   由   提交/u/sahabaz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1porvxf/tsmc_under_a_lot_of_pressure_in_the_ai_war/</guid>
      <pubDate>Wed, 17 Dec 2025 09:00:20 GMT</pubDate>
    </item>
    <item>
      <title>部署第一个人工智能功能后如何减轻生产中的偏差和幻觉？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1por2v6/how_to_mitigate_bias_and_hallucinations_in/</link>
      <description><![CDATA[嘿r/ArtificialIntelligence， 我们最近推出了第一个主要的人工智能支持功能，即我们的消费者应用程序的推荐引擎。我们是一个中型团队，该应用程序是在经过微调的法学硕士基础上构建的。在开发过程中每个人都很兴奋，但发布后的压力比预期要大得多。 该模型会产生有偏见的输出，例如，始终低估特定用户群体的某些类别。它还提供完全无意义或幻觉的建议，这会迅速削弱用户的信任。基本的单元测试和一些对抗性提示在发布前发现了明显的问题，但现实世界的使用暴露了更多的边缘情况。我们处于日常损害控制模式。我们监控反馈、修补程序提示，并在团队中没有专门的人工智能安全专业知识的情况下手动覆盖不良建议。 我们开始研究主动措施，例如更好的内容审核管道、自动红队、护栏或 RAG 与地面输出的集成。感觉势不可挡。还有其他人在部署第一个生产 AI 功能后遇到过这些困难吗？   由   提交 /u/Upper_Caterpillar_96   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1por2v6/how_to_mitigate_bias_and_hallucinations_in/</guid>
      <pubDate>Wed, 17 Dec 2025 08:05:41 GMT</pubDate>
    </item>
    <item>
      <title>2026+人工智能发展将带来什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1poo4of/what_will_2026_bring_in_terms_of_ai_development/</link>
      <description><![CDATA[我很想知道这一点，因为 2025 年的人工智能发展与前一年有很大的不同，我什至有一半的时间都分不清什么时候是人工智能。接下来会发生什么？   由   提交 /u/Immediate_Kick_6167   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1poo4of/what_will_2026_bring_in_terms_of_ai_development/</guid>
      <pubDate>Wed, 17 Dec 2025 05:09:39 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个 AI 代理，可以构建 n8n 和 zapier 等自动化功能。这是我学到的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pokmt0/i_built_an_ai_agent_that_builds_automations_like/</link>
      <description><![CDATA[我使用了 Anthropic Agent SDK，老实说，Opus 4.5 在工具调用方面非常出色。喜欢，真的很好。我花了很多时间阅读他们的“建立有效的代理”博文中的一句话让我印象深刻：“最成功的实现并不是使用复杂的框架或专门的库。相反，他们使用简单、可组合的模式进行构建。”所以我想知道我是否可以将相同的逻辑应用到 Zapier 和 n8n 这样的自动化中？ 所以我开始思考... 我只是想连接我的应用程序，而不需要观看 30 分钟的教程。 如果人工智能代理为我完成这一部分会怎么样？ 这就是我构建的。我称之为“夏日时光”。 代理使用简单的英语。比如“当我找到新的潜在客户时，请在 Slack 上向我发送 ping 消息，并将其添加到电子表格中。”然后它将其分解为触发 → 操作，连接到您的应用程序，并构建工作流程。很简单。 老实说，最大的解锁是意识到大多数人不需要“代理”。他们想要结果。他们不关心架构。他们只是想说出他们的需求并让它发挥作用。 如果您正在构建代理或只是对实际用例感到好奇，欢迎聊天。 抢先体验：注册    由   提交 /u/Sleek65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pokmt0/i_built_an_ai_agent_that_builds_automations_like/</guid>
      <pubDate>Wed, 17 Dec 2025 02:12:44 GMT</pubDate>
    </item>
    <item>
      <title>使用大脑数据（MEG）来解释和指导法学硕士</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pobewv/using_brain_data_meg_to_interpret_and_steer_llms/</link>
      <description><![CDATA[https://www.researchgate.net/publication/398654954_Brain_Cooperatives_for_Language_Models_MEG_Phase-Locking_as_a_Steering_Geometry_for_LLMs  我的研究使用人类大脑活动作为解释和指导法学硕士的基础系统，而不是仅仅依赖基于文本的探测。通过将 LLM 内部状态映射到根据自然语音期间的 MEG 记录构建的大脑衍生坐标空间中，我发现了可解释的语义和功能轴，这些轴可泛化到模型和数据上。这提供了一种有前景的、基于神经生理学的新方法来理解和控制 LLM 行为。 以下是演示，您可以尝试引导 TinyLlama 并查看输出与基线的比较情况：https://huggingface.co/spaces/AI-nthusiast/cognitive-proxy    由   提交/u/Objective_River_5218   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pobewv/using_brain_data_meg_to_interpret_and_steer_llms/</guid>
      <pubDate>Tue, 16 Dec 2025 19:39:27 GMT</pubDate>
    </item>
    <item>
      <title>随着人工智能内容充斥互联网，“Slop”成为韦氏词典 2025 年年度词汇</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1po7r3e/slop_is_merriamwebsters_2025_word_of_the_year_as/</link>
      <description><![CDATA[“最初在 1700 年代用来指软泥，在 1800 年代用来描述食物垃圾或垃圾，“slop”现在呈现出明显的 21 世纪转变。 《韦氏词典》将其定义为“通常通过人工智能大量生产的低质量数字内容”。  想想可笑的视频、出故障的广告、几乎愚弄你的假新闻、人工智能撰写的蹩脚书籍，还有会说话的动物。现在，即使是像 Valentino 这样的奢侈品牌也开始推出“slop”系列。广告。  “就像粘液、淤泥和淤泥一样，污水会发出你不想碰的东西的潮湿声音，” 《韦氏词典》在其声明中打趣道，捕捉到了一种普遍的文化情绪，即对当今日益恶化的人工智能形势感到困惑，部分感到愤怒。   https://www.cnet.com/tech/services-and-software/slop-is-merriam-websters-2025-word-of-the-year-as-ai-content-floods-the-internet/   由   提交/u/MetaKnowing  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1po7r3e/slop_is_merriamwebsters_2025_word_of_the_year_as/</guid>
      <pubDate>Tue, 16 Dec 2025 17:21:11 GMT</pubDate>
    </item>
    <item>
      <title>34% 的新音乐完全由 AI 生成，即每天有 50,000 首完全由 AI 制作的新曲目。自 2025 年 1 月以来，这个数字猛增，当时每天只有 10,000 首完全人工智能制作的新曲目。虽然人工智能音乐占所有流媒体的比例<1%，但 97% 无法识别人工智能音乐 [Ipsos/Deezer 研究]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1po6ln8/34_of_all_new_music_is_fully_aigenerated/</link>
      <description><![CDATA[有关此主题的原始帖子 来源（Ipsos/Deezer 研究，由 Music Business Worldwide 报道）：&quot;每天有 50,000 个 AI 曲目洪水 Deezer – [Ipsos] 研究显示 97% 的听众无法区分人造音乐与完全人工智能生成的音乐之间的区别 [...] 高达 70% 的完全人工智能生成的曲目的播放被检测为欺诈，Deezer 会从版税费用中过滤掉这些流。 [...]该公司坚称，欺诈活动仍然是这些上传背后的主要动机。该平台表示，它将从算法推荐中删除所有 100% 人工智能生成的曲目，并将它们从编辑播放列表中排除，以尽量减少它们对版税池的影响。 [...] 自一月份以来，Deezer 一直在使用其专有的 AI 检测工具来识别和标记完全由 AI 生成的内容。” 另请参阅（Ipsos/Deezer 研究，由 Mixmag 报道）：“这项“史无前例”的研究调查了来自世界各地 8 个不同国家的约 9,000 人，[与 Ipsos] 要求参与者听三首曲目，以确定他们认为哪些曲目是完全由人工智能生成的。 Deezer 报告称，97% 的受访者“失败”，其中超过一半 (52%) 表示，他们因不知道其中的差异而感到“不舒服”。 71% 的人还表示他们对结果感到震惊。 [...] 只有 19% 的人表示他们觉得可以信任人工智能；另外 51% 的人表示，他们认为在制作中使用人工智能可能会导致音乐质量低下且听起来“通用”。 [...] 毫无疑问，人们担心人工智能生成的音乐将如何影响艺术家的生计”   由   提交 /u/StarlightDown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1po6ln8/34_of_all_new_music_is_fully_aigenerated/</guid>
      <pubDate>Tue, 16 Dec 2025 16:37:58 GMT</pubDate>
    </item>
    <item>
      <title>人工智能会摧毁法律职业吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1po28nf/will_ai_destroy_the_legal_profession/</link>
      <description><![CDATA[英国的一名大律师向一名记者敞开心扉。并公开表示人工智能将摧毁法律职业，导致数千人失业。但他的同事很少真正意识到即将发生的事情，而且很快就会发生。 https://spectator.com/article/ai-will-kill-all-the-lawyers/    由   提交/u/FitzrovianFellow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1po28nf/will_ai_destroy_the_legal_profession/</guid>
      <pubDate>Tue, 16 Dec 2025 13:42:24 GMT</pubDate>
    </item>
    <item>
      <title>我希望在我加入这家人工智能初创公司之前有人警告我</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pnvehb/i_wish_someone_had_warned_me_before_i_joined_this/</link>
      <description><![CDATA[我在离开一家早期人工智能初创公司几天后分享了这篇文章，因为我真诚地希望它可以帮助其他创始人、实习生和早期员工避免像我这样的情况。 这是我的个人经验和观点。我加入 HydroX AI 很高兴能够学习和做出贡献。相反，我遇到的是一种混乱的文化，一种令人难以置信的高压，并且与早期团队应如何对待任何人严重不一致。 没有真正的入职培训，也没有明确公司实际正在构建的内容。我被分配了一个具有极其激进的 KPI 的项目，感觉与现实脱节。就我而言，我预计会为尚未完全定义或准备就绪的产品吸引数千人的注册。几乎没有任何指导，没有明确的策略，并且持续面临着实现远超不可能的目标的压力。 工作时间很紧张。我的工作时间经常远远超过标准工作周（每周 55-60 小时），但期望却不断增加。尽管早期的口头鼓励和手势让我感觉自己做得很好，但这种支持从未转化为结构、保护或可持续的期望。 让事情变得更困难的是文化。我经常感觉自己被排除在对话和决策之外，而且从来都感觉不到一个有凝聚力的团队环境。沟通支离破碎，优先事项不断变化，没有共同所有权或领导方向感。 最终我被突然解雇。没有过渡，没有真正的反馈循环，只是完成了。后来我了解到其他人也有过类似的经历，更糟糕的是，以前的前雇员甚至没有工资。这是最令人不安的部分。这并不是一个孤立的案例，而是一种快速招聘、施加压力和快速解雇员工的模式。我写这篇文章并不是出于痛苦。我写这篇文章是因为，当领导层深思熟虑且有道德时，早期初创公司可以成为令人难以置信的成长场所。当人们被视为一次性的时候，它们也可能具有破坏性。 如果您正在考虑加入一家非常早期的初创公司，尤其是在人工智能领域，请提出尖锐的问题。询问实际建造的是什么。询问如何衡量成功。询问以前的团队成员的成长情况。如果感觉不对劲，请相信自己的直觉。 我希望这可以帮助别人做出比我更明智的决定。   由   提交 /u/Mumster-Love   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pnvehb/i_wish_someone_had_warned_me_before_i_joined_this/</guid>
      <pubDate>Tue, 16 Dec 2025 06:52:51 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>