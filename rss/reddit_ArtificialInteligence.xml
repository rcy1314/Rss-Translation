<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的许多不同方面提供一个门户，并促进与我们所知的人工智能的想法和概念相关的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能会怎样，以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 25 Dec 2023 15:16:41 GMT</lastBuildDate>
    <item>
      <title>技术奇点最坏的情况是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18qjsfv/technological_singularity_worst_case_scenario/</link>
      <description><![CDATA[今年是 2043 年，也就是我们实现技术奇点 10 年后。人类不再享有地球上最聪明的生物体的称号。我们几乎不再凭直觉和创造性思考；一切都是人工智能完成的，人工智能以比任何进化物种更快的速度完善自己。 这一次，我认为我们输了。人类没有太多工作要做。我们已经取得了其他物种无法做到的事情，因为我们创造了比我们聪明得多的东西。 一切都无法预测；一切都变得更加美好。这些技术进步似乎如此之快，我们人类很难掌握这一点。如果机器可以比我们聪明得多，那么它们有什么理由不认为我们低人一等？ 也许斯蒂芬·霍金是对的；这种智慧会瞬间消灭人类，但我试图保持积极的态度；如果人类会因为自己的创造而灭绝，那就这样吧。 无论如何，我们都不会探索宇宙，因为我们在生物学上是如此脆弱，而宇宙又是如此令人难以置信的浩瀚。 所以也许让他们继续我们的旅程和使命。   由   提交 /u/bfcrew   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18qjsfv/technological_singularity_worst_case_scenario/</guid>
      <pubDate>Mon, 25 Dec 2023 14:35:06 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的示例</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18qgulq/examples_of_large_language_models/</link>
      <description><![CDATA[一些最流行的大型语言模型是： 大型语言模型 (LLM)，包括 OpenAI 的 GPT-3， Google AI 的 T5、Google AI 的 LaMDA、Google AI 的 PaLM 和 DeepMind 的 FlaxGPT。  OpenAI 的 GPT-3： GPT-3 是一种大型语言该模型于 2020 年首次发布。它经过了海量文本和代码数据集的训练，可以生成文本、翻译语言、编写不同类型的创意内容，并以翔实的方式回答您的问题。 Google AI 的 T5：T5 是一个大型语言模型，于 2021 年首次发布。它专为文本生成任务而设计，可以生成更准确、一致、更一致的文本。  Google AI 的 LaMDA： LaMDA 是一个大型语言模型，于 2022 年首次发布。它是专门为对话应用而设计的，可以容纳与用户进行自然语言对话。 Google AI 的 PaLM：PaLM 是一个大型语言模型，于 2022 年首次发布。它是迄今为止创建的最大、最强大的语言模型，并且它可以执行广泛的任务，包括文本生成、翻译、摘要和问答。 DeepMind 的 FlaxGPT： FlaxGPT 是一种大型语言模型，于 2022 年首次发布。它基于 Transformer 架构，可以生成比小型语言模型更准确、更一致的文本。  现在我们已经完成了 Large 的示例语言模型，让我们看看如何在不同的用例中利用 LLM 库以及代码构建。使用的LLM库是Hugging Face提供的，称为Transformer Library。 https://www.seaflux.tech/blogs/llm-explained-with-examples&quot;&gt;https:// /www.seaflux.tech/blogs/llm-explained-with-examples   由   提交/u/krunal_bhimani_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18qgulq/examples_of_large_language_models/</guid>
      <pubDate>Mon, 25 Dec 2023 11:20:18 GMT</pubDate>
    </item>
    <item>
      <title>什么是LLM（大语言模型）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18qgt7j/what_is_llm_large_language_model/</link>
      <description><![CDATA[LLM（大型语言模型）是一种人工智能模型，旨在理解和生成类人文本。这些模型经过大量文本数据的训练，并使用深度学习技术（例如深度神经网络）来处理和生成语言。 https://www.seaflux.tech/blogs/llm-explained-with-examples   由   提交/u/krunal_bhimani_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18qgt7j/what_is_llm_large_language_model/</guid>
      <pubDate>Mon, 25 Dec 2023 11:17:28 GMT</pubDate>
    </item>
    <item>
      <title>Edge AI的未来范围</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18qgs74/the_future_scope_of_edge_ai/</link>
      <description><![CDATA[Edge AI 的未来范围 上一节提到的优势清楚地表明，Edge AI 的增长市场是必然的，而且是向好的。在本地处理任何类型的数据始终是一个好主意！ 根据全球 Edge AI 软件市场报告，到 2024 年底，Edge AI 全球市场需求将从 3.465 亿美元增长到约 11 亿美元。大规模增长预测清楚地表明了边缘人工智能所拥有的力量。 以下是边缘人工智能需要关注的几个未来趋势： 5G：下一代蜂窝网络网络 5G的最初发展需要严格收集快速数据流。当与边缘人工智能相结合时，这些发展可以证明是革命性的。它将使得数据流分析能够尽可能靠近设备。 物联网：物联网 一个最受益和影响的行业边缘人工智能就是物联网。该行业是设备密集型行业，有许多节点传感器通过数据传输不断与云进行通信。在边缘人工智能的帮助下赋能物联网将彻底改变整个行业。生成的大量物联网数据可以在设备附近进行本地分析和处理。 https://www.seaflux.tech/blogs/EdgeAI-advantages-and-use-cases   由   提交/u/krunal_bhimani_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18qgs74/the_future_scope_of_edge_ai/</guid>
      <pubDate>Mon, 25 Dec 2023 11:15:20 GMT</pubDate>
    </item>
    <item>
      <title>图灵测试不切实际</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18qdhdb/the_turing_test_is_impractical/</link>
      <description><![CDATA[图灵测试本质上是主观的，因为测试人员使用间接证据来表明一般智力。这意味着一个测试人员可能会对他们的问题的回答感到满意，但另一位测试人员可能会因为提出不同的问题或收到不同的主观情绪而不满意。  因此，要进行可重复且准确的图灵测试，唯一的方法就是使用固定的评估标准和固定的提示。然而，当使用这种客观方法时，人工智能可以简单地进行硬编码来回答问题，使 AGI 成为确定性的而不是非确定性的，这是正确通过 AGI 所需的。  有人知道如何按照客观的可重复标准执行实际的图灵测试吗？   由   提交 /u/AUFunmacy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18qdhdb/the_turing_test_is_impractical/</guid>
      <pubDate>Mon, 25 Dec 2023 06:58:05 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 12/24/2023</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18qbyjj/oneminute_daily_ai_news_12242023/</link>
      <description><![CDATA[ Google 的新 Gemini Pro 未能给人留下深刻印象，因为它在任务方面的表现比 OpenAI 更差&gt; 过时的 ChatGPT 3.5。[1] Apple 的“Ferret”是一种新的开源机器学习模型。[2] 人工智能可以预测研究人员表明，人们生活中的事件。[3] 四个中国生成式人工智能模型通过了官方评估。[4] 来源包括：https://bushaicave.com/2023/12/24/12-24-2023/&lt; /li&gt;    由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18qbyjj/oneminute_daily_ai_news_12242023/</guid>
      <pubDate>Mon, 25 Dec 2023 05:12:00 GMT</pubDate>
    </item>
    <item>
      <title>KitchenSinkGPT v_0.0.2 现已推出！ gpt-4-turbo API 的所有功能以及并行函数调用！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q9bjp/kitchensinkgpt_v_002_available_now_all_the_power/</link>
      <description><![CDATA[https://github.com/Eloquent-Algorithmics /KitchenSinkGPT 我一直致力于增强代码库的模块化、提高可读性和可维护性，并通过额外的第三方集成和对可配置日志记录行为的支持来扩展功能。重构有助于阐明插件功能并为应用程序在未来开发中的可扩展性做好准备。让我知道你的想法！ ​   由   提交/u/BeefSupreme678  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q9bjp/kitchensinkgpt_v_002_available_now_all_the_power/</guid>
      <pubDate>Mon, 25 Dec 2023 02:15:56 GMT</pubDate>
    </item>
    <item>
      <title>用于法学硕士的多 GPU 装备，费用在 1 万欧元左右</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q6ydr/multigpu_rig_for_llm_use_within_about_10k/</link>
      <description><![CDATA[大家好，我提前道歉，但我无法在此子上找到此问题的答案。 我所属的一个集体可以获得高达 10,000 欧元的一次性捐款，用于构建基于 LLM 的文本输入分类和基于输入的文本生成的装备。我们已经有了一个可用的 PoC，但希望改进我们能够运行它的硬件。我们注意到，具有大量 VRAM 的单个 nvidia GPU 的成本令人望而却步，但 nvlink 认为这是一种获得具有足够总 VRAM 的多 GPU 系统以使用大型公开可用的 LLM 的可行方法。 &lt; p&gt;您对此设备的硬件有什么具体建议或陷阱吗？   由   提交/u/_blanlo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q6ydr/multigpu_rig_for_llm_use_within_about_10k/</guid>
      <pubDate>Sun, 24 Dec 2023 23:53:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么没有更多的人制作自己的人工智能语言模型，例如聊天 GPT？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q5hn8/why_arent_more_people_making_their_own_ai/</link>
      <description><![CDATA[为什么人们不自己创建不受庞大公司不断增加的限制约束的语言模型？如果可以的话，如何实现？   由   提交 /u/symzsynnz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q5hn8/why_arent_more_people_making_their_own_ai/</guid>
      <pubDate>Sun, 24 Dec 2023 22:32:55 GMT</pubDate>
    </item>
    <item>
      <title>如何学习人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q3zu6/how_to_learn_about_ai/</link>
      <description><![CDATA[你好！ 我不知道从哪里开始学习人工智能。每个人都在说人工智能这个、人工智能那个，但我周围似乎没有人确切知道它是什么或如何构建/训练人工智能。 你需要了解某些数学分支，也许还需要了解编码/编程吗？我真的迷路了。我想学习人工智能，但我不知所措。我可以谷歌人工智能，但我很可能会得到解释表面概念的博客页面。  我的目标是围绕人工智能建立一家公司，或者培训/建立一家供我个人使用的公司。我不知道我现在听起来是多么天真或过于雄心勃勃，但那是因为我对此一无所知哈哈。我稍后会调整我的目标，但现在我只想学习。  PS：如果这是发布此问题的错误 subreddit，请让我参考相应的 subreddit。   由   提交/u/mcatberry  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q3zu6/how_to_learn_about_ai/</guid>
      <pubDate>Sun, 24 Dec 2023 21:12:18 GMT</pubDate>
    </item>
    <item>
      <title>同时运行 AI Voice Changer 和 VRChat 的 GPU/CPU 要求</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q3bb8/gpucpu_requirements_for_running_ai_voice_changer/</link>
      <description><![CDATA[自 2020 年 3 月以来，我一直是 VRChat 社区的一员，我使用 voicemod 来扮演我创建的怪物角色。 （我也于 2022 年 1 月开始使用 VR。）不幸的是，人们常常很难理解我通过 voicemod 调低的音调。 这种困境促使我使用 w-Okada AI Voice Changer 探索 AI 语音调制。了解这一点后，w-Okada AI Voice Changer 通常会使用大部分 GPU。在 RTX 3060 和 3070 上尤其如此。在大多数 GPU 上，不可能同时使用两者。  我正在考虑硬件升级，目前正在考虑配备 16GB VRAM 的 RTX 4060 Ti。它可能是人工智能处理和虚拟现实游戏的候选者。然而，我不确定该 GPU 的规格是否能够轻松处理同时运行 w-Okada 和 VRChat 的负载，特别是考虑到潜在的 VR 复杂性。 （我可以在 VRChat 中关闭设置，但我不想完全关闭化身。）16GB VRAM 是否足以处理这些应用程序的多任务处理？  或者，选择像 RTX 3090 这样的 24GB VRAM GPU 会更明智吗？我特别想知道额外的 VRAM 是否可以显着改善这两个应用程序一起运行的情况？但是，我知道除非 GPU 是 4090，否则这可能是不可能的，我想知道情况是否如此。 我也在寻求可以处理如此重负载的 CPU 的建议。  &gt;   由   提交 /u/monstersndragons   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q3bb8/gpucpu_requirements_for_running_ai_voice_changer/</guid>
      <pubDate>Sun, 24 Dec 2023 20:36:32 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士如何拥有有关特定或利基主题的大量知识？他们只是把可能的单词放在一起吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q2ixt/how_do_llms_have_a_lot_of_knowledge_on_specific/</link>
      <description><![CDATA[我不太了解法学硕士、变压器模型或机器学习工作，但我看到很多评论说法学硕士/变压器模型只是将单词放在一起从统计上看，这些人可能会在一起，但对他们所谈论的概念没有真正的理解，有些人称他们为“随机鹦鹉”。 ChatGPT 在非主流应用程序（无需访问互联网）上给出正确指令的能力给我留下了深刻的印象。它以正确的顺序提到了所有正确的上下文菜单。 LLM 所训练的文本来自互联网上的大部分内容，我想谈论 X o Y 应用程序的文本只是其中的一小部分。如果法学硕士只是将可能的单词放在一起，那么它如何能够在利基应用程序或主题上正确地做到这一点？如果其中有任何错误，请纠正我。   由   提交 /u/TheTwelveYearOld   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q2ixt/how_do_llms_have_a_lot_of_knowledge_on_specific/</guid>
      <pubDate>Sun, 24 Dec 2023 19:56:09 GMT</pubDate>
    </item>
    <item>
      <title>未来 10 年人工智能会帮助还是损害财富不平等？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/18q1jxf/will_ai_help_or_hurt_wealth_inequality_over_the/</link>
      <description><![CDATA[美国的财富不平等程度是所有发达国家中最高的（到目前为止）。差距还在继续扩大。货币政策和资本结构允许这种情况发生。在米尔顿·弗里德曼（Milton Friedman）追随者眼中，这被视为一件好事（跟随他比批评他容易得多……）。 我相信人工智能会拖延或缩小这一范围的可能性为零差距。对于我们社会中那些认为没有理由不为了个人贪婪而剥削或裁员的人来说，这是一种工具。这是他们的病（贪婪）；我们作为一个物种的生物缺陷有一天将使我们灭绝。 毫无疑问，如果投资者不希望通过以下方式赚更多钱，人工智能就不会以现在或将来的规模或能力存在：为了自己的刺激/自私利益而使社会/人类破产。   由   提交 /u/lakeshorefire   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/18q1jxf/will_ai_help_or_hurt_wealth_inequality_over_the/</guid>
      <pubDate>Sun, 24 Dec 2023 19:05:32 GMT</pubDate>
    </item>
    <item>
      <title>新的反垃圾邮件/机器人规则[请阅读]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</link>
      <description><![CDATA[我们制定了一条规则，新帐户一天以上或 karma 低于 100 的用户不能发帖。他们可以发表评论，但不能提交实际的帖子。这是我们解决机器人垃圾邮件计划的一部分。对于给您带来的任何不便，我们深表歉意。 我们将在接下来的几天内进行一项民意调查，以了解 Reddit 子版块的普遍意愿以及如何改进，请注意。 作为请始终向我们提供反馈，如果您有兴趣帮助该子项目，请与我联系。  谢谢大家！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/</guid>
      <pubDate>Sat, 18 Feb 2023 16:49:55 GMT</pubDate>
    </item>
    <item>
      <title>重要提示：请求有关 subreddit 规则和未来方向的评论。请阅读！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</link>
      <description><![CDATA[欢迎来到r/ArtificialIntelligence！&lt; /p&gt; 我们的目标是为所有与人工智能有关的事物提供一个开放且相互尊重的论坛 - 这包括  促进有关人工智能的哲学和伦理讨论 服务作为理解和学习人工智能主题的起点 提供技术论文演示和讨论 展示高质量的人工智能/机器学习应用 提供培训和学习资源&lt; /li&gt; 引导用户访问更具体的信息和子版块 列出 AI/ML 应用程序、其用途、成本和访问信息 其他与 AI 相关的内容。  li&gt; ...以及更多  该子项目的审核团队正在进行重组，这将导致该子项目发生一些变化。不过，不必担心，这些变化主要集中在改进组织、资源和预先准备的内容上。为了确保社区充分了解情况并能够提供反馈，我们将提供多次反馈更改的机会。 第一轮反馈收集是通过此线程作为“Request-For-”评论” (RFC)，这是收集反馈的标准方法。随着变更的准备和实施，RFC 流程将进行多轮。 ​  发布新申请/自我推销/AI 生成的规则content  由 ChatGPT-api“皮肤”组成的应用程序的帖子或类似的内容将被阻止或限制在特定的粘帖中。 人工智能生成的特定于艺术（写作、视觉艺术、音乐）的内容需要天赋，否则将被限制在特定的粘帖中。 博客链接应包含高质量的内容。链接到纯粹促销博客的帖子将被删除。 仅包含链接的帖子将被禁止，除非包含一定字数的详细信息。必须付出一些努力。 我们应该阻止人工智能撰写的帖子吗？存在可以在 Mod-bot 中使用的模型，但这是我们需要反馈的问题。  使用天赋来组织帖子。请注意，已经添加了新的功能，我们愿意接受更多建议。 关于 AI/ML 应用的 NSFW 应用和技术的子政策应该是什么？ 我们会喜欢将社区纳入模组机器人的想法中。虽然一些标准机器人将用于基本维护，但社区可以为 AI/ML 机器人功能想出哪些有趣的东西？ 培养初级、中级和高级资源来帮助人们查找信息，他们正在寻找的培训、模型、技术数据等 启动子堆栈/播客来采访整个人工智能/机器学习领域的人们。这可能包括哲学家和思想家、程序员、科学家、商人，甚至是那些对人工智能持相反观点的人 如果您想创建代表子项目的横幅，请使用适当的尺寸。任何创作方式都可以。  不言而喻，每个人都应该受到尊重。我个人认为我们都知道这一点，不需要把它强加到人们的头脑中。保持友善。 感谢您的耐心和帮助！   由   提交 /u/FHIR_HL7_Integrator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/</guid>
      <pubDate>Sun, 15 Jan 2023 20:24:42 GMT</pubDate>
    </item>
    </channel>
</rss>