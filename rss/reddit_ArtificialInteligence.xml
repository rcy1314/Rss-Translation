<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 20 Dec 2025 21:20:48 GMT</lastBuildDate>
    <item>
      <title>绝对是任何人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prowq6/absolutely_anything_ai/</link>
      <description><![CDATA[您好，我希望这没问题，我不知道如何展示这一点 - https://absolutelyanything.ai/ 我使用 Lovable.dev 创建了一个将互联网上当前所有应用程序集成到一个系统中的全包平台 - 请检查一下，我相信我创造了我们一生中最大的转变 这是我写给企业的信 - https://absolutelyanything.ai/the-shift   由   提交 /u/hivincenzo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prowq6/absolutely_anything_ai/</guid>
      <pubDate>Sat, 20 Dec 2025 21:13:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们如此讨厌使用 ChatGPT</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prlqz4/why_people_hate_so_much_when_using_chatgpt/</link>
      <description><![CDATA[在我的帐户上，我写了我生活中发生的事情，有些是现在发生的，有些是在线发生的（比如在网上看到奇怪的视频等）。  当我第一次发布一些关于我的生活的严肃内容时，人们扭曲了我自己的话，并且从我所说的内容中一无所获。  之后我要求chatgpt将我的故事转为“R. Post”，故事完全相同，但没有重复自己，犯语法错误（因为英语不是我的母语）并使用“更好”来表达。的话（就像我现在没有做的那样，因为在这篇文章中我没有使用chatgpt）。  我开始总是这样做，发短信给我的故事或观点，他让它们变得不那么混乱和“更好”。 过了一会儿，有人开始说它们是假的，我解释了真相并试图用我自己的话发布一些东西，他们再次扭曲我的话并理解了一些我从来不想说的东西。  现在，我在他的帖子下礼貌地与一个非自愿者争论，他说女人权利较少的地方男人更快乐:)  过了一会儿他说他检查了我的个人资料并知道我使用chatgpt。  现在，为什么没有人可以使用chatgpt？？？基本上，人类创建它是为了帮助我们获取信息等，但每当我告诉别人这件事时，他们就像“”哦，我不喜欢chatgpt”。它告诉你的事情与谷歌完全相同，并且有很大帮助。我使用它是因为它可以帮助我表达自己，而不会让人们误解我。  为什么感觉像是犯罪？？？ ??   由   提交/u/lil_moon153  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prlqz4/why_people_hate_so_much_when_using_chatgpt/</guid>
      <pubDate>Sat, 20 Dec 2025 18:54:28 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的观点：“完全自主”的人工智能是用户体验的噩梦。请给我原始提示。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prllsl/unpopular_opinion_fully_autonomous_ai_is_a_ux/</link>
      <description><![CDATA[在过去的六个月里，我一直在尝试将视频生成集成到我的机构的工作流程中，现在我正式完成了“一键魔法”功能。工具。 问题不在于质量，而在于控制。当你使用黑盒生成器时，你本质上是在赌博。如果人工智能生成了一个完美的 30 秒广告，但在场景 4 中出现了第六根手指的幻觉，你通常必须重新滚动整个视频并祈祷其余部分保持良好。它对于客户端工作来说不可扩展。 我终于找到了一种解决方法，可以将视频生成视为代码而不是魔法。我一直在测试分离生成过程的代理工作流程。它创建了视频，但最重要的是，它提供了一个补充文件，其中包含时间线中每个剪辑的特定文本提示。 现在，如果场景 4 很奇怪，我不会废弃该项目。我只需复制场景 4 的提示，调整否定提示以消除故障，然后重新生成特定的 3 秒片段。 这将我的工作流程从“老虎机”转变为“老虎机”。到“视频编辑”。 你们是否看到更多工具采用这种“透明层”？方法，还是我们现在仍然陷入黑匣子？   由   提交/u/ProgrammerForsaken45  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prllsl/unpopular_opinion_fully_autonomous_ai_is_a_ux/</guid>
      <pubDate>Sat, 20 Dec 2025 18:48:24 GMT</pubDate>
    </item>
    <item>
      <title>认真思考低概率、高影响的人工智能风险</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prkzai/thinking_rigorously_about_lowprobability/</link>
      <description><![CDATA[关于人工智能风险的争论通常分为短期的、凭经验可观察到的危害和高度推测性的灾难性场景。一种新兴的思路表明这种二分法是不完整的。其他高风险领域，例如金融、保险和国家安全，通常使用结构化投机分析来推理高度不确定性下的尾部风险。 应用于人工智能时，这种方法强调严格的场景构建、明确的假设建模以及对机构响应能力的考虑，而不是对单一结果的预测。目标是改善不确定性下的决策，并揭示标准基准测试和评估方法可能遗漏的与治理相关的见解。 从技术和政策角度来看，这提出了几个问题：  投机风险分析如何与实证安全评估和审计一起实施？ 什么方法标准应该区分严格的尾部风险分析和不可证伪的叙述？ 这些框架如何为模型部署提供信息决策、监管阈值或应急计划而不阻碍创新？  对这里的研究人员和从业者如何考虑将这种推理整合到当前的人工智能安全和治理工作中感兴趣。 链接到全文此处。以及对其中一位作者的采访此处。   由   提交 /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prkzai/thinking_rigorously_about_lowprobability/</guid>
      <pubDate>Sat, 20 Dec 2025 18:21:35 GMT</pubDate>
    </item>
    <item>
      <title>在学习 Python 中的 AI 开发时，IDE 选择重要吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prkdku/does_ide_choice_matter_when_learning_ai/</link>
      <description><![CDATA[当人们谈论用 Python 学习 AI 时，大多数关注点都是模型和框架，而不是工具。但我注意到，根据我使用的是 PyCharm 还是更轻量级的编辑器，我的工作效率会发生很大变化。 PyCharm 起初感觉较慢，但一旦项目增长，它就有助于保持事情井井有条。我还注意到，像 Sweep AI 这样的 AI 工具在结构化 IDE 中比在松散的编辑器中更有用。 您如何学习和构建 AI 系统？   由   提交 /u/Cristiano1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prkdku/does_ide_choice_matter_when_learning_ai/</guid>
      <pubDate>Sat, 20 Dec 2025 17:56:04 GMT</pubDate>
    </item>
    <item>
      <title>我们认为“氛围编码”到底是什么？人类是创意者，而不是技术员</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prkd19/what_do_we_think_vibe_coding_is_really_human_as/</link>
      <description><![CDATA[你好， 我是法学硕士的高级休闲用户。最近，我一直在“编码” C# 程序。但称我为程序员绝对是对程序员的侮辱。我提供了 GPT 5.2 英语参数和风格指南，它确实可以做到这一点。我是一名氛围程序员。但说我什么都没做也是不诚实的。我没有编写 C#，而是花了很多时间为 GPT 编写布局、功能和路线图指令。即使由人工智能进行实际编码，您也必须付出一定的努力，至少不能学到一些东西。当你想到 Vibe 编码时，它只是一种非常非常抽象的编程语言，不是吗？ 我现在已经考虑到人工智能将把我们的社会从技术专家转变为思想家 - 人类将给出大致的轮廓、风格参数、功能，而人工智能将完成幕后工作。这让我既兴奋又担忧。我是一个有很多想法的人，但这些想法往往与我的技能不重叠。能够要求法学硕士做我做不到的部分是一种难以置信的解放。我真正担心的是我们的社会完全失去这种专业知识。即使人工智能可以完美地完成这件事，你仍然需要能够完成这件事的人。 对思考和讨论感兴趣。   由   提交/u/_Haverford_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prkd19/what_do_we_think_vibe_coding_is_really_human_as/</guid>
      <pubDate>Sat, 20 Dec 2025 17:55:24 GMT</pubDate>
    </item>
    <item>
      <title>如果我以后想专攻人工智能和网络安全，我应该获得什么是最好和最相关的学士学位。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prh5hn/what_is_the_best_and_most_relavent_bachelors/</link>
      <description><![CDATA[由于预算紧张，我只能攻读信息技术理学学士或软件工程工学学士。如果我需要专攻我提到的上述领域，什么学位更适合我？如果我愿意在学位学习期间或之后（毕业后工作时）在这些领域自行积累知识？ 我来自斯里兰卡，但任何人的建议都很有价值，谢谢！   由   提交 /u/Any_Fault2737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prh5hn/what_is_the_best_and_most_relavent_bachelors/</guid>
      <pubDate>Sat, 20 Dec 2025 15:38:16 GMT</pubDate>
    </item>
    <item>
      <title>前沿模型认为他们最好的特点是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prgyjm/what_do_the_frontier_models_think_their_best/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prgyjm/what_do_the_frontier_models_think_their_best/</guid>
      <pubDate>Sat, 20 Dec 2025 15:30:12 GMT</pubDate>
    </item>
    <item>
      <title>关于人工智能模型和自动宣传与实际人工智能的问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prgr8m/question_on_ai_models_and_automated_advocacy_vs/</link>
      <description><![CDATA[** 这并不是一场政治对话，所以请不要将其设为政治对话。这完全是关于人工智能中数据集的操作。 ** 今天早上我看到埃隆·马斯克的一条推文，称 Grok 是唯一承认平权行动是种族主义的人工智能，我认为这很有趣。参见此处：x.com 链接，使用风险自负 我对 Grok 采购与其他人工智能工具进行了一些深入探讨，并指出 Groks 的基础是 xAI，这是马斯克的另一家企业，而其他人则使用其他人工智能模型进行采购。 《商业内幕》报道关于内部培训暗示 xAI 员工（AI 导师）参与了针对特定争议主题的机器人培训并过滤内容，决定应该或不应该包含哪些内容。如果没有完全透明的公开发布的训练数据集或公开的手动注释过程，在我看来，来源信息的有效性就会受到质疑。  来源：商业内幕  来源 2：请参阅有关“Grok 是如何训练的”部分 我的人工智能工作主要围绕人工智能在 IT 领域的使用展开，因为那是我工作和生活的地方，尽管我们确实为一些面向客户的通信和营销工具采购了公开可用的人工智能工具，例如 Co-Pilot。因此，我个人也曾使用过一些面向消费者的工具，例如 Claude、MetaAI、ChatGPT 等。但我确实对 Grok 有一些真正的担忧。所以，我对围绕这个主题的对话感兴趣。 这里有一个问题：Grok 是一个真正的人工智能工具，还是自动宣传？当它的主要数据源之一是 X（它的功能在很大程度上是一个保守的孤岛）并且其输出始终向右倾斜时，它是否会引起真正的担忧？是独立推理，还是强化平台及其构建者的世界观？ “训练数据”什么时候会成为意识形态编程？ 提前感谢您的对话。   由   提交 /u/Successful-Coyote99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prgr8m/question_on_ai_models_and_automated_advocacy_vs/</guid>
      <pubDate>Sat, 20 Dec 2025 15:21:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么人们想要 agi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/</link>
      <description><![CDATA[不要从技术角度误解我的意思，我内心的书呆子认为这很酷，但是，现在大部分资金来自企业主和首席执行官，他们看到了更换劳动力带来的美元迹象。如果人工智能能够真正复制任何“人类”像客户服务这样的工作，所有智力工作都消失了。会计师、律师、工程师、所有行政/文书角色、客户支持、艺术家、媒体制作，基本上所有没有物理组成部分的工作都不需要存在。  每天，我都会看到专业人工智能人士围绕 chatgpt 制作包装，试图创建业务，但同样，如果人工智能可以做所有事情，那么它也可以做到。我只是不太明白为什么普通人会想要通用人工智能，因为它真正受益的唯一人是模型的所有者和体力劳动企业的所有者？    由   提交/u/WillDanceForGp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/</guid>
      <pubDate>Sat, 20 Dec 2025 14:14:37 GMT</pubDate>
    </item>
    <item>
      <title>小岛秀夫将人工智能比作智能手机</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pra2la/kojima_compares_ai_to_smartphones/</link>
      <description><![CDATA[小岛秀夫将人工智能技术比作智能手机：一项曾经注定的创新，如今已变得日常生活中不可或缺：   https://www.gamesradar.com/games/action/metal-gear-solid-and-death-stranding-creator-hideo-kojima-thinks-we-cant-go-back-to-a-world-without-ai-smartphones-were-the-same/   由   提交 /u/Barmy_Deer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pra2la/kojima_compares_ai_to_smartphones/</guid>
      <pubDate>Sat, 20 Dec 2025 09:02:04 GMT</pubDate>
    </item>
    <item>
      <title>人工智能答案是否正在改变用户点击网站的方式？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6nib/are_ai_answers_changing_how_users_click_websites/</link>
      <description><![CDATA[我注意到人们更多地依赖人工智能答案，点击更少的链接。您认为这会长期损害网站，还是只会改变流量的行为方式？   由   提交 /u/Real-Assist1833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr6nib/are_ai_answers_changing_how_users_click_websites/</guid>
      <pubDate>Sat, 20 Dec 2025 05:31:33 GMT</pubDate>
    </item>
    <item>
      <title>我厌倦了人们把对人工智能的愤怒发泄到使用它的人身上。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pr3ufi/im_getting_tired_of_people_taking_their_anger/</link>
      <description><![CDATA[我猜是因为那些人就在那里，他们可以对他们发泄和愤怒，但他们不能对公司这样做？人们会因为说我有时会制作酷龙的人工智能图像或其他什么而对我如此生气和侮辱。 我被告知这样的东西“你正在毁灭地球，你应该为让这件事变得恶心而感到羞耻” ”“没有人关心或想看到你恶心的愚蠢的污水，把你愚蠢的、低效的垃圾污水龙留给自己吧，笨蛋。”“你的每一代都使用加仑的水和成吨的能源，并导致我们整个物种的死亡”“你宁愿便宜又懒惰地制作人工智能污水，也不愿给艺术家一份工作，这样他们就可以直播&quot;&quot;你正在用你的垃圾造成地球和每一位艺术家的死亡&quot;&quot;学会画画，而不是做一个懒惰的无用的混蛋&quot;&quot;你真的在杀死艺术家。你总是让我恶心”。 这什么时候才能停止？我厌倦了人们表现得好像我个人对人工智能曾经做过/将要做的所有坏事负有责任，而且我是邪恶的。不可能说服这些人，否则他们太多了。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pr3ufi/im_getting_tired_of_people_taking_their_anger/</guid>
      <pubDate>Sat, 20 Dec 2025 03:01:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能将要求开发人员变得更加熟练</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</link>
      <description><![CDATA[警告。这篇文章可能会冒犯一些人。我属于那些应该冒犯它的人之一。我就是这篇文章所针对的开发者类型。因为我是一个自学成才的程序员，没有接受过真正的教育。当谈到人工智能时，我可能遇到麻烦了。 人工智能优化了软件开发。现在，构建省力的 SaaS CRUD 应用程序从未如此简单。这将使构建业务应用程序的技能变得更加容易。我个人认为情况不会有明显改善。但企业会让这些开发人员变得不那么重要。这些开发人员可能会是技术性更强的产品经理，而不是完全技术性的人员。 但问题是这样的。人工智能将使软件变得更加复杂。这实际上会增加进入壁垒。让我解释一下。 自从网络出现以来，软件质量不一定要很好。由于交付机制始终是远程的，因此您可以推出某些内容，然后快速更改它。整个摩托车是快速移动并打破东西。 另一方面。如果软件质量不好，许多软件公司可以依靠销售人员将客户锁定在合同中。他们可能会交付非常糟糕的软件产品。但顾客无法离开，因为他们被锁定在长期交易中，而打破这些交易的代价高昂。  现在，如果软件如此容易生产，那么所有这些销售软件的优势就会消失。软件客户现在几乎拥有无限的选择，因为现在编写软件非常容易。 但更重要的是。如果每个人都可以廉价且轻松地生产软件。那么手段就是进取平庸。真正销售软件的唯一途径就是质量。虽然非常简单的软件可以通过人工智能生产，但更高质量的软件却不能。  这引出了我的下一点。仍然存在的软件工程师肯定比今天要好得多。现在开发人员必须考虑性能和优化。他们确实需要担心高质量的用户体验。他们不能再带着明显的错误发货了。因此，现在软件工程师需要担心缓存性能、时间与空间复杂度、分布式系统和共识、验证和验证。以及许多其他事情。 现在软件工程师需要非常优秀。因为软件工程师不太可能再在功能工厂工作了。上市时间不再是一个有价值的指标。随着时间的推移，我们会发现它变得不那么重要。  当然，在速度重于质量的时代长大的首席技术官和产品经理必须重新思考人工智能时代的软件。这将是一个痛苦的过渡，不要指望这种情况会在一夜之间发生改变。由于糟糕的低质量软件让客户感到沮丧，因此有一段时间感到不安。我们现在已经看到了这一点，而且情况只会变得更糟。 对于那些想知道是否应该学习编码的初级人员来说。答案是肯定的，而且现在比以前更重要   由   提交 /u/GolangLinuxGuru1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pqm4ao/ai_will_demand_devs_become_more_skilled/</guid>
      <pubDate>Fri, 19 Dec 2025 14:13:40 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>