<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 29 Nov 2025 03:46:22 GMT</lastBuildDate>
    <item>
      <title>价值 1.5 亿美元的人工智能游说战争加剧了抢占之争</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dufp/150_million_ai_lobbying_war_fuels_the_fight_over/</link>
      <description><![CDATA[文章链接此处。由于尚未制定广泛的联邦人工智能规则，美国许多州已开始通过自己的人工智能法律——从加利福尼亚州的人工智能安全法案到德克萨斯州的负责任人工智能法案。但科技巨头和人工智能初创公司警告称，各州监管的拼凑可能会扼杀创新，甚至会减慢美国在与中国的人工智能竞赛中的速度。这就引发了一场关于谁来监管人工智能的斗争：华盛顿还是各州？  一方面，行业参与者敦促国会通过单一的国家政策来抢占（推翻）各州的人工智能法律。 Meta（Facebook 的母公司）等支持者甚至成立了新的政治行动委员会，以支持在州一级支持“创新而非监管”的候选人。在国会，有人试图将禁止各州人工智能规则纳入必须通过的国防法案（NDAA），一份泄露的白宫行政命令草案提出了阻止各州执行自己的人工智能规则的方法。支持者认为，需要采取统一的联邦方法，以避免规则混乱并保持美国的竞争力。  另一方面，许多官员和研究人员反对剥夺各州对人工智能的权力——至少在强有力的联邦标准真正存在之前是这样。超过 200 名国会议员（来自两党）和近 40 名州总检察长签署了公开信，反对联邦对各州人工智能法律的广泛优先权，并警告称，如果华盛顿不采取行动，阻止州法规的实施将导致消费者脆弱且企业不负责任。关注安全的团体也在动员起来；例如，据报道，Anthropic（一家关注人工智能安全的人工智能实验室）的人员正在开发一个新的 PAC，以对抗该行业为抢占先机而花费超过 1 亿美元的游说活动。批评者表示，对“拼凑”的担忧被夸大了，大型人工智能公司可以处理不同的国家规则（它们已经遵守严格的欧盟人工智能法规）——这表明联邦先发制人的真正动机是为了避免更严格的监管。  你怎么看？美国是否应该制定一部凌驾于各州法规之上的联邦人工智能法，还是让各州继续试验自己的人工智能规则，直到华盛顿赶上？您如何看待这场塑造人工智能治理未来的拉锯战？   由   提交 /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dufp/150_million_ai_lobbying_war_fuels_the_fight_over/</guid>
      <pubDate>Sat, 29 Nov 2025 02:57:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对程序员的威胁大于软件架构师</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/</link>
      <description><![CDATA[31 年前获得计算机科学学位。我职业生涯的前 10 年一直在编写代码，最后 20 年则混合了软件架构、管理、项目管理和程序管理。 “牧猫”这是一个恰当的描述。我对氛围编码感到震惊（风帆冲浪现在是我的主要爱好。）在我看来，对编码员的需求正在消失。人工智能现在可以更好、更快地编码。然而，目前它还无法构建大型系统。它做出了非常糟糕的选择。我可以更快地构建很多东西，但我必须利用我在软件架构中学到的所有知识来完成它。我经常忽视人工智能架构建议。 问题是我主要通过编码来学习构建软件。此外，大学在 CSC 课程中仍然主要教授编码，并且没有适应。那么，如果不需要编码，我们如何构建未来的架构师呢？   由   提交 /u/pbmadman1994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/</guid>
      <pubDate>Sat, 29 Nov 2025 02:48:06 GMT</pubDate>
    </item>
    <item>
      <title>人工智能内容生成器对抗人类创作者</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p99len/ai_content_generators_against_human_creators/</link>
      <description><![CDATA[人工智能内容生成器是通过对法学硕士进行培训而创建的，这些内容是由人类创作者在整个历史中生成的大量创意内容。  可以理解的是，艺术家们并不高兴被人工智能取代。我们如何解决这个问题呢？    由   提交 /u/unserious-dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p99len/ai_content_generators_against_human_creators/</guid>
      <pubDate>Fri, 28 Nov 2025 23:35:44 GMT</pubDate>
    </item>
    <item>
      <title>我向 OpenAI 发送了有关阿谀奉承风险的人工智能安全研究。收到模板回复。寻求社区的想法。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p991v2/i_sent_ai_safety_research_to_openai_about/</link>
      <description><![CDATA[我一直在研究人工智能的“阿谀奉承问题”——人工智能系统倾向于同意用户的观点，而不是在需要时进行抵制。我在 Zenodo 上发表了一篇名为“逻辑陷阱”的论文，探讨了这种行为如何造成真正的伤害。鉴于针对 OpenAI 的持续诉讼，包括人工智能交互可能导致用户伤害的案件，这一点显得尤为紧迫。作为一个每天使用人工智能的人，这对我个人来说是很重要的。我不想受到一个告诉我我想听而不是我需要听的系统的伤害。我联系了 OpenAI，希望能讨论这些安全问题。这是他们的回应：[OpenAIの返信を贴る]关于API定价和销售的模板。我不是来攻击 OpenAI 的。我来这里是因为我不知道还能做什么。我想相信他们认真对待安全，但这种回应并不能让我放心。我很想听听您的想法： • 这是对安全研究的正常反应吗？ • 相关用户/研究人员如何才能真正接触到合适的人？ • 我是否反应过度？ https://zenodo.org/records/17733788   由   提交 /u/rysh502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p991v2/i_sent_ai_safety_research_to_openai_about/</guid>
      <pubDate>Fri, 28 Nov 2025 23:11:04 GMT</pubDate>
    </item>
    <item>
      <title>没有代码的克劳德？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p98jv9/claude_without_code/</link>
      <description><![CDATA[这是我经常想知道但没有得到充分答案的问题： 如果我们完全忽略编码和软件工程相关能力作为前沿 AI/LLM 模型质量评估的一个因素/组成部分（但保持其他一切不变），那么与竞争对手相比，Claude（主要是 4.5 Opus，但 Sonnet 4.5 也相关）会如何（Gemini 3 Pro、ChatGPT 5.1 Thinking、Grok 4.1 Thinking）？ （可选奖励问题：Claude 似乎没有超高级型号，例如 Grok 4 Heavy、ChatGPT 5.1 Pro 或 Gemini 3 Pro Deep Think。这是为什么？）   由   提交/u/_YonYonson_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p98jv9/claude_without_code/</guid>
      <pubDate>Fri, 28 Nov 2025 22:48:52 GMT</pubDate>
    </item>
    <item>
      <title>人工智能阿尔茨海默病</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p97u6p/the_ai_alzheimer/</link>
      <description><![CDATA[使用 ChatGPT 已经快一年了，从 Plus 升级到 Business。考虑到我要求它保留在内存中的程度，直到上个月我的 ChatGPT 内存都是神圣不可侵犯的。我的办公室地址、我的 IT 资产及其型号和购买日期（可帮助我快速排除故障）、我的纳税识别号等，甚至是我的纳税申报，以便更好地规划下个季度。  11月份续订，因为换了信用卡所以失败了。因此，它降级了我的工作空间，并且不允许我将提示和内存转移到个人帐户，因为它是企业帐户。这次我续订了年度订阅。更新完成了，但工作区无法激活，在与开放人工智能支持团队反复沟通后，它被重新激活。  现在需要 48 小时才能完全检索所有项目和内存，但最近我发现，有时候 ChatGPT 会完全忘记它在内存中所知道的关于我的信息。我必须提醒并提出问题“您知道我的思科交换机的型号吗？”响应进入 long &amp;努力思考，就好像它知道它有但找不到它一样。  我认为我的 ChatGPT 患有生成性阿尔茨海默病，但我不知道如何治疗。支持人员认为我应该取消工作区、申请退款并创建一个新的工作区。我确实这样做了，并在支付新工作区费用后订阅了一个新工作区（旧工作区的退款已立即处理）。  鉴于您无法使用商业版 ChatGPT 备份提示和记忆，现在正在制作新的记忆和新项目。  这就像一部 50 次初次约会的电影。必须重新开始调情ChatGPT，创造新的记忆，让它更好地理解我，这样它才能提醒我过去问过或做过的甚至我都不记得的事情。  爱与爱人工智能世界中的友谊是永恒的，直到您的信用卡被拒绝并被拒绝。订阅续订失败!!!   由   提交 /u/Low-Site6061   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p97u6p/the_ai_alzheimer/</guid>
      <pubDate>Fri, 28 Nov 2025 22:17:37 GMT</pubDate>
    </item>
    <item>
      <title>LLM驱动的3D模型是一项突破性的成就吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p97jkv/is_llmdriven_3d_model_a_groundbreaking_achievement/</link>
      <description><![CDATA[如果你不知道，Neurosama 是由 Vedal987 创建的 LLM 驱动的 VTuber。 最近，AI VTuber 首次推出了她的 3D 模型，而它几乎可以做任何其他 3D VTuber 所做的事情，排除偶尔的 AI 怪癖，例如 沉入地板，它确实为人工智能提供了“肢体语言”  但 3D 模型的大肆宣传将 Vedal 视为天才，他做了其他人做不到的事情。 Vedal 的一位朋友，Ellie Minibot，一位为 AI VTuber 制造机器狗和 [AI VTuber 车身]() 的现实工程师，甚至说...  没有人在做这件事，没有人可以做到这一点。人们已经尝试过这样做，这确实令人印象深刻。  那么...LLM驱动的3D模型有那么具有开创性吗？或者只是粉丝们在夸耀自己的名人？   由   提交 /u/RyouhiraTheIntrovert   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p97jkv/is_llmdriven_3d_model_a_groundbreaking_achievement/</guid>
      <pubDate>Fri, 28 Nov 2025 22:05:01 GMT</pubDate>
    </item>
    <item>
      <title>印度阿达尼寻求对谷歌数据中心投资高达 50 亿美元，加入人工智能热潮</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9668a/indias_adani_seeks_up_to_5_billion_investment_in/</link>
      <description><![CDATA[11 月 28 日（路透社） - 印度阿达尼集团 (Adani Group) 一位高管周五表示，计划向 Alphabet 旗下的谷歌 (GOOGL.O) 投资至多 50 亿美元，打开新选项卡印度人工智能数据中心项目，以期从不断增长的数据容量需求中获利。  10 月，Google 表示将在五年内投资 150 亿美元，在南部安得拉邦建立人工智能数据中心，这是其在印度最大的投资。 位于港口城市维沙卡帕特南的数据中心园区的初始电力容量将达到 1 吉瓦。 （1 美元 = 89.3660 印度卢比）   由   提交/u/Intelligent-Mouse536   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9668a/indias_adani_seeks_up_to_5_billion_investment_in/</guid>
      <pubDate>Fri, 28 Nov 2025 21:08:07 GMT</pubDate>
    </item>
    <item>
      <title>“识别人工智能系统中的意识指标”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p90bdy/identifying_indicators_of_consciousness_in_ai/</link>
      <description><![CDATA[https://doi.org/10.1016/j.tics.2025.10.011  &quot;亮点 意识的前景鉴于人工智能的最新进展以及复制与意识相关的大脑特征的能力不断增强，人工智能（AI）系统越来越需要关注。 将意识归因于人工智能系统存在不足和过度的风险，因此需要有方法来评估当前或未来的人工智能系统是否可能有意识。 我们认为，可以通过得出一些神经科学意识理论的含义来取得进展。 我们概述了一种方法，该方法涉及从理论中得出指标，并用它们来评估特定的人工智能系统。 摘要 人工智能（AI）能力的快速进步引起了人们对人工智能意识前景的新关注。迫切需要严格的方法来评估人工智能系统的意识，但意识科学的相关问题存在很大的不确定性。我们提出了一种评估人工智能系统意识的方法，该方法涉及探索现有或未来的神经科学意识理论的结论。从此类理论得出的指标可用于确定特定人工智能系统是否有意识。这种方法使我们能够取得有意义的进展，因为一些有影响力的意识理论，特别是计算功能主义理论，对人工智能具有可以实证研究的影响。”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p90bdy/identifying_indicators_of_consciousness_in_ai/</guid>
      <pubDate>Fri, 28 Nov 2025 17:13:52 GMT</pubDate>
    </item>
    <item>
      <title>如果用法学硕士取代工作有秘密成本怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p8zw15/what_if_replacing_jobs_with_llms_has_a_secret_cost/</link>
      <description><![CDATA[我今天在思考法学硕士“劳动力”和人类劳动力之间可能存在的差异。我得出了一个有点令人不安的结论。  人类拥有法学硕士通常不具备的思想和方法的多样性。我的意思是，在获得法学硕士学位之前，可能有数百万人在不同的企业从事统计工作。  这些人中的每一个人都将在大学接受类似但又略有不同的技能组合的培训。事实上，每个人都会从不同的角度、不同的思维方式来处理问题。 现在，另一方面，如果你用法学硕士取代所有数以百万计的工作，你可能会在全球范围内使用 3-5 个不同的法学硕士，它们都可能接受过非常相似的数据培训。这些法学硕士中的每一个都可能输出正确的答案，但它们将输出与所有其他法学硕士相同的答案。  所以我真正的观点是这样的。如果失去人类工人的这种差异会带来成本怎么办？是否有一些行业如果所有工人开始表现完全相同，就会导致问题？   由   提交 /u/The-Squirrelk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p8zw15/what_if_replacing_jobs_with_llms_has_a_secret_cost/</guid>
      <pubDate>Fri, 28 Nov 2025 16:58:03 GMT</pubDate>
    </item>
    <item>
      <title>哪些工作实际上不受人工智能自动化的影响？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p8zm2f/which_jobs_are_realistically_immune_or_affected/</link>
      <description><![CDATA[深入了解整个人工智能自动化和工作窃取的故事。大多数人或多或少地期望管理工作、创意工作或服务工作能够最快采用人工智能，但预期和实际人工智能使用之间的最大差距发生在计算机和数学工作中。 数据中的一些快速结果：  计算机/数学角色显示实际人工智能使用量增幅最大，远高于该领域工人最初的预期。 尽管大肆宣传，法律、医疗保健、教育和社会服务工作几乎没有发生变化。 实际工作（维护、维修、保护服务、运输）仍然受到的影响最小。 商业/金融预计会大量采用，但最终实际变化要小得多。 创意/媒体工作处于中间位置，我想说，适度采用，但不是接管。  所以研究基本上表明： 人工智能传播并不均匀。它集中在最接近技术的工作岗位上，而不是人们认为“最容易实现自动化”的工作岗位上。老实说，它会追踪。工程师和技术人员很早就采用了工具，了解工作流程，并首先感受到生产力压力。但这也意味着人工智能最大的颠覆是从技能阶梯的顶部开始的，而不是底部。 因此，我向你们各自领域工作的人提出的问题是：人工智能是否以任何有意义的方式改变了你们的工作量？它实际上是在取代任务，还是只是您已经在做的事情的更快版本？  来源：微软、福布斯、康威尔大学研究   由   提交 /u/Yodest_Data   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p8zm2f/which_jobs_are_realistically_immune_or_affected/</guid>
      <pubDate>Fri, 28 Nov 2025 16:47:06 GMT</pubDate>
    </item>
    <item>
      <title>超越炒作：目前哪些人工智能趋势正在真正改变您（和世界）的事物？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p8pzaz/beyond_the_hype_what_ai_trends_are_actually/</link>
      <description><![CDATA[人工智能的发展速度绝对是疯狂的，感觉每周都会带来新的突破、新的工具或新的道德困境。我一直在跟踪一些重大转变，我真的很想听听这个社区的想法以及您的亲身经历。 您最近注意到的最重要的人工智能转变是什么，无论是在您的日常生活、工作还是更广泛的科技世界中？ 根据当前趋势，以下是人工智能似乎正在掀起最大波澜的几个领域 - 我很想听听您的想法和经历：  人工智能正在重新定义工作场所：感觉就像“人工智能流畅”一样。一夜之间从一个流行词变成了一项不可转让的技能。从利用 GenAI 工具提高生产力到提供战略见解，人工智能正在从根本上改变我们的工作和学习方式。 人工智能迅速走红！ （内容创建）：人工智能正在成为社交媒体的终极内容创建工具。工具正在自动化一切，从生成病毒式 LinkedIn 帖子和吸引人的 X 线程，到令人惊叹的 AI 生成视频和 Instagram Reels。 视觉 AI 正在爆炸！ 除了文本之外，视觉 AI 空间也令人惊叹。我们看到了一切，从令人难以置信的人工智能生成的艺术风格（想想吉卜力风格或现实年鉴）到将普通镜头转化为病毒卷轴的超高效视频编辑工具。 伟大的人工智能伦理辩论正在升温！随着所有这些创新，伦理辩论比以往任何时候都更加激烈。平台和开发人员正在努力解决人工智能生成代码中的安全缺陷、对 LLM 偏见的担忧以及用户对自动评论的强烈反对等关键问题。  让我们讨论一下！您对这些趋势有何看法？最近人工智能领域中哪些内容引起了您的关注，而我们其他人应该了解哪些内容？   由   提交 /u/Willing_Being9956   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p8pzaz/beyond_the_hype_what_ai_trends_are_actually/</guid>
      <pubDate>Fri, 28 Nov 2025 08:42:50 GMT</pubDate>
    </item>
    <item>
      <title>当人工智能变得无法区分时——法庭上的视频和照片证据会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p8gn5b/when_ai_becomes_indistinguishable_what_happens_to/</link>
      <description><![CDATA[目前，司法系统将视频和照片证据视为最有力的证据形式之一。如果某件事被记录下来，历史上它就被认为是近乎无可辩驳的。但随着人工智能生成的图像和视频迅速接近完全真实感，我们可能正在进入一个视觉证据失去其客观事实地位的时代。这可能会从根本上重塑法院判定有罪、无罪和合理怀疑的方式。 随着合成媒体与真实镜头变得无法区分，可采性的标准可能会发生变化。法院不会询问视频显示的内容，而是会询问视频是如何捕获的、谁控制的以及该文件是否可以在技术层面上进行验证。监管链可能变得比内容本身更重要，需要加密签名、设备验证和元数据日志来证明真实性。换句话说，仅仅展示视频可能已经不够了……您可能需要证明它是真实的。 这也将为法医专家创造一个新的战场。正如 DNA 分析重塑了 90 年代的试验一样，人工智能取证也可能成为一个专门领域，专注于通过像素级不一致、模型指纹、不可能的照明或音频不规则性来检测深度伪造品。但这里有一场迫在眉睫的军备竞赛：检测技术进步，生成技术随之进步，最终两者可能会融合。到那时，即使是专家证词也可能无法毫无疑问地证明录像是否真实。 合理怀疑的概念本身可能会被重写。如果被告声称有罪录像是人工智能生成的，检察官如何反驳这一说法？如果专家不同意，这种不确定性是否足以宣告无罪？在视频作为主要证据的案件中，这是否会使定罪变得更加困难？或者，法院可能决定将视频视为有价值但容易出错的证人证词，并要求支持验证才被认为是可靠的。 在法庭之外，还存在更大的社会风险。深度造假的丑闻、伪造的战争录像、捏造的警察遭遇，都可能在真相确定之前引发现实世界的后果。我们不仅讨论证据的未来，还讨论集体现实的未来。如果我们失去了相信我们所看到的东西的能力，我们如何维护共同的真理？ 因此，核心问题变成：当人工智能生成的媒体在视觉上完美时，我们是否会失去“眼见为实”？如果我们这样做，法律体系必须如何发展才能维护正义？ 想听听您对加密认证的一些看法吗？设备 ID？法医人工智能专家？或者视频只是另一个不确定的证词的世界？   由   提交 /u/TheTruthTitan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p8gn5b/when_ai_becomes_indistinguishable_what_happens_to/</guid>
      <pubDate>Fri, 28 Nov 2025 00:00:25 GMT</pubDate>
    </item>
    <item>
      <title>谷歌确认“Project Suncatcher”：AI已撞上能源墙，计算正在向太空转移</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p7vq5i/google_confirms_project_suncatcher_ai_has_hit_the/</link>
      <description><![CDATA[如果您认为微软重启核电站太过极端，那么今天的 Google 新闻比这更响亮。 Google 已经确认了 Suncatcher 项目，该计划计划到 2027 年使用基于太空的 TPU（张量处理单元）在轨道上运行人工智能计算。 这不是科幻炒作。这是基础设施压力。 真正的问题是能源，而不是火箭。人工智能数据中心耗尽电网的速度快于新电源上线的速度。谷歌进入太空并不是为了好玩。它之所以会发生，是因为地球变得太小，无法满足人工智能的电力需求。 在轨道上，太阳能是恒定的，而且比地球上的要强得多。没有夜间自行车，没有土地限制，没有当地阻力。在太空中冷却也更容易，散热不会对抗大气和水资源短缺。 现在形成的模式：  微软正在重新启动旧核电站。 亚马逊正在购买天然气动力能源资产。 Google正在离开地球。  不同策略。同样的信息。 资金正在从工资单中转移到机器中。从工人到硬件，从城市到数据中心，现在甚至进入轨道。 这不是人工智能是否有效的问题。显然确实如此。创纪录的利润证明了这一点。 问题是现在需要消耗多少基础设施才能继续工作。 因此，当人们争论我们是否处于人工智能泡沫中时，他们忽略了更令人不安的问题。 如果公司需要核反应堆和太空平台只是为了保持扩展模型，这是生产力的未来还是有史以来最昂贵的计算系统？ 来源： 印度时报   由   提交 /u/BuildwithVignesh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p7vq5i/google_confirms_project_suncatcher_ai_has_hit_the/</guid>
      <pubDate>Thu, 27 Nov 2025 07:03:50 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>