<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 04 Jan 2026 09:24:14 GMT</lastBuildDate>
    <item>
      <title>在责怪模型之前，请尝试仅修复提示中的一件事</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3le8y/before_you_blame_the_model_try_fixing_just_one/</link>
      <description><![CDATA[快速实验建议： 接受一个给你带来不好结果的提示，只更改一件事： 添加一个明确的角色定义输出格式限制范围 不要改变想法 - 只改变结构。在大多数情况下，结果会立即改善。对您帮助最大的一项即时更改是什么？   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3le8y/before_you_blame_the_model_try_fixing_just_one/</guid>
      <pubDate>Sun, 04 Jan 2026 09:09:41 GMT</pubDate>
    </item>
    <item>
      <title>最大的人工智能子系统，但其中大部分是由反人工智能人士组成的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ji7j/biggest_ai_sub_but_its_mostly_populated_by_far_by/</link>
      <description><![CDATA[我支持人工智能。我不会隐瞒，我喜欢人工智能。我喜欢使用它，并且对它未来的发展感到兴奋。我仍然担心所有令人讨厌的事情，比如政府用它来监视人们，用它进行审查等等。 任何时候我在这里发帖，它总是支持人工智能。我对人工智能无法做某事感到失望，我对朋友们在得知我使用人工智能时对我生气感到困扰，我对那些喜欢用它生成愚蠢视频的人的仇恨感到遗憾，我很兴奋它将能够做一些新的和很酷的事情。 但是每一次，几乎每次，帖子都会立即变为 0，在我这边，帖子会继续下降，有时低至 -24，很多回复都是只是侮辱我，称我为愚蠢的人工智能兄弟，说“没有人想看到你愚蠢的垃圾”之类的话，告诉我“很好”当我感到悲伤时，朋友们会因为人工智能而对我非常生气，并且通常会侮辱我，并且非常反人工智能。 我所做的任何回复都会立即被否决，并且随着帖子停留的时间越长，投票率就会继续下降，最终所有支持人工智能的人（很少）都说出了他们的观点，如果我不删除该帖子，我只会得到近乎无限的人偶尔进来侮辱我或告诉我他们有多么讨厌人工智能。 然后我所看到的就是所有反人工智能的人都以大量的赞成票来侮辱我，而所有支持人工智能的人都以大量的反对票来侮辱我。 这里没有真正的讨论，只是一群人进来侮辱别人。到目前为止，大多数回复都是这样的：“好吧，哭得更厉害，没有人想看到你的愚蠢的垃圾。”把那恶心的狗屎留给你自己。” 我真的不明白这个子的意义是什么？看起来更像是对专业人工智能人士来说这是一个陷阱。他们来这里以为可以讨论人工智能，但他们得到的只是人们侮辱他们，告诉他们他们是垃圾，垃圾人类，应该感到羞耻。   由   提交 /u/Dogbold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ji7j/biggest_ai_sub_but_its_mostly_populated_by_far_by/</guid>
      <pubDate>Sun, 04 Jan 2026 07:14:57 GMT</pubDate>
    </item>
    <item>
      <title>人工智能内存功能正在快速推出，但安全模型尚未跟上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</link>
      <description><![CDATA[使用 ChatGPT 内存大约 6 个月了。真正有用 - 记住我的工作设置、偏好、家庭事务。但我也告诉了它关于健康问题、工作压力、财务决策的问题。如果有人可以访问它，他们不仅仅会获得密码。他们得到了我是谁的综合资料。 现在每个大公司都在推动这一点。 ChatGPT 有记忆。克劳德有项目。双子座正在测试它。音调始终是“真正了解你的人工智能”。 这就是困扰我的地方：传统数据库存储孤立的数据。 Gmail有电子邮件。日历有约会。独立的孤岛。 人工智能内存主动连接一切。在一次聊天中提到胸痛，在另一次聊天中提到工作压力，在第三次聊天中提到家庭健康史——它综合了所有这些。这就是特点，但也是使违规变得更加危险的原因。您的电子邮件提供商不会建立心理档案。 AI 内存确实是这样设计的。 尝试在谷歌上搜索这些系统的安全性。找到了 ChatGPT 的一些文档，几个开源文档（Mem0、Zep、EverMemOS）。大多数人专注于使检索工作顺利进行。安全部分只是说“我们加密数据”没有太多细节。 无法找到以下方面的好信息：  人工智能在回答编码问题时可以访问健康数据吗？ 如果一个内存受到损害，所有内容都会泄漏吗？ 当你“删除”某个内存时一段记忆，它真的消失了吗？  OpenAI 每周有 2 亿+ 用户。即使 10% 的人启用了记忆功能，也意味着 2000 万人拥有了解他们一切的人工智能系统。一次泄露不仅仅是泄露密码——它还会泄露多年的背景、人际关系、私人想法、健康信息，所有这些都已合成并可供使用。 与密码不同，泄露后你无法更改你的生活史。 也许我想得太多了。但业界似乎在功能方面进展迅速，而在安全模型方面进展缓慢。我们不应该在它成为主流之前进行对话吗？ 我只是偏执还是这确实令人担忧？   由   提交/u/Secure-Run9146  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ip8f/ai_memory_features_are_rolling_out_fast_but/</guid>
      <pubDate>Sun, 04 Jan 2026 06:29:44 GMT</pubDate>
    </item>
    <item>
      <title>构建音频验证 API：如何在没有机器学习的情况下检测人工智能生成的语音 我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</link>
      <description><![CDATA[花了太长时间构建一些可能毫无意义的东西 制作了一个 API 来判断录音是人工智能还是人类 结果人工智能声音出奇地完美。比如 0.002% 的时间变化，而人类则为 0.5-1.5% 人类很混乱。人工智能不是。 无论如何，有人真的需要这个吗？还是我只是浪费了一个月的时间。  仍然非常困惑如何在不放弃我的整个项目的情况下将其提供给其他人，这是我愿意放弃的一部分   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f62f/building_an_audio_verification_api_how_to_detect/</guid>
      <pubDate>Sun, 04 Jan 2026 03:31:55 GMT</pubDate>
    </item>
    <item>
      <title>公开编码我不会推广</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</link>
      <description><![CDATA[所以今天我大部分时间都在听 Zane 的演讲，努力反对智能合约测试，希望这是一件很困难的事情让我度过难关，但我认为这实际上不会起作用，我不认为我认为我们会提供帮助，只是更多代码或编写代码   由   提交 /u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3f49x/coding_in_the_open_i_will_not_promote/</guid>
      <pubDate>Sun, 04 Jan 2026 03:29:34 GMT</pubDate>
    </item>
    <item>
      <title>重温过去的电影《机械战警 2014》</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</link>
      <description><![CDATA[随着人工智能的进步，现在所需要的只是一个机器人，而这部 2014 年翻拍的机械战警电影几乎在人工智能可能发展的方向上变得越来越重要。当时，与过去的电影进行了比较，这使得这部电影不受欢迎，但如果不看任何以前的机械战警电影，就重新观看这部电影，而我们现在所处的人工智能世界，这部翻拍现在变得相关，可能是受欢迎的，令人毛骨悚然，人工智能可能会朝这个方向发展。电影中也知道人类仍然必须控制人工智能，就像现实世界中的情况一样。这部电影中提到了人工智能，并在《机械战警》中被描绘成机器，但他也提到了人的因素。我想知道最近看过这部电影的人发表评论。   由   提交 /u/poster4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3cfqx/revisiting_the_past_movie_robocop_2014/</guid>
      <pubDate>Sun, 04 Jan 2026 01:28:23 GMT</pubDate>
    </item>
    <item>
      <title>入侵台湾会扼杀人工智能的进步吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</link>
      <description><![CDATA[现在有很多关于委内瑞拉为中国入侵台湾开绿灯的预测... 鉴于用于人工智能的 90% 以上的先进芯片都是台湾制造的，这一切将走向何方？   由   提交/u/SirBoboGargle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3ac1z/will_the_invasion_of_taiwan_kill_the_advancement/</guid>
      <pubDate>Sat, 03 Jan 2026 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>从现实世界数据中自主发现物理不变量</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q3385u/autonomous_discovery_of_physical_invariants_from/</link>
      <description><![CDATA[我是本文的作者。它描述了一种从噪声观测数据中自主识别低维物理不变量的计算方法，无需指定控制方程或手动设计的特征。 该方法执行稀疏函数选择，然后进行数值优化以收敛于紧凑的不变量形式。它在合成系统和真实的 NASA 锂离子电池退化数据集上进行了评估，恢复了稳定、可解释的关系，而不是纯粹的预测模型。 重点是结构恢复和不变性识别，而不是预测性能。没有向系统提供特定于领域的方程。 论文：https://zenodo.org/records/18138728   由   提交 /u/anima-core   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q3385u/autonomous_discovery_of_physical_invariants_from/</guid>
      <pubDate>Sat, 03 Jan 2026 19:12:35 GMT</pubDate>
    </item>
    <item>
      <title>我对我们即将走向的未来感到恐惧。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2ylbg/im_terrified_of_the_future_we_are_heading_to/</link>
      <description><![CDATA[现在正在进行一场人工智能军备竞赛，世界上的每一块芯片最终都将用于为人工智能提供燃料。或者说大部分。现在就开始。几年后个人电脑将几乎买不起。游戏很可能会慢慢消失，我们将成为人工智能的数据收集机器人。人类的每一寸创造力都将被人工智能耗尽。 人工智能所承诺的为全人类带来的好处不会实现。相反，亿万富翁将利用人工智能来获得绝对的权力和控制权。向我们提供人工智能生成的内容，让我们变得麻木，控制我们的信息，从而控制我们的信仰。它现在正在发生。与 Palantir 一起，与 Musk 一起操纵 Grok。世界上最大的社交媒体网络实际上是由一位右翼亿万富翁控制的，他操纵其算法和人工智能来让自己看起来不错。一切从这里开始，几年后我们就生活在一个人工智能控制的信息空间中，我们不知道什么是真实的，什么是假的。目前，这种情况几乎发生在地球上每一个极权右翼地区。人工智能是获得绝对权力的完美工具。 而另一方面，有人谈论人工智能泡沫即将破裂，却根本不认真对待人工智能。不了解这项技术的后果以及人们会用它做什么。 我从人工智能乐观变成了彻底的厄运，但每天，每条关于人工智能和美国正在发生的事情的新闻都清楚地表明了这个方向。当然不是 100%，但我对即将发生的事情感到非常害怕。   由   提交 /u/RamenAfterRain   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2ylbg/im_terrified_of_the_future_we_are_heading_to/</guid>
      <pubDate>Sat, 03 Jan 2026 16:17:17 GMT</pubDate>
    </item>
    <item>
      <title>人类仍然很重要——从“人工智能将取代我的工作”到“人工智能是有限的”：《黑客新闻》对人工智能的现实检验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</link>
      <description><![CDATA[大家好，我刚刚发送了 14th我的每周通讯，Hacker News x AI 通讯，来自 HN 的最佳 AI 链接和围绕它们的讨论的综述。以下是本期分享的一些链接：  软件开发的未来是软件开发人员 - HN 链接 人工智能正在迫使我们编写好的代码 - HN链接 工业软件的兴起 - HN 链接 提示人们 - HN 链接 Karpathy 谈编程：“我从来没有感觉到落后这么多” - HN 链接  如果您喜欢此类内容，您可以在此处订阅每周简讯：https://hackernewsai.com/   由   提交/u/alexeestec  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2xnm6/humans_still_matter_from_ai_will_take_my_job_to/</guid>
      <pubDate>Sat, 03 Jan 2026 15:40:23 GMT</pubDate>
    </item>
    <item>
      <title>人工智能并没有让我们变得懒惰，而是让我们负债累累。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</link>
      <description><![CDATA[我们一直将人工智能视为效率。那是错误的镜头。实际上发生的是交易。我们正在用理解换取速度。短期速度的长期弹性。每当系统为我们思考时，我们现在会节省时间，但稍后就会失去能力。 这种损失会加剧。每个解决的问题都会悄悄地将作用力从人类转移到工具。输出保持高水平，仪表板保持绿色，一切看起来都经过优化。但在本质上，能力正在被削弱。您可以看起来非常高效，但在没有系统的情况下您的响应能力却接近于零。就像金融债务一样，你可能会看起来很富有，直到你实际上并不富有。 那就是崩溃发生的时候。不是因为人工智能失败了，而是因为现实最终要求系统在没有信用的情况下运行。但它不能。没有技能了。没有留下任何判断力。没有适应能力。这次事故并不神秘。账单即将到期。   由   提交 /u/Small_Accountant6083   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/</guid>
      <pubDate>Sat, 03 Jan 2026 09:00:27 GMT</pubDate>
    </item>
    <item>
      <title>我们正在讨论人工智能的未来，就好像法学硕士是最终形式一样</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</link>
      <description><![CDATA[LLM 对 AI 的影响就像软盘对数据中心的影响一样。 我认为人们犯的一个巨大错误是认为 AI 意味着 LLM，这限制了他们理解 AI 对社会的风险和影响的能力。 LLM（大型语言模型）是当前生成人工智能的最先进技术，但 AI不限于LLM。在 LLM 之前，有 HMM、GBM、RNN、VAE、GAN 等。 虽然 LLM 在生成 AI 功能方面提供了显着改进，但它们并不是 AI 模型将采用的最终形式。将会出现更多的创新，这些创新将使法学硕士看起来很原始，甚至可能过时。 因此，当人们说“人工智能不会取代你的工作”时，实际上是这样的。或“人工智能不够准确，不会导致大规模失业”，或者“人工智能不能有知觉或试图毁灭人类”，他们通常谈论的是当前法学硕士的局限性，而不是一般的人工智能。这些论点通常指出了我们今天看到的具体弱点，但这些只是当今技术的暂时限制，而不是人工智能最终可能成为的样子。 就像 RNN 无法生成大量连贯文本但法学硕士现在可以一样，较新形式的生成人工智能展示这些能力并可能在许多任务上超越人类可能只是时间问题。 现在，我们需要就人工智能对社会的影响进行对话，而不仅仅是思考法学硕士。我们需要展望该技术的未来，令人沮丧的是，大多数讨论都无法超越当前的法学硕士。   由   提交 /u/Je-ne-dirai-pas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/</guid>
      <pubDate>Sat, 03 Jan 2026 08:18:00 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的后处理可以破坏 Google SynthID 图像水印检测的证据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/</link>
      <description><![CDATA[我一直在对人工智能图像数字水印的鲁棒性进行人工智能安全研究，重点关注Google DeepMind 的 SynthID（如 Nano Banana Pro 中使用的）。 在我的测试中，我发现基于扩散的后处理会破坏 SynthID，从而导致常见的检测检查失败，而很大程度上保留了图像的可见内容。我记录了之前/之后的示例和检测屏幕截图，显示了在预处理过程中检测到的水印，而在处理后未检测到水印。 为什么要分享此内容？ 这是一个负责任的披露项目。我们的目标是推动讨论如何构建真正强大的水印，并且不能通过简单的重新扩散来擦除。我呼吁社区测试这些工作流程并帮助开发更具弹性的检测方法。 如果您无法使用强大的 GPU 或没有 ComfyUI 经验，您可以在我的 Discord 中免费试用：https://discord.gg/5mT7DyZu Repo（文章 + 工件）：https://github.com/00quebec/Synthid-Bypass 我很想听听你的想法！[](https://www.reddit.com/submit/?source_id=t3_1q2gu7a)   由   提交/u/LiteratureAcademic34  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/</guid>
      <pubDate>Sat, 03 Jan 2026 01:24:10 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>