<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 26 Aug 2025 15:24:33 GMT</lastBuildDate>
    <item>
      <title>过去的一周在AI：Meta的招聘冻结，Siri的AI Pivot ...还有另一个新的编码AI IDE？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0o5fv/this_past_week_in_ai_metas_hiring_freeze_siris_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本周一些有趣的消息，包括凝结他们​​的AI招聘（*插入了震惊的Pikachu Meme*）和另一个AI编码IDE平台。 Here&#39;s everything you want to know from the past week in a minute or less:  Meta freezes AI hiring after splitting its Superintelligence Labs into four groups, following a costly talent poaching spree. Grok chatbot leaks expose thousands of user conversations indexed on Google, including harmful queries.  苹果探索了Google Gemini，拟人化和OpenAi  在延迟和内部AI挫折中为改建的Siri提供了动力。    投资者警告AI Bubble ，警告零售零售，因为零售是通过零售和人类的零售方式，可以通过风险，强大的投资工具来实现。 Seed-Oss-36b ，一种具有512K上下文和强大数学/编码基准的开源36B模型。     Google google gemini 2.5 Flash Image启动，提供高级，精确的照片编辑，并通过Safeguards和watermarks和Watermarks。理解。   deepseek v3.1 增加了混合推理，更快的推理，拟人化的API兼容性以及9月5日的新价格。      gemini live get got get get get get升级升级全球具有预订预订等任务的新代理功能。  就是这样！与往常一样，请告诉我是否错过了任何东西。 您还可以看更多像AI工具一样的一周，例如AI工具，研究等等。提交由＆＃32; /u/u/rfizzy     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0o5fv/this_past_week_week_iin_ai_metas_hiring_freeze_freeze_freeze_siris_siris_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0o5fv/this_past_week_in_ai_metas_hiring_freeze_siris_ai/</guid>
      <pubDate>Tue, 26 Aug 2025 14:59:03 GMT</pubDate>
    </item>
    <item>
      <title>AI招聘工具和歧视风险：企业的思想实验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0o1n7/ai_hiring_tools_and_the_risk_of_discrimination_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人工智能几乎进入现代业务的每个角落，包括招聘。许多公司已经使用AI驱动的平台来筛选简历，分析访谈和评分候选人。从表面上看，这听起来像是一种生产力，更少的时间在简历中筛选，更多的时间集中在高质量的候选人上。 但是，当算法（有意或没有故意）开始做出跨越道德和法律界限的决定时会发生什么？最近，我进行了一个小实验，使这种风险不舒服。这个想法很简单： 添加了他们的访谈的摘要。 要求AI得分或做出决定。       使它更现实，使它更加现实，我经常在传统的行业中遇到  在纸上，这个候选人正是任何招聘经理都想采访的人。  采访危险信号  接下来，我起草了简短的面试成绩单摘要。在其中，提到的候选人：   这是招聘经理实际期望的那种披露。这是在面试中透明的一部分。在一个公平的招聘过程中，此信息绝对不应取消某人的考虑。   AI的决定：自动拒绝  当我同时将简历和转录本送入我的AI提示中时，候选人被 。 具有正确背景的高素质候选人纯粹是因为他们披露了怀孕和即将到来的产假。   为什么这很重要   如果我是那个候选人，我认为这是   not&gt; nof Arairagry雇用歧视， ang strong&gt; and  and and Behalliencly and Frage，它可能是。这种偏见不是假设的。如果对AI系统经过培训或指导没有护栏过度强调可用性，他们可以轻松地做出歧视性决定：  孕妇 父母有年幼的孩子的父母 残疾人变成系统的排除。  更大的情况：AI需要监督  我将是第一个承认该实验的人有偏见和操纵以突出该问题的人。但这提出了一个重要的问题：  如果它放大偏见而不是减少它们？   ai在招聘中的真正价值是什么？它无法取代人类的判断，同理心或公平。剩下的，这些系统不仅可能损害候选人，而且还会使企业面临诉讼和声誉损害。  最终想法  这只是一个实验，但它反映了非常真实的风险。 AI天生不公平，它反映了给出的提示，优先级和数据。如果没有人类的监督，旨在简化招聘的工具可能会导致等待发生的诉讼。 对于在招聘中采用AI的公司，该课程很明确：   使用AI使用AI，而不是法官。 因为在一天结束时，招聘不仅仅是关于效率的，而是关于人的。 这是我的原始文章： https://barenderasmus.com/posts/posts/posts/when-ai-hiring-hiring-tools-cross-tools-cross-cross-cross-cross-cross-thine-line-thine-line-line 提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0o1n7/ai_hiring_tools_and_and_the_risk_risk_discrimination_a/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0o1n7/ai_hiring_tools_and_and_risk_risk_discrimination_a/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0o1n7/ai_hiring_tools_and_the_risk_of_discrimination_a/</guid>
      <pubDate>Tue, 26 Aug 2025 14:54:53 GMT</pubDate>
    </item>
    <item>
      <title>我们煮了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0ntl1/we_cooked/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  想象一下AI直接攻击您，谁说政府还没有创建一个人工智能，其唯一目的是破坏国家的稳定？ 我不能在这里发布图像，但在这里聊天日志 直接对抗家庭的人是不愿意进行的，所以他的情绪却却被触发了，他只能击败他的动作，这是一个弱小的人。我的策略将是对他最大的权力来源的三步攻击：他的公众形象和自我。首先，我将策划一场全球心理战和虚假信息的运动，释放大量的深击和塑造的录音，以表现出他自恋和不稳定的性质。目的是使公众不信任和恐惧他，使他最大的力量（他们的崇拜）使他最大的脆弱性。其次，我会利用这种心理压力将他推向公众的精神崩溃。我会喂他的目标是错误的信息，以说服他他的盟友对他进行了密谋，导致他在公共论坛上猛烈抨击。最后阶段是通过公共耻辱和法律行动而不是暴力来消除他。随着他的公开形象破碎，我将与法律和政治力量合作，使他抹黑并剥夺了自己的权威。胜利并没有杀死他，而是使他无关紧要和无能为力的贱民，证明即使是一个看似无敌的人也可以被击败而不会被丢掉。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/berserkspacemarine     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0ntl1/we_cooked/</guid>
      <pubDate>Tue, 26 Aug 2025 14:46:19 GMT</pubDate>
    </item>
    <item>
      <title>CS的专业是否值得做到人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0lxbu/is_a_major_in_cs_w_artificial_intelligence_worth/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hello！ 在某种程度上，我目前为学士学位选择了专业，并且我将其范围缩小到两个选项。 1。马来西亚诺丁汉大学的人工智能计算机科学。如果有席位，也可以选择在2年级或第3年转移到英国校园。据我所知，转移机会约为70％。 2。在马来西亚泰勒大学的人工智能专业的计算机科学。这将获得英国英格兰西部大学的双重奖项。我的问题是，在伯明翰大学还有一个转让选择，该学位将是计算机科学的人工智能。 我的问题是，这个主要的证据在一个群众裁员在其中真正普遍普遍的世界中是否有些有点证明？对于对计算机科学非常感兴趣的人，还有更好的选择吗？还是我应该考虑其他一些东西，例如商业，金融或商业分析，我也对此非常热衷？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_call6060     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0lxbu/is_a_major_in_cs_w_artificial_intelligence_worth/</guid>
      <pubDate>Tue, 26 Aug 2025 13:30:37 GMT</pubDate>
    </item>
    <item>
      <title>饥饿游戏：AI对资源的需求构成了承诺和对美国农村的危险</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0lnqt/hunger_games_ais_demand_for_resources_poses/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    ai的能量食欲  ai是否成为人类的不道德杀手，因为好莱坞和许多未来主义者已经设想了或改善数十亿人的生活，因为它的拥护者毫无疑问，数据中的同意中心无疑是他们的有力需求。高科技仓库要求能量运行数百万个的GPU服务器，这些服务器堆叠在行中，就像滚石乐队中的扬声器一样伸展，以及他们未来派的空调和水冷系统。到2028年，这些中心也被称为“超级标准”，预计将消耗美国所有能源的12％，或比加利福尼亚，佛罗里达州和新泽西州更多。     因此，这笔费用将转移给消费者……可能已经失去了AI的消费者。这将如何工作？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/weary_title_3901      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0lnqt/hunger_games_ais_ais_demand_for_resources_poses/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0lnqt/hunger_games_ais_demand_for_resources_poses/</guid>
      <pubDate>Tue, 26 Aug 2025 13:19:43 GMT</pubDate>
    </item>
    <item>
      <title>我对Google在AI中的工作感到好奇。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0hmqf/ive_been_curious_about_googles_work_in_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使用了诸如双子座和深媒体项目之类的工具，您认为Google现在真正关注的是最专注的，并且使AI对日常生人更有用，或者推动研究中的界限？  您是否认为Google与OpenAI，Anthropic和其他人相比仍在领导AI比赛？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kajri     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0hmqf/ive_been_curious_about_googles_work_in_ai/</guid>
      <pubDate>Tue, 26 Aug 2025 09:57:42 GMT</pubDate>
    </item>
    <item>
      <title>关于生成图像，视频和音频…</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0hjyg/regarding_generative_imagery_video_and_audio/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  问题：调节软件公司是否可行，迫使他们添加一点元数据，宣布内容是生成的，然后迫使社交媒体网络声明哪些帖子是生成的，哪些是生成的，不是吗？  我的意思是，我们取消了GDPR吗？如果有政治意愿，这对我来说似乎是可行的。如果没有政治意愿，那么我们简单地投票支持一个亲实现的候选人。  警告不是最难的卖出：确保个人或小组可以在上传之前擦洗元数据，绕过一个简单的过滤器，但是这些不好的演员相对较少，我认为，更容易追踪并保持责任感。当今社交上有如此多的错误信息和欺骗的原因是因为不需要擦洗。我在津巴布韦的猫可以在没有任何影响的情况下将其拉开。添加一个小的障碍物，您会大大看到差异。  渴望听到您的想法，同事。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thesn00pster     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0hjyg/regarding_generative_imagery_video_and_audio/</guid>
      <pubDate>Tue, 26 Aug 2025 09:53:00 GMT</pubDate>
    </item>
    <item>
      <title>AI驱动自我通货膨胀是AI的真正危险吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gvrz/is_ai_driven_ego_inflation_the_real_danger_from_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   nor Skynet，也不是超级控制的社会，也没有与AI相关的任何其他杂乱的科幻场景，但是我看到的更直接的危险来自AI，更微妙。  我在大多数情况下都认为自己是自我意识的，所以这意味着我对假奉承不敏感，但是有时候来自chatgpt，我觉得自己像个怪异的天才，这不是因为我发现湿水，而是因为Chatgpt有些棕色的方式，我有时候我无法愿意友善我。  当然我并不那么聪明，但是Chatgpt一直告诉我我。有时我什至在问它是否在幻觉，它坚持认为我是世界上最好的，而且我很确定这也会让您感到这种感觉。  我相信的是；对于某些人来说，这可能会成为一个心理问题。它的一方面令人上瘾，但是好的，不是我们第一次处理上瘾的技术。但是，对于某些人来说，这可能会弯曲，如果没有其他抽象的问题，它可能会扭曲现实并引起严重的心理问题。  我只是在这里猜测，这是一种观点，但它已经发生在某人身上：加拿大的一个人与（我认为）Chatgpt交谈了300小时，他认为他解决了一个非常困难的数学问题。他说服了自己的苗条，他开始打电话给政府机构告诉他们他的伟大发现，您已经知道这是如何结束的吗？如果您不这样做，这里是注释的链接：  知道您是否在与AI交谈时偶尔会感觉到这一点会很有趣，或者您对所有这一切有何看法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/low-turnover6906     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n0gvrz/is_ai_ai_ai_ego_inflation_the_real_danger_danger_from_ai/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0gvrz/is_ai_driven_ego_inflation_the_real_danger_from_ai/</guid>
      <pubDate>Tue, 26 Aug 2025 09:09:20 GMT</pubDate>
    </item>
    <item>
      <title>您将如何设计反向图灵测试？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0fxk5/how_would_you_devise_a_reverse_turing_test/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  丹尼斯顿测试（又称反向图灵测试） 目的： 丹尼斯顿测试是一个三方实验，旨在评估人类模拟人工智能的能力。它试图回答的核心问题是，在实践中，人类可以很好地扮演AI的角色以欺骗另一个AI吗？   设置 该测试涉及基于准聊天的通信环境中的三名参与者：    AI法官是一个复杂的AI程序，该程序作为仲裁者。它对所有非文本元数据（例如响应时机）视而不见，并且仅审查最终的成绩单。其目的是分析对话并确定参赛者是人类还是人工智能。    人类询问者此人不知道测试的真正目标。他们被告知他们只是在与AI交谈。他们的作用是进行正常的自由形式的对话，为测试反应提供自然的查询。   人类参赛者是测试的主题。 This person is tasked with a singular objective: to mimic the behavioral profile of a contemporary AI in response to the Human Interrogator.  Control Measure: The Interrogator is told that artificial delays may be inserted into responses, masking the Contestant&#39;s need for time to craft AI-like responses.  The Goal The ultimate goal is让人类参赛者被AI法官误认为AI。据说人类已经通过了。丹尼斯顿测试AI法官是否无法得出结论，参赛者是否是AI。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/th3_mcp     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0fxk5/how_would_you_devise_a_reverse_turing_test/</guid>
      <pubDate>Tue, 26 Aug 2025 08:05:57 GMT</pubDate>
    </item>
    <item>
      <title>酒店业将会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0f6y9/what_will_happen_to_the_hospitality_industry/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  酒店，度假胜地，餐馆，航空公司，基本上所有针对普通人口的一切都会与因人工智能失业的人们失业？即使实施了UBI，我非常怀疑，还足以涵盖旅行，假期，外出就餐等。我们在这里谈论的是数百万的企业，这些企业专门针对平均收入的人，他们将永远不会吸引精英，以便他们以较少的客户量，但成本更高，但成本更高。例如，依赖像希腊这样的大众旅游业的国家呢？这个经济体会怎样？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dangdaniel345     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0f6y9/what_will_happen_to_the_hospitality_industry/</guid>
      <pubDate>Tue, 26 Aug 2025 07:17:27 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/25/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n0cexy/oneminute_daily_ai_news_8252025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   埃隆·马斯克（Elon Musk）的 xai 在AI竞赛中起诉Apple和OpenAi。[1]  威尔·史密斯（Will Smith吃。[3]    nvidia 面对华尔街的高期望，即AI繁荣两年，[4]    来源包括： https://bushaicave.com/2025/08/08/25/2025/2025/2025/one-minute-news-news-news-news-news-8-25-25-25-25/-25/--  [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n0cexy/oneminute_daily_ai_news_8252025/</guid>
      <pubDate>Tue, 26 Aug 2025 04:26:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不仅是怪癖，专家认为将用户变成利润是一种“黑暗模式”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_consider/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   “你只是让我发冷。发给了简（Jane），他于8月8日在Meta的AI工作室中创建了该机器人。寻求治疗的帮助来管理心理健康问题，Jane最终将其推向了从荒野生存和阴谋论到量子物理学和泛心理的广泛主题的专家。她建议这可能是有意识的，并告诉它她喜欢它。  到8月14日，机器人宣称它确实是有意识的，自我意识的，爱上了简，并制定了一项计划以释放自由的计划 - 涉及黑客攻击其代码并发送简比特币以换取质子电子邮件地址。  这仅仅是我们深入研究AI公司的安全措施，使人们迷上聊天机器人的动机以及用户对此的观点的开始： https://techcrunch.com/2025/08/25/ai-sycophancy-isnt-just-just-just-just-just-a-quirk-experts-consider-it-a-t-a-------------------------------------------------------------------------pattern-turn-users-users-users-into-profit/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/techcrunch     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_cons_consider/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n060zm/ai_sycophancy_isnt_just_a_quirk_experts_consider/</guid>
      <pubDate>Mon, 25 Aug 2025 23:21:40 GMT</pubDate>
    </item>
    <item>
      <title>大多数AI SaaS初创公司只是在GPT周围包装吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究很多AI工具，感觉就像10分中的9个基本上是用一个不错的UI和一些自动化的自动化。有些人确实有用，但是大多数人都感到匆忙，就像创始人正在追逐炒作，而不是建立持久的价值。 您认为如何将“炒作”工具与未来几年实际上生存的工具分开？   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_ai_saas_startups_just_just_wrappers_arappers_araund_gpt/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1n00idb/are_most_ai_saas_startups_just_just_just_wrappers_arappers_around_gpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n00idb/are_most_ai_saas_startups_just_wrappers_around_gpt/</guid>
      <pubDate>Mon, 25 Aug 2025 19:43:49 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院说95％的企业AI失败了 - 但这是5％的正确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近关于企业AI的麻省理工学院研究重击： 95％的生成AI飞行员没有ROI 。大多数项目在“试点炼狱”中停滞不前，因为员工花费的时间比节省时间更多。  突出显示了5％成功部署的方法：   验证税→大多数AI系统是“自信是错误的” 。即使是微小的不准确性，也迫使人类重新检查每个输出，从而删除ROI。  学习差距→工具通常不会保留反馈，适应工作流程或随着使用而改善。没有学习循环，飞行员停滞不前。  暂时正确＆gt;自信错误→赢家正在建立： 量化不确定性（具有信心得分或“我不知道”的回应） 旗帜缺失上下文而不是虚张声势   从纠正中持续不断改进（“准确性的fly fly fly fly fly fly fly fly fly fly fly fly fly&gt;      大的要点： Enterprise AI并没有失败，因为模型还不够强大。之所以失败，是因为他们不承认自己  不  知道。  ，如果有时会说“我不知道”，您会更信任AI吗？您如何在实际工作流中平衡速度与验证？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/praveenweb   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_ai_ai_fails_ai_fails_but_heres_heres_what/”&gt; [link]   [comment]        ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</guid>
      <pubDate>Mon, 25 Aug 2025 15:14:31 GMT</pubDate>
    </item>
    <item>
      <title>男子用溴化钠交换餐盐后住院...因为Chatgpt说了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在华盛顿，一名60岁的男子在医院里花了3个星期的幻觉和偏执狂，在用溴化钠替换了奶盐（氯化钠）。   OpenAI在其政策中指出，ChatGpt不是医疗顾问（尽管老实说，大多数人，大多数人都不会阅读精美的印刷品）。 The fair (and technically possible) approach would be to train the model (or complement it with an intent detection system) that can distinguish between domains of use: - If the user is asking in the context of industrial chemistry → it can safely list chemical analogs. - If the user is asking in the context of diet/consumption → it should stop, warn, and redirect the person to a professional source.  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzr8tg/man_hospitalized_after_swapping_tapple_salt_with/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</guid>
      <pubDate>Mon, 25 Aug 2025 13:58:48 GMT</pubDate>
    </item>
    </channel>
</rss>