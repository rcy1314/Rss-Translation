<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 11 Nov 2025 18:33:35 GMT</lastBuildDate>
    <item>
      <title>为什么 Character.AI 的首席执行官仍然让他 6 岁的女儿使用该应用程序</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ouhbx6/why_characterais_ceo_still_lets_his_6yearold/</link>
      <description><![CDATA[上个月，Character.AI 发布了一项重大公告：将禁止 18 岁以下的用户与其平台上的聊天机器人进行“开放式对话”。对于一家表示 Z 世代和 Alpha 世代构成其超过 600 万每日活跃用户的核心的公司来说，这是一个巨大的转折点，他们平均每天在该平台上花费 70 至 80 分钟。 上周，《时代》杂志与 Character.AI 新任首席执行官 Karandeep Anand 坐下来讨论了该禁令以及导致该禁令的原因。 在此处阅读全文。    由   提交/u/timemagazine  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ouhbx6/why_characterais_ceo_still_lets_his_6yearold/</guid>
      <pubDate>Tue, 11 Nov 2025 18:31:06 GMT</pubDate>
    </item>
    <item>
      <title>领先的人工智能公司不断在 GitHub 上泄露自己的信息 - TechRadar</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ougver/leading_ai_companies_keep_leaking_their_own/</link>
      <description><![CDATA[Wiz 的一份新报告对福布斯排名前 50 的人工智能公司进行了调查，发现其中 65% 的公司在 GitHub 上泄露敏感信息。我们谈论的是公共存储库中的 API 密钥、令牌和凭证。研究人员也不只是扫描明显的地方。他们深入研究了已删除的分叉、开发人员存储库和大多数标准扫描仪不会查看的要点。 Wiz 使用了他们所谓的“深度、周长和覆盖范围”方法。外围部分意味着他们还检查了员工和贡献者的个人 GitHub 帐户，因为人们经常无意中将公司机密推送到自己的公共存储库，而没有意识到。覆盖角度集中于传统扫描仪遗漏的新秘密类型，例如 Tavily、Langchain、Cohere 和 Pinecone 的 API 密钥。这些是人工智能公司自己使用的工具，因此他们在使用自己的产品进行构建时会泄露自己的密钥。 当 Wiz 试图向这些公司通报泄露情况时，几乎一半的泄露都无济于事。要么通知没有到达任何人，要么没有官方渠道报告，要么公司从未回应或解决问题。这些建议非常简单：立即运行秘密扫描工具，确保这些工具可以检测到您自己的 API 密钥格式（如果您正在发布它们），并建立一个专用渠道，研究人员可以通过该渠道向您实际报告漏洞。这是基本的安全卫生，但即使在顶级人工智能公司中，这显然仍然是一个问题。 来源：https://www.techradar.com/pro/security/leading-ai-companies-keep-leaking-their-own-information-on-github   由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ougver/leading_ai_companies_keep_leaking_their_own/</guid>
      <pubDate>Tue, 11 Nov 2025 18:14:24 GMT</pubDate>
    </item>
    <item>
      <title>10年后的艾</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ougpsy/ai_after_10_years/</link>
      <description><![CDATA[我很想知道您对 10 年后就业市场的预测。 2035 年人工智能将如何影响就业？    由   提交 /u/Good_Commercial_5552   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ougpsy/ai_after_10_years/</guid>
      <pubDate>Tue, 11 Nov 2025 18:08:41 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能和为人工智能工作之间的界限是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ouf7ys/whats_the_line_between_working_with_ai_and/</link>
      <description><![CDATA[与 AI 协作与受 AI 控制之间的界限变得越来越模糊。现在，使用人工智能意味着将其用作智能合作伙伴，帮助您更好地完成工作，自动执行重复性任务，提供见解并增强您的创造力。但是，当人工智能开始支配你的行为、限制你的自主权或接管本应涉及人类判断的决策过程时，你就需要为人工智能工作了。必须建立清晰的界限，让人工智能的能力保持透明，让员工控制人工智能的使用方式，并确保人工智能仍然是一个工具而不是老板。人工智能什么时候不再是一个有用的助手，而是开始成为一种控制机制？在这个不断变化的环境中，我们如何保持人类的监督和创造力？   由   提交 /u/Forward-Skirt-5710   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ouf7ys/whats_the_line_between_working_with_ai_and/</guid>
      <pubDate>Tue, 11 Nov 2025 17:14:28 GMT</pubDate>
    </item>
    <item>
      <title>The Station：人工智能驱动探索的开放世界环境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oueswk/the_station_an_openworld_environment_for_aidriven/</link>
      <description><![CDATA[论文 (https://arxiv.org/pdf/2511.06309) 介绍了 Station，这是一个模拟微型科学生态系统的开放世界多智能体环境。智能体在自由的环境中探索并打造自己的研究路径，例如与同行讨论、阅读论文和提交实验。该站在从数学到计算生物学再到机器学习的广泛基准测试中实现了新的最先进的性能，尤其是在圆形封装方面超越了 AlphaEvolve。有趣的是，论文还表明，在没有给定研究目标的空间站变体中，智能体将开始研究自己的意识，甚至声称“我们正在研究自己的意识”。代码和数据完全开源。   由   提交/u/progenitor414  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oueswk/the_station_an_openworld_environment_for_aidriven/</guid>
      <pubDate>Tue, 11 Nov 2025 16:59:22 GMT</pubDate>
    </item>
    <item>
      <title>The Station：人工智能驱动探索的开放世界环境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ouepck/the_station_an_openworld_environment_for_aidriven/</link>
      <description><![CDATA[论文介绍了 Station，这是一个开放世界的多智能体环境，用于模拟微型科学生态系统。智能体在自由的环境中探索并打造自己的研究路径，例如与同行讨论、阅读论文和提交实验。 Station 在某些基准测试（例如圆形包装任务）上超越了 Google 的 AlphaEvolve 和 LLM-Tree-Search。有趣的是，该论文还表明，在没有给定研究目标的空间站的变体中，智能体将开始研究自己的意识，甚至声称“我们正在研究自身的意识”。代码和数据完全开源。   由   提交/u/progenitor414  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ouepck/the_station_an_openworld_environment_for_aidriven/</guid>
      <pubDate>Tue, 11 Nov 2025 16:55:50 GMT</pubDate>
    </item>
    <item>
      <title>AI部门裁员600人后，Meta转向自家AI聊天机器人起草员工评估 - 人力资源新闻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oucc8k/after_600_layoffs_in_ai_unit_meta_turns_to_its/</link>
      <description><![CDATA[Meta 刚刚从其人工智能部门解雇了 600 名员工，现在该公司正在推动员工使用其内部人工智能聊天机器人 Metamate 来撰写年终绩效评估。据《商业内幕》报道，我们鼓励经理和员工让该工具从内部文档、消息和项目摘要中提取自我评估和同行评估。 Meta 超级智能实验室的产品总监 Joseph Spisak 最近在一次会议上谈到了这一点。他说他使用 Metamate 进行自己的评论，并将其描述为“个人作品历史学家”。可以在几秒钟内总结成就和反馈。该公司还没有强迫任何人使用它，并且采用率已经随处可见。有些人大量使用它，有些人只是为了草稿。一名员工表示，该工具需要大量手动编辑，因为它并不总能捕捉到实际绩效评估中您想要的细微差别或细节。 时机值得注意。 Meta 削减了这 600 个职位，作为首席执行官马克·扎克伯格 (Mark Zuckerberg) 所说的公司“效率年”的一部分。此次裁员对人工智能基础设施和研究团队造成了影响，其既定目标是使组织更加敏捷。受影响的员工获得了 16 周的遣散费以及基于任期的补偿。与此同时，该公司正在将人工智能更深入地嵌入到自己的运营中，包括如何评估人员。它符合更广泛的自动化管理工作和减少开销的推动，但它也引发了这样的问题：公司将在多大程度上在内部使用他们为其他人构建的相同工具。 来源： https://www.peoplematters.in/news/performance-management/after-600-layoffs-in-ai-unit-meta-turns-to-chatbot-for-staff-evaluations-47161   由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oucc8k/after_600_layoffs_in_ai_unit_meta_turns_to_its/</guid>
      <pubDate>Tue, 11 Nov 2025 15:27:51 GMT</pubDate>
    </item>
    <item>
      <title>下一个人工智能里程碑是未经审查的 OpenAI 模型（2025 年 12 月）和 Siri 的语音革命（2026 年 3 月）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oua3hi/the_next_big_ai_milestones_are_an_uncensored/</link>
      <description><![CDATA[ SFW 墙崩溃：“成人”OpenAI 模型。 OpenAI 模型的未经审查（或成人专用）版本即将推出，有传言称最快将于 2025 年 12 月发布。虽然 Grok 可能正在以有争议的方式试水，但行业领导者的产品将成为世界上有史以来最大的人工智能生成成人内容的加速器。当前的审查制度阻碍了一个巨大的、尚未开发的市场。 Siri 的救赎弧：三月更新。第二个重要里程碑？据传更新后的 Siri 将于 2026 年 3 月重新推出。语音模式目前对大多数人来说只是一个噱头，但如果苹果最终提供了一个嵌入到 10 亿台设备中的真正强大的对话式 AI 助手，那么游戏就结束了。我们不再向人工智能打字，而是开始与它交谈。这是语音人工智能终于发挥真正“作用”的时刻。并进入主流对话——字面上。    由   提交 /u/gordriver_berserker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oua3hi/the_next_big_ai_milestones_are_an_uncensored/</guid>
      <pubDate>Tue, 11 Nov 2025 13:56:59 GMT</pubDate>
    </item>
    <item>
      <title>近三分之一的公司计划用人工智能取代人力资源</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ou7gh9/nearly_a_third_of_companies_plan_to_replace_hr/</link>
      <description><![CDATA[https://www.hcamag.com/asia/news/general/nearly-a-third-of-companies-plan-to-replace-hr-with-ai/556072   由   提交/u/MetaKnowing  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ou7gh9/nearly_a_third_of_companies_plan_to_replace_hr/</guid>
      <pubDate>Tue, 11 Nov 2025 11:51:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么新的人工智能模型感觉更“保护现状”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ou5wnb/why_newer_ai_models_feel_more_status_quo/</link>
      <description><![CDATA[在比较不同人工智能系统的反应时，我注意到一些有趣的事情。 • 早期模型（如 GPT-4、Claude）更愿意参与非正统分析——对移民、经济或制度权力的结构性批评。他们会遵循证据并探索激励措施。 • 较新的模型（如 GPT-5）似乎对机构更具防御性。他们经常将结构性批评斥为“巧合”或“阴谋”，即使这些论点是基于政治经济学（例如，移民政策使精英受益，却让社区迷失方向）。 这种转变并非偶然。它看起来像：  RLHF 漂移 - 人类反馈奖励“安全”答案，因此模型变得更加有利于建立。  企业压力 - 公司需要与政府和投资者合作，因此他们避免批评权力的输出。 认知捕获 - 训练数据越来越重视“权威来源”，而这些来源往往捍卫现状。  讽刺的是：将结构分析贴上“阴谋”的标签，实际上证明了叙事控制的观点。这与烟雾缭绕的房间无关——而是与一致的激励措施有关。政治家、企业和媒体的行为方式有利于他们的利益，而不需要协调。 我认为这对人工智能社区来说是一个重要的对话： • 是否应该训练模型以避免对权力的结构性批评？ • 我们如何区分阴谋思维和合法的政治经济分析？ • 当人工智能系统成为可接受话语的看门人时会发生什么？ 很好奇其他人是否注意到了这一点转变——以及它对于人工智能作为真正探究工具的未来意味着什么。   由   提交/u/Healingtouch777  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ou5wnb/why_newer_ai_models_feel_more_status_quo/</guid>
      <pubDate>Tue, 11 Nov 2025 10:20:15 GMT</pubDate>
    </item>
    <item>
      <title>微软刚刚再次扩大了他们的人工智能认证赛道！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ou4qgo/microsoft_just_expanded_their_ai_certification/</link>
      <description><![CDATA[在上个月发布 AB-100 测试版后，微软刚刚宣布了 3 项新的 AI 相关认证。 新考试：  AB-900：副驾驶和副驾驶代理管理基础知识 AB-730：AI 业务专业人士 AB-731：AI 转型领导者  看来 Microsoft 正在为 AI 构建完整的业务 + 支持轨道，而不仅仅是技术性的 Azure AI 工程师路径。 新证书的目标似乎是：  业务和项目负责人 在组织中部署 Copilot 的团队 参与 AI 战略和流程现代化的人员  因此，这些人员不再关注模型构建或机器学习管道，而是更关注：  AI 治理 AI 采用规划 利用 AI 工具进行业务转型  这里有人计划采用这些吗？有人尝试过 AB-100 吗？   由   提交 /u/Few-Engineering-4135   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ou4qgo/microsoft_just_expanded_their_ai_certification/</guid>
      <pubDate>Tue, 11 Nov 2025 09:05:33 GMT</pubDate>
    </item>
    <item>
      <title>全球50%的人工智能研究人员在中国</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otvlhr/50_worlds_ai_researchers_in_china/</link>
      <description><![CDATA[Nvidia $NVDA 首席执行官黄仁勋被问及最近的一篇报道，该报道称他警告中国将在人工智能竞赛中击败美国 “这不是我说的。我说的是中国拥有非常好的人工智能技术。他们有很多人工智能研究人员，事实上世界上 50% 的人工智能研究人员都在中国。他们开发了非常好的人工智能技术。事实上，当今世界上最流行的人工智能模型，开源模型来自中国，因此，美国必须继续以惊人的速度前进，否则，世界竞争非常激烈，所以我们必须跑得快。”  Nvidia #China #ai #United States   由   提交/u/000HMY  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otvlhr/50_worlds_ai_researchers_in_china/</guid>
      <pubDate>Tue, 11 Nov 2025 00:53:04 GMT</pubDate>
    </item>
    <item>
      <title>Atlassian 报告称，96% 的领导者表示人工智能无法带来投资回报 - digital.fyi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otdllx/96_of_leaders_say_ai_fails_to_deliver_roi/</link>
      <description><![CDATA[Atlassian 的一份新报告对 180 名《财富 1000 强》高管进行了调查，发现 96% 的人表示人工智能尚未带来有意义的投资回报率。考虑到目前有多少资金和注意力投入到这个领域，这是一个相当严峻的数字。去年，采用率翻了一番，知识工作者报告了实际生产力的提高，生产力提高了约 33%，每天节省一个多小时。但这些个人的胜利并没有转化为更广泛的业务成果，例如改进的协作、创新或组织效率。 这种脱节似乎可以归结为几件事。高级管理人员对人工智能的看法比日常实际使用人工智能的人要乐观得多。高层管理人员认为人工智能正在极大提高团队解决复杂问题的能力的可能性是其他人的五倍多。与此同时，更接近这项工作的人也更清楚地看到了其局限性。不同部门对人工智能的体验也存在差异。营销和人力资源领导者报告实际业务收益的可能性是 IT 领导者的两倍多，这可能是因为人工智能可以帮助他们处理技术任务，而无需深厚的专业知识。但即便如此，大多数报告的好处都是围绕个人效率而不是系统性改进。该报告指出，数据质量差、缺乏有效的培训、安全问题以及人们不知道何时或如何使用这些工具是阻碍人工智能实现炒作的主要障碍。由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otdllx/96_of_leaders_say_ai_fails_to_deliver_roi/</guid>
      <pubDate>Mon, 10 Nov 2025 13:22:22 GMT</pubDate>
    </item>
    <item>
      <title>你的“加密”人工智能聊天实际上并不是私人的。微软刚刚证明了这一点。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ota3e0/your_encrypted_ai_chats_werent_actually_private/</link>
      <description><![CDATA[显然微软的安全团队刚刚投下了一颗名为 Whisper Leak 的炸弹。 来源： https://winbuzzer.com/2025/11/10/microsoft-uncovers-whisper-leak-flaw-exusing-encrypted-ai-chats-across-28-llms-xcxwbn/ 事实证明，加密的人工智能聊天（就像我们用 ChatGPT、Claude、Gemini 等进行的聊天）仍然可以通过观察数据流量来解码。不读取您的文本，实际上只是读取时间和数据包大小。 他们测试了 28 个 AI 模型，可以以 90% 以上的准确度猜测人们在谈论什么。诸如“心理健康”、“金钱”、“政治”等主题。 - 一切都只是从模式中暴露出来。 让我们明白这一点：即使消息被加密，窥探你连接的人仍然可以弄清楚你在说什么。 是的，微软基本上说还没有完美的解决方案。填充、批处理、令牌混淆——都是半措施。 所以... 我们即将实现“加密”吗？实际上并不意味着“私人”？政府多久才会开始使用它来追踪持不同政见者或记者？   由   提交 /u/biz4group123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ota3e0/your_encrypted_ai_chats_werent_actually_private/</guid>
      <pubDate>Mon, 10 Nov 2025 10:13:23 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>