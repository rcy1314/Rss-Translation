<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 22 Aug 2025 15:23:53 GMT</lastBuildDate>
    <item>
      <title>蒸汽机末日的复兴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx9d67/the_resurgence_of_steam_engine_doomers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   蒸汽机末日的重新出现   [原始作者]，1825年8月    近年来，蒸汽引擎已成为行业的未来，使一切都革命到了运输公司的未来。然而，除了这种乐观的态度外，还出现了一群“蒸汽机末日”的声音，警告说这些机器可能导致社会崩溃。这些持怀疑态度的人通常被视为警报者。但是，随着蒸汽发动机变得越来越融入日常生活，他们的担忧正在引起关注。 蒸汽机繁荣开始始于能够自动化重复任务的机器，例如旋转棉花或供电机车。现在，先进的蒸汽机可以进行复杂的操作，从计算贸易路线到起草法律合同。像Xsteam和Steamworks这样的公司发布了与人类创造力相媲美的模型，引发了兴奋和不安。对于末日的人来说，恐惧不仅是失业 - 尽管研究预测，蒸汽机可能在2030年到2030年自动化30％的工作，而且这些机器有可能超过人类监督的潜力。  domer心态的批评者，例如Steamworks，例如Steamworks，例如Steamworks Ceo Elon Gearson，都认为蒸汽机是工具，而不是威胁。 “这些机器扩大了人类的潜力，”齿轮在最近的一次采访中说。 “害怕他们就像害怕印刷媒体。”然而，Doomers指出了诸如2023年锅炉事件之类的事件，在该事件中，错误校准的蒸汽机引起了工厂爆炸，这是未经检查的风险的证据。他们还引用了哲学的关注：如果蒸汽引擎可以模仿人类的推理，什么是什么阻止他们追求与人类的目标不一致的目标？ 辩论已经从边缘论坛转变为主流话语。诸如Steamhub之类的平台上的帖子警告“失控的蒸汽场景”，自我调节引擎可能会失控。同时，工程师和政策制定者正在努力调节这些机器。蒸汽安全研究所是一个新的智囊团，倡导严格的监督，而其他人则认为，扼杀创新可能会使经济理由归结为竞争对手。   ，随着蒸汽机的力量更多，我们的世界更加有力，末日的观点不再容易被忽视。他们的警告 - 大约经济动荡，道德困境或灾难性的故障，使我们面对不舒服的问题。人类可以利用蒸汽动力而不会失去控制权吗？答案可能会影响未来的世纪。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/key-account5259     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx9d67/the_resurgence_of_steam_engine_doomers/</guid>
      <pubDate>Fri, 22 Aug 2025 15:19:26 GMT</pubDate>
    </item>
    <item>
      <title>人工智能登录者正在变得厄运</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx8nob/the_ai_doomers_are_getting_doomier/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Matteo Wong：过去几年对Nate Soares和Dan Hendrycks感到恐惧，“他们俩都带领组织致力于防止AI消除人类的人性，” Matteo Wong写道。 “与其他AI末代言人一起，他们反复警告，颇具巨大的繁荣，机器人可能有一天流氓 - 带有世界末日的后果。但是在2025年，末日越来越近距离地倾斜了一定的宿命论……在4月，几个启示的研究人员都可以在4月份出版了“ ai 2027”，这是一个较长的模型，并逐渐成为一个apother的模型，并逐渐逐渐成为ai 2027的现场，又是一定的，是一定的，``AI 2027&#39;&#39;，这是一定的，``AI 2027&#39;&#39;的现场效果。 2027年，从那里扑灭了人类。 “ AI 2027”文章长达数十页，既挑剔又虚构，其中包含对行业趋势的详细分析，以及有关“ Openbrain”和“ openbrain”和“ Deepent”的极端推断，中国的间谍活动以及险恶的机器人。作者想象，在2030年中期，一个超级智能AI将用生物武器杀死人类：“大多数人在几个小时内死亡；少数幸存者（例如，在掩体中的预科，潜艇上的水手）被无人机擦伤了。’ “但是，同时，与之相关的担忧是，聊天机器人似乎更难被聊天机器人变得更加困难，因为聊天机器人似乎不再是在自我范围内的人，即使是在自我范围内的人，也没有生成的产品。流氓。”  阅读更多： https://theatln.tc/jj8qqs74 提交由＆＃32; /u/theatlantic     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx8nob/the_ai_doomers_are_getting_doomier/</guid>
      <pubDate>Fri, 22 Aug 2025 14:52:37 GMT</pubDate>
    </item>
    <item>
      <title>AI接管我的学校</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx6of3/ai_is_taking_over_my_school/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在线学校和第一周的AI使用令人恐惧。到目前为止，他们已经使用AI对我进行了评分（这做错了），AI RO写作作业，AI来生成图像（签署《独立宣言》吗？），他们为我们提供了3种不同的AI工具。然而，他们禁止学生以任何形式使用AI。我知道这是一所在线学校，所以每个老师有很多学生，但是那时候老师为什么有老师呢？您有AI进行任务，写单词，制作图像，帮助学生并进行评分。在某个时候，我希望完全AI老师。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/snapships4life     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx6of3/ai_is_taking_over_my_school/</guid>
      <pubDate>Fri, 22 Aug 2025 13:34:08 GMT</pubDate>
    </item>
    <item>
      <title>美国人通常对AI的感觉如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4glb/how_do_americans_generally_feel_about_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在日常生活中经常使用AI，并注意到许多Reddit用户似乎持怀疑态度。大多数人都信任和使用还是有很多犹豫？我特别好奇的是，在行业或人口统计学方面的看法如何不同。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/silent-worry-4650     [link]        [commist]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4glb/how_do_americans_generally_feel_about_ai/</guid>
      <pubDate>Fri, 22 Aug 2025 11:56:41 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）：巨像2将是世界上第一个Gigawatt+ AI训练超级计算机。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4294/elon_musk_colossus_2_will_be_the_worlds_first/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/yshys-reception23     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1MX4294/1MX4294/ELON_MUSK_COLOSSUS_2_WILL_WILL_BE_BE_THE_WORLDSS_FIRST/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx4294/elon_musk_colossus_2_will_be_the_worlds_first/</guid>
      <pubDate>Fri, 22 Aug 2025 11:36:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么AI几乎总是在其答复中使用长仪表板（ - ）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mx215s/why_does_ai_almost_always_use_the_long_dash_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai在哪里学会始终使用long dash（ - ）？这可能是培训数据的习惯，或者只是可读性的样式选择？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mx215s/why_does_ai_ai_ai_almost_always_ase_the_long_dash_in/&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mx215s/why_does_ai_ai_ai_almost_always_always_always_the_long_dash_in/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mx215s/why_does_ai_almost_always_use_the_long_dash_in/</guid>
      <pubDate>Fri, 22 Aug 2025 09:42:57 GMT</pubDate>
    </item>
    <item>
      <title>哈维尔·米利（Javier Milei）的政府将监视与AI的社交媒体，以“预测未来犯罪”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwyvjn/javier_mileis_government_will_monitor_social/</guid>
      <pubDate>Fri, 22 Aug 2025 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>AI编码不是实际编码更有用的技能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎这些论坛完全是关于吹嘘自己的AI工作流程多么复杂的人。关于他们的上下文如何提出Claude代码的合法技能。我就像还好吗？这比在C ++中学习游戏开发或编写数据库或学习内存管理更为复杂吗？ 这等同于设置开发人员已经知道该怎么做的开发工作流程和环境。设置Claude代码是否比通过自定义配置和工作流程设置Neovim更复杂？可能不是。 那么，您知道克劳德代码是这项疯狂的新技能，从本质上讲，您只需在整个地方都有文本文件。归根结底，它只是以非确定性的方式生成了一堆代码。或者充其量只是成为一种花式的自动完成，因为您已经限制了模型如此之多，以至于无论如何您还是只要自己编码所有内容。 ，看来只有非编码器似乎只包含Vibe编码。同时，我去了与开发人员有关的论坛，并且有清理错误的恐怖故事。 这是关于LLM的事情，没人想承认： 它们是不可预测的，永远不会预测的。 这就是为什么我只能研究它们的原因。我没有用它们实际做实际的工作。因为工作需要上下文并试图使LLMS上下文意识到上游正在与上游进行战斗。 在短上下文中，窗口很难增加，因为 增加上下文窗口具有二次复杂性。它需要更多的矩阵乘法。 有优化，但它们具有稀疏注意的缺点。但是它的精度较小。  llms仅限于其数学。要通过上下文窗口绕过问题，您需要完全丢弃注意力机制 这对开发意味着什么？根据代码库的复杂性，LLM的性能越来越差。而且，您向LLM的外包代码越多，您对架构的介绍的黑匣子行为 因此，所有这些工作和“ AI技能”的范围比仅仅了解代码更糟糕。由于LLM的基本数学，情况将会变得更糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [links]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwwqu9/ai_coding_is_not_a_more_useful_skills_than_actual/</guid>
      <pubDate>Fri, 22 Aug 2025 04:17:13 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人在工作中对SEO和AI的混合感打交道吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mws6f4/anyone_else_dealing_with_mixed_feelings_about_seo/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在使用AI来帮助工作中的SEO写作。我不是像大学生那样只是要求它去做所有工作，而是让我的语气更加一致并充实某些领域。  在排名方面，它的效果非常好，但是当我的经理发现他们并不激动时。我们从来没有关于在工作场所使用AI使用的对话，而我所听到的只是关于我的内容的积极信息，所以我认为我没有错。  怪异的部分是我公司的其他部分正在启动全面的AI文章，而我的团队显然希望完全避免它。感觉就像行业的不同部分（甚至同一公司）正在以这些东西的速度完全不同。 好奇是否有人遇到了类似的紧张局势，以及他们如何在工作场所处理AI？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mws6f4/anyone_else_else_deal_with_mixed_mixed_feelings_feelings_about_seo/”&gt; [link]   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mws6f4/anyone_else_dealing_with_mixed_feelings_about_seo/</guid>
      <pubDate>Fri, 22 Aug 2025 00:35:09 GMT</pubDate>
    </item>
    <item>
      <title>编码LLMS应该是扩散模型，而不是自回归文本生成器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwpvhu/coding_llms_should_be_diffusion_models_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近使用claude/cursor/gpt来编码和神圣的狗屎，我必须提醒这些模型上有关上下文的次数使我发疯。   好吧，好的，您可以帮助我重构功能，很棒。但是哦，等等，现在读书人已经过时了。哦，有一个测试文件引用旧功能名称。哦，API文档需要更新。哦，还有一个配置文件...您会得到这个想法。 当前的llms基本上是在用代码库一致性播放whack-a摩尔。当它实际上是一个依赖关系的图表时，他们就像是线性对话一样。我们为什么不为代码执行此操作??  想象：您描述了一个更改，而模型只是...  diffuses     是代码库的整个正确状态。所有文件。所有依赖性。所有文档。一枪。不再＆quot oh btw，您还可以更新类型文件。或在3天后发现您的迁移脚本被打破了，因为模型忘记了它的存在。 当前的方法就像在蒙住眼睛时一次绘画Mona Lisa一个笔触，然后在鼻子不匹配脸部时会感到惊讶。同时，扩散就像“这是您的整个一致的代码库，先生”。 厨师的吻  我真的不明白为什么没有人认真对待这一点。仅仅是因为我们陷入了“代码”是文本，文本是顺序的。范例？还是我在这里缺少一些技术限制？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aginext     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwpvhu/coding_llms_should_be_diffusion_models_not/</guid>
      <pubDate>Thu, 21 Aug 2025 22:52:20 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft AI首席执行官称意识研究为“危险”，而Anthropic，Openai，Google在现场积极雇用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  穆斯塔法·苏莱曼（Mustafa Suleyman）刚刚发表了一篇博客文章，认为研究AI福利是&#39;早产，而且坦率地说是危险的。&#39; 他的理由？它可能会使人们认为AI可能有意识，导致“不健康的依恋”。 同时：  拟人化发起了一项专门的AI福利研究计划  OpenAi研究人员公开地接受了意识     google  google  li&gt; google   google            li&gt; li&gt; li&gt; li&gt;有害的对话（行动中的字面AI福利）  我试图了解何时“不研究，这是危险的”成为有效的科学方法论吗？这感觉不像科学推理，而更像是公司定位。 关于研究新兴现象和宣布整个研究领域之间应有的界限的想法？  https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petermossack     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwj5wu/microsoft_ai_chief_calls_consciousness_research/</guid>
      <pubDate>Thu, 21 Aug 2025 18:31:05 GMT</pubDate>
    </item>
    <item>
      <title>AI部门发生的裁员是没有意义的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgupn/layoffs_happening_in_ai_departments_doesnt_make/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  公司正在介绍对AI研究的重点，但是从统计数据中，AI研究部门也正在发生许多裁员。为什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ajagajan_007     [link]     32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgupn/layoffs_happening_in_ai_departments_doesnt_make/</guid>
      <pubDate>Thu, 21 Aug 2025 17:05:38 GMT</pubDate>
    </item>
    <item>
      <title>人工智能繁荣面临障碍 - 这就是为什么我认为重大估值更正即将接近</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mwgpah/the_ai_boom_is_facing_obstacles_heres_why_i/</guid>
      <pubDate>Thu, 21 Aug 2025 17:00:17 GMT</pubDate>
    </item>
    <item>
      <title>95％的公司AI计划是毫无价值的。华尔街恐慌。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在gizmodo上找到了本文。 TL; dr -95％的AI计划由公司发起的任何福利都没有产生任何福利，这可能会引起资金：   https://gizmodo.com/-/gizmodo.com/the-report-port-report-port-thats-pook---thats-pooking-wall-s-pooking-wall-wall-s-wall-street-street-s-2000645518 提交由＆＃32; /u/u/vengeful_bunny     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw9onw/95_of_corporate_ai_initiatives_are_worthless_wall/</guid>
      <pubDate>Thu, 21 Aug 2025 12:34:30 GMT</pubDate>
    </item>
    <item>
      <title>Zuckerberg冻结了AI在泡泡恐惧中招聘</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      此举与梅塔报道的薪水急剧相反，最高可达最高10亿美元的顶级人才        马克·扎克伯格（Mark Zuckerberg泡沫。 这家技术巨头已经冻结了其“独特实验室”的招聘，只有AI首席Alexandr Wang必须批准的极少数例外。    阅读更多：   https://www.telegraph.co.uk/business/2025/08/21/zuckerberg-freezes-ai-hiring-amid-bubble-fears/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thetelegraph   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_ai_amid_amid_amid_mid_bubble_fears/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mw7i5e/zuckerberg_freezes_ai_ai_hiring_amid_amid_amid_amid_amid_amid_amid_amid_mid_bubble_fears/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mw7i5e/zuckerberg_freezes_ai_hiring_amid_bubble_fears/</guid>
      <pubDate>Thu, 21 Aug 2025 10:47:53 GMT</pubDate>
    </item>
    </channel>
</rss>