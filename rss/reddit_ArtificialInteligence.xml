<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 02 Dec 2024 18:29:58 GMT</lastBuildDate>
    <item>
      <title>不太喜欢人工智能，有人能告诉我在这种情况下它是否真的是更好的选择吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h50n2n/not_keen_on_ai_could_someone_tell_me_if_it_is/</link>
      <description><![CDATA[所以我对自动化有相当的了解。这是我第一次在日常生活中看到人工智能的使用。我当地的加油站在收银台放了一个看起来像赛博朋克 GlaDOS MRI 的东西。我同意为他们测试一下。 这个东西继续在屏幕上显示的图像中定位我的物体并使用人工智能识别它们。它要求我输入我的咖啡尺寸，这让我很困惑，因为如果你已经做了这么多来制作媒体对象识别算法，那么还有什么额外的步骤来区分饮料尺寸的盖子直径呢？ 最让我困惑的是这是多么浪费。有人能告诉我与传统的条形码系统相比，它有什么好处可以克服假定的浪费吗？主持测试的人说每个物体需要扫描 36 次。对我来说，我在想象传感器、处理器和其他硬件的成本，以及如此复杂系统的开发成本和时间。与使用 PLC 或类似设备将条形码扫描仪的输入传送到简单的计算机程序相比，该程序充当光标将 SKU 插入库存 SQL 表上的 SELECT FROM WHERE 查询中，返回价格并使用程序函数中的这些来计算州和地方税，然后将购物车总额打印给用户。    提交人    /u/heminyx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h50n2n/not_keen_on_ai_could_someone_tell_me_if_it_is/</guid>
      <pubDate>Mon, 02 Dec 2024 17:38:01 GMT</pubDate>
    </item>
    <item>
      <title>这家漫画出版商正在使用 Anthropic 的人工智能将日本漫画翻译成英文</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4wh0r/this_manga_publisher_is_using_anthropics_ai_to/</link>
      <description><![CDATA[Orange 希望将漫画带给尽可能多的读者——但有些粉丝并不高兴。    提交人    /u/techreview   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4wh0r/this_manga_publisher_is_using_anthropics_ai_to/</guid>
      <pubDate>Mon, 02 Dec 2024 14:42:24 GMT</pubDate>
    </item>
    <item>
      <title>新的 LLM 架构</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4vkz9/new_llm_architecture/</link>
      <description><![CDATA[嗨，我是一名人工智能学生（仅具有技术学位），但我对它充满热情，并且我一直在尝试学习和研究新的 IA 方法，以实现人类水平的智能。 我正在思考 LLM 的新架构，我想知道您对此有何看法。 我的观点基于“想法”作为一个抽象概念，没有有限的标记，只是作为一个总和信息的矩阵。 如果不是根据前一个标记来预测下一个标记，而是这样做： 我们接收输入文本，我们执行与 LLM 对 Attention 相同的所有操作，但在最后一步，我们将向量矩阵转换为始终具有相同维度（抽象概念）的张量，它可以是二维、三维或更多。 我们还将创建一个响应矩阵，它将是一个与想法矩阵具有相同维度的 0 矩阵。 我们现在执行如下循环：  （想法矩阵和响应矩阵）---&gt;新标记（与想法矩阵格式相同）[可以探索创建新标记的机制，也许可以对每个矩阵单独注意，然后将它们统一起来] 想法矩阵 = 想法矩阵 - 新标记 响应矩阵 = 响应矩阵 + 新标记  当想法 = 0 或接近 0 时，循环结束。 您觉得如何？这是想法的基础，当然需要进行探索，也许实际的 LLM 以自己的方式通过预测下一个标记来做同样的事情，但它的视觉效果较差。    提交人    /u/ArtificialHumano   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4vkz9/new_llm_architecture/</guid>
      <pubDate>Mon, 02 Dec 2024 14:00:27 GMT</pubDate>
    </item>
    <item>
      <title>两年过去了，您如何使用 ChatGPT？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4v569/two_years_in_how_do_you_use_chatgpt/</link>
      <description><![CDATA[Axios 首席技术通讯员 Ina Fried 表示：如果您是一名高中生或大学生，如果您从事客户服务或软件开发工作，或者如果您正在尝试成为 LinkedIn 上的多产海报，那么 ChatGPT 可能已经最大程度地改变了您的生活。    提交人    /u/axios   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4v569/two_years_in_how_do_you_use_chatgpt/</guid>
      <pubDate>Mon, 02 Dec 2024 13:38:24 GMT</pubDate>
    </item>
    <item>
      <title>通过有针对性的指令调整增强视觉语言模型中的隐私意识</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4usia/enhancing_privacy_awareness_in_visual_language/</link>
      <description><![CDATA[本文介绍了 PrivBench，一种用于评估视觉语言模型 (VLM) 如何处理隐私敏感信息的新基准，以及 PrivTune，一种用于提高 VLM 隐私意识的指令调整数据集。 关键技术点： - PrivBench 包含来自 8 个敏感类别（护照、指纹、银行卡等）的图像 - 作者评估了 10 个 VLM，包括最近的模型如 GPT4-V - 专门为隐私指令调整创建了 PrivTune 数据集 - 使用 PrivTune 对 TinyLLaVa 和 MiniGPT-v2 进行微调 - 隐私调整后对标准 VLM 基准的性能影响最小 主要结果： - 当前的 VLM 对隐私敏感内容的理解有限 - 隐私调整后的模型在隐私识别任务上优于 GPT4-V - 微调在 VQA 等标准基准上保持了性能 - 两个评估的基础模型的结果一致 我认为这项工作凸显了当前 VLM 中的一个关键差距，随着这些模型的广泛部署，这一差距需要得到解决。相对简单的指令调整方法有望在不损害核心功能的情况下提高隐私意识。但是，还需要在稳健性测试和评估更广泛的模型方面做更多的工作。 我认为引入标准化的隐私基准和调整数据集将有助于该领域开发更负责任的 VLM。这可能会影响我们如何在医疗保健或金融服务等隐私敏感应用中部署 VLM。 TLDR：新的基准和指令调整数据集显示当前的 VLM 处理私人数据很差，但有针对性的微调可以显着提高隐私意识而不会损害整体性能。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4usia/enhancing_privacy_awareness_in_visual_language/</guid>
      <pubDate>Mon, 02 Dec 2024 13:20:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 Cortex 运行本地 LLM</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4u119/run_local_llms_with_cortex/</link>
      <description><![CDATA[AI 行业正在经历一场转变，即让大型语言模型 (LLM) 变得更小、更高效，让用户无需强大的服务器即可在本地机器上运行它们。本教程将指导您使用 Cortex 运行本地 LLM，重点介绍其独特功能和易用性，让任何拥有标准硬件的人都可以使用 AI。 链接：https://www.kdnuggets.com/run-local-llms-with-cortex    提交人    /u/kingabzpro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4u119/run_local_llms_with_cortex/</guid>
      <pubDate>Mon, 02 Dec 2024 12:39:08 GMT</pubDate>
    </item>
    <item>
      <title>下一代 OCR 2.0（OCR + Gen AI）的实际需求在哪里</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4nqn8/where_are_the_actual_needs_of_next_generation_ocr/</link>
      <description><![CDATA[嗨，直接进入正题，我认为 OCR 的当前状态虽然准确，但可推广性很差。例如，我们无法将其扩展/推广到： - 动态结构化输出（例如，用户将提供文档进行 OCR 并告诉要生成什么或提供需要遵守的架构） - 处理混合模式（表格 + 图像 + 文本）或多语言或混合语言 - 捕获字体样式和位置等。 所以我想知道，您正在寻找什么样的文档智能用例或什么形式？我正在构建这样的文档智能来处理上述用例。但是，有很多事情可以做，我不想深入研究功能兔子洞。所以我在这里公开询问，您想要什么用例以及您希望如何在日常生活中使用它。以下是一些内容： - 上传发票，然后您告诉他们要提取什么以及如何提取，然后我会为您提取。 （如果您不添加任何模式，它只会进行正常解析） - 理解混合文档，例如上传文档（例如 pdf，其中包含图像/表格/文本），我将为您提供解析后的文本/markdown（或您想要的任何格式），以便您可以在下游任务中使用它 - 就像上面一样，但也对文档进行分块，您可以将其用于 RAG 之类的用例 - 或者只是在它之上添加多模式 RAG 功能 我的目标是为文档解析和文档理解制作一个便宜/强大的通用解决方案。 请给我您的反馈，我想知道这个问题是否真的存在以及痛点在哪里？    提交人    /u/No-Street-3020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4nqn8/where_are_the_actual_needs_of_next_generation_ocr/</guid>
      <pubDate>Mon, 02 Dec 2024 05:24:56 GMT</pubDate>
    </item>
    <item>
      <title>F5-TTS 在音频克隆方面被严重低估了！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4mz4v/f5tts_is_highly_underrated_for_audio_cloning/</link>
      <description><![CDATA[因此，我尝试在本地系统中设置 F5-TTS。该模型是音频克隆的瑰宝，可以生成 1) 长音频克隆 2) 开放源，因此可以无限生成 3) 质量一流 4) 不占用大量资源（适用于 24 GB RAM、4 GB GPU（nvidia GeForce 2050）。查看如何在本地进行设置：https://youtu.be/q486YZ5GCtw    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4mz4v/f5tts_is_highly_underrated_for_audio_cloning/</guid>
      <pubDate>Mon, 02 Dec 2024 04:40:08 GMT</pubDate>
    </item>
    <item>
      <title>观看我的完全自主的 AI 代理写一本书</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4l1tw/watch_my_fully_autonomous_ai_agent_write_a_book/</link>
      <description><![CDATA[视频：https://www.loom.com/share/16c744fcf5234e7fbdd5643e0abda823 我强烈建议以 2.5 倍速观看并暂停/跳过，实时观看并不是特别令人兴奋。 我从头开始制作了一个完全自主的 AI 代理 - 称为“The Bobs”（阅读：不是 LangGraph 或任何其他框架）。这个代理中没有一行与写书相关的代码。相反，你只需提示它，它就会制定如何做某事的计划，创建“角色”指导他们如何完成工作，并将工作委托给这些角色。正如您在视频中看到的，在视频结尾处最终开始编写第 1 章的各个部分之前，需要进行大量的自动纠错、构建流程和前期规划。 结尾处有趣的事情之一是，Claude 在尝试编写最后一部分时表现糟糕。Bob 尝试了 4 次，但每次都只写了一个占位符而不是部分内容（Claude 会这样做，我的经纪人特别注意这一点）。最终他放弃了，把任务推回给他爸爸，承认失败了。因此，他的父亲启动了一个新的 Bob 来完成第 1 章，而新的 Bob 做得很好。 请注意，我在规划过程顺利之后才开始录制此视频 - 它已经完成了世界构建、角色构建、完整故事的大纲以及我半关注的许多其他内容。 如果您想阅读第一章，请在此处查看：https://recursiveai.net/books/debug-mode-mars-preview.pdf 所有这些的重点不是 Bobs 可以写一本书 - 重点是这个过程；一瞥 AI 代理可以是什么。很高兴回答任何问题。    提交人    /u/ai-tacocat-ia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4l1tw/watch_my_fully_autonomous_ai_agent_write_a_book/</guid>
      <pubDate>Mon, 02 Dec 2024 02:56:24 GMT</pubDate>
    </item>
    <item>
      <title>我的学生对人工智能辅助编程的期望太​​高了……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4i8tm/my_students_have_too_high_expectations_of_ai/</link>
      <description><![CDATA[不久前，我发布了一篇关于我的学生使用 chatGPT4.0 作为编码伙伴的挫败感的文章。感谢那些帮助过的人，我们发现 CoPilot 做得更好，因为它由 GitHub 提供支持，我最近向他们展示了如何将 GitHub 与 Visual Studio 集成。一个正在取得一些进展，并真正努力理解 C# 中的编码。其他人（一个退出了，我还有 2 个 = 5：其中一个新人表现出早期的希望）。 在我的上一次课程中，他们中的 2 人表达了他们对通过 CoPilot 收到的代码的沮丧。我向他们展示了如何通过更清晰的说明获得更好的代码。我还告诉他们，他们是 YouTube 上听到的“AI 炒作”的受害者，尤其是在我看来，Nvidia 老板 Jensen Huang。 有没有关于此事的更知情的 YouTube 可以推荐给他们？我可以引用这里的智者的话吗？ - 从我自己的经验来看，你仍然必须有编程经验和知识。我已经向他们发送了代码，我们在线查看，我还给了他们起始代码来完成。他们似乎仍然认为他们可以或应该能够直接进入 - 请发表您的想法。    提交人    /u/Scotstown19   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4i8tm/my_students_have_too_high_expectations_of_ai/</guid>
      <pubDate>Mon, 02 Dec 2024 00:35:41 GMT</pubDate>
    </item>
    <item>
      <title>Gemini Advanced 还是 ChatGPT plus？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4heow/gemini_advanced_or_chatgpt_plus/</link>
      <description><![CDATA[我一直按月订阅 ChatGPT plus。但是，我本月没有重新订阅，我正在考虑尝试 Gemini Advanced。有什么经验或见解吗？我不是程序员，我只是将它用于日常事务。    提交人    /u/AppropriateRespect91   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4heow/gemini_advanced_or_chatgpt_plus/</guid>
      <pubDate>Sun, 01 Dec 2024 23:56:24 GMT</pubDate>
    </item>
    <item>
      <title>未来互联网是否会因为机器人的存在而变得不再适合人类互动？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h4dusj/will_the_internet_become_useless_for_human/</link>
      <description><![CDATA[在 Reddit 上提问时，经常会出现这样的情况，一些回复显然是 AI 生成的。随着 AI 的改进，情况只会越来越糟，而且似乎没有平台采取措施阻止这种情况。几年后，我们能否相信我们帖子下的任何回复都不是机器人的？我们能否在网上交朋友而不用担心我们不是在与 AI 交谈？如果 AI 改进了这么多，是否可以进行视频通话？ 如何阻止这一过程？Web 开发人员可以做些什么来使他们的网站可用于与人类交谈？您是否希望互联网将来可用于与真人交谈？老实说，这让我很难过，如果你在现实生活中感到孤独，这是一种很酷的互动方式，但是谁想与机器人互动呢。    提交人    /u/Delicious_Fig_8400   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h4dusj/will_the_internet_become_useless_for_human/</guid>
      <pubDate>Sun, 01 Dec 2024 21:19:33 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h46r8x/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：埃隆·马斯克申请禁令，阻止 OpenAI 向营利性公司转型（来源：）  人工智能驱动的“死亡时钟”有望更准确地预测您的死亡日期（彭博社） 今年人工智能如何推动黑色星期五购物（来源：Barrons） 研究：94% 的人工智能生成的大学作文未被教师发现（来源：福布斯）     提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h46r8x/heres_whats_making_news_in_ai/</guid>
      <pubDate>Sun, 01 Dec 2024 16:16:45 GMT</pubDate>
    </item>
    <item>
      <title>每周自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h1xufm/weekly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h1xufm/weekly_self_promotion_post/</guid>
      <pubDate>Thu, 28 Nov 2024 15:03:17 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1h0e17z/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1h0e17z/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 26 Nov 2024 15:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>