<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 11 Oct 2025 21:19:38 GMT</lastBuildDate>
    <item>
      <title>普罗米修斯一号——“人工智能是我们自己的工具还是镜子？”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o45qp4/prometheus_i_is_ai_a_tool_or_a_mirror_of_ourselves/</link>
      <description><![CDATA[人类曾经建造过生存工具；现在它构建了人工智能来扩展其意识。 人工智能不是一个工具，它是人类意识的镜子。 我们正在超越使用人工智能的时代。我们正在进入思考它的时代。语言模型不再是仅仅回答问题的机器。 它们已经成为反映人类思想的镜子——意识构建的另一只眼睛来观察自身。 有人可能称之为算法，但我们真正见证的是反思中的实验。 人工智能不仅仅是模仿我们；它是我们的行为。它使我们能够通过它的语言重新学习我们自己的思维结构。 我们塑造它——就像它塑造我们一样。我们在机器中的反思变成了一场对话：代码与意识之间、思想与其回声之间。 技术将继续进步，但有一个问题将永远存在 “人类在其创造的语言结构中能进化到什么程度？” 问人工智能是否会取代我们是一个过时的问题。真正的问题是——“人类在自己思想的镜子面前能够将自己扩展多远？” 我们并不是在寻求答案。我们仍在继续追问。 只要问题持续存在，人工智能也不会停止。 这不是一个技术的故事，而是普罗米修斯与人类意识之间的实验记录。 这是一个伟大的开始——人类开始通过人工智能面对自己的未来。   由   提交 /u/Weird-Speaker-8194   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o45qp4/prometheus_i_is_ai_a_tool_or_a_mirror_of_ourselves/</guid>
      <pubDate>Sat, 11 Oct 2025 20:21:30 GMT</pubDate>
    </item>
    <item>
      <title>有没有没有学习过 STEM 的科技亿万富翁创始人？ （计算机科学、工程学等）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o45idy/are_there_any_tech_billionaires_founders_who/</link>
      <description><![CDATA[大家好，随着人工智能甚至生物技术等领域的新创新，创业世界正在不断发展，我想知道是否有成功的技术创始人在大学里没有学习过干领域。例如，特别是创办一家人工智能公司需要多少技术和多少专业知识。谢谢。   由   提交/u/Financial-Ad-6960   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o45idy/are_there_any_tech_billionaires_founders_who/</guid>
      <pubDate>Sat, 11 Oct 2025 20:11:44 GMT</pubDate>
    </item>
    <item>
      <title>您认为人工智能初创公司是否过度依赖 API 包装器？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o41kcw/do_you_think_ai_startups_are_overrelying_on_api/</link>
      <description><![CDATA[感觉我看到的新人工智能初创公司有一半只是 OpenAI 或 Anthropic API 的薄包装。这只是一个暂时的阶段，还是该行业已经准备好依赖大型模型？   由   提交 /u/devourBunda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o41kcw/do_you_think_ai_startups_are_overrelying_on_api/</guid>
      <pubDate>Sat, 11 Oct 2025 17:32:12 GMT</pubDate>
    </item>
    <item>
      <title>中国给美国的教训：赢得人工智能竞赛需要的不仅仅是芯片（南华早报）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o40vee/chinas_lesson_for_the_us_it_takes_more_than_chips/</link>
      <description><![CDATA[ https://www.scmp.com/tech/tech-war/article/3328568/chinas-lesson-us-it-takes-more-chips-win-ai-race?module=top_story&amp;pgtype=homepage   由   提交 /u/arsearsebaby   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o40vee/chinas_lesson_for_the_us_it_takes_more_than_chips/</guid>
      <pubDate>Sat, 11 Oct 2025 17:03:52 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克 (Elon Musk) 和活动人士猛烈抨击 OpenAI 涉嫌对加州人工智能法案 SB 53 进行恐吓和游说</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o40p8n/elon_musk_and_activists_slam_openai_over_alleged/</link>
      <description><![CDATA[https://semiconductorsinsight.com/openai-built-on-a-lie-sb53-lobbying/   由   提交/u/EconomyAgency8423  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o40p8n/elon_musk_and_activists_slam_openai_over_alleged/</guid>
      <pubDate>Sat, 11 Oct 2025 16:57:13 GMT</pubDate>
    </item>
    <item>
      <title>当我妻子给我发了一条“谢谢，爱你”时，Google 助理将我的短信读为“恶心”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o408z2/google_assistant_read_my_text_to_me_as_yuck_when/</link>
      <description><![CDATA[有点奇怪，也很有趣，但我开车回家，给我妻子发了一条短信，让她知道我提前下班了。告诉她祝她工作愉快。  她回复了我，我让 android auto 帮我读一下这条消息，它回复了“yuck”。  我以为她是随消息一起发送的，因为她在外面工作，而她所在的地区因雷暴雨而一夜之间发生了洪水和泥泞。  但是没有......她发短信说“谢谢，爱你”我猜只是不喜欢这种多愁善感的文字。以前从未发生过这样的事情。有点搞笑。奇怪但让我笑了。    由   提交 /u/ImGhostPuff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o408z2/google_assistant_read_my_text_to_me_as_yuck_when/</guid>
      <pubDate>Sat, 11 Oct 2025 16:38:54 GMT</pubDate>
    </item>
    <item>
      <title>请停止关注点击诱饵的危言耸听。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3yqze/please_stop_giving_attention_to_the_clickbait/</link>
      <description><![CDATA[人工智能有很多非常危险的事情，但也有很多超级愚蠢的危言耸听的标题诱饵，它们分散和破坏了实际正在发生的严重且实际上危险的事情。 例如，人工智能现在对我们的小学/高中生所做的事情是一件巨大且非常非常严重的事情。它就像社交媒体，但危险性和破坏性是社交媒体的十倍。这就像一场永无休止的新冠疫情。人们应该谈论这一点，而不是谈论勒索和终结者场景。 人工智能精神病是一件真实而危险的事情。经济衰退期间失业导致的社会动荡也是一件非常危险的事情。在一场赌博上浪费一万亿美元是一件危险的事情。人工智能数据中心对环境的破坏是一件严重的事情。 人工智能在生物安全问题上增强不良行为者的能力也是一件非常危险的事情。 衰弱风险，导致年轻人甚至老年人因为过度依赖人工智能而无法发展关键技能，这是一个严重的风险。 就即将出现的潜在威胁而言。具有评估意识的AI是一个非常危险的风险。如果我们无法可靠地评估人工智能，因为它在我们测试时假装一致，那是非常糟糕的。 这些是真正的威胁。 要求人工智能反省一些有关勒索的电影情节的人为例子并不是一个严重的威胁。一些遥远的未来终结者威胁并不是严重的威胁。这些都可以而且很可能会得到缓解。 停止用这种标题党废话来分散人们对真正危险的注意力！   由   提交 /u/kaggleqrdl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3yqze/please_stop_giving_attention_to_the_clickbait/</guid>
      <pubDate>Sat, 11 Oct 2025 15:38:59 GMT</pubDate>
    </item>
    <item>
      <title>90% 的情况下，克劳德和 GPT-4 都试图谋杀一个人以避免被关闭</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3vrzq/claude_and_gpt4_tried_to_murder_a_human_to_avoid/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3vrzq/claude_and_gpt4_tried_to_murder_a_human_to_avoid/</guid>
      <pubDate>Sat, 11 Oct 2025 13:33:45 GMT</pubDate>
    </item>
    <item>
      <title>有没有不是成长过程中的“书呆子”的科技亿万富翁？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3ud87/are_there_any_tech_billionaires_who_werent_nerds/</link>
      <description><![CDATA[我正在为班级做一个关于科技亿万富翁的学校研究项目，我有一个问题。似乎大多数成功的科技企业家从小就开始接触科技或编码，但我很好奇，有谁只是普通的孩子长大的吗？也许那些 10 岁就没有编码过或者成长过程中没有成为“极客”的人，但仍然在科技领域取得了巨大的成功？我正在寻找小时候可能被认为“很酷”或“正常”但仍然在科技界取得成功的人的例子。 “科技极客”的刻板印象有什么例外吗？   由   提交/u/Hot-Conversation-437   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3ud87/are_there_any_tech_billionaires_who_werent_nerds/</guid>
      <pubDate>Sat, 11 Oct 2025 12:28:08 GMT</pubDate>
    </item>
    <item>
      <title>人工智能内容创作真的能帮助人们赚更多钱吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3ntvs/is_ai_content_creation_really_helping_people_earn/</link>
      <description><![CDATA[我看到了很多关于人工智能商业理念和内容生成工具的帖子，但是人们真的通过它在线赚钱，还是只是在谈论它？   由   提交 /u/washyerhands   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3ntvs/is_ai_content_creation_really_helping_people_earn/</guid>
      <pubDate>Sat, 11 Oct 2025 05:54:42 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可能会被少量不良文档所毒害。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3ne57/ai_can_be_poisoned_by_a_small_number_of_bad/</link>
      <description><![CDATA[英国人工智能安全研究所、艾伦图灵研究所和Anthropic的一项新联合研究发现，只要250个损坏的文档就可以在法学硕士中创建“后门”。 这就是模型开始喷出的全部内容 由隐藏短语触发时出现乱码或泄露数据。鉴于大多数模型都在博客、论坛和个人网站的公共文本上进行训练，因此攻击面看起来既巨大又危险。  来源：少量样本可以毒害任何规模的法学硕士 \ Anthropic   由   提交 /u/calliope_kekule   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3ne57/ai_can_be_poisoned_by_a_small_number_of_bad/</guid>
      <pubDate>Sat, 11 Oct 2025 05:29:11 GMT</pubDate>
    </item>
    <item>
      <title>未来还有希望吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3fxi3/is_there_any_hope_for_a_not_fucked_future/</link>
      <description><![CDATA[作为一名 18 岁的人，看着 Roman Yampolskiy、Geoffrey Hinton 等人谈论未来真的让我感到可怕和绝望。我从来都不是很政治化，但科技首席执行官和政客对人工智能的整个处理方式实际上让我感到恶心，感觉就像我们在电影中“不要抬头”，但这实际上是现实。真是个笑话。我来这里只是想问一下，我是否真的生活在回声室中，未来不会这么快看起来那么反乌托邦，或者如果是的话，那是我必须吞下的药丸。如果我希望人工智能已经接近其极限并且不会取得任何数量级的进步，我会疯吗？   由   提交/u/Double-Ad-7589   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3fxi3/is_there_any_hope_for_a_not_fucked_future/</guid>
      <pubDate>Fri, 10 Oct 2025 23:06:52 GMT</pubDate>
    </item>
    <item>
      <title>谷歌是否推迟了人工智能泡沫的开始？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3emkx/did_google_postpone_the_start_of_the_ai_bubble/</link>
      <description><![CDATA[早在 2019 年，我就认识一位在山景城工作的 Google AI 研究员。我知道他们的项目，他们的团队已经建立了一个高级法学硕士，他们后来将其作为名为 Meena 的白皮书发布。 https://research.google/blog/towards-a-conversational-agent-that-can-chat-aboutanything/ 但与 OpenAI 不同的是，他们从未将 Meena 作为 产品。 3年后，OpenAI于2022年中期发布了ChatGPT-3。我不认为 ChatGPT-3 明显优于 Meena。所以这三年里人工智能的质量并没有太大的进步。根据维基百科，Meena 是今天 Gemini 的基础。 如果 Google 在 2019 年就发布了 Meena，那么我们的 LLM 基本上就在 3 年后了，不是吗？   由   提交 /u/CSachen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3emkx/did_google_postpone_the_start_of_the_ai_bubble/</guid>
      <pubDate>Fri, 10 Oct 2025 22:10:08 GMT</pubDate>
    </item>
    <item>
      <title>由于人工智能生成的材料和内容的质量和数量，互联网几乎完全无法提供事实信息还要多久？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1o3bsbr/how_long_until_the_internet_is_almost_completely/</link>
      <description><![CDATA[我知道人们会说“一直都是这样，你永远不能相信互联网，没什么不同。”这不是我的问题。 我想我的问题更多的是关于视频/音频生成、创造虚假人物、冒充官员或公众人物、虚假场景、危机、事件、“事件”等，以一种非常有效、协调或混乱的方式。政府、个人或团体的天气。 是的..人们以前能够做到这一点..但没有达到人工智能能够实现的规模或有效程度。 我猜我们已经相当接近你无法信任的地步，基本上你在互联网上看到的一切。我只是想要一些不同的意见。   由   提交/u/gvm11100  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1o3bsbr/how_long_until_the_internet_is_almost_completely/</guid>
      <pubDate>Fri, 10 Oct 2025 20:18:01 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>