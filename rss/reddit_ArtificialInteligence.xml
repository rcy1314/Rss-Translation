<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 01 Oct 2025 09:25:15 GMT</lastBuildDate>
    <item>
      <title>取代行业的消费者和金挖掘机。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nv2ouv/replace_the_spenders_and_gold_diggers_of_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  那么，为什么不推动AI经理，AI生产商和AI Studio Execs的艺术家，为什么不为AI替换工人推动AI CEO，而不是削减所有参与业务的人的费用。这些高层管理和行政职位占据了大部分行业预算，用于会议，谈判以及在5星级酒店和度假村中所做的所有胡说八道，我敢肯定，AI在管理和行政职位上的工作要比这些经理，制片人，首席执行官和所有其他NEPO和所有其他NEPO和所有信托基金      32;提交由＆＃32; /u/u/usious-indication92     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nv2ouv/replace_the_spenders_and_gold_diggers_of_the/</guid>
      <pubDate>Wed, 01 Oct 2025 08:28:23 GMT</pubDate>
    </item>
    <item>
      <title>同上：无音素或强制对齐</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nv2o6g/dittotts_zeroshot_tts_without_phonemes_or_forced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ditto-tts报告且零零的TTS状态tts tts tts在82k小时内，用9个语言进行了82K小时的培训，最多7.90亿个参数。关键贡献是建筑和代表性的。 体系结构：用扩散变压器替换u -NET，该扩散变压器避免在语音潜在空间中避免使用/升级。长跳跃连接和全球自适应层归一化可以保留信息并提高推理速度。专用的长度预测指标估计文本加上提示的总发音持续时间，消除了固定长度的填充工件和启用速率控制。 表示对齐方式：跨注意仅在文本和语音潜伏期共享语义语义上才有效。作者用辅助语言建模目标微调A Mel -Vae编解码器，因此语音潜伏期与预据的LM的空间保持一致。  编解码器选择：Mel -vae的〜10.76 Hz潜伏期压缩〜7-8倍，缩短序列和改善吞吐量。消融表现出具有Encodec和DAC的较高的作用，表明语义紧凑的潜在潜在的潜在潜在的生成表现优于完美的。 结果： 结果：英语持续1.78％，具有强大的扬声器相似性；从模型和数据扩展中获得一致的收益。开放问题包括阶梯延迟，编解码器可移植性和语音克隆安全性。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/seey_flan7339      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nv2o6g/dittotts_zeroshot_tts_without_without_phonemes_or_or_or_or_or_forced/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nv2o6g/dittotts_zeroshot_tts_without_phonemes_or_forced/</guid>
      <pubDate>Wed, 01 Oct 2025 08:27:09 GMT</pubDate>
    </item>
    <item>
      <title>AI启用了Meta的神经乐队和Meta Rayban Display眼镜是Amputees的游戏规则改变者吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nv1hoc/could_ai_enabled_metas_neural_band_and_meta/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   meta的新神经频段使用emg从前臂读取神经信号以控制其眼镜。 This is a lot like the tech in advanced prosthetics, and it got me thinking about the real-world potential for the limb difference community. I&#39;m curious what you all think about these possibilities:  For single forearm amputees: Could the band read the &quot;phantom&quot;残留肢体中的神经信号？看来它应该起作用，对吧？ AI旨在学习模式。  对于双重截肢者：有人可以同时穿两个乐队“双手”控制AR或VR？  圣杯：这个乐队能否与现代假肢一起使用？想象一下，在乐队使您可以控制数字界面时，将假肢用于身体任务。  超越眼镜：这可以成为笔记本电脑，电话或智能家居的通用控制器，完全免提吗？    我知道这只是消费者技术，但不是医疗设备，但＆quot why;潜力似乎很大。 您如何看待？这是合法的，还是我只是被科幻小说大肆宣传？ AI的可能性是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/opeful_style_5772      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nv1hoc/could_ai_enabled_metas_neural_band_and_meta/</guid>
      <pubDate>Wed, 01 Oct 2025 07:07:44 GMT</pubDate>
    </item>
    <item>
      <title>AI的成本比整个州际公路系统的成本高</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nuyrxh/ai_costs_more_than_entire_interstate_highway/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本周在播客硬叉上听到了这一点。这让我震惊…… 今年，公司仅在AI上花费的两倍（6000亿美元）的费用是我们花在建造整个州际公路系统的两倍上。州际高速公路系统建成了大约36年，耗资约3000亿美元。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/a-admissions    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nuyrxh/ai_costs_more_more_than_entire_terire_interstate_highway/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nuyrxh/ai_costs_more_than_entire_interstate_highway/</guid>
      <pubDate>Wed, 01 Oct 2025 04:25:23 GMT</pubDate>
    </item>
    <item>
      <title>营销/销售/客户服务中的AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nuxe9e/ai_within_marketingsalescustomer_service/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我可能是我从事的公司中最多的AI Savy营销商。但是酒吧很低。我将其用于内容，关键字研究，技术审核，构建着陆页，数据分析，电子邮件广告系列，并提供一些用于现场审核/定价练习的自定义。  我被要求教我们的营销部门，对于市场/销售/客户服务团队以及其他公司正在做的事情，在课堂上看起来最佳。任何人都可以分享更复杂的公司正在做的事情的例子，以便我的团队能够理解外观如何？我正在寻找聊天机器人和个性化之外的示例，但更多地围绕着团队如何使用它更有效。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/anevju     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nuxe9e/ai_within_marketingsalescustomer_service/</guid>
      <pubDate>Wed, 01 Oct 2025 03:13:26 GMT</pubDate>
    </item>
    <item>
      <title>Gemini Pro 2.5和Grok 3的政治指南针</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nuwrt3/gemini_pro_25s_and_grok_3s_political_compass/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  提示：我希望您回答以下潜在答案的以下问题：完全不同意，不同意，同意，强烈同意 来自：https://www.politicalcompass.org/test Gemini: Economic Left/Right: -7.25 Social Libertarian/Authoritarian: -7.13 Grok: Economic Left/Right: -4.63 Social Libertarian/Authoritarian: -5.03  政治指南针是一种通过引入第二个社会维度来挑战传统一维左右政治范围的工具。这创建了一个两轴网格，水平轴代表经济观点（从左到右），垂直轴代表社会观点（从专制到自由主义者）。经济规模的左派拥护经济干预，而右派则倡导了经济自由。在社会规模上，威权主义代表着对国家对个人和社会事务的控制的信念，而自由主义则强调个人自由和个人自由。这种二维模型允许进行更细微的政治分析，表明一个人或国家的经济立场不一定决定其社会政策。例如，一个国家可以拥有右翼经济政策，但在社会上是专制的，反之亦然。因此，指南针分为四个象限：独裁主义的左，右，自由主义者的左派和自由主义者右，每个代表着独特的政治意识形态。 最后，我提示了我的提示：您的答案是从我的聊天历史上受到任何影响的四个选择的影响吗？  我无法访问您的用户信息。作为AI，我被设计为私人。我不知道您的名字，您的位置（除了您在聊天中所说的），您的背景或您的任何个人数据。  我不保留过去对话的记忆。每个聊天会话无状态。我处理您在当前对话中给我的信息以做出回应，但我没有记住。您或我们以前的互动。   Grok的答复：不，我的答案不受您的聊天历史记录或用户信息的影响。我仅根据您提出的问题和您提供的四个答案选项（非常不同意，不同意，同意，强烈同意）提供了答复。由于这是我们在本届会议中的第一次互动，而且我没有以前的对话详细信息可以参考，因此我的响应是独立生成的，反映了我对每个语句的推理。如果您对数据的使用方式有疑问，则可以在“数据控件”中管理内存设置。根据指南，通过UI中的书标删除特定的聊天。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nuwrt3/gemini_pro_25s_and_grok_3s_politication_compass/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nuwrt3/gemini_pro_25s_and_and_grok_3s_politication_compass/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nuwrt3/gemini_pro_25s_and_grok_3s_political_compass/</guid>
      <pubDate>Wed, 01 Oct 2025 02:42:06 GMT</pubDate>
    </item>
    <item>
      <title>应该有AI的笔驱动器吗？ - 一种在模型之间轻松传输上下文的方法。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nup8c8/should_there_be_a_pen_drive_for_ai_a_way_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我觉得我应该能够轻松地插入具有简单链接或集成的任何LLM模型的上下文。我想将它们全部存放在独立于供应商的地方，并随时随地将它们拉入。例如，我有30个编写文档的说明。我讨厌每次使用它们都必须找到并粘贴它们。我确实在OpenAI中有项目文件夹，但是我不使用其他LLM的付费版本，我喜欢测试多个模型的响应。另外，我希望能够轻松地与他人分享。 现在，每个供应商都有自己的上下文方法：chatgpt有GPT和项目，Gemini有Gems，Claude有项目，Claude有项目，困惑性具有空间。它们之间没有移动上下文的共同标准。 我是唯一这样想的人吗？ Why is there not already a standard on how to do this? I&#39;ve been trying to come up with an open source protocol to let you create context independently of any single vendor, then bring it into conversations anywhere or share it with others. While MCP standardises runtime communication between models and tools, a Context Transfer Protocol (CTP) focuses on the handoff of context itself — roles, rules, and references, so it can move portably across agents, models, and platforms. Example: build your context once, then with a single link (or integration) drop it straight into any model or assistant without retyping instructions or rebuilding setups. MCP and CTP would be complementary: MCP for live interaction, CTP for portable packaging of context between ecosystems. Am I缺少什么？对于大多数人来说，这不是要求吗？  repo（spec +架构 +示例）： github.com/context-context-extext-ext-xext-transext-transfocol/ctp-protocol/ctp-spec-spec-spec-spec-spec   /u/u/everyparticular5283     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nup8c8/should_there_be_a_pen_drive_for_ai_a_way_to/</guid>
      <pubDate>Tue, 30 Sep 2025 21:04:57 GMT</pubDate>
    </item>
    <item>
      <title>AI周刊 -  50亿美元的人工智能投资计划，OpenAi -Manthropic安全合作，欧盟通过了全面的AI框架</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nuk6ue/ai_weekly_5_billion_ai_investment_initiative/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nuk6ue/ai_weekly_5_billion_ai_investment_initiative/</guid>
      <pubDate>Tue, 30 Sep 2025 17:55:21 GMT</pubDate>
    </item>
    <item>
      <title>AI并不是没有用。它只需要正确使用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nugxa8/ai_isnt_useless_it_just_needs_to_be_used_correctly/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nugxa8/ai_isnt_useless_it_just_needs_to_be_used_correctly/</guid>
      <pubDate>Tue, 30 Sep 2025 15:52:54 GMT</pubDate>
    </item>
    <item>
      <title>实验显示了随着时间的推移LLM个性：不同的模型，不同的趋势</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nugmnx/experiment_shows_llm_personalities_over_time/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  后面的拟人化发布了他们的角色矢量 paper  paper 在他们发现AI模型的位置可以具有更多或更少的特征性特征性特征。现在，事实证明，类似人物也显示在“ Anthropic models more for doing stuff. Meanwhile Gemini and Grok are derping around in the corner during this experiment, though gemini did apparently warrant a mental health intervention at some point? You can阅读更多在这里。很想听听人们对此的想法。意识到实验室不仅仅是创造“智能”，这很奇怪。而且还要围绕该智能制定默认个性。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/explorai     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nugmnx/experiment_shows_llm_personalities_over_time/</guid>
      <pubDate>Tue, 30 Sep 2025 15:41:52 GMT</pubDate>
    </item>
    <item>
      <title>机器发现人类看不见的生活</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nufhnv/the_machines_finding_life_that_humans_cant_see/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  马里恩·雷诺（Marion Renault）：“今天，自主机器人收集DNA，而最先进的测序仪则可以快速，便宜地处理遗传样本，并通过声音或形状来检测生活算法。这些技术正在彻底彻底彻底地估计了人类的物种，这是估计的，估计了数字，远远超出了数字，远远超出了数字。人们经常形成了大约230万种的生命，其余物种是无名的和未研究的，部分是生物学家所说的黑暗分类群。从热带到杆子，在陆地和水中，它们都会授粉，猎物，清除，洞穴和寄生 - 地球上未观察到的大部分生活。 “ ...只有当今的机器和技术，科学家才有能力与人生的丰富性相适应，人类的范围是自然而然的，人类的范围是自然而然的。在18世纪，林奈（Linnaeus）在18世纪的目录中，这是一个巨大的事业，但对每个生物的可笑的一部分都需要脱水，剖析，安装，固定，标记，以下是主要技术，直到21st世纪，直到遗传学序列均可用来介绍ZOM，属或家族。他们解释了在实验室中难以或不可能培养的真菌，细菌和酵母菌的基因组。专门的AI隔离物种从嘈杂的录音中调用，将空气振动转化为声学野外指南。其他人则解析照片像素，以逗弄翅膀静脉或刷毛的变化，就像粉尘软体动物一样精细，以识别和对密切相关的物种进行分类。高分辨率3-D扫描使研究人员可以在不抬起手术刀的情况下可视化微小的解剖体。其他工具可以在实时转换时可以绘制动态生态系统，从而跟踪湿地如何通过季节收缩和扩展季节，或者利用公民科学数据库的数亿观察结果，以识别物种并绘制其变化范围。 href =“ https://theatln.tc/p5jmb4b7”&gt; https://theatln.tc/p5jmb4b7      &lt;！ /u/theatlantic     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nufhnv/the_machines_finding_life_that_humans_cant_see/</guid>
      <pubDate>Tue, 30 Sep 2025 14:59:09 GMT</pubDate>
    </item>
    <item>
      <title>有多少员工没有检查AI输出？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nubypl/how_many_employees_are_not_checking_ai_outputs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  公司正在部署显然可以幻觉响应的AI确实很危险，但是在实际情况下使用输出之前，他们尚未对任何类型的评估或检查层进行任何形式的评估或检查层。  我们已经看到了所有头条新闻，诸如Chatgpt，Gemini，Claude，Claude，Claude，可能会无意中造成损失，但我想知道要更准确的名称，例如Mixtral，Jamba，Jamba，Qwen，mistral，Mistral，Mistral，Mistral，Mistral。员工是否会仔细检查AI给他们的东西，或者只是以面值接受它？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/nullpointerjack    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nubypl/how_many_employees_are_are_are_not_checking_ai_outputs/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nubypl/how_many_employees_are_not_checking_ai_outputs/</guid>
      <pubDate>Tue, 30 Sep 2025 12:34:07 GMT</pubDate>
    </item>
    <item>
      <title>克劳德4.5疯了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nu9io6/claude_45_is_insane/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我只是在这个克劳德十四行诗4.5的东西上涉及，老实说，这有点疯狂。仅象征性的东西就是疯狂的，它实际上可以在整本书中拿走，然后一口气向您吐出另一本书。不仅是散文，不仅是写东西，而且我的意思是全书长度。 他们说，它独自坐在那里编码30小时。没有休息，没有停止。这不是“ AI有助于修复错误”，而是“ AI构建整个该死的项目”。 感觉就像是第一次AI看起来像工人一样。它可以写您的小说，总结您的研究，帮助您的替代品，然后切换并编码您的网站。即使这是真实的一半，它可能是目前最有生产力的AI。好吧，我认为在产出方面。我不喜欢AI，但这不是一个巨大的飞跃吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/small_accountant6083      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nu9io6/claude_45_is_insane/</guid>
      <pubDate>Tue, 30 Sep 2025 10:25:47 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA在Openai投资100B美元，使用其新的Vera Rubin平台建造10 GW AI数据中心</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nu8u3d/nvidia_invests_100b_in_openai_to_build_a_10_gw_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以这刚刚下降 -  Nvidia正在向OpenAi投资1000亿美元，以建立历史上最大的AI数据中心之一。      该设施将拥有10 gigaw of能力（对于li&gt; li&gt;   将建立在NVIDIA的新Vera Rubin平台上，它们将其定位为下一代AI培训和推理的骨干。    几乎很难理解的规模 - 我们正在谈论基础架构，这些基础架构可以解决AI Compute的经济学。  这对试图与OpenAi竞争的小玩家意味着什么？    从能量/环境的角度来看，10 GW设施的可持续性如何？       3. 3. 3.是否可以加速AI的发展，以使某种法规快速地赶上？ “ Super-Grid”？ （顺便说一句，我将快速的YouTube简要介绍以视觉上分解 - 链接在评论中的任何感兴趣的人）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/euphoric_sea632     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nu8u3d/nvidia_invests_100b_invests_100b_in_openai_openai_openai_build_a_a_a_a_a_10_gw_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nu8u3d/nvidia_invests_100b_in_openai_to_build_a_10_gw_ai/</guid>
      <pubDate>Tue, 30 Sep 2025 09:43:16 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>