<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 05 Jul 2025 09:24:17 GMT</lastBuildDate>
    <item>
      <title>“大美丽的账单有一个大而丑陋的秘密</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls4gcu/the_big_beautiful_bill_has_a_big_ugly_secret/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;更完美的联盟&#39;的调查定义了该法案如何从字面上卖出我们的灵魂，而且任何人都无能为力。 （对科技公司敏感。他们不会欣赏它）  /u/u/kiki1701     [links]     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls4gcu/the_big_big_beautifer_bill_has_has_a_a_big_big_ugly_ugly_secret/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls4gcu/the_big_beautiful_bill_has_a_big_ugly_secret/</guid>
      <pubDate>Sat, 05 Jul 2025 07:43:04 GMT</pubDate>
    </item>
    <item>
      <title>帮助识别声音</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls43h9/help_to_identify_a_voice/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 有人可以告诉以下声音是人类还是ai？如果AI，哪一个？  即使是AI，也似乎是微调的，但至少我想知道他如何设法达到这样的微调水平。  我刚刚拿起音频并将其放入一个概念页面。    https://grey-humity-db7.notion.site/voice-human-or-ai-225e8ff2222222280878326ff37126c9ded    谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/logicalad5115     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls43h9/help_to_identify_a_voice/</guid>
      <pubDate>Sat, 05 Jul 2025 07:18:24 GMT</pubDate>
    </item>
    <item>
      <title>试图应付将来没有席位</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls0gq0/trying_to_cope_with_not_having_a_place_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好。我最近被踢了一个存在的拉比孔，然后在这里徘徊。在写这篇文章之前，我搜索了类似的问题，但是它们都不是正确的。抱歉，如果这是浪费时间。我一直在努力奋斗AI，很长一段时间以来它可以做什么。我曾经对这项技术充满矛盾/有些兴奋，但是随着我学到的更多并受到更多的了解，我就越讨厌它，不信任和恐惧。 我很年轻，而且我是一个有抱负的作家。人们告诉我，我实际上处于一个良好的位置，可以比普通人更好地利用AI。听到这让我恶心。我已经被告知“适应或被抛在后面”。这么多次。从我坐着的地方，我将无法适应。那我该怎么办？一个人如何使自己在将来没有位置的事实感到满意？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/critikat     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls0gq0/1ls0gq0/trying_to_cope_with_with_not_having_a_a_place_in_in_in_in_in_the/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls0gq0/trying_to_cope_with_not_having_a_place_in_the/</guid>
      <pubDate>Sat, 05 Jul 2025 03:27:05 GMT</pubDate>
    </item>
    <item>
      <title>我们达到了LLM峰吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls05va/have_we_reached_peak_llm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  显然对于代理AI有一条漫长的路。但是，似乎我们今天拥有的LLM不仅能够成为几乎任何任务执行的AI代理的大脑。我之所以问，是因为，我看到了所有大型科技公司，以及一些AI公司（Openai，人为），投资了数十亿美元，以建造更大，更好的LLM。我为其中一家大型科技公司工作。感觉就像类固醇上的FOMO。开发LLM的团队基本上有货车布兰奇（Cart Blanche）花费尽可能多的花费。他们唯一的限制是NVIDIA可以制造GPU的速度以及数据中心可以扩展的速度。我看不到有回报，并认为应该将努力集中在代理开发中。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls05va/have_we_reached_peaked_peak_llm/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls05va/have_we_reached_peak_llm/</guid>
      <pubDate>Sat, 05 Jul 2025 03:08:35 GMT</pubDate>
    </item>
    <item>
      <title>LLM可以拥有认知知识吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrzpda/can_llms_ever_have_epistemic_knowledge/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是当前体系结构的基本缺陷吗？ 这是在其DNA中吗？是否可以在未来的体系结构中开发认识论？   &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/u/health_peanut6753     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrzpda/can_llms_ever_have_epistemic_knowledge/</guid>
      <pubDate>Sat, 05 Jul 2025 02:41:08 GMT</pubDate>
    </item>
    <item>
      <title>algothromormormism</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrwctn/algothromorphism/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  拟人化是人类特征对非人类实体的归因。在软件中，这通常扩展到描述程序，就像它们有意图或欲望一样。但是，您所描述的不是人类特征，而是关于投影传统的软件逻辑（确定性，基于规则的“如果是elsse”的思维方式），即从根本上是非确定性的，基于模式的和自适应的。   https://sqirvy.xyz/posts/algothromorphism/ 提交由＆＃32;  /u/quad99   [link] ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrwctn/algothromorphism/</guid>
      <pubDate>Fri, 04 Jul 2025 23:30:03 GMT</pubDate>
    </item>
    <item>
      <title>浪漫的用例真的是一个有毒的话题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrw6ae/are_romantic_use_cases_really_such_a_toxic_topic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我试图创建一篇文章，说明是否有人试图通过使用c0mpanion单词来构建浪漫的聊天机器人，但有任何警告，但我们不允许任何帖子...绕过这个过滤器，将导致永久性禁令。  我感到惊讶。这个话题是如此加载和有毒吗？  mods，不要禁止我！我只是想对此用例进行元讨论。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/karakitap     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lrw6ae/are_romantic_cases_really_such_a_a_toxic_topic/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrw6ae/are_romantic_use_cases_really_such_a_toxic_topic/</guid>
      <pubDate>Fri, 04 Jul 2025 23:21:04 GMT</pubDate>
    </item>
    <item>
      <title>$ 20B搜索幻觉：AI如何在Apple设备上杀死Google</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lru3ip/the_20b_search_illusion_how_ai_might_kill_google/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您会注意到吗？ ，现在，Google每年支付apple 〜200亿美元，成为Safari中的默认搜索引擎。 不是因为用户要求它 - 而是因为默认= dimplault = todeault = note = note = primative =      re at re。 我们正在从“搜索和单击”移动到“询问并获取” Chatgpt，困惑，Apple Intelligence的即时答案。 否10个蓝色链接。没有SEO战争。只是从模型中直接从模型中的答案。只是搜索交易。  未来是AI优先，而不是Google-First。谁控制回答您问题的AI？ 控制知识，商业和文化的流程。 苹果拥有屏幕。唯一的问题是：他们什么时候决定不再需要Google？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lru3ip/the_20b_search_illusion_how_ai_might_kill_google/</guid>
      <pubDate>Fri, 04 Jul 2025 21:39:15 GMT</pubDate>
    </item>
    <item>
      <title>VTS引导的AI交互工作流程用于业务洞察力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrt054/vtsguided_ai_interaction_workflow_for_business/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要发展：“ VTS引导的AI相互作用工作流程，用于业务洞察力，由Sun Ding，Ude Enebeli，Atilhan Manay，Ryan Pua和Kamal Kotak撰写。  研究人员提出了一个新颖的框架，将视觉思维策略（VTS）整合到AI驱动的工作流程中，旨在增强从非结构化业务报告中提取可行的见解。以下是他们的研究中的一些关键见解：    三层方法：该系统在三个层面上运行 - 微米，中，中和宏 - 从文档中的各个数据点进行全面分析，从文档中的各个数据点到总体建议的策略性建议。 VTS-AI matched the rapid pace of responses from a leading language model like ChatGPT, while also providing richer information such as severity scores and causal links—attributes often lacking in simpler models. Human-AI Collaboration: Analysts can interact with AI outputs directly within the same integrated development environment (IDE), allowing for real-time adjustments and a strong强调保持人类的判断以验证发现。    未来的增强：作者计划通过整合对金融敏感的​​语言模型并开发强大的风险＆amp来进一步完善系统。确保数据安全和质量控制的安全层。     已证明的准确性：初始测试表明，VTS-AI不仅可以准确地确定业务轨迹，还突出了需要更深入的分析的领域，而且需要更深入的分析，从而促进敏捷决策的潜力。 href =“ https://www.thepromptindex.com/unlocking-business-ingights-ingights-with-ai-the--------------------------------------------- know-you-needed.html”&gt;在这里纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrt054/vtsguided_ai_interaction_workflow_for_business/</guid>
      <pubDate>Fri, 04 Jul 2025 20:48:09 GMT</pubDate>
    </item>
    <item>
      <title>有任何书籍的建议以开始AI吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrpxie/any_book_recommendations_to_get_started_with_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是软件工程师。我已经构建了网络和应用程序多年了，现在我想开始学习AI。您建议您推荐任何好书吗？ 编辑：我想了解AI的工作方式，看看我是否可以朝这个方向移动我的职业。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lrpxie/any_book_recommendations_to_to_get_start_started_with_ai/&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrpxie/any_book_recommendations_to_get_started_with_ai/</guid>
      <pubDate>Fri, 04 Jul 2025 18:31:39 GMT</pubDate>
    </item>
    <item>
      <title>泄漏的元文档与AI聊天机器人有关，并且情况正在认真下一步。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lroyg1/leaked_docs_of_meta_related_to_ai_chatbot_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  内部元文档详细介绍“项目Omni”。  事实证明，他们可以在Instagram，Messenger和Whatsapp上构建和自定义的新型AI Studio聊天机器人现在可以先发送给您，并记住对话的详细信息。 •他们接受了听起来友好和主题的训练：例如“我希望您有一个和谐的一天！最近发现了任何新的最喜欢的配乐吗？” ￼。 •META将其定位为打击孤独感的一种方式，但显然，更多的参与度=更多的广告（他们预测2025年的生成AI收入为2-3亿美元）。 •Alignerr的人类承包商正在对机器人的后续行动进行评级和完善，以确保它们保持积极和适当的效果。 1。整洁的技术：令人印象深刻的AI，可以记住您的偏好并伸出手感觉是个性化的。 2。令人毛骨悚然的潜力：感觉像聊天机器人“好友”可以玩着情感依赖。用户参与和操纵之间的界线在哪里？ 3。隐私风险：存储聊天历史的机器人……他们保留多长时间？用户可以删除该内存吗？ 4。货币化光学：这显然也是要让您滚动（和广告流动）。    meta说，如果您不回复，他们会停止消息传递，但是仍然是，您首先会觉得自己的数字助手像湿滑的斜坡。 你们所有人怎么看？     •这是下一级级别的AI便利性AI便利性便利性或昏迷的数字挂钩吗？ •您会先让机器人ping吗？ •您想从控件退出，内存删除，透明度方面看到什么？    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lroyg1/leaked_docs_meta_meta_relelated_to_ai_ai_chatbot_and/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lroyg1/leaked_docs_of_meta_related_to_ai_chatbot_and/</guid>
      <pubDate>Fri, 04 Jul 2025 17:51:13 GMT</pubDate>
    </item>
    <item>
      <title>复杂性是k石</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrowp5/complexity_is_kryptonite/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   llm尚未证明自己在我的经验中过于复杂。对于需要高度判断，酌处权和辨别力的任务，它们仍然非常不可靠。他们最大的弊端可能是他们的幻觉通常是“真实的”。   i/我们创建了多个代理/自定义GPT，供我们的业务客户使用。我们对更简单的工作流有了一定的信任，但是到目前为止，我们无法信任模型来可靠地解决中等复杂的（及以后）问题。他们的结果必须始终由经常发现持续错误的合格人类进行审查。即，错误似乎没有任何提示似乎可以可靠地减轻。  我质疑在LLM框架下是否可以解决这些问题。似乎模型与他们的能力一起扩展了他们的问题。我想我们会看看炒作是否到达目的地。  是否有人注意到复杂性与可靠性之间的反关系？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/maninarena     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrowp5/complexity_is_kryptonite/</guid>
      <pubDate>Fri, 04 Jul 2025 17:49:14 GMT</pubDate>
    </item>
    <item>
      <title>使用光子为AI进行线性代数。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrosrn/using_photons_to_do_linear_algebra_for_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  来自电子的热量是推进当前AI硬件的巨大阻滞剂。目前，几乎所有的AI数学 - 矩阵乘法，卷积，向量操作 - 都发生在硅芯片中。这些操作是通过通过CPU，GPU或ASIC中晶体管的电子来处理的。但是那些电子会产生热量。他们有潜伏期。他们消耗能力。而且，在遇到硬限制之前，您只能将这么多的芯片塞入芯片中。  光子计算范围的范例。它使用光子（光颗粒）代替电子来直接进行数学。  如何？  简而言之：通过光线通过微小的光学组件网络（调节器，波导，相移），以作为光线传播而执行数学转换。这些转换对应于线性代数操作AI模型的类型。 您对这种方法有何看法？您兴奋的选择是什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/iseethings404     [link]    [commist]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrosrn/using_photons_to_do_linear_algebra_for_ai/</guid>
      <pubDate>Fri, 04 Jul 2025 17:44:40 GMT</pubDate>
    </item>
    <item>
      <title>光标ai只是地毯拉了所有人，现在检查您的帐单</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lroc9e/cursor_ai_just_rug_pulled_everyone_check_your/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  只是注意到了这一点，并想警告其他人： 光标更改了他们的“无限”用法模型，而无需任何通知。 如果您一直使用SONNET-4或其他高级模型，他们可能会开始向您收取清晰的费用，而不会向您收取清晰的费用。没有弹出窗口。没有什么。我只通过随机检查仪表板来抓住它。 如果您正在按付费计划或高级型号进行，请尽快检查您的使用情况。有些人的充电性超出了预期。 这感觉超级阴暗。至少，它们应该是透明的。 在其他人尚未注意到的情况下对此进行标记。不要措手不及。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lroc9e/cursor_ai_just_rug_pulled_everyone_check_your/</guid>
      <pubDate>Fri, 04 Jul 2025 17:25:33 GMT</pubDate>
    </item>
    <item>
      <title>AI代理只是炒作吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lredx9/are_ai_agents_just_hype/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   gartner说，在成千上万所谓的AI代理中，实际上只有〜130个是真实的，估计AI代理项目中有40％的AI代理项目将在2027年取消，因为高成本，Vague ROI和安全风险。  老实说，我同意。  每个人突然声称自己是AI专家，这正是技术泡沫的形成方式，就像股市一样。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lredx9/are_ai_agents_just_hype/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lredx9/are_ai_agents_just_hype/</guid>
      <pubDate>Fri, 04 Jul 2025 09:21:12 GMT</pubDate>
    </item>
    </channel>
</rss>