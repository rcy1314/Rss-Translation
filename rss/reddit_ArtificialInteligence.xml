<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 16 Jan 2026 21:26:15 GMT</lastBuildDate>
    <item>
      <title>OpenAI 正式在 chatgpt 中添加广告，并推出新的 8 美元计划</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qer8aj/openai_is_officially_adding_ads_to_chatgpt_and/</link>
      <description><![CDATA[从公告来看，广告似乎只会向免费用户和新的 8 美元计划展示。  我们都看到了这一点，人们一直说他们正在测试广告，但 openai 一直说他们没有。    由   提交 /u/rumjs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qer8aj/openai_is_officially_adding_ads_to_chatgpt_and/</guid>
      <pubDate>Fri, 16 Jan 2026 20:28:33 GMT</pubDate>
    </item>
    <item>
      <title>IBM 警告如果缺乏人工智能素养，人工智能支出就会失败</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qep0ka/ibm_warns_ai_spend_fails_without_ai_literacy/</link>
      <description><![CDATA[来自 IBM 和北卡罗来纳州立大学的两位聪明人描述了 AI 素养不仅仅是知道如何制作提示；还包括如何掌握人工智能知识。需要跨学科学习才能掌握人工智能，从而造福企业和社会。 https://www.thedeepview.com/articles/ibm-warns-ai-spend-fails-without-ai-literacy   由   提交 /u/CackleRooster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qep0ka/ibm_warns_ai_spend_fails_without_ai_literacy/</guid>
      <pubDate>Fri, 16 Jan 2026 19:04:48 GMT</pubDate>
    </item>
    <item>
      <title>AI 对你了解这么多，它想给你买东西！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qeoncf/ai_knows_so_much_about_you_it_wants_to_buy_stuff/</link>
      <description><![CDATA[人工智能很快就能根据它了解的您的偏好进行购买。您只需交出您的信用卡即可。 Visa 和万事达卡上周均宣布，其持卡人将能够使用人工智能来自动进行信用卡购物，用于杂货、旅行和其他一切活动。 Visa 向 CNET 证实，其新的 Visa 智能商务计划正在北美进行测试，预计明年将广泛使用。万事达卡的代理支付计划与 Visa 的产品类似，目前在美国推出。  “很快人们就会让人工智能代理代表他们浏览、选择、购买和管理，” Visa 首席产品和战略官 Jack Forestell 在新闻稿中表示。 “这些代理在付款方面需要得到信任，不仅要得到用户的信任，还要得到银行和卖家的信任。”   由   提交/u/ranaji55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qeoncf/ai_knows_so_much_about_you_it_wants_to_buy_stuff/</guid>
      <pubDate>Fri, 16 Jan 2026 18:51:40 GMT</pubDate>
    </item>
    <item>
      <title>想象一下，一个人目前开始学习 HTML CSS，或者在设计方面他们刚刚开始使用 Figma 或 Illustrator，已经为课程或学位支付了高昂的费用，有些人还欠债，有些人没有……我无法想象他们现在会想到什么。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qenpc7/imagine_a_person_currently_starting_to_learn_html/</link>
      <description><![CDATA[我刚刚想到，我们的教育人工智能准备好了吗？我觉得人工智能普及后，教育行业将会出现巨大的繁荣。对于每个领域，我们都必须调整年轻人正在学习的东西，以便他们为未来做好准备。教授耐心、专注、头脑清晰、果断、在压力下保持冷静等东西应该是必修课。您认为未来的教育和课程会发生什么变化？   由   提交 /u/Accomplished-End5479   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qenpc7/imagine_a_person_currently_starting_to_learn_html/</guid>
      <pubDate>Fri, 16 Jan 2026 18:17:26 GMT</pubDate>
    </item>
    <item>
      <title>许多人工智能争论毫无结果，因为不同的故障模式被混在一起</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qembe6/a_lot_of_ai_debates_go_nowhere_because_different/</link>
      <description><![CDATA[每当 AI/LLM 出现时，我都会对同样的事情感到有点恼火。因为它是关于它们是否有用、危险、被高估等等的话题，已经被打死了，但一切都是“错误的”。人工智能只是合并成一大堆废话。然后人们互相争论，因为他们甚至没有谈论同一个问题。 我会在序言中说我不是技术人员。我只是花了很多时间使用这些工具，并且一直在注意它们的偏离方向。 过了一段时间，这些就是我将失败分组的主要类别。我知道这不是一个正式的分类，只是我在日常使用中区分人工智能故障的方式。 1）当它不遵循说明时 特定格式、顺序、约束、语气等。内容本身可能没问题，但输出违反了你明确制定的规则。 这感觉更像是控制问题，而不是智力问题。模型“知道”这些东西，但它只是不能干净地执行。 2）当它确实不知道信息时 有时数据根本不存在。太新、太小众，或者不是训练数据的一部分。它不是说它不知道，而是猜测。人们通常将其标记为幻觉。 3）当它错误地将事物混合在一起时 所有主要组件都在那里，但最终输出却关闭了。当它必须总结多个来源或进行多步骤推理时，通常会出现这种情况。每一部分本身可能都是准确的，但综合起来的结论并没有真正意义。 4）当问题模糊时 如果提示不够具体，并且模型无法弄清楚您真正想要什么，就会发生这种情况。它仍然需要返回一些东西，所以它只是选择一个解释。当这些发生时，这是非常明显的，我通常最终会打开一个新的聊天，并以更清晰的简介重新开始。 5）当答案有点正确但不是你想要的 我会要求它“总结”或“分析”或“建议”没有定义什么是好的。输出在技术上并没有错误，它只是不能真正用于我想要的东西。我通常会用硬数字或更详细的说明来跟踪这些输出，例如“给我一个 2 段摘要”。或“从xx的角度评价这篇文章”。这是我在使用 ChatGPT 进行写作或分析时遇到的最严重的问题。 这些在现实生活中显然是重叠的，但将它们分开有助于我思考修复问题。根据我的经验，提示对于 1 和 5 很有帮助，对于 2 则几乎没有帮助，有时对于 3 和 4 也只有一些帮助。 当有人说“这些模型不可靠”时，通常是指其中之一。但人们的反应就好像这五个问题都是同一个问题，这会导致错误的看法和奇怪的过度概括。 其中一些通过更清晰的提示得到了很大改善。无论您如何仔细地表达提示，有些都不会改变。有些更多地是关于人类的模糊性/主观性而不是实际的模型质量。有些是在可能不应该有答案的情况下强行给出答案。 将所有这些都集中在一起就可以了。很容易过度信任或完全忽视模型/技术，具体取决于您的偏见。 其他人对这些模型如何“破坏”进行分类在日常使用中？我很想听听您的看法以及我是否遗漏了任何内容。   由   提交/u/SonicLinkerOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qembe6/a_lot_of_ai_debates_go_nowhere_because_different/</guid>
      <pubDate>Fri, 16 Jan 2026 17:28:19 GMT</pubDate>
    </item>
    <item>
      <title>在某些时候，每个人工智能代理构建者都会被问到：它实际上做了什么。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qelvvr/at_some_point_every_ai_agent_builder_gets_asked/</link>
      <description><![CDATA[作为一个一直在尝试和学习无代码人工智能系统的非技术人员，我阅读了很多有关人工智能代理的文章。几个月前，在与人工智能代理一起工作时，我遇到了一个静静地陪伴着我的时刻。 没有发生任何戏剧性的事情。没有数据泄露。没有头条新闻。但人工智能系统的行为方式让我犹豫不决。 它有：  访问了技术上允许的工具 产生了没有人明确批准的成本 做出了孤立合理但难以端到端解释的决策  然后有人问了一个非常简单的问题：“这个代理到底做了什么，谁签署了它？”诚实的回答让人不舒服。 我有点知道。我可以重建它的一部分。但我无法给出一个干净、自信的答案。 那一刻改变了我对人工智能构建的看法。 随着代理从演示转向生产，难题不再只是能力。它是可见性、控制力和问责制。 在进一步构建任何内容之前，我决定暂停并倾听。 我整理了一个简短的匿名调查（5-7 分钟）来理解。如果您是构建者、创始人、软件开发人员、AI PM 或任何使用 AI 代理和系统的人，我想知道您是否遇到类似的情况以及是否值得为此构建解决方案。这项调查将帮助我了解当今人们如何实际运行人工智能代理 成本、访问和控制开始崩溃的地方 出现问题时团队现在该怎么做 这是一个真正的、紧急的问题还是只是我个人遇到的问题  这是纯粹的研究：  没有产品宣传 表单中没有公司或项目名称（我仍在弄清楚这是否是一个问题，因此进行调查） 除非您选择加入，否则无需发送电子邮件 完全匿名  如果您正在构建、部署或试验 AI 代理，您的观点将真正有所帮助。 如果这引起共鸣，请随时与该领域的其他构建者分享。   由   提交/u/OkAstronomer119   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qelvvr/at_some_point_every_ai_agent_builder_gets_asked/</guid>
      <pubDate>Fri, 16 Jan 2026 17:13:05 GMT</pubDate>
    </item>
    <item>
      <title>谷歌在人工智能方面的优势看起来越来越结构性，而不是周期性的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qejyfq/googles_advantage_in_ai_looks_increasingly/</link>
      <description><![CDATA[Alphabet 最近在整体估值方面领先于苹果，但专注于排名却忽略了潜在的更重要的转变。 谷歌构建了大部分早期神经网络基础设施，而当前的大型模型浪潮正在直接发挥这些优势。在内部引起关注的不是旗舰产品的发布，而是一项研究图像模型实验，该实验显示出比同类系统的推理延迟显着降低，从而引发了更广泛的组织变革。 DeepMind 和 Google Research 合并为现在的 Gemini 工程组织。模型开发、系统和部署不再是分散的研究和产品组，而是开始作为单个管道运行。 硬件层是这个故事的重要组成部分。 Google 最新一代 TPU Ironwood 采用 3nm 工艺和更高带宽的内存，与通用加速器相比，每个 Pod 的吞吐量更高，并且在大规模训练工作负载时能效明显更高。 在该堆栈之上，Gemini 最大的模型在同一垂直控制环境中进行训练和服务，保持训练规模、推理延迟和成本紧密耦合。如果不拥有整个管道，这种优化很难复制。 这就是结构优势的体现。谷歌控制着定制芯片、全球云基础设施以及来自搜索、YouTube、地图和 Android 的独特的大型现实世界数据流，并将分发内置到人们日常使用的产品中。这种组合对于合作伙伴来说很难完全复制。 随着 Gemini 功能进入 Google One，人工智能不再是一种独立的工具，而是开始看起来更像是捆绑到日常数字生活中的默认层，在家庭之间共享，而不是一次采用一个用户。这里的转变并不是投机炒作。这是基础设施优势逐渐转化为长期平台杠杆。   由   提交 /u/Simple_Response8041   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qejyfq/googles_advantage_in_ai_looks_increasingly/</guid>
      <pubDate>Fri, 16 Jan 2026 16:04:21 GMT</pubDate>
    </item>
    <item>
      <title>测试您的人工智能项目</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qejrsu/testing_your_ai_project/</link>
      <description><![CDATA[在研究 AI 代理时，我发现自己不断思考如何有效地测试它们。 随着我们整合更多的知识源并扩展代理的能力，测试变得越来越复杂。作为标准做法，我们使用评估来确保质量。但老实说，我觉得缺少了一些东西。 我看到的问题是，我们作为工程师，有时没有足够的领域知识来准确判断代理的响应。与此同时，当前的工具限制了与领域专家合作共同执行测试的可能性。 这是我迄今为止的经验 - 我很想听听您对此的想法。   由   提交 /u/Direct-Reception-514   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qejrsu/testing_your_ai_project/</guid>
      <pubDate>Fri, 16 Jan 2026 15:57:56 GMT</pubDate>
    </item>
    <item>
      <title>人工智能博士学位值得吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qejcw5/is_a_phd_in_ai_worth_it/</link>
      <description><![CDATA[最近开始攻读人工智能硕士学位，也许现在我只是过度思考了未来的所有可能性，但我想知道毕业后攻读人工智能/机器学习博士学位是否值得。  就背景而言，我真的很喜欢了解人工智能如何运作，以及如何以积极和创造性的方式影响社会。此外，作为一名声学本科生，我非常有兴趣了解人工智能如何帮助设计师/集成商创造更好的音响空间。  我现在担心的是诚实地放弃我生活的一部分。我新婚不久，喜欢和妻子一起度过时光、去滑雪以及做一份全职工作。我很清楚，攻读博士学位并不是“在公园里散步”。然而，我想知道在从事全职工作并想与所爱的人共度时光时是否可以管理。  理想情况下，我希望获得博士学位，最终在人工智能研究领域工作，并能够“书呆子”地从事人工智能研究。作为我的工作，当然能够为我的家人提供体面的薪水（我不需要成为百万富翁，只是一个能够为家庭带来足够收入的人） 对于那些目前正在攻读人工智能博士学位或已毕业的人来说，你觉得值得吗？您能够有效地平衡工作、生活和学校吗？  只是想看看大家的想法。   由   提交/u/Concient_Sundae540   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qejcw5/is_a_phd_in_ai_worth_it/</guid>
      <pubDate>Fri, 16 Jan 2026 15:42:30 GMT</pubDate>
    </item>
    <item>
      <title>停止在提示中垃圾邮件“4k，超现实”。这就是为什么你的图像看起来像塑料的原因。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qeiz7q/stop_spamming_4k_hyperrealistic_in_your_prompts/</link>
      <description><![CDATA[我一直在尝试修复那个奇怪的“蜡像”几个星期以来，我这一代人都感到困惑。我认为这是一个模型问题，所以我不断添加诸如“不良解剖结构”之类的负面提示。或者堆砌诸如“虚幻引擎 5、8k、超详细”之类的流行语。 我今天偶然发现了这个细分，它实际上解释了塑料外观背后的逻辑，它完全改变了我的工作流程。 要点是：模型接受摄影字幕的训练。当您使用通用流行语时，人工智能默认为平面广角“智能手机”。看（无限景深 = 假看）。 我开始测试文章建议的内容——将“超现实”换成“超现实”。对于实际相机物理（例如，“在 85mm、f/1.8 光圈下拍摄”）。皮肤纹理和光线的差异是白天和黑夜。它停止尝试“渲染”图像并开始“拍摄”  如果你想自己测试物理原理，这里有一个不错的镜头备忘单。如果您陷入恐怖谷，绝对值得一读：真实感 AI 生成   由   提交 /u/ProgrammerForsaken45   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qeiz7q/stop_spamming_4k_hyperrealistic_in_your_prompts/</guid>
      <pubDate>Fri, 16 Jan 2026 15:28:20 GMT</pubDate>
    </item>
    <item>
      <title>蓝领工人没有意识到人工智能对他们同样构成威胁</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qed560/bluecollar_workers_dont_realize_that_ai_is_the/</link>
      <description><![CDATA[我经常听到焊工、电工等工作的人嘲笑上班族，说他们因为有行业而倒霉。  我的预测是，这些人没有意识到经济是残酷地相互关联的，而接受他们命令的人可以从办公室工作中赚钱。 当办公室工作因人工智能而被消除时，对新厨房、屋顶维修等的需求将大幅下降。 另一部分是，办公室工作人员将迅速重新培训手工技能，以养活自己和家人，并会冷静地提供低得多的价格来支付为了租金和食物，彻底破坏了竞争，创造了巨大的供过于求的局面。  有人有类似的看法吗？    由   提交 /u/Big-Butterscotch2608   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qed560/bluecollar_workers_dont_realize_that_ai_is_the/</guid>
      <pubDate>Fri, 16 Jan 2026 11:05:33 GMT</pubDate>
    </item>
    <item>
      <title>厌倦了法学硕士、人工智能工具和人工智能废话</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</link>
      <description><![CDATA[现在有很多无用的人工智能工具，而且大多数只是彼此的重复。总结者、集思广益、审计代码、代码生成器等等，太无聊了。然后，每个人都一遍又一遍地广播同样的内容。就像关注不同法学硕士的小更新一样，从短期到长期来看，谁会赢得谁。同样的事情在播客和 YouTube 视频中一遍又一遍地出现。  是否有任何有趣的人工智能，呃，与 NBA、NFL、Nascar 或与运动或爱好相关的东西相关的东西？不是严肃的工作而是更休闲？不是像 Grok 这样的色情生成器。    由   提交 /u/Impressive-Flow2023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</guid>
      <pubDate>Fri, 16 Jan 2026 03:39:44 GMT</pubDate>
    </item>
    <item>
      <title>StackOverflow 应得的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</link>
      <description><![CDATA[作为 2020 年开始使用 Stackoverflow 的人，我真的可以说他们活该被 AI 痛打一顿。 你提出一个问题，几秒钟后你就得到了第一次投反对票，“无所不知”。愚蠢的模组编辑了你的问题，几分钟后，你要么得到一个羞辱性的答复，说我不知道这个话题，还问了一个问题，要么你的问题被删除了。 那些模组除了编辑问题（看在上帝的份上，这是标点符号）什么也没做，并通过他们的垃圾回复让平台变得更加有毒。 据我所知，Stackoverflow 严格拒绝人工智能生成的回复，因为你可能会在人工智能。就像如果你像 2009 年推出的那样被问到同样多的问题，谁还会关心声誉。 它每天都变得越来越有毒。他们确实应得的。不接受人工智能答案？你是什​​么穴居人？他们的观点应该是帮助提问者，而不是试图与人工智能对抗。 他们也删除了“工作”部分。得到了近 4000 票反对。很多人不喜欢这个决定，但他们还是这么做了。   由   提交 /u/Hairy-Recognition-84   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</guid>
      <pubDate>Thu, 15 Jan 2026 21:38:15 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>