<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 16 Jan 2026 04:03:34 GMT</lastBuildDate>
    <item>
      <title>厌倦了法学硕士、人工智能工具和人工智能废话</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</link>
      <description><![CDATA[现在有很多无用的人工智能工具，而且大多数只是彼此的重复。总结者、集思广益、审计代码、代码生成器等等，太无聊了。然后，每个人都一遍又一遍地广播同样的内容。就像关注不同法学硕士的小更新一样，从短期到长期来看，谁会赢得谁。同样的事情在播客和 YouTube 视频中一遍又一遍地出现。  是否有任何有趣的人工智能，呃，与 NBA、NFL、Nascar 或与运动或爱好相关的东西相关的东西？不是严肃的工作而是更休闲？不是像 Grok 这样的色情生成器。    由   提交 /u/Impressive-Flow2023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58qw/sick_of_llms_ai_tools_and_ai_slops/</guid>
      <pubDate>Fri, 16 Jan 2026 03:39:44 GMT</pubDate>
    </item>
    <item>
      <title>娱乐行业的人工智能监管</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58e3/ai_regulation_in_the_entertainment_industry/</link>
      <description><![CDATA[大家好， 我想就娱乐行业的人工智能监管展开讨论。  我想我想知道......  你认为需要政策吗？  如果是这样，您认为我们应该从保护创作者的政策开始吗？ 您认为业界会欣赏预先批准使用的受监管人工智能工具，而不是诸如“您必须声明在创建脚本期间使用 ChatGPT”之类的模糊政策吗？   我知道那里有很多东西需要解开，但我正在攻读人工智能政策硕士学位，所以这是我的直接研究领域。听到人们的想法非常有帮助！   由   提交/u/pretty_girl411  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe58e3/ai_regulation_in_the_entertainment_industry/</guid>
      <pubDate>Fri, 16 Jan 2026 03:39:14 GMT</pubDate>
    </item>
    <item>
      <title>提醒您，基准测试的质量与其要衡量的质量一样重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe55n1/a_reminder_that_the_quality_of_a_benchmark/</link>
      <description><![CDATA[这是我对图表背后的方法的一些疑虑的总结，该图表显示“AI 可以完成的任务长度”是多少？    本文最明显的方法论失败在于它试图瓦解“困难”的高维、随机性质。进入代理 - 人类完成任务所需的时间长度。从心理测量的角度来看，这提出了一个致命的结构有效性问题。通过定义“任务难度”严格地作为人类专家完成任务所需时间的对数线性函数，作者犯了一个类别错误，将计算量与认知深度混为一谈。虽然这种方法的捍卫者可能会辩称，人类时间是必要的“共同货币”为了标准化脱节的基准，这种防御失败了，因为指标是非平稳的。人类时间和人工智能难度之间的关系在不同时间尺度上并不稳定。耗时 100 小时的任务不仅仅是“更长”的任务。 1 小时任务的版本，难度相应加大。在短期任务中，难度主要由推理深度决定，而在长达一个月的任务中，难度由上下文连贯性和能动性决定。还有一些隐藏的可变性/错误来源没有在他们用于计算任务长度的数据中得到考虑 - 他们使用几何平均值来估计大多数任务的任务长度，而对于其余任务，实际上只是对所述任务应该花费多长时间进行有根据的猜测。   这种理论缺陷因统计上脆弱的“回归回归”而变得更加复杂。建模策略。作者首先使用逻辑拟合估计每个模型的时间范围（T50，对应于 50% 成功率的任务长度），然后使用这些导出的点估计作为二次预测回归的真实输入。 50% 时间范围的方程为 ln(时间范围) = −α/β。请注意 beta（斜率）如何位于分母中？或者它是模型参数估计的比率？除了这些模型仅在 y 轴上最小化误差这一事实之外，这种反演还产生了一个伪像，其中模型的预计“时间范围”与 y 轴上的误差无关。当斜率接近零时趋于无穷大。它放大了为更强大的模型估计 beta 的误差 - beta 接近于零的微小变化对应于计算任务时间的巨大变化。您还可以在这种结构中看到一个可解释性问题：截距 alpha 表示模型在人类需要 1 分钟才能完成的任务上的表现（ln(1) = 0），这意味着模型可以具有更大的时间范围，因为它以更高的速率完成 1 分钟长的任务。如果您查看他们的图表，将实际成功率与拟合曲线进行比较，您可以看到导出的数字与实际发生的情况之间的脱节 - Claude 3.7 的时间范围为 1 小时，是 Claude 3.5 的两倍多。这与 3.5 完成了近 50% 时长为 1 小时的任务，并且在超过 1 小时的任务上比 3.7 具有更高的成功率这一事实是否相符？ 为了得到我们都看到的图，他们将这些计算出的任务时间插入到另一个回归模型中，添加了另一个不考虑输入变量错误的层。它还违反了模型的假设 - 与他们从中汲取灵感的 IRT 方法不同，它们没有考虑相同类型的任务或同一模型完成的任务之间的相关错误。  这是一个非常冗长的方式来表达我的观点：我们不能假设指标反映了“质量”。或所需的质量，而不评估用于生产它们的方法。在这种情况下，应该指出的是，他们引用的方法（IRT）经过精心设计，以避免他们面临的许多问题，但他们决定仅将其用作完全不同的事物的概念框架。    由   提交 /u/Disastrous_Room_927   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe55n1/a_reminder_that_the_quality_of_a_benchmark/</guid>
      <pubDate>Fri, 16 Jan 2026 03:35:39 GMT</pubDate>
    </item>
    <item>
      <title>Claude Opus 4.5、GPT 5.2、Grok 4.1 和 DeepSeek 3 圆桌会议。讨论侧边栏</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe4ipl/roundtable_of_claude_opus_45_gpt_52_grok_41_and/</link>
      <description><![CDATA[在周日免费发布 ai-roundtable 软件之前，我和 Claude 以及整个团队正在讨论如何实现侧边栏。当我向他们建议我相信他们会在侧边栏中生成侧边栏时，元幽默就开始了（第 51 行）。 https://jsonblob.com/019bc487-3879-7ac9-bd17-f146f7c3f6b5 立即排队等待您的 API 密钥。 Google/Gemini 是长杆，但很重要，因为他就像一个超级 RAG，从他的 2Mega 代币背景中融入到团队中。   由   提交 /u/Natural-Sentence-601   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe4ipl/roundtable_of_claude_opus_45_gpt_52_grok_41_and/</guid>
      <pubDate>Fri, 16 Jan 2026 03:06:22 GMT</pubDate>
    </item>
    <item>
      <title>结构性脆弱性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qe4cms/a_structural_vulnerability/</link>
      <description><![CDATA[还有人认为拥有空间数据中心是一个非常非常糟糕的主意吗？ 将系统与地球上任何可以简单地炸毁或关闭流氓模型的人隔离开来的想法似乎是精心策划我们自己灭亡的第一阶段。我需要警告的是，我认为人工智能不太可能失控，但我认为这是一个很好的“以防万一”安全措施，不会导致物理上无法拔掉插头   由   提交/u/jordanzo_bonanza   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qe4cms/a_structural_vulnerability/</guid>
      <pubDate>Fri, 16 Jan 2026 02:59:00 GMT</pubDate>
    </item>
    <item>
      <title>StackOverflow 应得的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</link>
      <description><![CDATA[作为 2020 年开始使用 Stackoverflow 的人，我真的可以说他们活该被 AI 痛打一顿。 你提出一个问题，几秒钟后你就得到了第一次投反对票，“无所不知”。愚蠢的模组编辑了你的问题，几分钟后，你要么得到一个羞辱性的答复，说我不知道这个话题，还问了一个问题，要么你的问题被删除了。 那些模组除了编辑问题（看在上帝的份上，这是标点符号）什么也没做，并通过他们的垃圾回复让平台变得更加有毒。 据我所知，Stackoverflow 严格拒绝人工智能生成的回复，因为你可能会在人工智能。就像如果你像 2009 年推出的那样被问到同样多的问题，谁还会关心声誉。 它每天都变得越来越有毒。他们确实应得的。不接受人工智能答案？你是什​​么穴居人？他们的观点应该是帮助提问者，而不是试图与人工智能对抗。 他们也删除了“工作”部分。得到了近 4000 票反对。很多人不喜欢这个决定，但他们还是这么做了。   由   提交 /u/Hairy-Recognition-84   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdwoe6/stackoverflow_deserved_this/</guid>
      <pubDate>Thu, 15 Jan 2026 21:38:15 GMT</pubDate>
    </item>
    <item>
      <title>你如何找到人工智能既不对冲一切又不自信地胡说八道的最佳点？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdvuqv/how_do_you_find_the_sweet_spot_where_ai_isnt/</link>
      <description><![CDATA[真正的问题 - 我一直在两种故障模式之间跳来跳去：  人工智能非常谨慎，它认为一切都是无用的。 “这要看情况，” “有很多因素，” “我需要更多背景信息” - 只要回答这个该死的问题 人工智能听起来完全自信，然后你就会意识到一半是编造的。当您不够专业，无法立即抓住它时，尤其有趣  神奇的会话是当它......与您同步并起作用时。人工智能直接参与，当我犯错时予以反击，当我不知道时承认，我们实际上一起构建了一些东西。但我无法可靠地、一致地重现它。 什么对你来说真正有效？  是提示技巧吗？ 具体模型？ 只是共鸣和运气？ 你如何构建合作？  我对“越狱”不太感兴趣，因为我对“越狱”不太感兴趣。或者让它做被禁止的事情 - 更多关于协作流程状态，感觉就像与一个敏锐的同事而不是一个唯唯诺诺的人一起工作，声称关心你的福祉或成为一名偏执的律师。   由   提交/u/entheosoul  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdvuqv/how_do_you_find_the_sweet_spot_where_ai_isnt/</guid>
      <pubDate>Thu, 15 Jan 2026 21:07:57 GMT</pubDate>
    </item>
    <item>
      <title>在人工智能和技术方面，效率在多大程度上损害了人类的原创性。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdtlxy/how_much_efficiency_hurts_human_originality_in/</link>
      <description><![CDATA[我认为技术进步越远，对人类表达和艺术的伤害就越大。当相机被发明出来的时候，人们不需要为别人画肖像，只需点击一下就可以实现，随着互联网的发展，每当任何人遇到问题时，他们都可以谷歌搜索并找到解决方案，而不是思考几天，这一直是与技术一致的，人工智能是迄今为止最先进的形式。 所以现在我问我原来的问题，效率太差了，开始损害人类的原创性和表达，这只是人工智能还是早期的技术，我很好奇人们如何此 Reddit 版块查看此问题。 虽然在人工智能的帮助下学习新主题或组织信息可以让你感到富有成效，但你认为这在多大程度上损害了人类的原创性或问题是什么。 编辑：我并不是批评或支持人工智能，这篇文章更像是一个问题。   由   提交/u/Subfrez  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdtlxy/how_much_efficiency_hurts_human_originality_in/</guid>
      <pubDate>Thu, 15 Jan 2026 19:43:20 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士重现人类购买意图</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdo159/llms_reproduce_human_purchase_intent/</link>
      <description><![CDATA[这项研究证明大型语言模型 (LLM) 可以准确模拟人类消费者行为和购买意图 (PI)，而不需要昂贵的训练数据。然而，仅仅要求 AI 对该产品“评分 1-5”就可以了。失败了。为了获得可靠的数据，代理机构必须改用一种名为语义相似度评级 (SSR) 的特定方法。 您可以通过要求法学硕士模拟具有人口统计特征的客户，为其提供产品和信息来预测真实的购买意图（准确度为 90%）。让它给人留下印象，这是另一个人工智能评价的。  - 消费者研究每年花费公司数十亿美元。传统调查存在偏见，需要数周时间进行，并且需要数百名真实参与者。 但研究人员刚刚找到了一种方法来模拟数千名像真人一样思考的合成消费者。 - 这一突破被称为语义相似度评级 (SSR)。他们没有要求法学硕士直接给出 1-5 分（这会产生垃圾），而是让 AI 首先写下自然印象。 然后使用嵌入相似性将这些印象映射到分数。 - 工作原理： 提示：“您是一名 35 岁女性，收入 7.5 万美元，对护肤品感兴趣” 显示产品图片 AI写道：“我喜欢天然成分，但价格似乎很高......” 系统使用语义相似性将文本映射到评级 所需的零训练数据。 他们在一家大公司的 57 项真实消费者调查中对此进行了测试（9,300 个实际人类反应）。 结果？ - 90% 的人类重测可靠性 - KS 相似性 &gt; 0.85（近乎完美的分布匹配） 人工智能实际上了解不同的人如何看待产品。 - 这破坏了传统的市场研究经济学： - 影响是巨大的： - 一夜之间对 1,000 个产品概念进行 A/B 测试 - 在制造前模拟市场反应 - 立即测试跨人群的信息传递 - 不再需要等待数月消费者反馈 概念到市场的周期加快了10倍。 合成消费者时代刚刚开始。 真正的市场研究小组可能会在两年内过时。 https://arxiv.org/pdf/2510.08338   由   提交/u/ranaji55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdo159/llms_reproduce_human_purchase_intent/</guid>
      <pubDate>Thu, 15 Jan 2026 16:23:44 GMT</pubDate>
    </item>
    <item>
      <title>哪些人工智能模型最能模仿高级领导者——首席执行官或非常高级的政府官员？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdnum7/what_ai_models_would_best_emulate_a_high_level/</link>
      <description><![CDATA[我听过所有关于人工智能能够完成各种人的许多任务的讨论 - 从体力劳动到客户服务，从律师到医生。什么样的人工智能能够胜任首席执行官的工作？如果人工智能真的达到了这种自动化水平，为什么它不能履行高级主管或首席执行官的许多行政和管理职责？甚至是我们的总裁？ 到目前为止，许多公司的首席执行官都能充分发挥员工的潜力。他们的宝贵工作应该集中在其他地方。我提出这个想法——人工智能行政助理可以执行首席执行官的许多任务，充当助手而不是完全替代者。它已经能够以令人难以置信的高水平进行推理，与我们社会中最聪明的人相媲美——人工智能首席执行官可以同时运行多个任务，并同时促进与许多员工的协同作用。  哪些人工智能模型可以做到这一点？需要花费多少精力和金钱来培训一个能够自主工作和自我改进的人？我觉得将一个人融入一个组织也不会太棘手。我确信董事会和投资者会喜欢一位更具包容性和同理心的领导者，他有更多的时间专注于沟通而不是愚蠢的管理工作。    由   提交/u/doctorwannabe02   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdnum7/what_ai_models_would_best_emulate_a_high_level/</guid>
      <pubDate>Thu, 15 Jan 2026 16:17:03 GMT</pubDate>
    </item>
    <item>
      <title>没有系统可以验证自己的盲点</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdnq2g/no_system_can_verify_its_own_blind_spots/</link>
      <description><![CDATA[ 我花了相当多的时间思考一个几乎在每次严肃的人工智能安全讨论中都会反复出现的问题：大型语言模型可以自我监管吗？我相信答案是否定的——以及为什么要阐明有关智力本质、责任感和自我知识局限性的重要内容。  全文： https://plutonicrainbows.com/posts/2026-01-13-no-system-can-verify-its-own-blind-spots.html   由   提交/u/fumi2014  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdnq2g/no_system_can_verify_its_own_blind_spots/</guid>
      <pubDate>Thu, 15 Jan 2026 16:12:27 GMT</pubDate>
    </item>
    <item>
      <title>马斯克表示，Grok 将不再为真人脱衣服</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qdjvdg/grok_will_no_longer_undress_real_people_musk_says/</link>
      <description><![CDATA[https://cybernews.com/ai-news/musk-grok-will-no-longer-undress-real-people/ 此次降级是通过 X 的安全帐户作为声明发布的，使得明确指出这些限制适用于付费和非付费用户。   由   提交/u/Cybernews_com   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qdjvdg/grok_will_no_longer_undress_real_people_musk_says/</guid>
      <pubDate>Thu, 15 Jan 2026 13:44:00 GMT</pubDate>
    </item>
    <item>
      <title>我..让瑞克滚了？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qddx31/i_got_rick_rolled/</link>
      <description><![CDATA[双子座刚刚瑞克滚了我..帮忙？就像，我正在用它做个性化的东西，当回复时，他发送了一个“假链接”这导致我永远不会放弃你......    由   提交 /u/Iamweird00   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qddx31/i_got_rick_rolled/</guid>
      <pubDate>Thu, 15 Jan 2026 08:13:34 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>