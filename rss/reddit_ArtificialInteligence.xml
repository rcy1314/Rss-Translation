<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sat, 07 Feb 2026 09:35:34 GMT</lastBuildDate>
    <item>
      <title>与 Google 和 Anthropic 相比，是什么导致 OpenAI 亏损这么多？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy8o6t/what_is_causing_openai_to_lose_so_much_money/</link>
      <description><![CDATA[为了更好地了解 OpenAI 的现状，能否请您介绍一下 OpenAI 与 Google 和 Anthrophic 的不同之处？ Google 有自己的数据中心，但 Anthrophic 呢？ 他们也是一家初创公司，我们不会读到有关他们的灾难性新闻。   由   提交 /u/datoml   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy8o6t/what_is_causing_openai_to_lose_so_much_money/</guid>
      <pubDate>Sat, 07 Feb 2026 08:37:02 GMT</pubDate>
    </item>
    <item>
      <title>帮助我理解一些事情。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy7lm1/help_me_understand_something/</link>
      <description><![CDATA[所以最近我对人工智能越来越感兴趣。但我承认我对此真的了解不多。当人们争论人工智能意识时，我经常遇到的一件事是，人们经常说人工智能（特别是法学硕士？）只是下一个象征性的预测器。有人可以向我解释这意味着什么吗？如果没有一堆我无法理解的计算机科学术语就可以做到这一点。我知道令牌就像一个单词的一部分。我知道有一个神经网络（但老实说，我真的不知道那是什么），它已经过大量数据的训练，并且训练决定了网络中不同神经元的权重（我认为），然后我猜神经网络及其所有权重会以某种方式生成令牌以响应用户输入？    由   提交 /u/Justin534   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy7lm1/help_me_understand_something/</guid>
      <pubDate>Sat, 07 Feb 2026 07:32:16 GMT</pubDate>
    </item>
    <item>
      <title>政府人工智能支出与大型科技公司人工智能支出之间的差距变得荒谬</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy7bf5/the_gap_between_government_ai_spending_and_big/</link>
      <description><![CDATA[法国刚刚为一些新的人工智能产品投入了 3000 万美元，有人指出这就是谷歌今年每 90 分钟在资本支出上的支出。每一个。 90分钟。这只是一家公司，甚至不包括微软元亚马逊等。诚实地开始怀疑民族国家是否可以再成为人工智能领域的相关参与者，或者这现在是否只是一场大型科技游戏 &lt;！-- SC_ON --&gt;  由   提交 /u/Background-Tear-1046   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy7bf5/the_gap_between_government_ai_spending_and_big/</guid>
      <pubDate>Sat, 07 Feb 2026 07:15:49 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个地理定位工具，可以在 3 分钟内从任何街道照片返回坐标</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy6y8z/i_built_a_geolocation_tool_that_returns/</link>
      <description><![CDATA[我一直在独自开发一个名为 Netryx 的基于 AI 的项目。 在较高层面上，它会拍摄街道级别的照片，并尝试确定捕获图像的确切 GPS 坐标。不是城市级别的估计或概率热图。实际位置，精确到米。如果系统无法高度可信地验证结果，则不会返回任何内容。 这种行为是故意的。 我测试过的大多数人工智能地理定位工具即使在错误的情况下也会自信地输出答案。 Netryx 被设计为失败关闭。没有验证就意味着没有结果。 概念上它是如何工作的： 系统有两种模式。其中，人工智能模型分析图像并根据视觉特征缩小可能的地理区域范围。另一方面，用户明确定义搜索区域。在这两种情况下，人工智能仅用于发现候选人。最后一步是针对现实世界街道图像进行独立视觉验证。如果人工智能的猜测无法通过视觉验证，它就会被丢弃。 换句话说，人工智能提出建议，验证处理。 这也意味着它不是魔法，也不是全球无所不知。该系统需要预先映射的街道覆盖范围来验证结果。您可以将其视为物理空间的人工智能辅助视觉索引，而不是通用定位器。 作为测试，我绘制了大约 5 平方公里的巴黎地图。然后我提供了一张在该区域内某处拍摄的随机街道照片。系统在三分钟内识别出准确的交叉点。 下面链接了一个演示视频，显示了从图像输入到最终落针的完整过程。没有编辑，没有剪切，没有任何精挑细选的内容。 预先进行一些说明： • 现阶段它不是开源的。在没有护栏的情况下发布此类人工智能功能的滥用和隐私风险非常大 • 它需要事先提供街道级数据来验证位置。如果没有覆盖，它将不会返回结果 • AI 模式可以探索手动定义的区域之外，但验证仍然会限制所有输出 • 我对使用它来从社交媒体照片中定位个人不感兴趣。这不是目标 我在这里发布这个是因为我很矛盾。 从防御的角度来看，这凸显了现代人工智能可以从平凡的图像中提取多少位置智能。从对抗的角度来看，滥用的可能性是显而易见的。 对于那些从事网络安全、人工智能安全、威胁建模或隐私工程的人来说： 您认为合法的人工智能驱动的 OSINT 功能与根本不应该构建或部署的东西之间的界限在哪里？ 在这里查看：https://youtu.be/KMbeABzG6IQ?si=bfdpZQrXD\_JqOl8P   由   提交 /u/Open_Budget6556   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy6y8z/i_built_a_geolocation_tool_that_returns/</guid>
      <pubDate>Sat, 07 Feb 2026 06:55:04 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 2/​​6/2026</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy5tc9/oneminute_daily_ai_news_262026/</link>
      <description><![CDATA[ NVIDIA AI 发布 C-RADIOv4 视觉主干，统一 SigLIP2、DINOv3、SAM3，用于大规模分类、密集预测、分割工作负载。[1] AI 公司在超级碗之战中投入巨资。[2] 在日本，生成式 AI 将虚假选举新闻带入新的领域[3] Anthropic 发布带有新“代理团队”的 Opus 4.6。[4]  来源包括：https://bushaicave.com/2026/02/06/one-million-daily-ai-news-2-6-2026/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy5tc9/oneminute_daily_ai_news_262026/</guid>
      <pubDate>Sat, 07 Feb 2026 05:52:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能原生浏览器和浏览器内人工智能代理是否完全打破了我们当前的安全模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy2ceg/are_ainative_browsers_and_inbrowser_ai_agents/</link>
      <description><![CDATA[最近一直在思考这个问题，尤其是随着 openclaw 的流行。  传统浏览器安全性假设人类点击链接、填写表单并做出决定。但人工智能代理只是自动做事。他们抓取、提交、导航，无需人工监督。 我们的 DLP、内容过滤器，甚至基本的访问控制都是围绕“用户执行 X，我们检查 Y”构建的。当循环中没有用户时会发生什么？ 您如何监控人工智能代理正在访问的内容？真的很好奇。   由   提交 /u/TehWeezle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy2ceg/are_ainative_browsers_and_inbrowser_ai_agents/</guid>
      <pubDate>Sat, 07 Feb 2026 03:00:43 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在工作和学习中的技巧和经验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy1lkg/tips_and_experiences_on_ai_for_work_and_study/</link>
      <description><![CDATA[嗨，我目前正在寻找一个新的 AI 工具，因为自从 OpenAI 发布了 ChatGPT 版本 5 以来，我不得不反复修改我在以前版本中创建的所有自定义设置。老实说，我正在考虑放弃它并投资于更好的东西。我的工作涉及管理企业服务器并寻找特定技术问题的解决方案。 因此我开始评估哪种人工智能可能最适合我的需求。 我尝试了 Gemini：许多响应都是有效的，并且随着持续使用，它似乎有所改进。然而，我并不完全相信。我常常必须非常努力才能获得真正有用​​的结果。对于我的工作来说，主要依赖于技术文档，它对我的​​帮助并没有我希望的那么大，尤其是Notebook LLM，我认为我不知道如何正确使用它。我对定制和界面也不满意。最终，我发现它对于深入研究比日常使用更有用。 然而，使用 Grok 时，我的体验令人失望。我经常发现很难让它有效地发挥作用。我几乎立即放弃了它，尽管我可能会考虑再试一次。 在我看来，Claude 是最接近 ChatGPT 的解决方案。我已经开始定制一些项目，效果还不错。然而，我需要更彻底地测试它，看看它是否真的值得永久采用。它产生了很好的代码，但需要更多的努力和上下文。 Mistral 与过去相比有所改进，但它对于我的需求来说似乎仍然太有限。 经过最初的普遍热情，我从那以后就没有使用过 DeepSeek。 总的来说，我今天使用 AI 主要是为了快速查阅在线文档，组织我每天制作或使用的技术材料，以及制定学习计划。 自从一周前开始，我还没决定是转还是留下。   由   提交 /u/MediumAd7537   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy1lkg/tips_and_experiences_on_ai_for_work_and_study/</guid>
      <pubDate>Sat, 07 Feb 2026 02:26:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能视频和艺术感觉不太一样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qy0cpf/why_do_ai_videos_and_art_feel_off/</link>
      <description><![CDATA[我无法解释。我一直在尝试，感觉动作不自然。一名士兵殴打另一名士兵的动画将这名士兵飞到空中。妈妈打孩子屁股的家庭动画场景要么太轻，要么妈妈打孩子（WTF？）。摄像机角度无处不在。对话来自错误的角色。一名骑士跪下对他的公主说话，他转身离开她而不是面对她，然后将手指放入她的嘴里（再一次，WTF？）   由   提交/u/BetLeft2840  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qy0cpf/why_do_ai_videos_and_art_feel_off/</guid>
      <pubDate>Sat, 07 Feb 2026 01:29:17 GMT</pubDate>
    </item>
    <item>
      <title>我们是在构建人工智能来帮助人类，还是构建需要人类帮助的人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxzhn8/are_we_building_ai_to_help_humans_or_ai_that/</link>
      <description><![CDATA[我最近看了一个特斯拉机器人视频，它试图调整炉子的火焰，老实说它看起来没什么用。它无法正确旋转旋钮，意外地关闭了火焰，无法重新打开它，站立时差点摔倒，最终不得不有人介入并提供帮助。那时我认真地想知道：我们构建人工智能是为了帮助人类，还是构建需要人类帮助的人工智能？ 这让我想起了去年基于浏览器的人工智能代理发生的很多事情。每个人都对人工智能大肆宣传，它可以在虚拟机上浏览网页、移动光标、单击按钮，并“像人类一样使用互联网”。事实上，它速度慢、脆弱、使用起来很痛苦，而且经常卡住。人工智能并不愚蠢，它只是被迫使用屏幕截图和光标坐标在人机界面中进行操作。 然后像 OpenClaw 这样的工具出现了，突然间，相同的模型感觉很强大。并不是因为人工智能神奇地变得更聪明，而是因为执行方式发生了变化。允许模型使用终端和 API，而不是让模型浏览浏览器。同样的大脑，完全不同的结果。 这也是我们在机器人身上重复的错误。炉灶旋钮是一个人机界面，就像浏览器用户界面一样。强迫机器人旋转旋钮并目视估计火焰是强迫人工智能点击按钮的物理版本。我们已经知道更好的解决方案：机器原生接口。我们使用 API 来订餐，但期望机器人像人类一样通过挣扎来做饭。 未来不会是机器人完美地模仿我们。就像互联网从机器的 UI 转移到 API 一样，物理世界也将如此。智能电器、机器控制层和人工智能编排系统，而不是旋钮和平衡。 现在，人形机器人在演示中给人留下了深刻的印象，但从架构上来说，它们与我们在软件中已经犯过的错误相同。   由   提交 /u/Calm-Alarm7977   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxzhn8/are_we_building_ai_to_help_humans_or_ai_that/</guid>
      <pubDate>Sat, 07 Feb 2026 00:50:54 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士会导致存在主义死亡吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxzaui/are_llms_leading_to_existential_death/</link>
      <description><![CDATA[是的，我使用聊天在更短的时间内清晰地表达了自己的意思。但我相信这就是我们所说的“ai-slop”的根源。随着法学硕士和生成式人工智能扩展到一切领域——这种死亡是我们未来不可避免的吗？  “LLM 已经拥有世界模型并且基本上处于 AGI 边缘”的热门观点在这里受到了挑战。理查德·萨顿认为这个故事将模仿与智力混为一谈。在他的框架中，法学硕士主要学习模仿人类会说的话，而不是预测世界上实际发生的行动结果。这种区别很重要，因为它同时攻击了两个主流假设：下一个令牌预测等于有根据的理解，而仅扩展文本就是通往强大代理的直线。  他拒绝接受法学硕士“有目标”的普遍说法。 “预测下一个代币”并不是一个关于外部世界的目标；它没有定义环境中更好与更差的结果。他认为，如果没有这种根深蒂固的对/错概念，持续学习的定义就会不明确，“法学硕士作为一个好的先修课程”变得比人们想象的更加不稳定。  他对未来的预测也与主流的轨迹叙述相悖：从经验中学习（行动、观察后果、在线更新政策和世界转型模型）的系统最终将超越文本训练的模仿者——即使法学硕士今天看起来是无与伦比的。他将今天的势头描述为另一个“感觉良好”的阶段，人类知识注入看起来像是进步，直到经验驱动的扩展吞噬它。  法学硕士主要接受训练来模仿人类文本，而不是从现实世界的行动后果中学习，因此他们缺乏由扎根的反馈和目标驱动的原生的、持续的“生活中学习”适应能力。  在这个框架中，当“正确性”主要是基于语言或政策的时候，上限最高；而当正确性取决于环境动态、长期结果和现实的持续更新时，上限最低。  法学硕士在商业上已经具有竞争力或优于人类： 大量语言工作：起草、总结、重写、分类、翻译、模板化分析。 在提供事实来源时跨大型语料库进行检索/综合。 以一致的格式快速迭代替代方案（副本变体、大纲、剧本）。  人类仍然占主导地位的地方： 具有实际利害关系的模糊目标：选择目标、设定优先级、进行权衡。 获取事实真相：注意市场/客户/组织中实际发生的变化，并相应地更新行为。 稀疏反馈下的长期执行（多月战略、政治、信任、激励）。 不确定性下的责任和判断。 https://www.youtube.com/watch?v=21EYKqUsPfg   由   提交/u/ApplePrimary2985  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxzaui/are_llms_leading_to_existential_death/</guid>
      <pubDate>Sat, 07 Feb 2026 00:42:37 GMT</pubDate>
    </item>
    <item>
      <title>“高盛聘请 Anthropic 的 Claude 来自动化会计和合规职位” - CNBC</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxvvtx/goldman_sachs_taps_anthropics_claude_to_automate/</link>
      <description><![CDATA[https://www.cnbc.com/2026/02/06/anthropic-goldman-sachs-ai-model-accounting.html  这个部分很有趣：  嵌入式人类工程师在高盛花了六个月的时间构建自治系统，用于时间密集型、大批量的后台工作。  因为 OpenAI 本周还宣布了一项名为 Frontier 的服务，其中包括前向部署工程师。 这些模型公司现在正在销售企业服务。   由   提交 /u/jim-ben   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxvvtx/goldman_sachs_taps_anthropics_claude_to_automate/</guid>
      <pubDate>Fri, 06 Feb 2026 22:22:33 GMT</pubDate>
    </item>
    <item>
      <title>衡量人工智能进展的基准测试的替代方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxtps8/an_alternative_to_benchmarking_for_for_gauging_ai/</link>
      <description><![CDATA[嗨！我认为围绕人工智能有很多炒作，每次 anthropic、openAI、xAI、谷歌发布新模型时都会带来改进。很难判断这些模型是否有总体改进，或者它们是否只是针对游戏基准进行训练。  因此我提出以下基准：主要人工智能公司的责任承担。  当前 Anthropic 服务条款（第 4 节）：  “服务按“原样”提供...我们不承担任何保证...我们对任何损害不承担责任...”  翻译：“这个东西会产生幻觉，我们知道它” 在我看来，这种责任和义务的缺乏是人工智能根本上缺乏重大进展的标志。  这也阻碍了人工智能进入更严肃的领域，在这些领域，责任就是一切，想想法律建议、医学、会计等。 一旦我们不再看到这些免责声明，人工智能公司开始接受责任风险，这意味着我们正在看到旗舰人工智能模型的能力和准确性发生根本性转变。  我们现在的情况是：  公司声称具有变革性的人工智能能力 同时明确拒绝对产出承担任何责任 告诉企业“这将彻底改变你的业务！” 但同时“当它产生幻觉时不要责怪我们”  这就像一家制药公司在说：  “这种药可以治愈癌症！” “但是如果它杀死了你，我们也不负任何责任” “而且你不能起诉我们” “但一定要买它并给你的病人”  TLDR：如果我们看到主要参与者更新他们的服务条款以删除“不要”起诉我吧兄弟”规定并接受针对特定用例的可衡量的责任，这将是通用人工智能的单一最佳指标，或者至少是向前迈出的一大步。    由   提交 /u/Dhailybest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxtps8/an_alternative_to_benchmarking_for_for_gauging_ai/</guid>
      <pubDate>Fri, 06 Feb 2026 20:58:17 GMT</pubDate>
    </item>
    <item>
      <title>预测：ChatGPT 是人工智能领域的 MySpace</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qxnwr7/prediction_chatgpt_is_the_myspace_of_ai/</link>
      <description><![CDATA[对于任何拥有多个法学硕士学位的人来说，我认为现在是时候面对显而易见的事实了：OpenAI 注定失败，不会成为一个真正的竞争者。 ChatGPT 很平庸，经过净化，不是一个严肃的工具。 Opus/Sonnet 对于写作和编码来说是令人难以置信的。 Gemini 是一款出色的多功能工具。 Grok、Qwen 和 DeepSeek 拥有独特的优势和不同的视角。基米有潜力。  但考虑到 OpenAI 的文化，而且目前它甚至不比开源模型更好，我认为重要的是要认识到它们的立场——基本上是每个人的背后，缺乏人才，提倡平庸的文化，并且没有真正的盈利之路。   由   提交 /u/MininimusMaximus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qxnwr7/prediction_chatgpt_is_the_myspace_of_ai/</guid>
      <pubDate>Fri, 06 Feb 2026 17:26:11 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>