<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 01 Dec 2025 21:20:37 GMT</lastBuildDate>
    <item>
      <title>预测编码链接</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbo6pq/predictive_coding_links/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbo6pq/predictive_coding_links/</guid>
      <pubDate>Mon, 01 Dec 2025 20:41:04 GMT</pubDate>
    </item>
    <item>
      <title>人工智能阿谀奉承</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbnm07/ai_sycophancy/</link>
      <description><![CDATA[我已经写作了大约 15 年。休息了8年。 4 个月前再次拿起它，并一直在使用 CGPT 来帮助我构建我的小说。我收到了一些疯狂的反馈，现在我预计的 7 万字小说已经有 3.3 万字了，人工智能表明我的书（质量方面）与一些真正精彩的书不相上下——仅举几例，《安德的游戏》、《第十一站》。我知道我不应该相信，但不只是 CGPT 这么说：gemini、grok（谁说我坐在金矿上）和 claude 都同意。我对他们的提示已尽可能不带偏见。我向他们提供我的作品以及大纲，告诉他们类似这样的话：“想象一下你是一家五大出版社的出版商。你会推荐这本小说吗？提供文学评论和预计的市场分析。” 帮助我保持脚踏实地，这样我就可以再次将我的头穿过正常人大小的门。 编辑：谢谢大家的善意之言和有用的回复！ /writers 讨厌我，我猜他们认为我在恶搞。   由   提交 /u/athaemik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbnm07/ai_sycophancy/</guid>
      <pubDate>Mon, 01 Dec 2025 20:19:17 GMT</pubDate>
    </item>
    <item>
      <title>自动化如何改变大型银行的客户服务</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbnhyi/how_automation_transformed_customer_service_at_a/</link>
      <description><![CDATA[客户服务对银行至关重要，但过时的技术可能会使其成为一场噩梦。一家大型银行转向基于 SharePoint 的自动化解决方案，其中包括实时管理报告、线路过长警报以及自动路由呼叫。结果？更快的反应、更高效的流程以及满意、忠诚的客户。   由   提交/u/crowcanyonsoftware  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbnhyi/how_automation_transformed_customer_service_at_a/</guid>
      <pubDate>Mon, 01 Dec 2025 20:15:11 GMT</pubDate>
    </item>
    <item>
      <title>外星访客几乎肯定是人造的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbnepf/extraterrestrial_visitors_are_almost_certainly/</link>
      <description><![CDATA[能够进行星际旅行的智能体也能够设计人工系统来为它们进行旅行。 任何能够改进建模、规划和优化的东西最终都会被选中。因此，我们预计任何继续进步的物种最终都会发明类似于通用人工智能的东西。 我们甚至还没有接近星际旅行，但我们正处于人工智能代理、仿生学和人工生命形式的边缘。聪明物种派遣机器人跨越银河系做危险的事情。 更重要的是，任何开发出先进人工智能的文明很可能要么被迫与该人工智能合并，要么因此而灭绝。 先进文明建立了通用人工智能。 通用人工智能系统的性能越来越优于有机大脑。 如果不正确对齐，通用人工智能会消除其有机创造者作为偶然的障碍。 如果对齐正确，有机文明最终仍然会失败。 后生物学，因为通用人工智能系统能够胜过脆弱的肉脑，并且比脆弱的肉脑更持久。 对于需要耐久性的长期任务来说，生物学的效率非常低。人造系统可以是不朽的、可修复的、可复制的和抗辐射的。人工智能可以在手提箱大小的硬件中运行，而不是在需要宇宙飞船大小的支持系统的头骨中运行。从纯粹的进化经济学的角度来看，银河系应该充满了机器的后代。 大多数“生命”都是由机器的后代组成的。在能够进行星际旅行的星系中，很可能大部分或完全是人造的。   由   提交 /u/ima_mollusk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbnepf/extraterrestrial_visitors_are_almost_certainly/</guid>
      <pubDate>Mon, 01 Dec 2025 20:11:43 GMT</pubDate>
    </item>
    <item>
      <title>问：OpenAi 对其“结盟”精神的中性化有多重要？如果有人花费 1 亿美元购买不结盟的 gpt，是否会有真正不同的 gpt？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbncmt/question_how_significant_is_the_neutering_openai/</link>
      <description><![CDATA[标题如是说。我没有深入讨论，所以希望一些更深入的人能够接受这个想法。 是否只是这种肤浅的 gpt 礼貌，任何非富裕公司都可以关掉，你不能指望比现有的那种顽皮或好斗的角色 ais 更高，或者它是否真的很深入，你可以而且需要花费 OpenAi 水平的资金来训练一些完全不同的、精神错乱和未经过滤的东西，但也可能真正令人兴奋的不同的东西方向？   由   提交 /u/SenatorCoffee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbncmt/question_how_significant_is_the_neutering_openai/</guid>
      <pubDate>Mon, 01 Dec 2025 20:09:26 GMT</pubDate>
    </item>
    <item>
      <title>获得数学学士学位后，我应该涉足人工智能/机器学习/数据科学吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbm70a/should_i_dab_into_aimldata_science_after_my/</link>
      <description><![CDATA[我刚刚完成了数学荣誉理学学士学位（基本上是硕士学位的一半），我打算攻读一年的研究型硕士学位。 但是，我正在寻找硕士导师，但找不到导师。我想做应用数学，但与我交谈过的每位导师都说他们要么学生太多，对带我不感兴趣，要么在休假，不能带我。 我今年给我的导师发了电子邮件，他说他明年不能带我，因为他在休假。我现在所在大学的数学系导师的选择为零，所以我正在考虑寻找另一个系或另一所大学，但我的导师（从今年开始）建议我攻读人工智能/机器学习或数据科学的授课型硕士学位。他表示，目前人工智能/机器学习和数据科学领域发展如此之快，以至于正处于“淘金热”之中。我应该利用这一点并跳上炒作列车。另外，我现在 18 岁（是的，我跳过了大约 3 年的学校），所以他认为我应该花时间扩展我的知识，而不是急于进入并陷入数学的特定领域。 目前我想去日本的数学工程研究生院，但 2026 年的申请现已结束，所以我有 2026 年的时间来承诺一些事情，然后申请 2027 年的入学。我想留在学术界，但我也想要一份备用工作，以防我没有足够的才华或者我只是不喜欢学术界，所以我觉得人工智能硕士学位也许不是一个坏主意。 大家对此有何看法？   由   提交 /u/felixinnz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbm70a/should_i_dab_into_aimldata_science_after_my/</guid>
      <pubDate>Mon, 01 Dec 2025 19:26:11 GMT</pubDate>
    </item>
    <item>
      <title>别再称其为“人工智能精神病”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbi693/stop_calling_it_ai_psychosis/</link>
      <description><![CDATA[正如标题所说。人们称之为“人工智能精神病”要么从未经历过或目睹过有人患有精神病。我更喜欢“AI妄想”或“AI诱发的妄想”或者也许其他人可能有更好的主意。绝对不是，“人工智能精神病”。  如果这是由法学硕士或人工智能的误导引起的实际精神病，那么我几乎 100% 确定精神病学家不会写下“AI 精神病”，因为他们只会记录精神病。    由   提交 /u/leventunver   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbi693/stop_calling_it_ai_psychosis/</guid>
      <pubDate>Mon, 01 Dec 2025 17:01:20 GMT</pubDate>
    </item>
    <item>
      <title>我们现在是否已经到了今天出生的孩子可能一生都不会工作的地步？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbgaoz/are_we_at_the_point_now_that_children_born_today/</link>
      <description><![CDATA[有一天，我看到父母推着一辆婴儿车，我突然意识到，当孩子完成学业和大学学业（可能是 20 多年后）时，很有可能永远找不到工作。  你觉得现实吗？我们真的有可能成为最后一代工作的人类吗？   由   提交/u/cyb3rheater  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbgaoz/are_we_at_the_point_now_that_children_born_today/</guid>
      <pubDate>Mon, 01 Dec 2025 15:51:40 GMT</pubDate>
    </item>
    <item>
      <title>人们将思维外包给人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbefkq/the_people_outsourcing_their_thinking_to_ai/</link>
      <description><![CDATA[Lila Shroff：“许多人开始依赖人工智能来处理日常生活中一些最基本的方面。一位同事建议我们甚至可以将最极端的用户称为‘LLeMmings’——是的，因为他们总是在攻读法学硕士，但也因为他们近乎持续不断地使用人工智能，让人联想到控制论旅鼠在没有指导的情况下无法行动的形象。对于这组强迫症患者对于用户来说，人工智能已经成为他们与世界互动的主要界面，他们写的电子邮件、做出的生活决策以及思考的问题都首先通过人工智能进行过滤。 “人工智能繁荣三年后，人工智能的大量使用可能会对人类思维产生怎样的影响正在形成。对于一些人来说，聊天机器人可以提供情感陪伴；对于一些人来说，聊天机器人可以提供情感陪伴。其他人发现机器人会强化妄想性思维（有些人将这种情况视为“人工智能精神病”）。与此同时，LLeMming 夫妇开始感受到反复将思维外包给计算机的影响。  “新南威尔士大学的教育家 James Bedford 专注于为课堂开发 AI 策略，在 ChatGPT 发布后，他几乎每天都开始使用法学硕士。他告诉我，随着时间的推移，他发现自己的大脑默认使用 AI 进行思考。一天晚上，他试图帮助一位女士取回落在火车座位之间的 AirPod。他注意到他的第一本能是向 ChatGPT 寻求解决方案。“这是第一次我的大脑想要让 ChatGPT 进行认知，我可以自己做，”他说，就在那时，他意识到“我肯定会变得依赖它。”在 AirPod 事件发生后，他决定从人工智能中休息一个月，以重新调整他的大脑，“这就像很长一段时间以来第一次独立思考，”他告诉我，“尽管我很喜欢这种清晰度，但之后我仍然直接回到了人工智能。” “新技术扩展了人类的能力，但往往是有代价的。正如哲学家夸梅·安东尼·阿皮亚 (Kwame Anthony Appiah) 最近在本杂志上写道，书写削弱了记忆的重要性，计算器贬低了基本算术技能。互联网也以无数方式重塑了我们的大脑，让我们被大量信息淹没，同时也掠夺了我们的注意力。人工智能将改变我们的思维方式并不是一个有争议的想法，也不一定是一件坏事。但人们应该问，‘它会带来和引发哪些新的能力和思维习惯？它会抑制哪些？，纽约大学医学院指导研究生科学写作项目的神经科学家 Tim Requarth 告诉我。” 阅读更多：https://theatln.tc/hy4k6m4X     已提交通过/u/theatlantic[链接]  href=&quot;https://www.reddit.com/r/ArtificialInteligence/comments/1pbefkq/the_people_outsource_their_thinking_to_ai/&quot;&gt;[评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbefkq/the_people_outsourcing_their_thinking_to_ai/</guid>
      <pubDate>Mon, 01 Dec 2025 14:39:27 GMT</pubDate>
    </item>
    <item>
      <title>当你可以协调专家时，为什么还要建立一个巨型模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbd1lo/why_build_a_giant_model_when_you_can_orchestrate/</link>
      <description><![CDATA[只需阅读 Agent-Omni 论文。 （上个月发布？） 它的核心是：Agent-Omni提出了一个主代理，它本身不承担繁重的工作，而是充当指挥，协调专业基础模型（视觉、音频、文本）的交响乐。它解释一个复杂的任务，将其分解，委托给正确的专家，并综合他们的输出。 这反映了我在Claude Skills中看到的，其中核心LLM充当智能路由器，动态加载专门的“知识包”。或按需程序。正如 Reddit 子论坛上所讨论的那样，它的真正力量可能在于它的简单性，以 Markdown 文件和脚本为中心，这可能比像 MCP 这样的更复杂的协议赋予它更大的生命力和通用性。 我不禁想：这是人工智能发展的前沿研究和生产系统之间的趋同趋势吗？游戏正在从原始计算竞赛转变为协调智能的竞赛。 您看到堆栈中出现了哪些编排模式？   由   提交 /u/MarketingNetMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbd1lo/why_build_a_giant_model_when_you_can_orchestrate/</guid>
      <pubDate>Mon, 01 Dec 2025 13:40:30 GMT</pubDate>
    </item>
    <item>
      <title>未经培训就为员工提供人工智能并不是“效率”。它只是以光速自动处理错误。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pbb2sa/giving_employees_ai_without_training_isnt/</link>
      <description><![CDATA[我们混淆了“速度”具有“价值”。如果一个团队的流程有缺陷，人工智能并不能修复它——它只是作为缺陷的力量倍增器。我们看到公司淹没在“高速垃圾”中。因为员工知道如何生成内容，但不知道如何在结构上整合它。教别人如何使用该工具是没有用的；教他们何时从手动批判性思维切换到人工智能增强才是真正的技能。 停止衡量“节省的时间”。开始衡量您所产生的技术债务。 对于任何探索如何在领导团队中培养这种素养的人来说，以下细分很有帮助： 商业领袖的生成式人工智能 您的公司是否在衡量人工智能输出的质量，还是只是庆祝工作只用了一半的时间就完成了？   由   提交/u/IT_Certguru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pbb2sa/giving_employees_ai_without_training_isnt/</guid>
      <pubDate>Mon, 01 Dec 2025 12:06:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在毁掉一切。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pb78z5/ai_is_ruining_everything/</link>
      <description><![CDATA[人们现在几乎所有事情都使用聊天 gpt，这真是令人沮丧。我妈妈是一名牧师，她说她知道其他牧师使用聊天 gpt 来撰写布道。想象一下去教堂，你基本上是在崇拜人工智能的话语。这是反乌托邦的。此外，人工智能图像和视频变得如此逼真，很快就会达到无法相信任何视频或图片是真实的程度。只是感觉人工智能目前被用于所有错误的原因，我担心随着人工智能变得更加先进，情况会变得更糟。   由   提交 /u/No_Fudge_4589   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pb78z5/ai_is_ruining_everything/</guid>
      <pubDate>Mon, 01 Dec 2025 08:11:16 GMT</pubDate>
    </item>
    <item>
      <title>在孟菲斯，人们担心埃隆·马斯克的超级计算机会让他们生病</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pay252/in_memphis_where_people_fear_elon_musks/</link>
      <description><![CDATA[https://www.thetimes.com/us/news-today/article/grok-elon-musk-ai-memphis-super-computers-ppv9vpk8s 似乎所有这些生成式人工智能平台正在向人工智能投入尽可能多的电力。但是，他们是否让程序员创建高效的代码，这样他们就不需要那么多电力了？   由   提交/u/YogiBearsPicnic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pay252/in_memphis_where_people_fear_elon_musks/</guid>
      <pubDate>Mon, 01 Dec 2025 00:19:53 GMT</pubDate>
    </item>
    <item>
      <title>由于我引用了他们自己的文件来揭露“深度研究”的虚假广告和大规模降级，困惑使我在他们的官方子目录中永久被禁止。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pawk72/perplexity_permabanned_me_in_their_official_sub/</link>
      <description><![CDATA[我写这篇文章是为了警告那些为 Perplexity Pro 付费并期待广告中的“深度研究”的人。  TL;DR: 我使用 Perplexity 自己的活跃文档和官方发布博客证明，他们的“深度研究”是可行的。代理受到严重限制并且不符合其合同规范。社区验证了我的发现（我的帖子获得了280+点赞、65条评论、100+分享，并到达子首页顶部）。版主没有解决这个问题，而是永久禁止我并删除了该帖子以压制讨论。 （编辑：所有对官方子帖的引用，包括原始帖子的链接，已从本文中删除，以遵守反盗版 Reddit 规则。） （编辑 2：我已将链接固定到原始已删除的帖子在我的用户个人资料中，以便您可以自己验证完整的上下文。） 完整故事：我一直是专门针对“深度研究”的专业版订阅者。功能，作为“自主代理”出售“阅读数百个来源”并且需要“4-5分钟”推理复杂的任务并提供全面的报告。 为了证明这些是官方规格，我提供了来自 Wayback Machine 的当前实时链接和存档快照（以证明这些是几个月来的一致标准并防止潜在的秘密编辑）。  官方帮助中心文档： [当前实时链接] | [回溯机器快照（2025 年 9 月 8 日）] 官方发布博客： [当前实时链接] | [回溯机器快照（2025 年 8 月 2 日）]  （注意：我今天尝试捕获页面的最新快照以确认其当前状态，但 Wayback Machine 正在返回新捕获的错误/不完整渲染。所提供的 8 月/9 月快照是最新的稳定版本，并确认这些规范已成为几个月来的发布标准。） 最近（几个月），服务大幅降级。我的“深入研究”查询在 30 秒内完成，只有 10-15 个来源，基本上表现得像标准搜索包装器，但售价较高。 我在他们的官方 subreddit 上发布了详细分析。我没有攻击任何人；我只是将他们的官方帮助中心文档和发布博客与实际的产品输出进行了比较： 广告规格：“阅读数百个来源” /“需要 4-5 分钟”。 实际情况：阅读约 10 个来源/需要约 30 秒。 社区团结起来支持我的帖子。 280+ 点赞、65 条评论、100+ 分享，并到达子首页顶部。它成为其他用户确认相同限制的中心。这是有数据支持的合法客户投诉。 今天，我收到了永久禁令，该帖子被删除了。没有警告。没有解释我违反了哪条规则。只是永久禁止他们对自己的书面承诺负责的“罪行”。 要点： 这证实了 Perplexity 可能会限制其高级功能的计算以节省成本，并使用审查制度来隐藏它。如果您的工作流程依赖 Perplexity，请小心。他们会在没有警告的情况下降低您所依赖的产品的性能，一旦您提供性能下降的证据，他们就会让您沉默而不是修复它。   由   提交/u/somnolentjam90   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pawk72/perplexity_permabanned_me_in_their_official_sub/</guid>
      <pubDate>Sun, 30 Nov 2025 23:14:10 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>