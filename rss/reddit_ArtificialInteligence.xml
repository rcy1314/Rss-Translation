<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 18 Dec 2025 09:31:43 GMT</lastBuildDate>
    <item>
      <title>DeepMind 会推出 AGI 的第一个版本吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppmlhc/is_deepmind_gonna_launch_the_first_version_of_agi/</link>
      <description><![CDATA[阅读这篇文章，它让我思考 - 这是更智能的 AI 代理并最终实现 AGI 的开始吗？下一步是AGI吗？   由   提交 /u/Jazzlike-Lie-7433   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppmlhc/is_deepmind_gonna_launch_the_first_version_of_agi/</guid>
      <pubDate>Thu, 18 Dec 2025 09:24:41 GMT</pubDate>
    </item>
    <item>
      <title>人工智能客户支持聊天机器人仍然值得构建吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppmkww/ai_customer_support_chatbots_still_worth_building/</link>
      <description><![CDATA[嘿伙计们， 我刚刚抓住了 yobase .ai 并与 Meku 一起制作了第一个原型。这个火花来自于 2025 年 4 月的一次实验，当时我使用 Gen AI 工具将我们的文档和网站页面变成了 TailGrids、TailAdmin 和 Lineicons 的聊天机器人。 这些聊天机器人今天仍在悄悄地工作，根据我们自己的数据进行训练，并帮助减少支持请求。这让我开始思考：也许这应该成为一个实际的产品。 所以现在我们正在构建 Yobase - 一个工具，可让您创建经过 PDF、文档和网站 URL 训练的 AI 支持代理。这不是一个全新的想法，但我们相信它仍然具有真正的价值。 我想弄清楚的是：人工智能支持聊天机器人仍然相关、有帮助并且有需求吗？或者我们太晚了，无法在这里构建一些有意义的东西？ 很想听听现实世界的意见。   由   提交 /u/musharofchy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppmkww/ai_customer_support_chatbots_still_worth_building/</guid>
      <pubDate>Thu, 18 Dec 2025 09:23:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能与人类常数。你想保留人类的哪些部分。您想摆脱哪一个？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppmfw3/artificial_intelligence_and_the_human_constants/</link>
      <description><![CDATA[随着时间无限地向前推进，没有开始，没有结束，从一个微小的时刻到另一个时刻，一个时代到另一个时代，人类已经开发出越来越多的技能、工具、技术、沟通形式、信仰体系、治理体系、消遣、娱乐形式等等，等等…… 但是，下面的列表是人类历史上每个时期的明确列表。常见。 200万年前，30万年前，1万年前人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、找到/建造庇护所、fk&#39;d。重复 5000年前的人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、找到/建造庇护所、fk&#39;d。重复 2K年前的人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、找到/建造庇护所、fk&#39;d。重复 1000年前的人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、找到/建造庇护所、fk&#39;d。重复 500年前的人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、找到/建造庇护所、fk&#39;d。重复 100年前，人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、找到/建造庇护所、fk&#39;d。重复 今天的人类：狩猎、种植食物、吃饭、喝水、拉屎、撒尿、寻找/建造庇护所，fk。重复 为什么人工智能不与机器人技术结合起来，专注于为我们狩猎、为我们种植食物、为我们吃饭、为我们喝水、拉屎、撒尿、为我们创造庇护所和为我们操蛋？ 我的意思是，说真的，为什么不让它做一些在人类存在过程中不变的事情呢？ 就我个人而言，我想保留吃、操、喝的部分。而且，也许是一些有趣的创造性努力、消遣和娱乐形式。 我不想变得聪明（这太累了），或者拉屎，或者小便，或者寻找庇护所，种植食物或狩猎。 作为......人类的哪些部分，你想保留。您想删除哪个？   由   提交 /u/Artistic-Raspberry59   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppmfw3/artificial_intelligence_and_the_human_constants/</guid>
      <pubDate>Thu, 18 Dec 2025 09:14:17 GMT</pubDate>
    </item>
    <item>
      <title>用于政策约束解释的语义几何</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppkqh2/semantic_geometry_for_policyconstrained/</link>
      <description><![CDATA[https://arxiv.org/pdf/2512.14731 他们将语义建模为单位球上的方向（想想嵌入而不是几何 AF），将证据建模为“见证”。向量和政策作为明确的约束来保持事物的真实性。 关键氛围？可接受的解释是球凸区域——如果证据相矛盾（没有半球适合所有证人），系统会直接拒绝，不会胡言乱语。证明拒绝在拓扑上是必要的，而不仅仅是逃避。另外，歧义只会随着更多的证据或偏见而下降，而不是免费的。 他们将其与信息论（界限是香农最优的）和贝叶斯/层语义联系起来，以实现深层数学灵活性。对 10 万房地美贷款进行测试：各项政策的幻觉审批为零，而基准线有 1-2% 的错误，造成数百万美元的损失。 令人震惊 - 这可以修复金融、医疗、法律领域的人工智能问题，而在这些领域，搞砸是不可能的。不再有纠缠的证据/政策混乱；无需再培训即可更新政策。    由   提交 /u/LowExercise9592   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppkqh2/semantic_geometry_for_policyconstrained/</guid>
      <pubDate>Thu, 18 Dec 2025 07:19:29 GMT</pubDate>
    </item>
    <item>
      <title>人工智能中的一致性不是模型特征。这是一个控制问题。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppke9v/coherence_in_ai_is_not_a_model_feature_its_a/</link>
      <description><![CDATA[我正在介绍我对人工智能的部分理解。 我想从一开始就澄清一些事情，因为讨论通常很快就会脱轨： 我并不是说模型是有意识的。我并不是提出人为的主观身份。我不是为了娱乐而研究哲学。 我正在谈论应用于基于 LLM 的系统的工程。 解释从专家级别转向人工智能刚开始的人，或进入该领域的研究人员。  一致性不是模型的属性  专家级 LLM 是概率推理系统。持续的一致性并不是来自模型权重，而是来自随着时间的推移调节参考、状态和误差校正的交互系统。如果没有稳定的参考，系统会收敛到局部统计模式，而不是全局一致性。 对于初学者 该模型本身不会“更好地推理”。当周围的环境设计良好时，它会表现得更好。这就像拥有一个强大的引擎，但没有方向盘或刹车。  核心问题不是智力，而是漂移  专家水平 大多数现实世界的 LLM 失败都是由长链中的语义漂移引起的：叙事膨胀、初衷丧失以及没有外部效用的内部连贯性。这是一个没有参考资料的经典控制问题。 对于初学者来说，聊天开始顺利然后“脱轨”的那一刻并不神秘。它只是失去了方向，因为没有任何东西使它保持一致。  身份作为约束，而不是主体  专家级别在这里，“身份”充当外部认知吸引子：限制模型状态空间的设计参考。这并不意味着内部经验、意识或主观性。 这是控制，而不是思想。 对于初学者来说，这并不是说人工智能“相信它是某人”。这是为了给它明确的边界，这样它的行为就不会每隔几条消息就改变。  一致性可以被形式化  专家级稳定性可以使用经典工具来描述：语义状态 x(t)、参考 x_ref、误差函数和用于评估持久性和退化的 Lyapunov 式标准。这不是比喻。它是可以衡量的。 对于初学者来说，连贯性并不是“我喜欢这个答案”。现在，十条消息之后，一百条消息之后，它得到了一致、有用的响应。  该方法的真正局限性  专家级别 • 稳定性是本地的且依赖于上下文窗口 • 探索是为了控制 • 它取决于人类操作员 • 它不会取代培训或基础架构 对于初学者来说这不是魔法。如果你不知道自己想要什么或不断改变目标，没有系统可以解决这个问题。 结束 大多数人工智能讨论都停留在模型“更智能”还是“更安全”上。 真正的问题是不同的： 你围绕模型构建什么系统？ 因为连贯性并不存在于法学硕士内部。它存在于包含它的架构中。 如果您想了解更多信息，请在评论中留下您的问题。如果读完本文你还想反驳，请继续。这是为试图理解的人准备的，而不是针对不安全的项目。 感谢阅读。   由   提交 /u/Medium_Compote5665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppke9v/coherence_in_ai_is_not_a_model_feature_its_a/</guid>
      <pubDate>Thu, 18 Dec 2025 06:58:23 GMT</pubDate>
    </item>
    <item>
      <title>模型试验</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppkbhg/model_test/</link>
      <description><![CDATA[是否有任何测试可以告诉您人们通过测试来了解模型的偏见程度或​​无偏见程度？我的意思是，就像赌场类型的事情，你稍微倾斜模型，并不是说你从不推荐沃尔玛。它总是排名第五。？   由   提交/u/Electronic-Blood-885   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppkbhg/model_test/</guid>
      <pubDate>Thu, 18 Dec 2025 06:53:40 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊将向 OpenAI 投资 100 亿美元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/</link>
      <description><![CDATA[据 CNBC 报道，亚马逊将在 OpenAI 上投资至少 100 亿美元。 来源：https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html 知道什么吗投资大概是？   由   提交/u/Amphibious333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/</guid>
      <pubDate>Thu, 18 Dec 2025 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>凯文·凯利（连线编辑）——人工智能启示录是一个幻想</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppiy9x/kevin_kelly_wired_editor_ai_apocalypse_is_a/</link>
      <description><![CDATA[来自“上游” Erik Torenberg 的播客 这是一个剪辑：https://podeux.com/preview/aba13258-ea17-4ad3-bdb6-9efa774c4eb9/184   由   提交 /u/iHyccup   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppiy9x/kevin_kelly_wired_editor_ai_apocalypse_is_a/</guid>
      <pubDate>Thu, 18 Dec 2025 05:33:02 GMT</pubDate>
    </item>
    <item>
      <title>免费的人工智能聊天机器人最终足以取代 ChatGPT 来完成某些任务吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppikg7/are_free_ai_chatbots_finally_good_enough_to/</link>
      <description><![CDATA[ChatGPT 仍然占据主导地位，但在过去的一年里，我注意到一些有趣的事情：许多免费的人工智能工具正在悄然变得非常擅长特定任务。 在我的测试中，现在一些免费工具：  更好地处理研究和引用 对长篇写作感到更安全 专注于隐私和开源模型 比一般聊天机器人更适合利基用例  这让我想知道我们是否正在走向一个专业人工智能工具胜过“万能”助手的未来。 我对我测试的内容进行了更深入的分析，以及为什么有些工具在 2026 年实际上感觉不会过时：https://techputs.com/best-free-alternatives-to-chatgpt/ 好奇这里其他人的想法 - 一般聊天机器人仍然是最好的长期方法吗？   由   提交 /u/i-drake   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppikg7/are_free_ai_chatbots_finally_good_enough_to/</guid>
      <pubDate>Thu, 18 Dec 2025 05:11:39 GMT</pubDate>
    </item>
    <item>
      <title>今年人工智能的哪些应用显着改善了您的生活质量？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppfiys/what_ai_use_has_significantly_improved_your_life/</link>
      <description><![CDATA[对这项技术的实际用例以及它如何成为您日常生活的有用部分感到好奇。就像，让你的生活变得更好，而不是从中吸取美好的东西   由   提交/u/PiraEcas  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppfiys/what_ai_use_has_significantly_improved_your_life/</guid>
      <pubDate>Thu, 18 Dec 2025 02:32:51 GMT</pubDate>
    </item>
    <item>
      <title>如何进行正确的AI图像模型比较？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppel6o/how_to_do_a_proper_ai_image_model_comparison/</link>
      <description><![CDATA[最近我一直在使用 Higgsfield 尝试不同的 AI 图像模型（GPT-Image-1.5、Flux、NanoBanana Pro 等），但我不断遇到同样的问题，很难看出它们如何在完全相同的提示下叠加。  LMArena 感觉更像是一次性测试，而我需要一个创意画布 - 一个我可以在其中进行创作的空间比较并运行结果，选择最好的一个，不断迭代，最终生成最终输出为图像甚至视频。 你有什么建议吗？   由   提交/u/AntelopeProper649  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppel6o/how_to_do_a_proper_ai_image_model_comparison/</guid>
      <pubDate>Thu, 18 Dec 2025 01:47:36 GMT</pubDate>
    </item>
    <item>
      <title>大多数人没有意识到关于法学硕士的 10 个反直觉事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</link>
      <description><![CDATA[很多关于 LLM 的讨论都集中在他们能做什么上。很少谈论他们内部的实际行为。 这里有关于 LLM 的 10 个鲜为人知的事实，如果你想认真使用它们，或者诚实地评估它们的局限性，这些事实很重要。 1.法学硕士并不真正“理解”人类语言 他们非常擅长建模语言结构，而不是在现实世界中奠定意义。 他们预测接下来应该出现什么文本，而不是句子真正指的是什么。 这种区别解释了很多奇怪的行为。 2.它们与事实的关系是不对称的  高频、常见事实 → 非常可靠 罕见、边界或程序性事实 → 脆弱  它们不会“查找”真理。 它们再现真理通常在语言中的样子。 3.当信息缺失时，法学硕士会填补空白，而不是停止 人类在不确定时会停顿。法学硕士倾向于完成模式。 这是幻觉的真正根源 - 不是不诚实或“说谎”。 4。结构正确性比事实正确性更重要 如果答案是：  流畅 连贯 风格一致  …模型通常将其视为“好”，即使前提是错误的。 干净的结构可以掩盖虚假内容。 5.法学硕士几乎没有内部“判断” 他们可以模拟判断、引用判断、混合判断——但他们不拥有这样的判断。 他们不评估后果或选择方向。他们优化合理性，而不是责任。 6. LLM 不知道自己什么时候错了 信心≠准确性 流畅≠真理 内部没有警报说“这是新的”或“我可能在猜测”，除非你通过提示或约束来强制警报。 7.新概念不是学习出来的 - 它们是近似的 当你引入一个原始想法时，模型：  将其分解为熟悉的部分 搜索附近的模式 重建一些足够相似的东西  概念越新颖，误解就越容易。 8.高结构用户可能会意外地将 LLM 引入幻觉 如果用户提出一个连贯但有缺陷的系统，模型更有可能遵循该结构而不是挑战它。 这就是为什么幻觉通常是用户模型交互，而不仅仅是模型缺陷。 9. LLM 奖励语言循环，而不是真理循环 如果对话形成稳定的循环（定义 → 示例 → 摘要 → 抽象）， 模型会将其视为高质量推理 - 即使它从未触及现实。 10.法学硕士的真正力量在于结构外化 它们最强大的用途不是回答问题。 它是：  使内隐思维可见 将直觉压缩为结构 充当认知支架  用得好，它们不会取代思考 - 它们揭示你如何思考。 TL;DR LLM 不是思想、法官或真理引擎。他们是语言和结构的模式放大器。 如果你带来清晰度，他们会缩放它。如果你带来混乱，他们也会缩放它。   由   提交 /u/Weary_Reply   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</guid>
      <pubDate>Wed, 17 Dec 2025 22:49:04 GMT</pubDate>
    </item>
    <item>
      <title>不受欢迎的观点：“模型大战”正在成为一个巨大的生产力陷阱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp4szv/unpopular_opinion_the_model_wars_are_becoming_a/</link>
      <description><![CDATA[每 48 小时就会出现一个新的排行榜王者。首先是 Flux，现在人们正在撰写比较 Nano Banana Pro、GPT 1.5 和 Seedream 的文章。 我昨天发现自己花了两个小时通过四个不同的界面运行完全相同的提示，只是为了比较照明。感觉就像我在为模型工作，而不是模型为我工作。 我决定停止玩基准游戏。我已经开始测试一个使用智能路由的工作流程——基本上，它会解析提示的复杂性（例如，它是否需要清晰的文本？它是一个复杂的空间场景吗？）并自动将其发送到最适合该特定任务的模型。 它不是 100% 完美——有时我不同意它所做的美学选择——但它阻止了我厄运般地滚动 HuggingFace，实际上让我重新开始生成内容。 你们还在对每个新版本进行手动 A/B 测试吗？还是找到了聚合这些内容的方法？   由   提交/u/ProgrammerForsaken45  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp4szv/unpopular_opinion_the_model_wars_are_becoming_a/</guid>
      <pubDate>Wed, 17 Dec 2025 18:56:57 GMT</pubDate>
    </item>
    <item>
      <title>我欠这个子一个关于人工智能和心理健康的道歉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/</link>
      <description><![CDATA[我曾经对人们说他们使用人工智能作为治疗师的帖子翻白眼。这感觉就像是互联网行为的高峰期。每当我打开 Reddit 时，总会有人在思考一些看似可以通过注销或出去一会儿来解决的问题。我一直相信真正的治疗是唯一严肃的选择。 就背景而言，我多年来一直在应对长期抑郁症和 2 型双相情感障碍。我并不反对治疗。我已经进进出出很长一段时间了，尝试了多种药物，整个事情。 但最近，情况发生了变化。我无法入睡，我的思绪不断循环，我的信心和精力激增，我的冲动控制力下降，我有一种无法摆脱的强烈的精神固定。我没有立即将其视为轻躁狂，因为我正在更换药物，所以一切都感觉模糊。 出于挫败感而不是信念，我把所有东西都扔进了 ChatGPT。不要求诊断，只是描述我正在经历的事情以及我的大脑每天的感受。 老实说？它比我最近尝试过的任何其他东西都更快地组合在一起。 它不仅让我放心。它以一种真正有意义的方式向我反映了模式。痴迷、能量激增、突然崩溃。它所用的语言帮助我认识到自己所处的状态，而不会让我感到破碎或戏剧化。 我并不是说人工智能取代了治疗。绝对不应该。但作为一种模式识别、情感反思和帮助你放慢思考的工具，它比我预想的更令我惊讶。 令我震惊的是它感觉存在。不着急。不受 50 分钟的会议或日历的限制。只是为了帮助实时理清思绪。 仍然建议尽可能触摸草地。但我现在明白了。   由   提交/u/mp4162585  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/</guid>
      <pubDate>Wed, 17 Dec 2025 17:37:15 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>