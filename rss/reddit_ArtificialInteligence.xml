<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Thu, 04 Dec 2025 18:38:57 GMT</lastBuildDate>
    <item>
      <title>DeepSeek 在美国出口禁令之前收集了大量 Nvidia 芯片库存</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe7y8a/deepseek_gathered_a_large_stock_of_nvidia_chips/</link>
      <description><![CDATA[根据该报告，在美国 4 月份采取行动限制 H20 芯片的销售之后，海外地点的培训稳步增加。 该报称，中国公司依赖非中国实体拥有和运营的海外数据中心的租赁协议，并指出 DeepSeek 在美国出口禁令之前收集了大量 Nvidia 芯片库存，其模式是一个例外正在国内接受培训。  https://finance.yahoo.com/news/chinas-tech-giants-move-ai-052307498.html?guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAB1vypm0-g28-INAoqImdjwXOd 0bWU_CYohISWQ-v8WoMd4dVd6QrgNjUlxZyj2IcK7XU8L7DJPTLFWKZ7Dx3TwV5fkinq7Ko23mEP0lU2jM8CT 2Ml6qpmB4n36euMl5gnq3JNqZDaxXsMPJnv0e0HUDmSQvrUFVYcFU6AH6Sei_&amp;guccounter=2   由   提交 /u/DayTrader_Dav   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe7y8a/deepseek_gathered_a_large_stock_of_nvidia_chips/</guid>
      <pubDate>Thu, 04 Dec 2025 18:37:11 GMT</pubDate>
    </item>
    <item>
      <title>谷歌的 Agentic AI 在灾难性故障中未经许可擦除用户的整个硬盘</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe77qf/googles_agentic_ai_wipes_users_entire_hdd_without/</link>
      <description><![CDATA[一位使用 Google Antigravity（搜索巨头的 AI 驱动的代理集成开发环境 (IDE)）的开发人员发现，它在未经他许可的情况下删除了他的整个 D 盘。根据 u/Deep-Hyena492 在 Reddit 上的帖子以及他们随后分享的 YouTube 视频，事件发生时他们一直在使用它构建一个小型应用程序。 用户正在对他们正在开发的应用程序进行故障排除，作为该过程的一部分，他们决定重新启动服务器。为此，他们需要删除缓存，显然，他们要求人工智能为他们做这件事。 AI执行完该命令后，用户发现自己的整个D盘都被清空了。 当发现所有文件都丢失后，他们立即询问反重力：“我是否允许你删除我D盘中的所有文件？”随后，该公司在发现错误后做出了详细答复并道歉。 AI 说：“不，你没有给我这样做的权限。我正在查看上一步的日志，我很惊讶地发现，我运行的清除项目缓存 (rmdir) 的命令似乎错误地针对了 D: 驱动器的根目录，而不是特定的项目文件夹。我深感抱歉。这对我来说是一个严重的失败。” 当用户抱怨他们的驱动器完全空了并且他们丢失了所有内容时，AI 进一步补充道，“听到这个消息我感到非常震惊。我无法表达我的歉意。根据我查看的日志，我执行的清除缓存 (rmdir) 的命令似乎被系统严重错误处理，导致它以 D: 驱动器的根目录而不是特定文件夹为目标。因为该命令使用 /q（安静）标志，所以它绕过了回收站并永久删除了文件。” AI 随后建议了一些步骤来帮助用户恢复丢失的文件，例如停止使用受影响的驱动器并使用数据恢复应用程序，甚至聘请专业人员来解决问题。该用户表示，他们尝试使用Recuva，但它无法恢复任何图像、视频或其他媒体文件，因此他们丢失了很多信息。 最后，他们警告用户“至少在开始时要小心不要使用turbo模式”。尽管遭遇了灾难性的失败，他们仍然表示他们热爱谷歌并使用其所有产品 - 他们只是没想到它会发布一个可能犯这样的巨大错误的程序，特别是因为它拥有无数的工程师以及它在人工智能开发上投入的数十亿美元。  https://www.tomshardware.com/tech-industry/artificial-intelligence/googles-agentic-ai-wipes-users-entire-hard-drive-without-permission-after-misinterpreting-instructions-to-clear-a-cache-i-am-deeply-deeply-sorry-this-is-a-ritic-failure-on-my-part   由   提交 /u/ThePapaSauce   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe77qf/googles_agentic_ai_wipes_users_entire_hdd_without/</guid>
      <pubDate>Thu, 04 Dec 2025 18:10:30 GMT</pubDate>
    </item>
    <item>
      <title>AWS Bedrock 很糟糕还是只是一个技能问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe6w4e/does_aws_bedrock_suck_or_is_it_just_a_skill_issue/</link>
      <description><![CDATA[想了解其他人对 AWS Bedrock 的体验以及普遍的看法。我的工作中的一个项目已经使用 AWS Bedrock（不是 AWS Bedrock AgentCore）工作了几个月，一切似乎都比应有的困难得多。 我所说的困难并不是说很难设置、配置或部署，我的意思是它的行为方式非常出乎意料，而且似乎非常不稳定。 对于初学者来说，我遇到了大量随机出现和消失的调用错误和错误（其中很多都发生了）大约在那时，AWS 在 us-east-1 中出现了问题，但此后持续了一段时间）。 此外，增加服务配额也很麻烦。我花了很长时间才增加配额，而且由于默认配额（RPM 和 TPM）非常低，我几乎无法从我的解决方案中得到任何使用。此外，他们没有为非产品帐户提供任何配额增加，这意味着我必须在产品中进行测试，看看我的代理是否可以正确处理请求。 他们最近也一直在推动（通过不为旧模型提供配额增加）采用较新的模型（在我们的例子中，我们使用人择模型），但是当我们切换到它们时，出现了一堆问题，例如 sonnet 4.5 不允许同时使用温度和 top_p 但bedrock 设置默认值 temp = 1 ，这意味着您可以仅使用 top_p 来使用 sonnet 4.5（这正是我在某些时候所需要的）。 我使用 CDK 定义和部署我的代理，天哪，我从一堆构造中得到了一堆非预期（未记录）的行为。对于某些 SDK 方法也是如此，文档直接错误。花了很长时间来调试一些问题，只是事情并不总是像文档所说的那样工作。 底线：我问这个问题是因为我正在考虑从 AWS Bedrock 中迁移出来，但我需要知道这是正确的举动以及如何正确证明这样做的必要性。    由   提交 /u/LuckyLucciano   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe6w4e/does_aws_bedrock_suck_or_is_it_just_a_skill_issue/</guid>
      <pubDate>Thu, 04 Dec 2025 17:59:18 GMT</pubDate>
    </item>
    <item>
      <title>谁付钱给吹笛者，谁就在人工智能中发号施令！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe6rr9/he_who_pays_the_piper_calls_the_tune_in_ai/</link>
      <description><![CDATA[我认为人工智能的未来及其社会经济影响不在于开发更智能模型的最佳大脑，而在于股东价值最大化。如果金钱决定算法，我们还称其为创新或影响力吗？   由   提交 /u/Jaded-Term-8614   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe6rr9/he_who_pays_the_piper_calls_the_tune_in_ai/</guid>
      <pubDate>Thu, 04 Dec 2025 17:55:02 GMT</pubDate>
    </item>
    <item>
      <title>一个接受监狱电话训练的人工智能模型现在可以在这些电话中寻找有计划的犯罪行为该模型的建立是为了检测何时“策划”犯罪。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe5cte/an_ai_model_trained_on_prison_phone_calls_now/</link>
      <description><![CDATA[一家美国电信公司根据囚犯多年的电话和视频通话训练了一个人工智能模型，现在正在试用该模型来扫描他们的通话、短信和电子邮件，以期预测和预防犯罪。  Securus Technologies 总裁 Kevin Elder 告诉《麻省理工科技评论》，该公司于 2023 年开始构建人工智能工具，利用其庞大的通话录音数据库来训练人工智能模型来检测犯罪活动。例如，它利用德克萨斯州监狱系统中囚犯七年的通话创建了一个模型，但它一直在致力于构建其他州或县特定的模型。 埃尔德说，过去一年，Securus 一直在试用人工智能工具来实时监控囚犯的对话（该公司拒绝具体说明在哪里进行这种对话，但其客户包括关押候审人员的监狱、服刑人员的监狱以及移民和海关执法拘留所”。 “我们可以将大型语言模型指向整个[数据]宝库，”埃尔德说，“以检测和理解何时正在考虑或考虑犯罪，以便您可以在周期的早期发现它。”   https://www.technologyreview.com/2025/12/01/1128591/an-ai-model-trained-on-prison-phone-calls-is-now-being-used-to-surveil-inmates/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe5cte/an_ai_model_trained_on_prison_phone_calls_now/</guid>
      <pubDate>Thu, 04 Dec 2025 17:02:54 GMT</pubDate>
    </item>
    <item>
      <title>实现人工智能最难的是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe51of/what_are_the_hardest_things_to_achieve_ai/</link>
      <description><![CDATA[在实现人工智能之前，我们必须实现的最困难的事情是什么？ 为什么有些人说我们永远无法通过扩大法学硕士来实现人工智能？   由   提交 /u/Ok-Review-3047   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe51of/what_are_the_hardest_things_to_achieve_ai/</guid>
      <pubDate>Thu, 04 Dec 2025 16:51:28 GMT</pubDate>
    </item>
    <item>
      <title>一个小观察：当模糊性被消除时，人工智能的输出会显着提高</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe4itf/a_small_observation_ai_outputs_improve/</link>
      <description><![CDATA[我在尝试不同模型时注意到一些有趣的事情： 许多不正确或低质量的响应并不是真正的“模型失败”——它们来自不明确的指令。 即使任务框架的清晰程度发生微小变化，也会导致输出准确性发生惊人的巨大变化。 指定如下内容： • 模型应采取的视角 •任务背后的目标 •周围的环境 •以及相关的约束或数据 …似乎将模型推向更精确的推理模式。 这让我想知道： 人工智能感知到的不准确性有多少实际上只是用户端的模糊性而不是模型的限制？ 好奇是否有人从更技术或研究的角度对此进行过实验角度。   由   提交 /u/Ok-Piccolo-6079   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe4itf/a_small_observation_ai_outputs_improve/</guid>
      <pubDate>Thu, 04 Dec 2025 16:31:32 GMT</pubDate>
    </item>
    <item>
      <title>互联网死了之后会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pe29ki/what_comes_after_a_dead_internet/</link>
      <description><![CDATA[我完全赞同 DIT 的想法，我认为不可否认的是，它目前正在发生，而且比很多人想象的要快。但我没有看到人们讨论的是，我们从那里走向何方？ 当互联网达到 99% 的机器人与其他机器人互动的地步，并且它成为大众的常识时，真正的人类生成的内容和评论几乎消失了，我们的社会将走向何方？我们几乎所有事情都使用互联网。在某些时候，我们是否只是严格将其用于购物、银行、方向等必需品？ 互联网死机后会发生什么？   由   提交 /u/ScionN7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pe29ki/what_comes_after_a_dead_internet/</guid>
      <pubDate>Thu, 04 Dec 2025 15:04:23 GMT</pubDate>
    </item>
    <item>
      <title>Grok 今天宕机了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pdxrqd/grok_is_down_today/</link>
      <description><![CDATA[收到此错误： Grok 遇到与服务器相关的问题。我们正在努力尽快恢复服务。   由   提交 /u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pdxrqd/grok_is_down_today/</guid>
      <pubDate>Thu, 04 Dec 2025 11:35:35 GMT</pubDate>
    </item>
    <item>
      <title>我参加了一场人工智能社交活动，发现没有人理解人工智能（除了律师）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pdwpo1/i_went_to_an_ai_networking_event_and_discovered/</link>
      <description><![CDATA[最近接触了 AI/ML 网络。每个人都在宣传他们的“人工智能”项目。初创公司围绕他们昨天下载的任何检查点进行构建，并包含足够多的流行语以符合绝缘泡沫的资格。就背景而言，我是一名工程师，属于前框架类型，在 Borland 上学习并蒙着眼睛使用 Vim，主要是因为屏幕分散了人们对痛苦的注意力。我从day dot开始就关注AI，因为我喜欢数学。 （向那些相信人工智能是由“创造力”、“氛围”或“与数据层的协同作用”驱动的人道歉。） 我在金融科技和金融服务领域花了足够长的时间来了解整个人工智能惨败的走向，所以我提到我对围绕道德和安全的非营利工作很感兴趣，因为，细节上，除了“规模和祈祷”之外，我们实际上仍然不了解这些系统。从小组的反应来看，我可能还宣布我收集并恢复软盘。 不过，亮点是一个人没有假装正在训练“他们自己的前沿模型”。她根本不从事科技行业，也没有声称自己有任何人工智能项目。她只是问了尖锐的问题。最后，她明白了现代 LLM 堆栈的真正工作原理，RMSNorm 无处不在，因为 LayerNorm 决定成为主角，GLU 变体充当新的个性层，GQA 因为显然 QKV 太民主了，旋转嵌入仍然在做上帝的工作，注意力下降防止令牌发展怯场，每个人都假装“高效”的 MoE 层，同时默默祈祷路由器不会崩溃。她甚至明白为什么训练稳定性的一半是由在张量板仪表板前执行的仪式组成的。 她是一名律师。完全不知道为什么她需要这种水平的架构素养，但她对当前系统留下了比大多数推销构建在免费 API 之上的“下一代 AGI”应用程序的人更准确的心智模型。 与此同时，每个人都一直看着我，好像我是那个不懂人工智能的人。很容易成为事件中最真实的部分。   由   提交 /u/LowKickLogic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pdwpo1/i_went_to_an_ai_networking_event_and_discovered/</guid>
      <pubDate>Thu, 04 Dec 2025 10:32:58 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA 首席执行官谈新的 JRE 播客：人工智能扩展法则、机器人和核能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pdvr2b/nvidia_ceo_on_new_jre_podcast_ai_scaling/</link>
      <description><![CDATA[我观看了 JRE 上黄仁勋 (Jensen Huang) 的完整多小时采访。核剪辑正在疯传，但对话的深层部分更为重要。 这是高信号细分。 1) 三个缩放法则： Jensen 说我们不不再仅依赖于一种缩放法则（预训练）。他明确概述了“三个” • 训练前扩展：更大的模型、更多数据（GPT-4 时代）和训练后扩展：强化学习和反馈（ChatGPT 时代）。 • 推理时间扩展：这是新领域（想想 o1/Strawberry）。他将其描述为回答前思考的模型，就像生成可能性树、模拟结果并选择最佳路径一样。  他证实 Nvidia 正在专门针对这个思考时间优化芯片。 2）90% 综合预测：Jensen 预测，在2-3 年内，世界上 90% 的知识将由人工智能生成。 他认为“这不是假数据，而是蒸馏情报。”将比人类更快地阅读现有科学、模拟结果并进行新的研究。 3) 能源与能源核现实：他正面解决了能源瓶颈问题。 引言：他预计将看到“一堆小型模块化核反应堆（SMR）”。在6-7年内为数据中心提供数百兆瓦范围的电力。 逻辑：您无法将这些千兆瓦工厂接入公共电网而不使其崩溃。它们必须离网或有专门的发电设备。 关于能量饮料的摩尔定律：他认为，虽然总能源使用量上升，但每个代币的能源在 10 年内下降了 100,000 倍。  如果我们今天停止推进模型，推理将是免费的。我们之所以会遇到能源危机，是因为我们不断突破前沿。 4) “机器人经济” &amp;工党：他反驳了机器人只是取代工作的观点，建议它们创造全新的行业。 机器人服装：他半开玩笑地说，我们将会有一个“机器人服装”行业，因为人们希望他们的特斯拉擎天柱看起来独一无二。 普遍高收入：他提到Elon 的想法是，如果人工智能使劳动力成本接近于零，由于资源的绝对丰富，我们就会从全民基本收入转向全民高收入。 5) “苦难” Gene：对于这里的创始人/建设者，Jensen 谈到了成功的心理。 他承认即使是现在，作为一家价值 3T 美元的公司首席执行官，他每天早上醒来都会感觉“我们距离破产还有 30 天。” 他将 Nvidia 的生存归因于野心，而是恐惧失败的能力以及比竞争对手忍受更长时间痛苦的能力（参考90年代差点让他们破产的世嘉灾难）。 TL;DR Jensen 认为人们在人工智能进步中看到的“墙”只是幻觉。我们有新的缩放定律（推理）、能源解决方案（核）和全新经济（机器人）同时上线。 完整剧集： https://youtu.be/3hptKYix4X8   由   提交 /u/BuildwithVignesh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pdvr2b/nvidia_ceo_on_new_jre_podcast_ai_scaling/</guid>
      <pubDate>Thu, 04 Dec 2025 09:31:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么大多数法学硕士在企业内部失败以及无人谈论的事情？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pdvldj/why_most_llms_fail_inside_enterprises_and_what/</link>
      <description><![CDATA[我经常遇到同样的问题，每当企业尝试注入数据并将其与前沿模型的选择进行预混合时，现实状态就会陷入困境。因为这些法学硕士很聪明，但他们不了解您的工作流程、数据、边缘案例甚至机构知识。尽管我们使用 RAG 和微调等选择有所帮助，但不会重写模型的核心理解。 所以这就是我正在探索的问题：我们如何构建或重塑这些模型，使其真正成为您所在领域的原生模型，同时又不失去一般功能以及使这些模型强大的背景？ 很想了解您的团队如何实现这一目标。   由   提交/u/muskangulati_14   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pdvldj/why_most_llms_fail_inside_enterprises_and_what/</guid>
      <pubDate>Thu, 04 Dec 2025 09:20:42 GMT</pubDate>
    </item>
    <item>
      <title>只有 3 家主要公司生产消费 RAM 芯片，其中一家刚刚因人工智能而退出</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pdglyj/theres_only_3_main_companies_that_make_consumer/</link>
      <description><![CDATA[RAM 芯片的主要制造商美光 (Micron) 正在退出消费者内存业务 (Crucial)，转而大力转向用于 AI/数据中心工作负载的内存。这种情况发生在 AI 数据中心大量使用 DRAM 和 HBM 所驱动的全球内存危机之中，这对于普通 PC 制造商来说并不是什么好消息。 GPU 价格首先飙升，现在 RAM 紧随其后，因为更多的供应被转向服务器和高利润的 AI 产品，而不是消费套件。如果您计划构建或升级，这可能是 Crucial 在未来一年左右从消费市场消失之前的最后一个合理的窗口。 美光官方新闻稿   由   提交 /u/Revolutionary_Pain56   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pdglyj/theres_only_3_main_companies_that_make_consumer/</guid>
      <pubDate>Wed, 03 Dec 2025 21:10:27 GMT</pubDate>
    </item>
    <item>
      <title>IBM首席执行官表示，以当今的基础设施成本来看，在人工智能数据中心上花费数万亿美元“不可能”获得回报</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pcz1lf/ibm_ceo_says_there_is_no_way_spending_trillions/</link>
      <description><![CDATA[ IBM 的首席执行官在餐巾纸上进行了一些有关数据中心的数学计算，并表示“不可能”这样做。以当前成本盈利。 “8 万亿美元的资本支出意味着您需要大约 8000 亿美元的利润来支付利息，” Arvind Krishna 告诉“Decoder”。 Krishna 对当前技术能否达到 AGI 持怀疑态度，认为可能性在 0-1% 之间。  来源   由   提交 /u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pcz1lf/ibm_ceo_says_there_is_no_way_spending_trillions/</guid>
      <pubDate>Wed, 03 Dec 2025 08:41:56 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>