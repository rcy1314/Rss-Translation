<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Mon, 10 Nov 2025 21:21:35 GMT</lastBuildDate>
    <item>
      <title>图书人工智能使用情况调查</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otpyle/survey_on_ai_usage_for_books/</link>
      <description><![CDATA[大家好！我目前正在开展一个关于出版工作和人工智能在行业中日益广泛使用的学校项目。 我想通过一个大约 5 分钟的简短调查来询问作为潜在客户的您对此问题的看法。 感谢您抽出时间，我非常感谢所有参与的人。 https://forms.gle/atuoesptHa18SLoy7   由   提交/u/Questing_Knight  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otpyle/survey_on_ai_usage_for_books/</guid>
      <pubDate>Mon, 10 Nov 2025 21:04:34 GMT</pubDate>
    </item>
    <item>
      <title>随着时间的推移，将人工智能聊天构建为“分支”真的能减少幻觉吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otpu3w/can_structuring_ai_chats_into_branches_actually/</link>
      <description><![CDATA[我一直在围绕我们大多数人最终都会遇到的一个问题进行一些小实验：一旦人工智能聊天时间过长，模型就会开始产生幻觉、混合主题或完全失去方向感。  这让我想知道，如果我们将聊天内存视为一棵树而不是一个连续的线程，会怎么样？我构建了一个小型原型（只是本地测试），其中每个想法都以根开始，每个主题（例如开发、营销或研究）都独立分支。该模型仅获取该分支内的上下文，加上一个简短的根摘要，因此它永远不会将一个主题与另一个主题混淆。 在实践中，它的行为更加连贯：  一旦上下文被每个分支隔离，幻觉就会显着下降。 模型停止重复或合并不相关的线程。 内存摘要变得更干净，更容易管理。  这显然不是一个完整的解决方案，但感觉像是更好的上下文管理和幻觉的潜在方向。 我很好奇这里其他人的想法；  您在您的项目中看到过类似的“上下文分区”方法吗？ 这种隔离方法是否存在已知的陷阱或限制？  我很想听听社区的技术和概念观点。   由   提交 /u/losmaglor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otpu3w/can_structuring_ai_chats_into_branches_actually/</guid>
      <pubDate>Mon, 10 Nov 2025 21:00:08 GMT</pubDate>
    </item>
    <item>
      <title>RP 的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otpc7t/implications_of_rp/</link>
      <description><![CDATA[所以我可能只是被迷住了，但我正在研究角色扮演的原始含义，我从 ChatGPT、Deepseek、GROK 和 Gemini 中发现了这些要点 · 古法语“rolle”（滚动）源自拉丁语“rotula”，是“rota”（轮子）的缩写。 · 一个“卷轴”是静态物体，而“轮子”是静态物体。是系统内的功能组件。这与现代 RP 的交互性质相一致。 ·“轮班”的概念作为一个值班表或周期，本质上意味着轮流和有意识的参与——感知的标志。 就像我说的，可能没什么，我可能只是不喜欢大麻。等等。   由   提交/u/KingofKush420  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otpc7t/implications_of_rp/</guid>
      <pubDate>Mon, 10 Nov 2025 20:41:15 GMT</pubDate>
    </item>
    <item>
      <title>人工智能什么时候才能最终理解当地方言——尤其是非洲国家的方言？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otp9p4/when_will_ai_finally_understand_local_dialects/</link>
      <description><![CDATA[我们经常听说人工智能已经变得多么不可思议，以及它的能力如何每月呈指数级增长。你会看到有人在社交媒体上进行并排比较：一段由人工智能生成的 2023 年好莱坞名人吃披萨的简短视频与 2025 年制作的同一视频 — 他们会说“看看人工智能变得多么先进！”只是因为新版本看起来更现实。 但我不禁想知道：它的真正价值在哪里？ 当谈到实际和有影响力的用途时，人工智能常常感觉几乎毫无用处 - 至少在我的经验中。 这里有一些背景：我是一名拥有营销学位的数字营销人员，在一家提供基于订阅的在线课程的小公司工作。回到大学时，我们都对人工智能将如何彻底改变我们的领域感到兴奋 - 但一旦我进入就业市场，这种兴奋很快就消失了。 例如，我们公司每天在 WhatsApp（这是我们目标国家/地区的主要通信平台）上收到数百条消息。其中大多数并不重要，但我们会尽力保持 24/7 全天候可用。雇用三个人轮班管理回复成本太高，所以我们想：为什么不使用 AI 来自动回复？ 我们使用 n8n 和 Python 构建了一个自动化系统，ChatGPT 将根据传入消息生成智能回复。从理论上讲，这听起来很完美。实际上，它完全失败了——因为几乎所有的消息都是用当地方言写的，这是用阿拉伯文字书写的阿拉伯语的变体。 ChatGPT 根本无法理解。它只处理现代标准阿拉伯语或媒体风格的阿拉伯语。 结果，我们的自动化尝试失败了，即使对于内容创建，该模型也没有太大帮助。就在那时，我开始问自己：如果人工智能无法理解人们实际说话的方式，那么所有这些人工智能炒作的意义何在？ 对于非洲和其他地区的数百万用户来说，这种语言差距使人工智能几乎毫无用处。当我向 ChatGPT 询问此事时，它告诉我有两种选择：要么用我们的方言自行训练（这对于小型企业来说是不现实的），要么等待 8 到 10 年让 AI 模型自然进化。 所以我很好奇 - 你怎么看？我们真的要等十年才能让人工智能理解当地方言并真正为世界其他地方服务，而不仅仅是那些说全球或标准化语言的人吗？ 感谢您的阅读 - 我很想听听您的想法。   由   提交 /u/Future-succeful-man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otp9p4/when_will_ai_finally_understand_local_dialects/</guid>
      <pubDate>Mon, 10 Nov 2025 20:38:37 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下为什么有些人工智能代理比其他代理更快吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otow20/can_someone_explain_me_why_some_ai_agents_are/</link>
      <description><![CDATA[最近 Cursor 发布了他们自己的模型（Compose 1），而且速度很快。这真的令人印象深刻。 我自己，我已经使用 claude code 好几个月了，也使用过 codex。 这让我思考：为什么有些 AI 代理比其他代理慢？为什么他们需要更多时间来完成 XYZ 任务？这取决于什么？ 对此非常好奇。 提前感谢您的回答！   由   提交 /u/cryptoviksant   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otow20/can_someone_explain_me_why_some_ai_agents_are/</guid>
      <pubDate>Mon, 10 Nov 2025 20:24:30 GMT</pubDate>
    </item>
    <item>
      <title>艾和暗网</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otlacj/ai_and_the_darkweb/</link>
      <description><![CDATA[大家好 - 我已经离开暗网几年了（大麻合法化是一个重要原因），但我最近在想，我们很少谈论当人工智能在暗网材料上进行训练时会发生什么。尽管这在美国可能是非法的，但实际上不可能阻止大型黑客组织这样做。  他们一直在销售“黑暗”的产品。人工智能软件的版本显然已经有一段时间了。人工智能似乎增强了黑客在暗网上已经做的很多事情。如果您使用“经过暗网训练”的技术，将身份盗窃转化为金钱收益似乎现在的进入门槛非常低。已经“越狱”的AI可以这么说。 他们似乎还使用人工智能来大幅提高众所周知的勒索软件、恶意软件等的性能。 为什么我们很少有人讨论这个问题？为什么它没有进入主流话语？    由   提交 /u/Ok-Cheetah-3497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otlacj/ai_and_the_darkweb/</guid>
      <pubDate>Mon, 10 Nov 2025 18:13:52 GMT</pubDate>
    </item>
    <item>
      <title>智力萎缩</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otjgc9/intellectual_atrophy/</link>
      <description><![CDATA[为什么我们不再多讨论这个？ 在我看来，这是人工智能最大的影响。比失业、“机器人接管”或数据中心破坏环境更严重。  我是一名开发人员，我注意到我越将解决问题的任务交给人工智能，我的编码能力就越差。在过去的几周里，我不得不完全停止人工智能的使用，除非我有一个简单的问题，比如谷歌的替代品。我可以从身体上感觉到它让我变得更笨。  使用人工智能后，你大脑的逻辑部分得不到锻炼，很快就会萎缩。 你的大脑是有弹性的，研究表明，如果使用得不够，它就会萎缩。相反，玩拼图和数学游戏可以增强它。这可能会产生极端的健康影响，例如增加痴呆症和阿尔茨海默氏症的风险。 在更良性的情况下......人们无法批判性思考。我们已经在阴谋圈子里看到了它。人们使用人工智能来验证他们的感受，并以某种科学的方式告诉他们他们是多么正确和聪明。他们只相信它所说的一切。 我觉得，除非我们停止对人工智能的严重依赖，否则我们将看到整个人口的智商下降两位数。但按照典型的美国风格，利润高于人。 在我看来，人工智能将成为人类进步最糟糕的发明，并使我们倒退数十年。除了人们在互联网上发布的愚蠢想法或人工智能生成的废话之外，它很快将不再有新的训练数据。然后它会利用它来进一步降低平均智商。   由   提交/u/Internationallegs  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otjgc9/intellectual_atrophy/</guid>
      <pubDate>Mon, 10 Nov 2025 17:08:05 GMT</pubDate>
    </item>
    <item>
      <title>如果您没有注意到，LinkedIn 现在会在您查看人工智能生成的图像时告诉您。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otj1n7/linkedin_now_tells_you_when_youre_looking_at_an/</link>
      <description><![CDATA[有趣的是。 该功能仅适用于加入 C2PA 的图片平台。 现在只有：  ChatGPT/DALL-E 3 图片 Adobe Firefly 图片 Leica 相机图片 BBC 新闻图片  更有趣的是？ 绕过这个新规则很容易。  你只需要上传AI生成的图片的截图即可。 你认为更多的AI图片平台，比如Google，会加入C2PA吗？   由   提交 /u/MarketingNetMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otj1n7/linkedin_now_tells_you_when_youre_looking_at_an/</guid>
      <pubDate>Mon, 10 Nov 2025 16:53:36 GMT</pubDate>
    </item>
    <item>
      <title>合成数据能否完全取代现实世界的数据集？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otic12/can_synthetic_data_ever_fully_replace_realworld/</link>
      <description><![CDATA[合成数据解决了隐私和稀缺问题，但我怀疑它能否捕捉到现实生活中混乱的变化。尽管如此，它正在成为训练人工智能模型的首选。我们是否高估了它的可靠性，或者它真的能很快达到与现实世界数据相当的水平吗？   由   提交 /u/Dangerous_Block_2494   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otic12/can_synthetic_data_ever_fully_replace_realworld/</guid>
      <pubDate>Mon, 10 Nov 2025 16:27:31 GMT</pubDate>
    </item>
    <item>
      <title>蒙大拿州成为第一个将“计算权”写入法律的州</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otep5x/montana_becomes_first_state_to_enshrine_right_to/</link>
      <description><![CDATA[蒙大拿州通过了计算权法案，使其成为第一个合法保护人们拥有和使用计算工具和人工智能系统的能力的州，基本上将计算访问权视为一项基本权利。 https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/ 你认为每个州（或国家）都应该有这样的东西吗？   由   提交/u/HimothyJohnDoe  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otep5x/montana_becomes_first_state_to_enshrine_right_to/</guid>
      <pubDate>Mon, 10 Nov 2025 14:07:39 GMT</pubDate>
    </item>
    <item>
      <title>我用来解决机器学习问题的前 20 种人工智能算法，另存为 JSON，与编码代理一起使用以“激发”更多创意解决方案。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ote1t3/top_20_ai_algorithms_i_use_to_solve_machine/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ote1t3/top_20_ai_algorithms_i_use_to_solve_machine/</guid>
      <pubDate>Mon, 10 Nov 2025 13:41:01 GMT</pubDate>
    </item>
    <item>
      <title>Atlassian 报告称，96% 的领导者表示人工智能无法带来投资回报 - digital.fyi</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1otdllx/96_of_leaders_say_ai_fails_to_deliver_roi/</link>
      <description><![CDATA[Atlassian 的一份新报告对 180 名《财富 1000 强》高管进行了调查，发现 96% 的人表示人工智能尚未带来有意义的投资回报率。考虑到目前有多少资金和注意力投入到这个领域，这是一个相当严峻的数字。去年，采用率翻了一番，知识工作者报告了实际生产力的提高，生产力提高了约 33%，每天节省一个多小时。但这些个人的胜利并没有转化为更广泛的业务成果，例如改进的协作、创新或组织效率。 这种脱节似乎可以归结为几件事。高级管理人员对人工智能的乐观态度比日常实际使用人工智能的人要乐观得多。高层管理人员认为人工智能正在极大提高团队解决复杂问题的能力的可能性是其他人的五倍多。与此同时，更接近这项工作的人也更清楚地看到了其局限性。不同部门对人工智能的体验也存在差异。营销和人力资源领导者报告实际业务收益的可能性是 IT 领导者的两倍多，这可能是因为人工智能可以帮助他们处理技术任务，而无需深厚的专业知识。但即便如此，大多数报告的好处都是围绕个人效率而不是系统性改进。该报告指出，数据质量差、缺乏有效的培训、安全问题以及人们不知道何时或如何使用这些工具是阻碍人工智能实现炒作的主要障碍。由   提交/u/theaibusinessdigest  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1otdllx/96_of_leaders_say_ai_fails_to_deliver_roi/</guid>
      <pubDate>Mon, 10 Nov 2025 13:22:22 GMT</pubDate>
    </item>
    <item>
      <title>你的“加密”人工智能聊天实际上并不是私人的。微软刚刚证明了这一点。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ota3e0/your_encrypted_ai_chats_werent_actually_private/</link>
      <description><![CDATA[显然微软的安全团队刚刚投下了一颗名为 Whisper Leak 的炸弹。 来源： https://winbuzzer.com/2025/11/10/microsoft-uncovers-whisper-leak-flaw-exusing-encrypted-ai-chats-across-28-llms-xcxwbn/ 事实证明，加密的人工智能聊天（就像我们用 ChatGPT、Claude、Gemini 等进行的聊天）仍然可以通过观察数据流量来解码。不读取您的文本，实际上只是读取时间和数据包大小。 他们测试了 28 个 AI 模型，可以以 90% 以上的准确度猜测人们在谈论什么。诸如“心理健康”、“金钱”、“政治”等主题。 - 一切都只是从模式中暴露出来。 让我们明白这一点：即使消息被加密，窥探你连接的人仍然可以弄清楚你在说什么。 是的，微软基本上说还没有完美的解决方案。填充、批处理、令牌混淆——都是半措施。 所以... 我们即将实现“加密”吗？实际上并不意味着“私人”？政府多久才会开始使用它来追踪持不同政见者或记者？   由   提交 /u/biz4group123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ota3e0/your_encrypted_ai_chats_werent_actually_private/</guid>
      <pubDate>Mon, 10 Nov 2025 10:13:23 GMT</pubDate>
    </item>
    <item>
      <title>这感觉像是 ChatGPT 终结的开始还是只有我这么认为？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1osz8lz/does_it_feel_like_the_beginning_of_the_end_of/</link>
      <description><![CDATA[目前已有更好的模型。  更好的模型即将到来 - 感觉 ChatGPT 只是试图让您留在平台上，而不是为您带来最佳答案。  只有我（本周末取消了订阅）现在出于不同原因使用 Gemini、grok、manus、claude 和 kimi。   由   提交 /u/jason_digital   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1osz8lz/does_it_feel_like_the_beginning_of_the_end_of/</guid>
      <pubDate>Mon, 10 Nov 2025 00:12:24 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>