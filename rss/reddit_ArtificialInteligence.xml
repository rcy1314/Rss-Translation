<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 25 Aug 2025 18:34:00 GMT</lastBuildDate>
    <item>
      <title>Google应该在Shapez / Shapez上进行RL 2</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwrzn/google_should_do_rl_on_shapez_shapez_2/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   shapez对于rl来说很棒;清晰的渐进信号需要很多（实际上）的推理，2D（Shapez）或3D（Shapez 2）网格，不需要实时管理。你们怎么看？还有其他看起来像很棒的环境的游戏吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_landscape_6819     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwrzn/google_should_do_rl_on_shapez_shapez_2/</guid>
      <pubDate>Mon, 25 Aug 2025 17:24:13 GMT</pubDate>
    </item>
    <item>
      <title>人类在AI方面有什么替代/互补性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwhfw/what_alternativecomplementarity_for_humans_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   随着AI逐步接管许多专业活动，可以肯定的是，必须接受这项技术而不是闭上眼睛，但我们必须反思这种情况。那么，人类在AI方面有什么替代/互补性？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzwhfw/what_alternativecomplentarity_for_humans_in/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzwhfw/what_alternativecomplementarity_for_humans_in/</guid>
      <pubDate>Mon, 25 Aug 2025 17:13:29 GMT</pubDate>
    </item>
    <item>
      <title>人工智能推动的新一波妄想思维浪潮使研究人员调查了AI陪伴的阴暗面</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzvhom/a_new_wave_of_delusional_thinking_fueled_by/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  媒体上越来越多的报告已经出现了个人螺旋式趋于“精神病思维”的情节。伦敦国王学院及其同事的研究人员最近检查了其中17个报告案例，以了解推动这种行为的大型语言模型（LLM）设计。研究人员在这些妄想螺旋中发现了三个常见的主题。人们经常相信他们经历了关于现实本质的形而上学的启示。他们可能还认为AI是有知情的或神圣的。否则他们可能会形成浪漫的纽带或其他依恋。 在这里链接到故事： https://wwwww.scientificamerican.com/article/article/article/article/article/how-ai-ai-ai-chatbots-may-beatbots-may-beepsy--------------------------经过同行评审，可以在预印式服务器psyarxiv和此处的链接中找到： https：&gt; sc_on-&gt;＆＃32;提交由＆＃32; /u/u/scientificamerican     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzvhom/a_new_wave_of_delusional_thinking_fueled_by/</guid>
      <pubDate>Mon, 25 Aug 2025 16:37:31 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）的Xai在AI比赛中起诉Apple和Openai，App Store排名</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    投诉称​​，苹果和Openai合谋抑制了Xai的产品，包括Apple App Store。 “如果不是因为与Openai的独家交易，Apple将没有理由避免更突出地在其App Store中使用X App和Grok App的特色，” Xai说。  Apple和Openai没有立即回应置评请求。 本月初，马斯克威胁要苏普蒂蒂诺，加利福尼亚州的苹果公司在他的社交媒体平台上的一篇文章中说，苹果的行为X上的一篇文章说，除了Ai I Company以外的任何AI公司在App Store中登录了＃1。”苹果与OpenAI的合作关系已将其AI平台融合到iPhone，iPad和Mac。 Microsoft Bass（MSFT.O）以及中国的初创公司DeepSeek都在加利福尼亚州的联邦法院（Sam Altman）起诉Openai及其在加利福尼亚州联邦法院的首席执行官Altman。 Maker Epic Games命令Apple允许Mike Scarcella的报告。    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzu6r7/elon_musks_xai_sues_sues_sause_apple_and_openai_over_over_ai/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu6r7/elon_musks_xai_sues_apple_and_openai_over_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 15:49:49 GMT</pubDate>
    </item>
    <item>
      <title>您的信息给AI的信息有多普遍？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu3z0/how_common_is_it_for_your_messages_to_ai_to_be/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试此方面AI应用程序，这让我想到，由于评论是如此现实，实际上有人在某处阅读这些帖子？   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dylan103906     [links]      &lt;a href =“ https://www.reddit.com/r/artaverinteligence/comments/1mzu3z0/how_common_is_is_it_for_your_your_your_messages_messages_to_ai_ai_ai_ai_ai_be/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzu3z0/how_common_is_it_for_your_messages_to_ai_to_be/</guid>
      <pubDate>Mon, 25 Aug 2025 15:46:55 GMT</pubDate>
    </item>
    <item>
      <title>AI代理等黑匣子应该有不同的型号。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mztk8q/there_should_be_different_models_for_ai_agents/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是的，今天的llms之后是编写代码的能力。但是我相信应该有一个LCM大型编码模型，大声笑。这种模型应在代码及其上下文上进行培训。我相信，现代LLM具有很大的潜力，但主要浪费了。我相信像BlackBox这样的AI代理应该问，OpenAi，人类等，以使用LCM等模型。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nigake_joke127     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mztk8q/there_should_be_different_models_for_ai_agents/</guid>
      <pubDate>Mon, 25 Aug 2025 15:26:50 GMT</pubDate>
    </item>
    <item>
      <title>麻省理工学院说95％的企业AI失败了 - 但这是5％的正确</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近关于企业AI的麻省理工学院研究重击： 95％的生成AI飞行员没有ROI 。大多数项目在“试点炼狱”中停滞不前，因为员工花费的时间比节省时间更多。  突出显示了5％成功部署的方法：   验证税→大多数AI系统是“自信是错误的” 。即使是微小的不准确性，也迫使人类重新检查每个输出，从而删除ROI。  学习差距→工具通常不会保留反馈，适应工作流程或随着使用而改善。没有学习循环，飞行员停滞不前。  暂时正确＆gt;自信错误→赢家正在建立： 量化不确定性（具有信心得分或“我不知道”的回应） 旗帜缺失上下文而不是虚张声势   从纠正中持续不断改进（“准确性的fly fly fly fly fly fly fly fly fly fly fly fly fly&gt;      大的要点： Enterprise AI并没有失败，因为模型还不够强大。之所以失败，是因为他们不承认自己  不  知道。  ，如果有时会说“我不知道”，您会更信任AI吗？您如何在实际工作流中平衡速度与验证？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/praveenweb   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_ai_ai_fails_ai_fails_but_heres_heres_what/”&gt; [link]   [comment]        ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzt825/mit_says_95_of_enterprise_ai_fails_but_heres_what/</guid>
      <pubDate>Mon, 25 Aug 2025 15:14:31 GMT</pubDate>
    </item>
    <item>
      <title>会计AI：Sage Copilot数据故障的教训</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzsnnb/ai_in_accounting_lessons_from_sage_copilots_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近阅读了一篇有关涉及 Sage Copilot 的情况，Sage Group的AI助手。据报道，当询问发票时，该工具从其他客户的帐户中披露了有限的详细信息。 Sage将其描述为一个小问题，确认没有暴露实际发票，并表示问题很快解决了。 虽然影响似乎很小，但它突出了一个重要的一点：当在会计或财务中使用AI时，数据隔离和隐私保护措施至关重要。当涉及敏感的客户信息时，即使是小故障也可能引起人们的担忧。似乎提醒您，从一开始就需要在体系结构中内置隐私控制。 很好奇听到您的想法：公司应如何在维持客户机密性的同时采用AI？    阅读完整的文章        &lt;！提交由＆＃32; /u/u/oncleangel     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzsnnb/ai_in_in_accounting_lesson_from_sage_copilots_data/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzsnnb/ai_in_accounting_lessons_from_sage_copilots_data/</guid>
      <pubDate>Mon, 25 Aug 2025 14:53:49 GMT</pubDate>
    </item>
    <item>
      <title>男子用溴化钠交换餐盐后住院...因为Chatgpt说了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在华盛顿，一名60岁的男子在医院里花了3个星期的幻觉和偏执狂，在用溴化钠替换了奶盐（氯化钠）。   OpenAI在其政策中指出，ChatGpt不是医疗顾问（尽管老实说，大多数人，大多数人都不会阅读精美的印刷品）。 The fair (and technically possible) approach would be to train the model (or complement it with an intent detection system) that can distinguish between domains of use: - If the user is asking in the context of industrial chemistry → it can safely list chemical analogs. - If the user is asking in the context of diet/consumption → it should stop, warn, and redirect the person to a professional source.  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzr8tg/man_hospitalized_after_swapping_tapple_salt_with/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzr8tg/man_hospitalized_after_swapping_table_salt_with/</guid>
      <pubDate>Mon, 25 Aug 2025 13:58:48 GMT</pubDate>
    </item>
    <item>
      <title>RLHF和宪法AI只是胶带。我们需要真正的安全体系结构。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkgv4/rlhf_constitutional_ai_are_just_duct_tape_we_need/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   rlhf，宪法AI使AI系统更安全在实践中更加一致，但他们还没有解决一致性。充其量是缓解层，而不是基本修复。 ＆gt; RLHF是一个昂贵的人类反馈回路，无法扩展。一半的时间，人类甚至都不同意什么好处。 ＆gt;宪法AI看起来很棒，直到您意识到谁写《宪法》决定了您的模型的想法。  这些方法基本上是训练模型，而在内部，它们仍然是巨大的随机鹦鹉，并保证了零。真正的危险不是他们现在所说的，而是当他们散布到各处，连锁任务或表现得像特工时会发生什么。礼貌的模型不一定是一个安全的模型。 如果我们认真对齐，我们可能需要核心的新安全体系结构，而不仅仅是事后修补输出。考虑内置的可解释性，在推理过程本身中运行的控制层，甚至可能是混合符号神经系统。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fordes_window8270     [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzkgv4/rlhf_constitutional_ai_ai_aie_just_just_duct_duct_tape_tape_tape_tape_tape_tape_tape_need/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzkgv4/rlhf_constitutional_ai_are_just_duct_tape_we_need/</guid>
      <pubDate>Mon, 25 Aug 2025 07:59:37 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/24/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzh87z/oneminute_daily_ai_news_8242025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   马来西亚推出了Ryt Bank  - 世界上第一家AI驱动的银行。[1]     YouTube 秘密使用AI来编辑人们的视频。结果可能会发生现实。[2]   AI驱动的Robo Dogs开始在苏黎世进行食品递送试验。[3]  研究表明，医生可能很快就依赖AI。[4]   来源包括： [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzh87z/oneminute_daily_ai_news_8242025/</guid>
      <pubDate>Mon, 25 Aug 2025 04:39:02 GMT</pubDate>
    </item>
    <item>
      <title>我花了一个月的时间测试Chatgpt与Claude作为AI导师与真正的学生。这实际上是有效的（什么无）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我花了一个月的时间测试chatgpt vs claude作为与真正的学生的AI辅导员。这是实际起作用的（以及什么不起作用）   chatgpt = speed demon进行考试准备，克劳德=思维教练，以深入理解。策略性地使用=改变游戏规则。 所以我是一名教育家，他厌倦了没有真实数据的所有AI炒作。决定实际测试Chatgpt的学习模式和Claude的学习模式，与50多名不同学科的50名学生整整一个月。 最令人惊讶的发现？   他们正在解决完全不同的问题。它就像将一辆跑车与远足的靴子与远足的靴子和完全不同的效果进行比较。   chatgpt学习模式在需要时获胜：   快速的作业帮助（快速解决数学问题40％） 逐步逐步过程 最后一分钟的考试cramming  清楚，清晰，清晰的解释模式对于：   实际理解概念（35％的保留率更好） 创意项目和论文 构建批判性思维 坚持   我的建议策略的瞬间：   使用克劳德（Claude  数学问题：通过3分找到圆的方程     chatgpt：直接进行配方，系统求解，在2分钟内进行检查的答案     claude：  &#39;什么使三个点特殊形成圆圈？首先导致真正的几何直觉，然后是JEE/竞争考试的数学  ？整天Chatppt。因为真正擅长数学？克劳德（Claude）的方法建立了一个基础，使您可以解决您从未见过的奇怪问题。 学生的底线： 停止询问哪个AI更好”并开始询问“哪个AI适合我现在要做的事情。您的经验是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fun-bet2862     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mzgk4v/i_spent_a_month_month_testing_chatgpt_vs_claude_claude_as_as_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzgk4v/i_spent_a_month_testing_chatgpt_vs_claude_as_ai/</guid>
      <pubDate>Mon, 25 Aug 2025 04:01:21 GMT</pubDate>
    </item>
    <item>
      <title>您的大脑成为训练数据</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不久前，我看着一个男人经历了AI的演变的tiktok。他提出了一个坚持我的声称（不确定是原来是他的）。他说，建立单人亿万美元的公司的人不会是一个从头开始编码AI的人，而是可以使AI自动化的人，而是可以让AI依靠身份并通过提示来操纵这些身份以在某些情况下操纵某些事情的人。基本上，创建了使某人以某种方式行事的最佳方法的模拟，并且拥有最人文数据的人，其中很多人可以训练AI来做到这一点。 我想到的第一个人是埃隆·马斯克（Elon Musk）。从这个角度来看，我认为他的大部分冒险与此相吻合并不是一个巧合。 x用于数据。特斯拉进行决策。作为个性和模拟。最糟糕的是，Neuralink。如果这成为标准，那么我们大脑中的芯片本质上将我们的身份变成AI的培训数据。而不是AI仅仅猜测我们从数字足迹或输入的东西中做什么，顺便说一句，这些东西已经很准确，它实际上会知道我们甚至在我们思考之前的一举一动。有访问该培训数据的人可以控制我们，模拟我们将准确地行事的情况。 那么，您如何看待？我只是偏执吗？我只是说明显的大声吗？您认为将有防御措施的保障措施吗？您还能添加什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/braiiie     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mzd9b7/your_brain_becoming_training_data/</guid>
      <pubDate>Mon, 25 Aug 2025 01:16:06 GMT</pubDate>
    </item>
    <item>
      <title>“ Palantir的工具构成了我们刚刚开始理解的隐形危险”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定这是正确的论坛，但这觉得很重要：  https://www.theguardian.com/commentisfree/2025/aug/24/palantir-artificial-intelligence-civil-rights  “被称为智力，监视，目标获取和侦察（ISTAR）系统，这些工具由几家公司构建，允许用户 track，track，detain，new and of war of war a a sake a sape a sape a sape a saper a sap a a sai  由ISTAR技术陷阱驱动的牵引力比移民以及他们的家人以及他们的家人以及他们的家人以及他们的家人以及他们的家人，以及他们的家人，以及他们的家人，以及他们以及他们的家人，以及他们以及他们的连接。他们似乎侵犯了第一和第四修正案的权利：首先，建立了庞大且无形的监视网络，这些网络限制了人们在公开场合共享的东西，包括他们遇到的人或旅行的地方；其次，通过启用无需进行保证的搜索和无人偏见的范围，而他们的知识很快。 href =“ https://www.amnestyusa.org/press-releases/usa-global-tech-made-by-palantir-palantir-palantir-and-babel-ind-babel-street-street-street-survreillance-theats-to-pro-pro--------------- href =“ https://www.thenation.com/article/world/world/nsa-palantir-israel-israel-gaza-ai/tnamp/”&gt;加沙的居民  - 他们的人权。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mz9w0u/palantirs_tools_pose_pose_an_invisible_danger_danger_we_we_are/”&gt; [link]   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz9w0u/palantirs_tools_pose_an_invisible_danger_we_are/</guid>
      <pubDate>Sun, 24 Aug 2025 22:43:37 GMT</pubDate>
    </item>
    <item>
      <title>LLM是人类管理知识能力的自然延续，而不是智力的突破</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mz1rya/llms_are_a_natural_continuation_of_human_ability/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mz1rya/llms_are_a_natural_continuation_of_human_ability/</guid>
      <pubDate>Sun, 24 Aug 2025 17:28:41 GMT</pubDate>
    </item>
    </channel>
</rss>