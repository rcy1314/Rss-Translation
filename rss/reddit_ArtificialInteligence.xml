<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 01 Mar 2026 02:44:11 GMT</lastBuildDate>
    <item>
      <title>我们正在走向快速的原生游戏引擎吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rhjygl/are_we_moving_toward_prompt_native_game_engines/</link>
      <description><![CDATA[我一直在思考 AI 如何改变游戏开发工作流程。 传统上，您从引擎（Unity、Unreal 等）开始，手动构建机制、编写脚本系统、迭代资产，并慢慢塑造体验。 但现在我们看到的工具是从语言而不是代码开始的。你不是先打开引擎，而是描述游戏： 在一个正在崩溃的空间站内进行合作生存游戏，环境危险且氧气有限。 系统会生成一个可以探索和迭代的可玩世界。 像 Tesana 这样的平台正在尝试这种从文本到可玩的工作流程，其中提示成为开发的起始层，而不是引擎 UI。 这似乎并没有取代传统的管道很快就会出现，但它确实感觉它可以极大地缩短想法到原型的周期。   由   提交 /u/Rude_Garbage4725   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rhjygl/are_we_moving_toward_prompt_native_game_engines/</guid>
      <pubDate>Sun, 01 Mar 2026 01:20:50 GMT</pubDate>
    </item>
    <item>
      <title>在取消开放 AI 订阅之前</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rhjo4y/before_you_cancel_your_open_ai_subscription/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rhjo4y/before_you_cancel_your_open_ai_subscription/</guid>
      <pubDate>Sun, 01 Mar 2026 01:07:35 GMT</pubDate>
    </item>
    <item>
      <title>个人人工智能计算是否应该与大规模集中式人工智能一起发展？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rhgnue/should_individual_ai_compute_grow_alongside/</link>
      <description><![CDATA[如果真正的人工智能军备竞赛不仅仅是扩大模型规模，而是谁能够控制智能本身呢？ 人工智能领域的主要参与者似乎都在竞相积累计算能力。更大的数据中心会带来更大的模型、数万亿个参数和更多的智能。计算感觉就像是解锁一切的万能钥匙。 但这带来了更深层次的结构问题。如果人工智能的集体智能在集中式数据中心内呈指数级增长，那么个体人类智能是否需要通过个人人工智能来与其一起扩展？ 一方面，您拥有由超大规模基础设施提供支持的大规模集中式智能。另一方面，个人本地模型有可能在个人拥有的硬件上运行。 为什么这种平衡很重要？ 如果中心化人工智能不断加速，权力自然会集中。优化的进展速度比大多数人能够理解的要快。随着时间的推移，人类可能会变得依赖于他们无法控制的系统。 但是，如果个人也有自己的本地模型、自己的人工智能内存、自己的计算和自己的增强功能，那么智力就会同时向两个方向发展。 集中式人工智能可以优化全球系统。个人人工智能可以保护自主性、思想多样性和弹性。 也许最健康的未来不仅仅是集中式超级智能。也许这是一个强大的集体智慧，与数百万或数十亿个主权的、人工智能增强的个体相结合。 这种平衡真的有必要吗？或者大型中心化人工智能本身就足够了吗？ 好奇人们的想法。   由   提交 /u/AI_investorX   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rhgnue/should_individual_ai_compute_grow_alongside/</guid>
      <pubDate>Sat, 28 Feb 2026 22:56:21 GMT</pubDate>
    </item>
    <item>
      <title>我对法学硕士的信任问题变得越来越昂贵（60 美元/月的俱乐部有人吗？）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rhcx3a/my_trust_issues_with_llms_are_getting_expensive/</link>
      <description><![CDATA[诚实的问题：你们现在有多少个订阅者？ 我从事数据分析工作（主要是 SQL、Python 和混乱的可视化库），我对工作流程已经达到了完全偏执的地步。 在很长一段时间里，我都在用 ChatGPT 来清理脚本和复杂的查询。但最近，它开始变得懒惰了。它会让我产生两年前已弃用的库的幻觉，或者给我一个看起来正确的正则表达式模式，但实际上却默默地删除了我的数据集的 10%。 因此，很自然地，我出现了信任问题。 我订阅了 Gemini，因为我的开发朋友说它通常更擅长逻辑/推理，并且有用于在文档中转储的巨大上下文窗口。但我不想像使用 ChatGPT 那样仅仅依赖这个。然后我抓起一个 Grok sub 只是为了自己试验哪个是最可靠的。 快进到上周：我坐在那里，打开三个浏览器窗口，每月支付 60 多美元，将完全相同的提示复制粘贴到三个不同的 UI 中，只是为了交叉引用 Python 代码。 如果 GPT 说“A”，Gemini 说“B”，Grok 说“C”，那么我必须扮演法官。它可以发现错误，但它非常乏味，而且伤害了我的眼睛（和我的钱包）。 我开始寻找一个可以聚合这些东西的解决方案，并偶然发现了这个叫做 Doraverse 的东西。我并没有真正听说过他们，但他们有这种“AI Parallel”基本上，你选择你的阵容（我通常保留 GPT、Gemini 和 Grok），输入一次提示，它们都会在侧栏中生成答案，你可以通过选择聊天中的结果框来切换到其他模型的答案。您可以看到下面的示例（我使用虚拟数据集仅用于测试目的。）  https://preview.redd.it/to9hdca9namg1.png?width=3846&amp;format=png&amp;auto=webp&amp;s=628ae0c4259e791d49726e6fff320962554055e3 &lt;一href=&quot;https://preview.redd.it/lwt9xelhnamg1.png?width=3854&amp;format=png&amp;auto=webp&amp;s=6b6911e8218dc4f22537557063f8d8d69101f633&quot;&gt; https://preview.redd.it/lwt9xelhnamg1.png?width=3854&amp;format=png&amp;auto=webp&amp;s=6b6911e8218dc4f22537557063f8d8d69101f633 &lt;一href=&quot;https://preview.redd.it/jhflkdqlnamg1.png?width=3848&amp;format=png&amp;auto=webp&amp;s=bbbbf6845c043967dfba8e23570b3b5db3870820&quot;&gt; https://preview.redd.it/jhflkdqlnamg1.png?width=3848&amp;format=png&amp;auto=webp&amp;s=bbbbf6845c043967dfba8e23570b3b5db3870820 为什么它对数据任务实际上有用：  “差异”检查：我不必切换选项卡。我可以立即看到一个模型是否产生了参数幻觉。如果三分之二的模型在语法上达成一致，我相信那个。 窗口切换：听起来很懒，但不必按 Ctrl+C -&gt; 。 Alt+Tab -&gt;当你深陷调试漏洞时，按 Ctrl+V 三次可以节省大量的精力。 数据安全：他们拥有 SOC 2 Type II 认证，所以它对我来说很合适，因为我处理敏感数据  坏东西（所以你知道我不是先令）：  它并不完美。我希望 UI 能够真正并行，答案并排放置在 3 列中（我猜他们尝试过这样做，但对于长答案来说可能太局促了）。 而且，他们并不总是在发布时就拥有最新的模型。例如，我注意到他们运行的是 Gemini 3 Pro，但最新的是 3.1 Pro，并且没有立即在工具中更新。因此，如果您需要 5 分钟前发布的版本，它可能会有点滞后。  无论如何，我仍在免费/试用版中探索它，看看它是否能坚持下去。不确定我是否会升级到他们更大的计划，直到我更加努力地推动它，但对于其他遭受法学硕士信任问题的人来说，这真是一种解脱。   由   提交 /u/p4pkiing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rhcx3a/my_trust_issues_with_llms_are_getting_expensive/</guid>
      <pubDate>Sat, 28 Feb 2026 20:21:32 GMT</pubDate>
    </item>
    <item>
      <title>AI驱动的3D打印和3D模型生成已达到全新水平</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rhc1ku/aidriven_3d_printing_and_3d_model_generation_have/</link>
      <description><![CDATA[ 由   提交/u/Least_Bus_6848   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rhc1ku/aidriven_3d_printing_and_3d_model_generation_have/</guid>
      <pubDate>Sat, 28 Feb 2026 19:47:12 GMT</pubDate>
    </item>
    <item>
      <title>独家专访：Anthropic 首席执行官达里奥·阿莫迪谈五角大楼的不和</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rha7mz/exclusive_interview_anthropic_ceo_dario_amodei_on/</link>
      <description><![CDATA[Anthropic 首席执行官达里奥·阿莫迪 (Dario Amodei) 接受了哥伦比亚广播公司新闻 (CBS News) 的独家采访，几小时前，国防部长皮特·赫格斯 (Pete Hegseth) 宣布该公司对国家安全构成供应链风险，这限制了军事承包商与这家人工智能巨头开展业务。阿莫代称此举是“报复性和惩罚性的”他说，Anthropic 试图在市场上划出“红线”。政府对其技术的使用，因为“我们认为跨越这些界限有悖于美国价值观，我们希望捍卫美国价值观。”   由   提交/u/CBSnews  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rha7mz/exclusive_interview_anthropic_ceo_dario_amodei_on/</guid>
      <pubDate>Sat, 28 Feb 2026 18:35:26 GMT</pubDate>
    </item>
    <item>
      <title>人类我们爱你</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh9pcw/anthropic_we_love_you/</link>
      <description><![CDATA[感谢您坚持正义。希望你越来越坚强。科技需要找到脊梁，2/3 的美国人对此表示赞赏   由   提交 /u/Clear-Dimension-6890   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh9pcw/anthropic_we_love_you/</guid>
      <pubDate>Sat, 28 Feb 2026 18:15:51 GMT</pubDate>
    </item>
    <item>
      <title>现在，在大多数基准测试中，开源模型与专有模型的差距仅为个位数，我们是否正处于一个转折点？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh7auj/with_opensource_models_now_within_single_digits/</link>
      <description><![CDATA[2026 年 2 月开源模型（GLM-5、Kimi K2.5、DeepSeek V3.2 Speciale）的排名均在被视为“仅限前沿”的范围内。就在一年前。您可以自行托管这三个项目，LiveCodeBench 分数达到 90%，AIME 分数达到 96%。 Together.ai 和 Groq 等提供商提供的 API 成本从 0.20 美元到 0.80 美元/M 代币不等。 什么时候为大多数用例支付专有 API 的费用就不再有意义了？是什么让您仍然坚持封闭模型？   由   提交/u/nihal_was_here  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh7auj/with_opensource_models_now_within_single_digits/</guid>
      <pubDate>Sat, 28 Feb 2026 16:42:49 GMT</pubDate>
    </item>
    <item>
      <title>Citrini Research 模拟了如果人工智能确实按照承诺工作的话会发生什么。结果很可怕</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh72xl/citrini_research_modeled_what_happens_if_ai/</link>
      <description><![CDATA[Citrini Research 发布了一份虚构的“2028 年宏观备忘录”这是我今年读过的最令人不安的事情。不是因为这是末日小说，而是因为链条中的每一步都是单独理性的。 场景：代理编码工具在 2025 年末达到阶跃功能。有能力的开发人员现在可以在几周内复制中端市场 SaaS。首席信息官们开始问“为什么我们每年要为此支付 50 万美元？”企业续订以 30% 的折扣重新协商。长尾 SaaS 受到的打击更大。 但这就是它变得黑暗的地方。 ServiceNow 出售座位。当财富 500 强客户削减 15% 的员工数量时，他们就会取消 15% 的许可证。人工智能驱动的削减提高了客户利润，但机械地破坏了 ServiceNow 的收入。受人工智能威胁最大的公司成为人工智能最积极的采用者。各公司的反应都是理性的。集体结果是灾难性的。 本文通过中介崩溃（代理商没有品牌忠诚度或应用程序疲劳）、消费者支出下降（收入最高的 20% 人推动了 65% 的可自由支配支出）以及最终对“经常性”承销的 PE 支持的软件交易的私人信贷违约来追踪这一点。收入停止循环。 DoorDash 的例子是残酷的。他们的护城河是“你饿了，你懒了，这就是你主屏幕上的应用程序。”代理没有主屏幕。它会检查 20 种替代方案并选择最便宜的。 这与典型的厄运作品的不同之处在于其金融机制。 AI 改进 -&gt;公司削减成本-&gt;节省下来的资金用于更多的人工智能 -&gt;更多削减-&gt;失业工人支出减少 -&gt;向消费者销售产品的公司实力减弱 -&gt;循环加速。没有自然制动。 很难不将这与我自己每天使用编码代理的经验联系起来。 Verdent 和 Codex 等工具确实让我的速度提高了 2-3 倍。生产力的提高是实实在在的。但谁获得了价值呢？现在我的雇主确实这么做了，因为需要的我更少了。 这不是预测。但这种情况值得对你的假设进行压力测试。   由   提交 /u/No-Fact-8828   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh72xl/citrini_research_modeled_what_happens_if_ai/</guid>
      <pubDate>Sat, 28 Feb 2026 16:34:07 GMT</pubDate>
    </item>
    <item>
      <title>人类现在发生了什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh3hor/what_happens_to_anthropic_now/</link>
      <description><![CDATA[ 由   提交/u/theatlantic  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh3hor/what_happens_to_anthropic_now/</guid>
      <pubDate>Sat, 28 Feb 2026 14:05:40 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在缩小技能差距，但也扩大了学科差距</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh2riq/ai_is_reducing_skill_gaps_but_increasing/</link>
      <description><![CDATA[人工智能使知识比以往任何时候都更容易获得。 你不再需要知道一切——你需要知道如何很好地使用工具。 但我注意到的是： 技能差距正在缩小。 学科差距正在扩大。 执行、专注和一致性正在成为真正的现实。差异化因素。 人工智能为每个人提供了影响力。 并不是每个人都知道如何指导它。 从长远来看，你认为人工智能会比原始人才更能奖励纪律吗？   由   提交/u/ClearThinkingLab  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh2riq/ai_is_reducing_skill_gaps_but_increasing/</guid>
      <pubDate>Sat, 28 Feb 2026 13:33:35 GMT</pubDate>
    </item>
    <item>
      <title>A.I 正在失控。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rh1eya/ai_is_getting_out_of_hand/</link>
      <description><![CDATA[我曾经很喜欢这样的日子，你可以随意观看一些视频，然后觉得这很酷等等。但如今，十分之九的视频都是人工智能的东西，看起来很假，让我的大脑受伤。人们是如何做到的，并认为这看起来非常好，我将发布它。您目前对人工智能有何看法？    由   提交 /u/KaleidscopePublic12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rh1eya/ai_is_getting_out_of_hand/</guid>
      <pubDate>Sat, 28 Feb 2026 12:28:26 GMT</pubDate>
    </item>
    <item>
      <title>特朗普命令所有联邦机构逐步停止使用人择技术</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rgk4ob/trump_orders_all_federal_agencies_to_phase_out/</link>
      <description><![CDATA[ 由   提交 /u/flGovEmployee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rgk4ob/trump_orders_all_federal_agencies_to_phase_out/</guid>
      <pubDate>Fri, 27 Feb 2026 21:53:02 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>