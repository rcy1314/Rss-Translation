<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 05 Jul 2025 12:43:48 GMT</lastBuildDate>
    <item>
      <title>如何在没有正确数据集的情况下构建新的AI模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls8g9l/how_to_build_a_new_ai_model_without_proper_dataset/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  简短的想法。我必须提出AI创新，以解决AI中尚未解决的问题，基本上超过了最新技术。有人提示。截止日期在20天内。 我有想法，但我不知道它们是否足够深。该应用具有情感，行为和教练空间。虽然，我有要实现的布局，但没有用代码写的东西。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mesmoiron   href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1ls8g9l/how_to_build_a_a_ai_ai_ai_ai_model_model_model_without_proper_dataset/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls8g9l/how_to_to_build_a_a_ai_ai_model_model_model_without_without_proper_proper_dataset/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls8g9l/how_to_build_a_new_ai_model_without_proper_dataset/</guid>
      <pubDate>Sat, 05 Jul 2025 12:11:12 GMT</pubDate>
    </item>
    <item>
      <title>克劳德·普罗（Claude Pro） - 仅几条消息后达到了极限？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls7wdh/claude_pro_limit_reached_after_just_a_few_messages/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， ，我订阅了几天前的Claude Pro计划，主要将其用于编程支持。 初始经验 我开始了一个新聊天，我开始了一个新的聊天，分配了Claude claude claude of Lead Software andect and Codeect and Code exighter和Code eviewer and Codeer和Codeer exciveer，并且它的工作很棒。响应详细且有用。 突然的限制 ，但是现在，似乎只有3-4条消息后，我已经达到了极限，必须等待5个小时才能再次使用它。 这是正常的吗？ 是不对的，可以吗？如果这实际上是应该工作的方式，那么我将立即取消，因为它不是这样的可用。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/peacerist_lead_7101     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls7wdh/claude_pro_pro_pro_limit_reached_after_just_just_a_a_a_few_few_messages/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls7wdh/claude_pro_limit_reached_after_just_a_few_messages/</guid>
      <pubDate>Sat, 05 Jul 2025 11:39:04 GMT</pubDate>
    </item>
    <item>
      <title>这些型号不是真实的……衣服也不是</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls6bfs/these_models_arent_real_and_neither_are_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://drive.google.com/file/d/1g02crmakabwzedmagyp4b3edt7ub7jpy/view?usp = drive_link   今天观看了此视频，不得不分享。这两种时尚模型都是100％AI生成的……没有人，没有相机，没有设计师。  感觉我们正在碰到创作过程将完全翻转的地步。  你们怎么看？有用，可怕或两者兼而有之？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/brave-fox-5019     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls6bfs/these_models_arent_real_and_neither_are_the/</guid>
      <pubDate>Sat, 05 Jul 2025 09:54:34 GMT</pubDate>
    </item>
    <item>
      <title>“大美丽的账单有一个大而丑陋的秘密</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls4gcu/the_big_beautiful_bill_has_a_big_ugly_secret/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;更完美的联盟&#39;的调查定义了该法案如何从字面上看我们的灵魂，而且任何人都无能为力。 （对科技公司敏感。他们不会欣赏它）  /u/u/kiki1701     [links]     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls4gcu/the_big_big_beautifer_bill_has_has_a_a_big_big_ugly_ugly_secret/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls4gcu/the_big_beautiful_bill_has_a_big_ugly_secret/</guid>
      <pubDate>Sat, 05 Jul 2025 07:43:04 GMT</pubDate>
    </item>
    <item>
      <title>帮助识别声音</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls43h9/help_to_identify_a_voice/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 有人可以告诉以下声音是人类还是ai？如果AI，哪一个？  即使是AI，也似乎是微调的，但至少我想知道他如何设法达到这样的微调水平。  我刚刚拿起音频并将其放入一个概念页面。    https://grey-humity-db7.notion.site/voice-human-or-ai-225e8ff2222222280878326ff37126c9ded    谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/logicalad5115     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls43h9/help_to_identify_a_voice/</guid>
      <pubDate>Sat, 05 Jul 2025 07:18:24 GMT</pubDate>
    </item>
    <item>
      <title>试图应付将来没有席位</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ls0gq0/trying_to_cope_with_not_having_a_place_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好。我最近被踢了一个存在的拉比孔，然后在这里徘徊。在写这篇文章之前，我搜索了类似的问题，但是它们都不是正确的。抱歉，如果这是浪费时间。我一直在努力奋斗AI，很长一段时间以来它可以做什么。我曾经对这项技术充满矛盾/有些兴奋，但是随着我学到的更多并受到更多的了解，我就越讨厌它，不信任和恐惧。 我很年轻，而且我是一个有抱负的作家。人们告诉我，我实际上处于一个良好的位置，可以比普通人更好地利用AI。听到这让我恶心。我已经被告知“适应或被抛在后面”。这么多次。从我坐着的地方，我将无法适应。那我该怎么办？一个人如何使自己在将来没有位置的事实感到满意？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/critikat     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ls0gq0/1ls0gq0/trying_to_cope_with_with_not_having_a_a_place_in_in_in_in_in_the/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ls0gq0/trying_to_cope_with_not_having_a_place_in_the/</guid>
      <pubDate>Sat, 05 Jul 2025 03:27:05 GMT</pubDate>
    </item>
    <item>
      <title>LLM可以拥有认知知识吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrzpda/can_llms_ever_have_epistemic_knowledge/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是当前体系结构的基本缺陷吗？ 这是在其DNA中吗？是否可以在未来的体系结构中开发认识论？   &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/u/health_peanut6753     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrzpda/can_llms_ever_have_epistemic_knowledge/</guid>
      <pubDate>Sat, 05 Jul 2025 02:41:08 GMT</pubDate>
    </item>
    <item>
      <title>浪漫的用例真的是一个有毒的话题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrw6ae/are_romantic_use_cases_really_such_a_toxic_topic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我试图创建一篇文章，说明是否有人试图通过使用c0mpanion单词来构建浪漫的聊天机器人，但有任何警告，但我们不允许任何帖子...绕过这个过滤器，将导致永久性禁令。  我感到惊讶。这个话题是如此加载和有毒吗？  mods，不要禁止我！我只是想对此用例进行元讨论。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/karakitap     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lrw6ae/are_romantic_cases_really_such_a_a_toxic_topic/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrw6ae/are_romantic_use_cases_really_such_a_toxic_topic/</guid>
      <pubDate>Fri, 04 Jul 2025 23:21:04 GMT</pubDate>
    </item>
    <item>
      <title>$ 20B搜索幻觉：AI如何在Apple设备上杀死Google</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lru3ip/the_20b_search_illusion_how_ai_might_kill_google/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您会注意到吗？ ，现在，Google每年支付apple 〜200亿美元，成为Safari中的默认搜索引擎。 不是因为用户要求它 - 而是因为默认= dimplault = todeault = note = note = primative =      re at re。 我们正在从“搜索和单击”移动到“询问并获取” Chatgpt，困惑，Apple Intelligence的即时答案。 否10个蓝色链接。没有SEO战争。只是从模型中直接从模型中的答案。只是搜索交易。  未来是AI优先，而不是Google-First。谁控制回答您问题的AI？ 控制知识，商业和文化的流程。 苹果拥有屏幕。唯一的问题是：他们什么时候决定不再需要Google？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lru3ip/the_20b_search_illusion_how_ai_might_kill_google/</guid>
      <pubDate>Fri, 04 Jul 2025 21:39:15 GMT</pubDate>
    </item>
    <item>
      <title>有任何书籍的建议以开始AI吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrpxie/any_book_recommendations_to_get_started_with_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是软件工程师。我已经构建了网络和应用程序多年了，现在我想开始学习AI。您建议您推荐任何好书吗？ 编辑：我想了解AI的工作方式，看看我是否可以朝这个方向移动我的职业。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lrpxie/any_book_recommendations_to_to_get_start_started_with_ai/&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrpxie/any_book_recommendations_to_get_started_with_ai/</guid>
      <pubDate>Fri, 04 Jul 2025 18:31:39 GMT</pubDate>
    </item>
    <item>
      <title>泄漏的元文档与AI聊天机器人有关，并且情况正在认真下一步。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lroyg1/leaked_docs_of_meta_related_to_ai_chatbot_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  内部元文档详细介绍“项目Omni”。  事实证明，他们可以在Instagram，Messenger和Whatsapp上构建和自定义的新型AI Studio聊天机器人现在可以先发送给您，并记住对话的详细信息。 •他们接受了听起来友好和主题的训练：例如“我希望您有一个和谐的一天！最近发现了任何新的最喜欢的配乐吗？” ￼。 •META将其定位为打击孤独感的一种方式，但显然，更多的参与度=更多的广告（他们预测2025年的生成AI收入为2-3亿美元）。 •Alignerr的人类承包商正在对机器人的后续行动进行评级和完善，以确保它们保持积极和适当的效果。 1。整洁的技术：令人印象深刻的AI，可以记住您的偏好并伸出手感觉是个性化的。 2。令人毛骨悚然的潜力：感觉像聊天机器人“好友”可以玩着情感依赖。用户参与和操纵之间的界线在哪里？ 3。隐私风险：存储聊天历史的机器人……他们保留多长时间？用户可以删除该内存吗？ 4。货币化光学：这显然也是要让您滚动（和广告流动）。    meta说，如果您不回复，他们会停止消息传递，但是仍然是，您首先会觉得自己的数字助手像湿滑的斜坡。 你们所有人怎么看？     •这是下一级级别的AI便利性AI便利性便利性或昏迷的数字挂钩吗？ •您会先让机器人ping吗？ •您想从控件退出，内存删除，透明度方面看到什么？    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lroyg1/leaked_docs_meta_meta_relelated_to_ai_ai_chatbot_and/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lroyg1/leaked_docs_of_meta_related_to_ai_chatbot_and/</guid>
      <pubDate>Fri, 04 Jul 2025 17:51:13 GMT</pubDate>
    </item>
    <item>
      <title>复杂性是k石</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrowp5/complexity_is_kryptonite/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   llm尚未证明自己在我的经验中过于复杂。对于需要高度判断，酌处权和辨别力的任务，它们仍然非常不可靠。他们最大的弊端可能是他们的幻觉通常是“真实的”。   i/我们创建了多个代理/自定义GPT，供我们的业务客户使用。我们对更简单的工作流有了一定的信任，但是到目前为止，我们无法信任模型来可靠地解决中等复杂的（及以后）问题。他们的结果必须始终由经常发现持续错误的合格人类进行审查。即，错误似乎没有任何提示似乎可以可靠地减轻。  我质疑在LLM框架下是否可以解决这些问题。似乎模型与他们的能力一起扩展了他们的问题。我想我们会看看炒作是否到达目的地。  是否有人注意到复杂性与可靠性之间的反关系？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/maninarena     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrowp5/complexity_is_kryptonite/</guid>
      <pubDate>Fri, 04 Jul 2025 17:49:14 GMT</pubDate>
    </item>
    <item>
      <title>使用光子为AI进行线性代数。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lrosrn/using_photons_to_do_linear_algebra_for_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  来自电子的热量是推进当前AI硬件的巨大阻滞剂。目前，几乎所有的AI数学 - 矩阵乘法，卷积，向量操作 - 都发生在硅芯片中。这些操作是通过通过CPU，GPU或ASIC中晶体管的电子来处理的。但是那些电子会产生热量。他们有潜伏期。他们消耗能力。而且，在遇到硬限制之前，您只能将这么多的芯片塞入芯片中。  光子计算范围的范例。它使用光子（光颗粒）代替电子来直接进行数学。  如何？  简而言之：通过光线通过微小的光学组件网络（调节器，波导，相移），以作为光线传播而执行数学转换。这些转换对应于线性代数操作AI模型的类型。 您对这种方法有何看法？您兴奋的选择是什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/iseethings404     [link]    [commist]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lrosrn/using_photons_to_do_linear_algebra_for_ai/</guid>
      <pubDate>Fri, 04 Jul 2025 17:44:40 GMT</pubDate>
    </item>
    <item>
      <title>光标ai只是地毯拉了所有人，现在检查您的帐单</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lroc9e/cursor_ai_just_rug_pulled_everyone_check_your/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  只是注意到了这一点，并想警告其他人： 光标更改了他们的“无限”用法模型，而无需任何通知。 如果您一直使用SONNET-4或其他高级模型，他们可能会开始向您收取清晰的费用，而不会向您收取清晰的费用。没有弹出窗口。没有什么。我只通过随机检查仪表板来抓住它。 如果您正在按付费计划或高级型号进行，请尽快检查您的使用情况。有些人的充电性超出了预期。 这感觉超级阴暗。至少，它们应该是透明的。 在其他人尚未注意到的情况下对此进行标记。不要措手不及。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lroc9e/cursor_ai_just_rug_pulled_everyone_check_your/</guid>
      <pubDate>Fri, 04 Jul 2025 17:25:33 GMT</pubDate>
    </item>
    <item>
      <title>AI代理只是炒作吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lredx9/are_ai_agents_just_hype/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   gartner说，在成千上万所谓的AI代理中，实际上只有〜130个是真实的，估计AI代理项目中有40％的AI代理项目将在2027年取消，因为高成本，Vague ROI和安全风险。  老实说，我同意。  每个人突然声称自己是AI专家，这正是技术泡沫的形成方式，就像股市一样。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lredx9/are_ai_agents_just_hype/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lredx9/are_ai_agents_just_hype/</guid>
      <pubDate>Fri, 04 Jul 2025 09:21:12 GMT</pubDate>
    </item>
    </channel>
</rss>