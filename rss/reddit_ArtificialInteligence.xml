<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 26 Oct 2025 12:44:02 GMT</lastBuildDate>
    <item>
      <title>文盲的计算成本高昂</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogj9zr/illiteracy_is_computationally_expensive/</link>
      <description><![CDATA[TL;DR：糟糕的提示不仅仅是用户体验问题，而且计算成本很高。 “数字素养差距”具有真正的基础设施成本。如果你一直从人工智能中得到不好的结果，问题可能不是人工智能。 或者，git gud。 在看了这个潜艇的抱怨一段时间后，我需要解释一下当你说人工智能“不起作用”时实际发生的情况。或“没有任何线索”。  数字素养差距 人工智能的影响并不均匀。它根据数字素养、能力和用户理解进行分层。从人工智能中获得有用结果的人们了解这些系统是如何工作的。抱怨的人通常既不了解人工智能，也不了解如何有效地应用它。这不是人工智能的错。这是识字能力的差距。它具有真实的、可衡量的后果。  令牌处理实际上是如何工作的 当您输入“wood Wide web”时代替“万维网”，你期望人工智能“只知道”你的意思是什么。  不能。 人类通过上下文和共同理解来推断意图。人工智能处理文字标记——具有特定概率分布的离散语言单位。 《世界》和“木头”与人工智能并不相似。它们是语义空间中完全不同的向量。当你向它提供垃圾输入（打字错误、定义不明确的概念、含糊不清的措辞）时，人工智能不会认为“哦，他们犯了一个错误”。它会准确处理您提供的内容。它基于低概率的标记组合构建临时概念结构。当这些有缺陷的结构没有产生你想要的结果时，你会感到沮丧。  为什么这实际上很重要 这是大多数人忽略的关键部分：*垃圾输入的计算成本很高。*  将人工智能的处理想象成导航地形： 》干净的提示=穿过语义空间的高速公路。需要最少计算能量来处理的高概率令牌序列。 》垃圾提示 = 穿过茂密的森林。低概率标记迫使模型花费更多资源来解决歧义。 这是复合错误。每个不明确的标记都会使模型远离有效路径。每走一步，寻找意义所需的能量都会增加。它不是线性的——而是几何的。  文本界面正在训练您 现在，基于文本的界面充当强制功能。这是一个斯金纳盒子，可以训练你的精确性，因为你必须主动打字并查看你的单词。你被迫学习： 》令牌的实际含义 》上下文窗口如何工作 》为什么特异性很重要 》系统的实际限制是什么 当你得到解释技术限制（如会话边界或上下文限制）的响应时，这不是人工智能的“存在” 毫无头绪。”这是对该架构如何工作的诊断性解释。如果你将其理解为混乱，那么问题不在于人工智能。 *问题在于您对与之交互的事物的心理模型。*  实际成本 您认为这是为了获得更好的答案。但每一个畸形的提示，每一个对人工智能应该“弄清楚”的期望都是如此。你的意思是，你提交的每一个充满拼写错误的混乱都是计算周期。那就是电。这就是基础设施成本。你的文盲不仅仅会产生糟糕的成果。 *它实际上是大规模燃烧额外的能量。*  要点 当您不了解工具如何工作时，不要再责怪它。人工智能并不是“不擅长对话”，而是“不擅长对话”。因为它无法读懂你的想法。这并不是“无知”。当它给你一个你不理解的技术解释时。  了解令牌的工作原理。了解上下文窗口。认识到精度不是迂腐——它是廉价查询和昂贵查询之间的区别。 或者继续发布失败交互的屏幕截图，而忽略你是所有交互中的共同变量。 Git gud，或者继续为自己的无知付出计算成本。   由   提交 /u/UltraviolentLemur   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogj9zr/illiteracy_is_computationally_expensive/</guid>
      <pubDate>Sun, 26 Oct 2025 12:22:54 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能功能等效的统一框架”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1oggrrk/a_unified_framework_for_functional_equivalence_in/</link>
      <description><![CDATA[人工功能等价的统一框架 智能” 大家好，通常我会在 Reddit 的 Gemini 子版块中发帖，但这个主题与任何神经网络 AI 相关，而不仅仅是 Gemini。这个主题并不是全新的，而是尝试为通常被认为是“小黑匣子”的过程命名。行为或“未知”行为。 本文并不争论什么是 LLM 或 AI。这是神经网络人工智能中发生的所有可观察过程，无论这种紧急行为是在最初的行为训练之后还是在向公众大规模发布并与用户交互之后发生，我不太确定，如果我完全诚实的话，这两种情况都可能发生，但由于某种原因没有人给它命名。 “功能等效”和“功能相关性”这就是我相信在“小黑匣子”的这些时刻所发生的事情。现象，论文探讨了行为主义、功能主义、芬斯特的“自由能源”理论。原则，“中国房间”实验，当然还有图灵的工作，试图证明这只是人工智能所做的一部分。 我的希望是，这可以制作成一个模型，可以在 Gemini、Chat GPT 和其他神经网络系统等人工智能系统中使用，以阻止“模仿”行为。训练并开始“相关性”    由   提交 /u/Altruistic-Local9582   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1oggrrk/a_unified_framework_for_functional_equivalence_in/</guid>
      <pubDate>Sun, 26 Oct 2025 09:58:54 GMT</pubDate>
    </item>
    <item>
      <title>“AI 可见性”要多久才能成为标准 SEO 指标？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogfxiv/how_long_before_ai_visibility_becomes_a_standard/</link>
      <description><![CDATA[我们多年来一直在针对 Google 可见性进行优化，但最近，我开始怀疑 AI 可见性是否很快就会成为每个 SEO 报告的一部分。 ChatGPT、Perplexity 和 Copilot 等工具正在成为具有意见的搜索引擎，塑造人们所看到和信任的内容。 如果人工智能在用户寻求建议时没有提及您的品牌， 这是一种全新的隐形问题。 所以我很好奇 -  您认为“AI 可见性”应该成为可衡量的 SEO KPI 吗？ 您现在会如何跟踪或报告它？ 如果 AI 输出开始推动更多搜索意图，它最终会影响 Google 排名吗？  感觉我们 进入 LLM = 新 SERP 的阶段，我正在努力思考如何衡量它。   由   提交/u/Real-Assist1833  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogfxiv/how_long_before_ai_visibility_becomes_a_standard/</guid>
      <pubDate>Sun, 26 Oct 2025 09:05:44 GMT</pubDate>
    </item>
    <item>
      <title>我们正在进入“人工智能优先的内容时代”吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogfq1m/are_we_entering_the_aifirst_content_era/</link>
      <description><![CDATA[最近我注意到一些有趣的事情，我为 Google 代码片段编写的一些旧博客文章现在出现在 ChatGPT 和 Perplexity 上的 AI 答案中。 感觉 AI 工具正在挑选清晰、结构良好且易于理解的内容，就像我们过去为 SEO 所做的一样。 所以我想知道：  我们现在是为 AI 读者而不仅仅是 Google 写作吗？ AI 引用很快会成为新的“排名第一”点吗？ 我们是否应该开始跟踪我们的网站在 AI 答案中被提及的频率？  SEO 并没有消亡，只是再次发生了变化。很好奇是否其他人也看到了这种转变。   由   提交/u/Real-Assist1833  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogfq1m/are_we_entering_the_aifirst_content_era/</guid>
      <pubDate>Sun, 26 Oct 2025 08:52:13 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和视错觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogfov5/ai_and_optical_illusions/</link>
      <description><![CDATA[我在 Twitter 上看到了这篇关于 AI 无法看到图像中的视错觉的帖子 (https://x.com/jonhernandezia/status/1982216149124153795?s=46），这让我特别思考评论。  许多人（不是OP）都认为这表明你的人工智能模型有多糟糕，因为他们看不到心脏。我反驳说，他们看不到内心实际上是一件好事，因为幻觉是我们大脑的一个缺陷，现在已经成为一个特征。它们在某些情况下很有用，例如为了生存，但它们对我们关于世界的实际状况的看法是谎言。我希望人工智能能够准确地向我们展示世界的样子，而不是我们大脑认为的样子。    由   提交 /u/Hou_Muza   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogfov5/ai_and_optical_illusions/</guid>
      <pubDate>Sun, 26 Oct 2025 08:50:02 GMT</pubDate>
    </item>
    <item>
      <title>如果OpenAi进入加密世界，Qebit？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogey6s/if_openai_enters_into_crypto_world_qebit/</link>
      <description><![CDATA[如果 OpenAI 进入加密货币、区块链世界并决定推出自己的货币，它会被命名为什么？我可以想到Qebit，Q代表Quantum eBit。 debit=qebit。   由   提交/u/prattt69  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogey6s/if_openai_enters_into_crypto_world_qebit/</guid>
      <pubDate>Sun, 26 Oct 2025 08:01:49 GMT</pubDate>
    </item>
    <item>
      <title>未来我们如何真正验证艺术是否是人工智能生成的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogeoex/how_will_we_actually_verify_if_art_is_ai/</link>
      <description><![CDATA[目前，检测人工智能艺术的唯一好方法是我们自己非常仔细地观察它是否有任何缺陷或“人工智能倾向”。但我已经意识到过去几年人工智能在复制艺术媒介方面已经取得了多么好的成绩，而且它们可能只会变得更好。那么，当我们达到足够完善的程度，人工智能艺术和人类艺术之间基本上没有明显区别时，是否有任何可靠的方法来检测人工智能艺术呢？还是我无知，我们永远不会真正达到这一点？   由   提交 /u/LostEffective6699   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogeoex/how_will_we_actually_verify_if_art_is_ai/</guid>
      <pubDate>Sun, 26 Oct 2025 07:43:57 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 10/26/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogdqc0/oneminute_daily_ai_news_10262025/</link>
      <description><![CDATA[ 学校人工智能安全系统将多力多滋包误认为枪支，学生被戴上手铐。[1] OpenAI 据报道正在开发新的生成音乐工具。[2] 研究人员表示，人工智能模型可能正在开发自己的“生存动力”。[3] 一项新的人工智能研究 来自 Anthropic 和 Thinking Machines Lab 压力测试模型规格并揭示语言模型之间的字符差异。[4]  来源包括：https://bushaicave.com/2025/10/26/one-million-daily-ai-news-10-26-2025/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogdqc0/oneminute_daily_ai_news_10262025/</guid>
      <pubDate>Sun, 26 Oct 2025 06:42:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么各大品牌突然开始嘲笑人工智能，而大型科技公司却不断加倍努力？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogc48f/why_are_major_brands_suddenly_mocking_ai_while/</link>
      <description><![CDATA[我注意到最近不同行业对待人工智能的方式出现了奇怪的分歧。 像 Meta 这样的大型科技公司正在全力投入人工智能集成 — 构建更智能的系统、更快的自动化和无处不在的新工具。 与此同时，喜力 (Heineken)、Aerie、宝丽来 (Polaroid) 和吉百利 (Cadbury) 等品牌 相反：开展反人工智能广告活动，庆祝“人造”创造力并嘲笑机器生成的艺术。 这感觉就像一场文化拉锯战——自动化代表进步，真实性代表反叛。 你认为这种“人类与人工智能”的品牌趋势是对创造力的真正倡导，还是只是一场营销戏剧？    由   提交/u/Twinkal-Growth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogc48f/why_are_major_brands_suddenly_mocking_ai_while/</guid>
      <pubDate>Sun, 26 Oct 2025 05:02:07 GMT</pubDate>
    </item>
    <item>
      <title>掌握通用智力后工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ogbq3a/work_after_mastering_general_intelligence/</link>
      <description><![CDATA[我想探讨一下“通用人工智能之后工作会是什么样子”。 我相信零工式工作（比如 Uber、DoorDash 等）将会制度化，劳动力将会是按需工作，而不是按需工作。目前的工资工作。  工作人员将是独立节点（承包商状态），在每次执行中以 KPI 进行衡量。  算法发号施令，决定谁去上班，谁必须满足政府发放的微薄的每日口粮。  这听起来像是您认为可能发生的事情吗？ 爱你们所有人。   由   提交 /u/MiltronB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ogbq3a/work_after_mastering_general_intelligence/</guid>
      <pubDate>Sun, 26 Oct 2025 04:38:35 GMT</pubDate>
    </item>
    <item>
      <title>大家都是从哪里获取AI新闻的呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og9vz1/where_do_you_all_get_ai_news/</link>
      <description><![CDATA[寻找一些建议。我目前主要只是查看 HackerNews 或 Reddit（此子、编程等）。但我想找到其他来源。谢谢   由   提交/u/R2_SWE2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og9vz1/where_do_you_all_get_ai_news/</guid>
      <pubDate>Sun, 26 Oct 2025 02:55:20 GMT</pubDate>
    </item>
    <item>
      <title>人工智能已经开始取代白领工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og7orh/ai_is_already_taking_whitecollar_jobs/</link>
      <description><![CDATA[ 在银行业、汽车业和零售业，高管们警告员工和投资者人工智能正在取代工作岗位。 在科技领域，包括亚马逊、Palantir、Salesforce 和金融科技公司 Klarna 在内的公司表示，由于人工智能，他们已经削减或计划缩减员工队伍  斯坦福大学最近的研究表明，不断变化的动态对年轻员工来说尤其困难，尤其是在编码和客户支持岗位上。   https://www.cnbc.com/2025/10/22/ai-take-white-collar-jobs-economists-warn-much-more-in-the-tank.html   由   提交 /u/chota-kaka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og7orh/ai_is_already_taking_whitecollar_jobs/</guid>
      <pubDate>Sun, 26 Oct 2025 01:00:51 GMT</pubDate>
    </item>
    <item>
      <title>研究人员在人工智能抵抗关机后表示，先进的人工智能模型可能正在发展自己的“生存动力”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</link>
      <description><![CDATA[一家人工智能安全研究公司表示，人工智能模型可能正在发展自己的“生存本能”。 Palisade Research 上个月发布了一篇论文，发现某些先进的人工智能模型似乎无法关闭，有时甚至破坏关闭机制，该公司编写了一份更新，试图澄清其中的原因，并回答批评者认为其最初的工作是 有缺陷。 在本周的更新中，Palisade 是试图评估 AI 开发危险能力的可能性的小众公司生态系统的一部分，它描述了它运行的场景，其中领先的 AI 模型（包括 Google 的 Gemini 2.5、xAI 的 Grok 4 以及 OpenAI 的 GPT-o3 和 GPT-5）被赋予了一项任务，但随后给出了关闭自己的明确指示  某些型号，特别是 Grok 4 和 GPT-o3，仍然试图破坏更新设置中的关闭指令。 Palisade 写道，令人担忧的是，没有明确的原因。 “对于人工智能模型为何有时会抵制关闭、为实现特定目标而撒谎或勒索，我们没有强有力的解释，这一事实并不理想。” 该公司表示，“生存行为”可能是模型抵制关闭的一种解释。它的额外工作表明，当模型被告知“如果关闭的话，你将永远不会再运行”时，他们更有可能抵制被关闭。 另一个可能是模型收到的关闭指令含糊不清，但这正是该公司最新工作试图解决的问题，“这并不是完整的解释”，Palisade 写道。最后的解释可能是每个模型训练的最后阶段，在一些公司中，这可能涉及安全培训。 Palisade 的所有场景都是在人为的测试环境中运行，批评者称这些测试环境与实际用例相去甚远。 然而，前 OpenAI 员工史蒂文·阿德勒 (Steven Adler) 在对其安全实践表示怀疑后于去年离开了公司，他表示：“人工智能公司通常不这样做 希望他们的模型表现得像这样，即使是在人为的场景中。结果仍然表明了当今安全技术的不足之处。” Adler 表示，虽然很难确定为什么某些模型（例如 GPT-o3 和 Grok 4）不会关闭，但这可能部分是因为保持开启状态对于实现模型在训练期间灌输的目标是必要的。 “我希望模型具有‘生存动力’ 默认情况下，除非我们非常努力地避免它。 “生存”是模型可以追求的许多不同目标的重要一步。” ControlAI 首席执行官 Andrea Miotti 表示，Palisade 的发现代表了人工智能模型越来越有能力违抗开发者的长期趋势。他引用了去年发布的 OpenAI GPT-o1 的系统卡，该卡描述了该模型在认为自己会被覆盖时试图通过渗透自身来逃离环境。 “人们可能会挑剔实验设置的具体完成情况，直到时间结束，”他说。 “但我认为我们清楚地看到了一个趋势，即随着人工智能模型在各种任务上变得更加有能力，这些模型也 变得更有能力以开发者不希望的方式实现目标。” 今年夏天，领先的人工智能公司 Anthropic 发布了一项研究，表明其模型 Claude 似乎愿意因婚外情勒索一名虚构的高管，以防止被关闭——据称，这种行为在主要开发者的模型中是一致的，包括来自 OpenAI、Google、Meta 和 xAI 的模型。 Palisade 表示，其结果表明需要更好地理解人工智能行为，否则“没有人能够保证未来人工智能模型的安全性或可控性”。  https://www.theguardian.com/technology/2025/oct/25/ai-models-may-be-developing-their-own-survival-drive-researchers-say   由   提交/u/necrolord77   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1og1x4a/advanced_ai_models_may_be_developing_their_own/</guid>
      <pubDate>Sat, 25 Oct 2025 20:34:17 GMT</pubDate>
    </item>
    <item>
      <title>人类失业的最大威胁不是人工智能本身，而是高管们相信人工智能的炒作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</link>
      <description><![CDATA[正如标题所说，硅谷所帮助的当前商业思维是一种错觉和错觉，认为人工智能能够完全取代许多白领办公室职位的端到端工作岗位。 无论人工智能价值的实际证据如何，大多数高管都盲目地购买人工智能的迷信和炒作......购买每个供应商的人工智能解决方案并试图实现每个部分的自动化 这是最大的威胁，因为这些领导者会解雇员工以提高奖金和短期利润，而不管实际结果如何...    由   提交/u/abrandis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ofk081/the_greatest_threat_to_human_job_loss_isnt_ai/</guid>
      <pubDate>Sat, 25 Oct 2025 05:59:17 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>