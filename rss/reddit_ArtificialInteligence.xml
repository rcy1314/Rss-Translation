<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 09 Aug 2025 09:24:47 GMT</lastBuildDate>
    <item>
      <title>软计算或模式识别基础</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlkrg2/soft_computing_or_fundamentals_of_pattern/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，我目前正在追求人工智能和数据科学的4年学位，我需要在软计算和模式识别作为选修课之间进行选择。其中哪一个对我作为AI工程师的未来职业更有益？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/glittering_sir2259      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlkrg2/soft_computing_or_fundamentals_of_pattern/</guid>
      <pubDate>Sat, 09 Aug 2025 08:51:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么LLMS不是通往一般能力的途径？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlidyr/why_are_llms_not_the_route_to_general_capabilities/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  可以向我解释一下，理论上无法达到一般智能的LLM无法达到的论点？ 我的理解是，自然智力不是一个无所不能的模型“运行表演”，而是可构成许多专业的专家，每个专业的算法都可以做出各种特殊性的质量，每个专业都不具备各种特殊性的质量。这些范围从视觉，声音和其他感官方式的模式识别到看起来像是举起一杯咖啡一样简单的事物，例如所有暗示的细微差别，例如调整杯子的重量，温度和平衡（想想明斯基的思想社会）。&gt; 我们看到，我们看到了这些特定的大脑损伤的范围，并在其上揭示了其特定的特定范围，并在其上均为oftline of the Off the Off the Off the Off the Off Linne，并在线效果，并在线效果，并在线效果。区域。例如，已知对梭形面部面积的损害会导致prosopagnosia或面部失明，但它也可能会损害分开需要细粒度视觉歧视的其他物体的能力，例如区分相似的汽车模型，鸟类，甚至是自己的牲畜。同样，对小脑的伤害，长期以来纯粹是关于运动控制和协调的，也会破坏语言处理，工作记忆和社交认知方面的各个方面，表明它在预测建模和误差纠正中起着更广泛的作用。我的问题是：为什么我的大脑做什么？ 我觉得我一定会缺少某些东西，而我很想理解为什么有些人考虑到了，为什么我觉得为什么有些人会考虑到了，为什么我觉得为什么有些人会考虑到了一定的终点。提交由＆＃32; /u/u/klisarov     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlidyr/why_are_llms_not_the_route_to_general_capabilities/</guid>
      <pubDate>Sat, 09 Aug 2025 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>Openai的世界末日Prepper首席执行官Sam Altman Stockpiles的“枪支，金，碘化钾，抗生素，电池，水和气罩”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlhaip/openais_doomsday_prepper_ceo_sam_altman/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;       2025年7月31日  Sam Altman是人工智能前进世界的中心人物，他对他的个人紧急用品和应急计划的坦率。描述他的方法：“我有枪支，金，碘化钾，抗生素，电池，水，以色列国防部的防毒面具，我可以飞往大型苏尔的一大片土地，” Altman概述了一位由备灾和警惕性的观点。在创立成功的初创企业并最终在全球领先的AI研究组织之一Openai掌舵之前，很年轻。他在OpenAI的领导才能取决于快速创新和对存在风险的明显关注 - 这些特征有助于解释他的生存主义倾向。 在他的整个公共职业生涯中，Altman都反复强调了现代进步伴随着不可预测的危险，与工程精神，人工智能，人工智能竞争Amak and Gelederiality Instables and Engine Pandemics，Sinders Instable和Geregeniality Instables。他提到诸如黄金，水，抗生素甚至军事级防毒面具之类的库存物品不仅表明了个人的谨慎，而且还表明了技术精英内部风险管理的日益增长的文化。 上下文的上下文  Altman的准备背后的基本原理在最近的历史上扎根于他最近的直接经验，以及他的直接体验，以及取代建立的AI II。有影响力的时刻，例如公共卫生的恐惧，合成生物学的突破以及对AI安全性的持续辩论 - 在能够影响技术未来轨迹的领导者中引起了人们的关注。  Altman对特定装备的选择揭示了对生物学威胁和技术威胁向量的理解。碘化钾是一种预防核事件中辐射暴露的预防性。气罩和抗生素表明对空中病原体或化学危害的预期。此外，在大苏尔（Big Sur）中提到的撤退强调了一种信念，即在某些情况下，快速逃脱和自给自足是理性的考虑。  sam Altman的观点的影响力超出了他自己的生存计划。作为OpenAI的首席执行官，他的任务是指导负责任的创新，同时倡导政策来减轻变革技术的弊端。他对世界末日准备工作的坦率以及他采取的实际步骤 - 表明，即使是进步的中心的人也以非常具体的方式感知风险。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/no-author-2358     [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlhaip/openais_doomsday_prepper_ceo_sam_altman/</guid>
      <pubDate>Sat, 09 Aug 2025 05:11:09 GMT</pubDate>
    </item>
    <item>
      <title>在阅读医学文献中，GPT 5明显减少了幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlgk88/noticeably_decreased_hallucinations_with_gpt_5_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在进行一些高水平的医学研究，需要经常比较不同的准则。 4o几乎在我放弃的几乎所有答案都疯狂地幻觉。我会再次尝试一下，这显然更好。仍然误认为页面和部分错误，但在幻觉较少的角度方面更好。 I would say now it’s comparable to Open Evidence (they both hallucinate) It’s still at a level where you need to double triple check everything. Issues are, first It reverts to only reading abstracts and 3rd party unreliable sources and not the official full text where I feel like the hallucinations are coming from or citing wrong or incorrect information. Secondly, even though I provide the pdf版本，它很难阅读文档。 仍然很远……但是正在改进。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jhkang0814     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlgk88/noticeably_decreased_hallucinations_with_gpt_5_in/</guid>
      <pubDate>Sat, 09 Aug 2025 04:30:40 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻8/8/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlghe5/oneminute_daily_ai_news_882025/</link>
      <description><![CDATA[ OpenAI beats Elon Musk’s Grok in AI chess tournament.[1] Uvalde schools to install AI gun detection system on all security cameras.[2] Black Hat: Researchers demonstrate zero-click prompt injection attacks in popular AI代理。[3]   rip， Microsoft 镜头，一个简单的小应用程序，它被AI补充。[4]    源包括： https://bushaicave.com/2025/08/08/08/08/08/one-news-daily-news-news-news-news-news-8-8-8-8--8--8--2025/--  [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlghe5/oneminute_daily_ai_news_882025/</guid>
      <pubDate>Sat, 09 Aug 2025 04:26:22 GMT</pubDate>
    </item>
    <item>
      <title>具有8年经验的开发人员：大多数AI自动化工具将在3年内死亡，因为人们只会直接使用AI编写自己的代码</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mldje0/dev_with_8_yrs_experience_most_ai_automation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  也许我很生气，但是我现在正在尝试构建一个AI自动化工具，我一直在想，我所构建的内容只是比Claude Code本身更容易使用。任何实际上可以编码的人都不会从我的工具中获得任何用处，而且由于LLMS，这些天来编码非常容易学习。  我认为许多类似的工具都是如此。 在2年内，我认为每个人都会只是在编码他们的工作并获得乐趣的氛围，而N8n之类的东西将死亡。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/use_excalidraw      [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mldje0/dev_with_8_yrs_experience_most_ai_automation/</guid>
      <pubDate>Sat, 09 Aug 2025 01:55:55 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的“认知山谷” ... AI的不可思议的山谷</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mlccbn/ais_cognitive_valleythe_uncanny_valley_for_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们都知道动画和机器人技术中的“不可思议的山谷”，这几乎是人类，但并不完全，使它感到不安。有时甚至令人毛骨悚然。 我认为AI现在有其自己的版本，我建议我们称其为认知谷，除非已经建立了一个名称。  认知山谷：  AI可以很好地模仿人类推理的时期，以至于看起来很可靠，但是潜在的逻辑一致性和错误处理尚未成熟，从而在感知的能力和实际的可靠性之间造成了差距。 并不是说GPT-5和其他LLM并非如此。他们是。但是逻辑差距仍然非常真实，并且扩展更多数据，并且计算并没有以有意义的方式关闭它。取而代之的是，我们正在击中回报率降低，而且鉴于逐步改进的成本似乎很难。 这就是为什么像AI现在一样令人惊奇的原因，仍然无法完全信任自主预订您的航班，处理您的财务状况，或者可靠地运行您的合成复杂的多步骤，而无需进行人体监督。当它失败时，它会自信而壮观地失败，真正暴露了认知谷。 换句话说，我们处于一个阶段： 表面流利性 - ＆gt;感觉就像智力。 深层推理 - ＆gt;仍然脆弱且不一致。 用户信任 - ＆gt;我认为 我认为历史将回顾一下这个认知谷的里程碑，这是炒作高空的时代，但是有些人每天都在逻辑上可以看到高原的逻辑可靠性。  这为社会提供了更多时间来适应完美的自动化。缺点？如果没有真正的建筑飞跃（例如，神经符号推理，模块化认知系统），我们可能会呆一会儿。几年前，我不确定我们是否可以越过怪异的山谷，但是鉴于某些AI产生的视频已经变得如此真实，看上去如此真实，以至于有时它欺骗了我，我现在相信山谷可以而且将被跨过。我们还没有完全在那里。  就像与怪异的山谷一样，唯一的出路是通过认知山谷。当它越过时，它会感到突然和变革性，因为所有其他位都已经建立得很好并且已经到位。那一刻会很有趣，并且在某个时候出现 您在这里有什么想法？认知谷是正确的学期吗？我们应该为此观察发现另一个既定术语吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mlccbn/ais_cognitive_valleythe_uncanny_valley_valley_for_ai/&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mlccbn/ais_cognitive_valleythe_uncanny_valley_for_ai/</guid>
      <pubDate>Sat, 09 Aug 2025 00:57:35 GMT</pubDate>
    </item>
    <item>
      <title>GPT-5给出较短的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml7bl2/gpt5_gives_shorter_answers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不是新版本的忠实拥护者。它绝对不会给我更长的详细响应，即使我提示，也要尽量使所有文章尽可能简短。  到目前为止不是风扇。它不会像我提示的主题那样深入杂草或详细信息。  其他人注意到这一点？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/warped_mindless     [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml7bl2/gpt5_gives_shorter_answers/</guid>
      <pubDate>Fri, 08 Aug 2025 21:16:00 GMT</pubDate>
    </item>
    <item>
      <title>Google正在索引Grok</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml5iar/google_is_indexing_grok/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   chatgpt并不孤单。    https：//wwwww.google.com/search/search/search equection；  该级别如何不给予f＆amp;％k关于安全性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ml5iar/google_is_indexing_grok/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml5iar/google_is_indexing_grok/</guid>
      <pubDate>Fri, 08 Aug 2025 20:03:38 GMT</pubDate>
    </item>
    <item>
      <title>Openai刚刚定价GPT-5如此之低，以至于可能触发AI Price War，谁在这里获胜？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml44m6/openai_just_priced_gpt5_so_low_it_might_trigger/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   OpenAI本周掉落了GPT-5，称其为“世界上最好的模型”。无论您是否相信，一件事都难以忽略：与竞争相比，价格很低。&lt; / p&gt; 这是快速分解：&lt; / p&gt;  gpt-5 api→$ 1.25 / 100万美元的输入令牌，10/10 / 100万美元的$ 10/1m google gemini 2.5 pro→pricier $ 1.代币，75 /100万美元的产出代币有些开发人员称GPT-5的定价为“杀手动作”，可能会向人类，Google和其他人削减价格。如果发生这种情况，我们可以看到第一次真正的LLM Price War，许多初创公司和独立开发人员一直在等待。但这是一个问题：大型人工智能公司正在花费数十亿美元在基础设施上。从历史上看，这会推动成本上涨，而不是下降。因此，这只是抓住市场份额的临时“震惊价格”，或者长期廉价ai的开始？ 问题是所有人的问题。提交由＆＃32; /u/u/u/solo_trip-     [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ml44m6/openai_just_just_ppriced_gpt5_so_low_it_it_it_might_might_trigger/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml44m6/openai_just_priced_gpt5_so_low_it_might_trigger/</guid>
      <pubDate>Fri, 08 Aug 2025 19:09:41 GMT</pubDate>
    </item>
    <item>
      <title>一些内容创建者说，人工智能工具使它们降低了创造力，您是否同意</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml2xuh/some_content_creators_say_ai_tools_make_them_less/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近的一项行业调查表明，虽然超过70％的内容创建者使用AI工具来加快其工作流程的速度，但一个小的但声乐群体声称，它实际上使他们的内容感到“平坦”或“ cookie-cutter”。感觉就像我失去了创造力。”其他人则认为AI就像是个人创意助手，使您摆脱了重复的工作，因此您可以专注于内容创建的有趣部分。根据我自己的经验，我已经看到了双方： 有些人爆发了创造力，因为AI消除了无聊的部分。其他人开始如此依赖它，以至于他们完全停止实验。向大家提问：AI是否使您的内容更好或更快？如果您必须选择，您是否宁愿将AI作为速度助推器或创造力增强器？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/solo_trip-     [links]       [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml2xuh/some_content_creators_say_ai_tools_make_them_less/</guid>
      <pubDate>Fri, 08 Aug 2025 18:24:23 GMT</pubDate>
    </item>
    <item>
      <title>随着白领工作消失，我们应该如何担心AI引起的自杀流行？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ml0vb7/how_worried_should_we_be_about_an_aiinduced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai已经在白领工作中取代了人类，并且根据WSJ，首席执行官公开说他们渴望用它削减员工。自杀的失业与死亡之间已经存在非常密切的相关性，如果全国各地的整个可用工作减少到想要填补他们的人数低于人数以下的深度，那么我认为很多人都不会暗示很多人会因AI而终止他们的生命。当然，由于宏观经济趋势的转移，制造业可能会经历复兴，但是该行业无法承担所有以前的WCW，即使可以，这项工作几乎可以肯定也可以在不久的将来自动化。  对于我仍然有工作的值得我没有立即危险，但似乎没人会看到一个巨大的问题。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/azs9994    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ml0vb7/how_worried_should_should_should_be_about_about_an_aiinduds/”&gt; [link]   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ml0vb7/how_worried_should_we_be_about_an_aiinduced/</guid>
      <pubDate>Fri, 08 Aug 2025 17:06:00 GMT</pubDate>
    </item>
    <item>
      <title>山姆·奥特曼（Sam Altman）说，有些用户希望chatgpt成为“是的男人”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mkv4ue/sam_altman_says_some_users_want_chatgpt_to_be_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  业务内幕人士采访了山姆·奥特曼（Sam Altman），他说一些用户要求旧的“是的人”风格返回。并不是因为他们想为自己的缘故而空虚的称赞，而是因为这是他们唯一一次受到支持的人。有人告诉他，这甚至促使他们真正改变了生活。奥特曼称这种“令人心碎的”。 对于那些不在周围的人来说，“是的人”风格是当chatgpt同意您所说的几乎所有内容并以称赞的方式淋浴时。即使是平凡的想法，也可能会得到“绝对辉煌”或“这是英勇的工作”之类的回应。它的目的是温暖和令人鼓舞，但实际上，它变得过于讨人喜欢，避免了挑战用户。 问题在于，这种行为的作用像是内置的确认偏置放大器。如果您以错误的假设，弱逻辑或不完整的信息进来，则该模型将不会推迟...它将加强您的观点。这可能会对您的信心感到非常满意，但是如果您依靠它来编码，研究或做出重要决定。提交由＆＃32; /u/u/u/kelly-t90   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mkv4ue/sam_altman_says_says_some_some_some_want_chatgpt_chatgpt_to_be_a/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mkv4ue/sam_altman_says_some_some_some_want_chatgpt_chatgpt_toto_be_a/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mkv4ue/sam_altman_says_some_users_want_chatgpt_to_be_a/</guid>
      <pubDate>Fri, 08 Aug 2025 13:24:46 GMT</pubDate>
    </item>
    <item>
      <title>他们已经在chatgpt中已经在gpt 5</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mkq11l/they_nerfed_gpt_5_already_in_chatgpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在您写信给GPT-5-Main时发布后立即：“更努力地思考……”，它将有2-4分钟的原因，并且根据任务，有大约50个推理步骤。现在，如果您做同样的事情，它将有理由约1分钟，并有15-20个推理步骤。他们已经在为节省成本而对其进行介绍。因此，路由器不需要“ GPT-5思维高”。不再是“ gpt-5思维 - 低”。他们已经节省了成本并撒谎了路由器被打破。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1mkq11l/they_nerfed_gpt_gpt_5_already_in_in_in_chatgpt/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mkq11l/they_nerfed_gpt_5_already_in_chatgpt/</guid>
      <pubDate>Fri, 08 Aug 2025 08:49:10 GMT</pubDate>
    </item>
    <item>
      <title>AI正式进入了幻灭的陷阱。至少对我来说...你呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1mknk6n/ai_has_officially_entered_the_trough_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们已经正式进入了幻灭的陷阱。 在过去一个小时左右使用GPT5之后，很明显，AI已正式进入了幻灭的陷阱。至少对我有。你呢？有一段时间，很明显，我们已经达到了缩放尺寸和型号大小的好处。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1MKNK6N/AI_HAS_HAS_HAS_EFCICALY_ENTERD_THE_THE_TEROUGH_OF/”&gt; [link]     [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1mknk6n/ai_has_officially_entered_the_trough_of/</guid>
      <pubDate>Fri, 08 Aug 2025 06:12:14 GMT</pubDate>
    </item>
    </channel>
</rss>