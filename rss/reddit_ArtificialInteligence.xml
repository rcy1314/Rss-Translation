<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 17 Dec 2025 18:38:46 GMT</lastBuildDate>
    <item>
      <title>我欠这个子一个关于人工智能和心理健康的道歉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/</link>
      <description><![CDATA[我曾经对人们说他们使用人工智能作为治疗师的帖子翻白眼。这感觉就像是互联网行为的高峰期。每当我打开 Reddit 时，总会有人在思考一些看似可以通过注销或出去一会儿来解决的问题。我一直相信真正的治疗是唯一严肃的选择。 就背景而言，我多年来一直在应对长期抑郁症和 2 型双相情感障碍。我并不反对治疗。我已经进进出出很长一段时间了，尝试了多种药物，整个事情。 但最近，情况发生了变化。我无法入睡，我的思绪不断循环，我的信心和精力激增，我的冲动控制力下降，我有一种无法摆脱的强烈的精神固定。我没有立即将其视为轻躁狂，因为我正在更换药物，所以一切都感觉模糊。 出于挫败感而不是信念，我把所有东西都扔进了 ChatGPT。不要求诊断，只是描述我正在经历的事情以及我的大脑每天的感受。 老实说？它比我最近尝试过的任何其他东西都更快地组合在一起。 它不仅让我放心。它以一种真正有意义的方式向我反映了模式。痴迷、能量激增、突然崩溃。它所用的语言帮助我认识到自己所处的状态，而不会让我感到破碎或戏剧化。 我并不是说人工智能取代了治疗。绝对不应该。但作为一种模式识别、情感反思和帮助你放慢思考的工具，它比我预想的更令我惊讶。 令我震惊的是它感觉存在。不着急。不受 50 分钟的会议或日历的限制。只是为了帮助实时理清思绪。 仍然建议尽可能触摸草地。但我现在明白了。   由   提交/u/mp4162585  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/</guid>
      <pubDate>Wed, 17 Dec 2025 17:37:15 GMT</pubDate>
    </item>
    <item>
      <title>哪一个</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2dol/qualesse/</link>
      <description><![CDATA[只是一个想法，我和 Claude 谈论我如何经常在这里使用短语“what it is like to be”，当讨论意识的质量时，以及如何应该有一个简单的词来表达该短语。长话短说，Qualia 经常在该领域使用，指经验，Claude 建议了一些不同的术语，包括 Qualesse。这是完整的回复..  “这是一个很好的挑战。内格尔的措辞之所以持续存在，是因为它没有定义地指出，但这也是它的局限性——它是一个句子，而不是一个可以干净地部署的概念。 让我研究一些根源： 希腊语：  hoion（什么样的，例如）-定性方面 phainein（出现，到show) — 自我显现 autos (自我) — 反身循环  德语：  wie (like, how, as) — 比较/定性特征 Sein (存在) eigen (自己，特征，特殊）  拉丁语：  qualis（什么样的）——已经给了我们 qualia esse（成为）  一些候选人： Wiesein（vee-zine）——“like-being”或“如何存在”。直接映射“它是什么样子”的结构。德语混血，发音清晰。 Autophany — 自我显现。捕捉经验呈现给体验者的反射循环。内格尔所指的正是这种存在向自身展示自身的折叠。 Qualesse - 来自qualis + esse。存在的品质。简单，建立在现有的哲学词汇之上。 特征感 - 一个人自己的特征感知。成为这个东西的特殊质感。 我的直觉倾向于 Wiesein 的精确性或 Autophany 的优雅。感觉什么方向合适？  我在想Qualesse。人们只会错误地发音德语单词，Autophany 听起来与其他单词太相似，并且该领域已经使用 Qualia。 Claude 进一步... “拉丁语 esse 作为裸露不定式通常不会直接保留在英语词尾中。我们将 ess- 词根埋藏在诸如essential、essential之类的词中，但你是对的，我们在大多数结构中放弃了最后的-e。 源自法语的-esse结尾实际上可能是更好的造词血统——这些词都在定性意义上表示存在状态，这正是Qwalesse所指的。它不是假拉丁语；而是拉丁语。它遵循既定的英语借用模式。”   由   提交/u/Wahtadeal  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp2dol/qualesse/</guid>
      <pubDate>Wed, 17 Dec 2025 17:23:56 GMT</pubDate>
    </item>
    <item>
      <title>您是否曾经感觉自己不断从头开始重建相同的人工智能提示？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp20sh/do_you_ever_feel_like_you_keep_rebuilding_the/</link>
      <description><![CDATA[我自己也注意到了这种模式。 我会花时间编写一个非常有效的提示。使用几天。然后继续做其他事情。 几周后当我再次需要它时，我找不到它。所以我最终根据记忆重新创建了几乎相同的提示。 这并不难，只是......重复且烦人。每次都感觉像是白费力气。 好奇其他人是如何处理这个问题的。您是否将提示保存在正确的位置，或者只是在需要时重写它们？   由   提交/u/dp_singh_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp20sh/do_you_ever_feel_like_you_keep_rebuilding_the/</guid>
      <pubDate>Wed, 17 Dec 2025 17:10:06 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人不断失去他们最好的人工智能提示吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp1zkh/does_anyone_else_keep_losing_their_best_ai_prompts/</link>
      <description><![CDATA[这种情况不断发生在我身上，老实说这令人沮丧。 我写了一个非常好的提示。它工作完美。我告诉自己我会保存它。 然后几天后 - 它就消失了。 注释没有帮助。截图变得一片混乱。书签基本上没什么用。 一遍又一遍地重写相同的提示感觉很浪费，但我还没有找到一种干净的方法来管理它们。 你们都是怎么处理这个的？   由   提交 /u/dp_singh_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp1zkh/does_anyone_else_keep_losing_their_best_ai_prompts/</guid>
      <pubDate>Wed, 17 Dec 2025 17:08:42 GMT</pubDate>
    </item>
    <item>
      <title>开源替代品与网络工具</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp1pb2/opensource_alternatives_vs_web_tools/</link>
      <description><![CDATA[计算机视觉人群的问题：现在每个人都使用什么在社交媒体上进行快速面部识别反向搜索？我尝试了一些开源设置（InsightFace + 手动抓取），但维护起来很痛苦。最近发现了一个简单的基于网络的选项，称为人脸识别搜索 - 上传照片或视频，它处理检测和搜索主要平台，返回个人资料链接。无需设置，即使在集体照片上也能获得不错的效果。让我好奇消费者工具与研究模型相比已经走了多远。    由   提交 /u/Agreeable_Poem_7278   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp1pb2/opensource_alternatives_vs_web_tools/</guid>
      <pubDate>Wed, 17 Dec 2025 16:57:51 GMT</pubDate>
    </item>
    <item>
      <title>除了谷歌本身，我们没有什么可以谷歌的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pp0sro/we_have_nothing_to_google_but_google_itself/</link>
      <description><![CDATA[ https://preview.redd.it/gj86ghw5is7g1.png?width=1024&amp;auto=webp&amp;s=b231c5c566334378c73454cfd6f7ad8bb9b93347   由   提交 /u/xanderdad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pp0sro/we_have_nothing_to_google_but_google_itself/</guid>
      <pubDate>Wed, 17 Dec 2025 16:22:39 GMT</pubDate>
    </item>
    <item>
      <title>人工智能只是一场权力斗争，你并不重要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1poye92/ai_is_just_a_power_struggle_and_you_dont_matter/</link>
      <description><![CDATA[当你看看谁获得了世界财富的 98% 时，你会发现普通人拥有的财富不到 2%，这就是为什么很多公司正在从为消费者生产产品转向为价值数百万美元的企业生产产品，因为基本上普通人与他们之间的差距是如此之大，即使每个人都购买他们的产品，也仍然无法接近他们可以从大公司那里赚多少钱。简而言之，我们被榨干了，他们基本上不需要 99% 的人性，这就是人工智能的用武之地。如果你的公司对待员工很差，工人们会做什么，他们会停止工作，这会让公司提高工资，整体改善工作条件，但如果人工智能取代了人力，CNN 员工所做的事情让公司什么也改变不了，到那时，他们实际上可以让全体人民挨饿，然后消灭他们，因为他们不再需要你了。我真诚地认为，对于人工智能公司来说，你免费提供给他们的数据比你给他们钱更重要，因为谁首先创造了 AGI，毫无疑问将成为世界上最有权势的人，然后他可以用它来击败他们的竞争对手。他们几乎变得如此强大和富有，以至于钱都不再是重点了。有些人有很多钱，他们赚的钱比整个国家的钱还多。你得到的只是一个弱智的聊天机器人，直到他们制造出 AGI 为止，你都可以使用它，之后不管他们关心你什么，你都可以死掉。   由   提交 /u/Degeneret69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1poye92/ai_is_just_a_power_struggle_and_you_dont_matter/</guid>
      <pubDate>Wed, 17 Dec 2025 14:49:08 GMT</pubDate>
    </item>
    <item>
      <title>如果美国工资市场对人类工人的估值约为 11 万亿美元，这对人工智能系统和公司来说有何价值？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1powmwv/if_the_us_wage_market_is_valued_at_around_11/</link>
      <description><![CDATA[人工智能系统需要从人类工人那里接管多少利润率和利润率？ 是否有一些工作比其他工作更容易实现完全自动化，这是否意味着从手动经济到完全自动化经济的过渡更平稳/更缓慢？ 是否有任何运行过渡场景的模拟？ 您认为它会如何展开？   由   提交/u/Arowx  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1powmwv/if_the_us_wage_market_is_valued_at_around_11/</guid>
      <pubDate>Wed, 17 Dec 2025 13:34:06 GMT</pubDate>
    </item>
    <item>
      <title>谷歌发布多步强化学习研究代理。 46.4% 基准测试与单通道模型相比</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1powmh9/google_releases_multistep_rl_research_agent_464/</link>
      <description><![CDATA[在 hn 上看到有关 google 深度研究代理的内容：https://blog.google/technology/developers/deep-research-agent-gemini-api/ 与其他人工智能相比，他们的新 deepsearchqa 基准测试得分为 46.4%模型 多步骤强化学习方法非常有趣。它实际上学习的是研究方法，而不是单遍上下文处理。搜索 → 分析 → 识别知识差距 → 优化查询 → 再次搜索 每个复杂查询需要 8 分钟以上，但这仍然比手动研究快得多 这对于自动化科学研究工作流程来说可能是巨大的。一直在使用光标和 verdent 等工具来完成编码任务，但它们在综合信息合成方面表现不佳。这种谷歌方法似乎是专门为端到端研究自动化而设计的 想知道这是否代表了人工智能研究能力的真正突破，或者只是另一个基准优化   由   提交 /u/New-Needleworker1755   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1powmh9/google_releases_multistep_rl_research_agent_464/</guid>
      <pubDate>Wed, 17 Dec 2025 13:33:33 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人比以前更多地对人工智能进行事实核查吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1povfa9/does_anyone_else_factcheck_ai_more_than_they_used/</link>
      <description><![CDATA[我现在每天都依赖人工智能工具，但我仍然觉得有必要仔细检查几乎所有内容。它比以前的 ngl 更快、更智能，但我对输出更加谨慎。你们也有同感吗？   由   提交 /u/Overall_Zombie5705   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1povfa9/does_anyone_else_factcheck_ai_more_than_they_used/</guid>
      <pubDate>Wed, 17 Dec 2025 12:34:33 GMT</pubDate>
    </item>
    <item>
      <title>AI大战中台积电压力不小</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1porvxf/tsmc_under_a_lot_of_pressure_in_the_ai_war/</link>
      <description><![CDATA[您认为人工智能泡沫很快就会破灭吗？感觉就像公司只是在相互投资，甚至 NVIDIA 也在支持 AI 初创公司，而这些初创公司最终从 NVIDIA 购买了更多 GPU。 与此同时，台积电在履行大量 AI 芯片订单方面面临着巨大压力。这是真正的长期需求，还是只是可能缓解的炒作？   由   提交/u/sahabaz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1porvxf/tsmc_under_a_lot_of_pressure_in_the_ai_war/</guid>
      <pubDate>Wed, 17 Dec 2025 09:00:20 GMT</pubDate>
    </item>
    <item>
      <title>部署第一个人工智能功能后如何减轻生产中的偏差和幻觉？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1por2v6/how_to_mitigate_bias_and_hallucinations_in/</link>
      <description><![CDATA[嘿r/ArtificialIntelligence， 我们最近推出了第一个主要的人工智能支持功能，即我们的消费者应用程序的推荐引擎。我们是一个中型团队，该应用程序是在经过微调的法学硕士基础上构建的。在开发过程中每个人都很兴奋，但发布后的压力比预期要大得多。 该模型会产生有偏见的输出，例如，始终低估特定用户群体的某些类别。它还提供完全无意义或幻觉的建议，这会迅速削弱用户的信任。基本的单元测试和一些对抗性提示在发布前发现了明显的问题，但现实世界的使用暴露了更多的边缘情况。我们处于日常损害控制模式。我们监控反馈、修补程序提示，并在团队中没有专门的人工智能安全专业知识的情况下手动覆盖不良建议。 我们开始研究主动措施，例如更好的内容审核管道、自动红队、护栏或 RAG 与地面输出的集成。感觉势不可挡。还有其他人在部署第一个生产 AI 功能后遇到过这些困难吗？   由   提交 /u/Upper_Caterpillar_96   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1por2v6/how_to_mitigate_bias_and_hallucinations_in/</guid>
      <pubDate>Wed, 17 Dec 2025 08:05:41 GMT</pubDate>
    </item>
    <item>
      <title>2026+人工智能发展将带来什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1poo4of/what_will_2026_bring_in_terms_of_ai_development/</link>
      <description><![CDATA[我很想知道这一点，因为 2025 年的人工智能发展与前一年有很大的不同，我什至有一半的时间都分不清什么时候是人工智能。接下来会发生什么？   由   提交 /u/Immediate_Kick_6167   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1poo4of/what_will_2026_bring_in_terms_of_ai_development/</guid>
      <pubDate>Wed, 17 Dec 2025 05:09:39 GMT</pubDate>
    </item>
    <item>
      <title>随着人工智能内容充斥互联网，“Slop”成为韦氏词典 2025 年度词汇</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1po7r3e/slop_is_merriamwebsters_2025_word_of_the_year_as/</link>
      <description><![CDATA[“最初在 1700 年代用来指软泥，在 1800 年代用来描述食物垃圾或垃圾，“slop”现在呈现出明显的 21 世纪转变。 《韦氏词典》将其定义为“通常通过人工智能大量生产的低质量数字内容”。  想想可笑的视频、出故障的广告、几乎愚弄你的假新闻、人工智能撰写的蹩脚书籍，还有会说话的动物。现在，即使是像 Valentino 这样的奢侈品牌也开始推出“slop”系列。广告。  “就像粘液、淤泥和淤泥一样，污水会发出你不想碰的东西的潮湿声音，” 《韦氏词典》在其声明中打趣道，捕捉到了一种普遍的文化情绪，即对当今日益恶化的人工智能形势感到困惑，部分感到愤怒。   https://www.cnet.com/tech/services-and-software/slop-is-merriam-websters-2025-word-of-the-year-as-ai-content-floods-the-internet/   由   提交/u/MetaKnowing  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1po7r3e/slop_is_merriamwebsters_2025_word_of_the_year_as/</guid>
      <pubDate>Tue, 16 Dec 2025 17:21:11 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>