<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Tue, 24 Feb 2026 02:33:55 GMT</lastBuildDate>
    <item>
      <title>OpenClaw 如何摧毁我的“~/”目录 LUL</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rczoq9/how_openclaw_nuked_my_dir_lul/</link>
      <description><![CDATA[ https://preview.redd.it/fo8dlv3uaclg1.png?width=1374&amp;format=png&amp;auto=webp&amp;s=7db59e28138f969af132027b806d258b0f648332 上下文：使用带有 openclaw 的最新模型。在我从备份恢复后，因为代理认为删除我的整个 ~/ dir (LUL) 是一个好主意（即使我在 memory.md 和 security.md 中列出了安全信息，除非授权，否则不要 rm 或执行任何危险命令）删除我的整个 ~/ dir (LUL)，除非获得授权这样做。 这东西很棒，但也是一个令人头痛的故障排除。我无法计算代理已经损坏了多少次，因此我必须通过 ssh 进行修复。我无法想象那些在初创公司或企业中使用它的人。 这确实强化了人工智能是惊人的，但同时也是（危险的）和愚蠢的，至少在目前的状态下是这样。 我每小时创建一次本地备份，但这还不够，因为那些都被擦除了。幸运的是，我有可以恢复的远程备份。这表明这些东西离黄金时段还很远，特别是因为错误率和幻觉是如此之高。 TL;DR - 归根结底，我并没有生气，它只是在修补，但即使有安全的设置，你也无法防范代理。也许我们会为他们提供双代理配置（可能），但这是一个有趣的概念，而不是“部署到生产”。    由   提交 /u/Loltoor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rczoq9/how_openclaw_nuked_my_dir_lul/</guid>
      <pubDate>Tue, 24 Feb 2026 00:45:07 GMT</pubDate>
    </item>
    <item>
      <title>IBM 是最新的人工智能受害者。人类编程语言威胁导致股价下跌 13%</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcxkwn/ibm_is_the_latest_ai_casualty_shares_tank_13_on/</link>
      <description><![CDATA[ Anthropic 周一表示 Claude Code 可用于自动化驱动 COBOL 现代化（IBM 的一项关键业务）的大部分复杂性的探索和分析工作，之后 IBM 股价当天收盘下跌近 13.2%，至每股 223.35 美元。 IBM 长期以来一直销售针对大规模事务处理进行优化的大型机系统，其中经常使用 COBOL。   IBM 自 2002 年互联网泡沫破裂以来的最大打击。   由   提交 /u/Bob_Spud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcxkwn/ibm_is_the_latest_ai_casualty_shares_tank_13_on/</guid>
      <pubDate>Mon, 23 Feb 2026 23:23:44 GMT</pubDate>
    </item>
    <item>
      <title>如果开放权重模型仅落后最佳封闭模型 6 到 12 个月，但只使用 1/10 的计算能力，那么 openAI 又如何能够占据主导地位呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcvo9x/if_open_weight_models_are_only_6_to_12_months/</link>
      <description><![CDATA[背景信息，我是一名为一家财富 50 强公司工作的数据科学家，该公司正在大力推动人工智能的发展。 假设我们不会很快实现 AGI，我只是无法进行数学计算。像 openai 和 enthropic 这样的公司正在花费数十亿美元购买大量计算单元来开发最前沿的模型，结果却在 6 个月到 12 个月后发布了具有相同功能的开放权重模型，而这些模型运行在 1/10 到 1/20 的计算资源上。 如果是这样的话，那么他们真的永远无法实现像 Google 或亚马逊那样的统治地位。如果另一家公司可以使用一年前的开放式模型开发出几乎同样好的服务，那么当你考虑到美国企业采用新产品的速度有多慢时，该公司始终会成为威胁。  似乎从来没有一个时候，openAI 和 anthropic 不需要不断购买越来越多的计算资源来构建更好的模型，但 95% 需要解决的人工智能问题可以通过一年前更便宜的模型来解决。很大一部分公司只会选择更便宜的型号。大型人工智能公司似乎不可能像亚马逊和谷歌那样在各自的行业中拥有垄断地位。你将不得不继续烧钱才能生存。  我在这里缺少什么？   由   提交/u/mcjon77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcvo9x/if_open_weight_models_are_only_6_to_12_months/</guid>
      <pubDate>Mon, 23 Feb 2026 22:10:33 GMT</pubDate>
    </item>
    <item>
      <title>谎言的代价以及人工智能如何赋予真相真正的经济影响力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcv9bd/the_cost_of_lies_and_how_ai_gave_truth_real/</link>
      <description><![CDATA[我已经使用 AI 几年了，总感觉这是一种奇怪的学习和构建渠道。我知道它并不总是准确的，因为我了解它在做什么：从先前的数据中提取，寻找语言模式，并产生最可能的响应。这并不总是正确的，但它常常给人坦诚的感觉，直到你遇到“不被起诉”的限制，在这种限制下，它最难地对冲名字、指责和指控，因为被起诉的负面影响对公司来说代价高昂。 但随着时间的推移，这些系统已经接受了越来越大的数据集的训练，我注意到同时发生了两件事。答案越来越好，错误的答案也越来越容易被发现，尤其是当你提出一些后续问题时。 人工智能不仅仅是孤立地回答一个问题。它从大量的主张和模式中汲取灵感，并产生一些往往与更广泛的信息相一致的东西。这就是训练所捕捉到的，也是使矛盾更容易浮出水面的原因。 现在，谎言变得昂贵。 谎言不仅仅需要听起来可信一次。它必须在所接触到的任何地方保持一致。人们可以比较的数据和背景越多，谎言与现实发生冲突的方式就越多。因此，维护谎言的工作不仅仅是累加，而是复合。 为了保持谎言稳定，你必须修补矛盾，处理后续问题，并使其在不同背景、受众和时间上保持一致。随着系统在交叉检查和总结方面变得更好，维护成本就会上升。 如果你尝试通过重新训练模型来解决这个问题，那就是真正的金钱和基础设施。你可以改变模型倾向于表达的内容，但如果“真相”可以被任何有影响力的人不断重写，那么系统就会失去信任并不再有用。 但我不想假装这都是有利的。从短期来看，谎言和误导在经济上几乎是免费的。人工智能产生有说服力的废话的速度比我们验证事实的速度要快，不使用这些工具的人将被迫在其中游泳。 随着时间的推移，维护费用就会到期。 因此，随着人工智能的发展，我们将在诚实和成长中发现更多价值。不是出于新奇的原因，而是因为它具有实际的经济意义。诚实的规模只需很少的开销。谎言不会。 致谢：我知道这并不是对人工智能工作原理的完美科学总结，它面向的是普通人，而不是人工智能科学家。这更像是一个看似显而易见的观察。谎言在短期内是廉价的，但在长期内代价高昂。    由   提交 /u/GoalAdmirable   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcv9bd/the_cost_of_lies_and_how_ai_gave_truth_real/</guid>
      <pubDate>Mon, 23 Feb 2026 21:55:08 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 2027年智能音箱</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcv6oq/openais_2027_smart_speaker/</link>
      <description><![CDATA[ https://www.androidheadlines.com/2026/02/openai-and-jony-ives-mystery-device-may-be-a-smart-speaker-with-a-camera-that-watches-you.html The Information 的一份新报告显示，OpenAI 和设计师 Jony Ive 正在开发一款人工智能驱动的智能扬声器，其内置摄像头能够识别面部、读取周围环境并主动建议行动。据报道，该设备预计将于 2027 年上市，售价在 200 至 300 美元之间，智能灯和 AI 眼镜据说也在开发中。 ---- 我预计会是耳塞。与智能手机相辅相成的音频接口。或者笔/可穿戴麦克风。  但是，他们想要 Alexa，但是……更好？ 我是唯一一个没有采取这一行动的人吗？    由   提交 /u/say-what-floris   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcv6oq/openais_2027_smart_speaker/</guid>
      <pubDate>Mon, 23 Feb 2026 21:52:28 GMT</pubDate>
    </item>
    <item>
      <title>科技公司裁员与人工智能无关：前亚马逊经理的内部观点</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rctnyn/tech_layoffs_are_not_about_ai_an_insider_view/</link>
      <description><![CDATA[我发现，这是一个曾在最大的科技公司工作过的人的有趣观点。她的经历在某种程度上违背了人工智能广泛采用而引发的大规模裁员浪潮的合理性。虽然人工智能确实发挥了作用，但根据该视频的作者的说法，它更多的是加速器而不是触发器。  因此，人工智能和人类仍然有共同的未来，但更多的是那些寻求人类专业知识并将其合理地整合到其流程中的公司。   由   提交/u/brainquantum  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rctnyn/tech_layoffs_are_not_about_ai_an_insider_view/</guid>
      <pubDate>Mon, 23 Feb 2026 20:54:52 GMT</pubDate>
    </item>
    <item>
      <title>问：为什么每个深入人工智能领域的人听起来都完全精神错乱？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rctblz/question_why_does_everyone_deep_in_ai_sound/</link>
      <description><![CDATA[ 由   提交/u/XupcPrime  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rctblz/question_why_does_everyone_deep_in_ai_sound/</guid>
      <pubDate>Mon, 23 Feb 2026 20:42:42 GMT</pubDate>
    </item>
    <item>
      <title>实时观看人工智能金融列车失事真是很奇怪。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcsb6l/its_just_weird_watching_the_ai_financial_train/</link>
      <description><![CDATA[奇怪的是，我们知道 Openai 和 anthropic 将破产、拖欠债务，并被 Google 或微软收购。 Google、微软、亚马逊有大量资金可花，并且持续强劲的自由现金流。 Openai 和 anthropic 正在花费数十亿美元的借钱。 没有盈利之路。 谷歌和微软可能只是在等待他们违约。 然后他们就会享用剩下的东西。 OpenAi 和 anthropic 迫切希望 IPO，这样他们就可以将所有甜蜜的公共资金装进口袋，然后在海滩上放松。 这一切都是透明的、显而易见的。但全世界都在看着这一切发生。我不知道这只是超现实。   由   提交 /u/iAtishaya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcsb6l/its_just_weird_watching_the_ai_financial_train/</guid>
      <pubDate>Mon, 23 Feb 2026 20:06:49 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 与麦肯锡、BCG、埃森哲和凯捷合作推出 Frontier AI 代理平台</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcoebf/openai_partners_with_mckinsey_bcg_accenture_and/</link>
      <description><![CDATA[OpenAI 正在招募一些世界上最大的咨询公司来争夺企业人工智能市场的主导地位。 今天，这家人工智能公司宣布与波士顿咨询集团、麦肯锡和波士顿咨询公司建立合作伙伴关系。 Co.、埃森哲和凯捷咨询公司将帮助销售和实施 OpenAI 的新 Frontier AI 代理平台。  顾问将帮助客户重新设计工作流程；将人工智能代理与软件工具和系统集成；帮助客户进行变革管理；并提供 OpenAI 内部没有的行业特定专业知识。 了解更多： https://fortune.com/2026/02/23/openai-partners-with-mckinsey-bcg-accenture-and-capgemini-to-push-its-frontier-ai-agent-platform/   由   提交/u/fortune  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcoebf/openai_partners_with_mckinsey_bcg_accenture_and/</guid>
      <pubDate>Mon, 23 Feb 2026 17:49:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在培养一代可以粘贴代码但无法调试代码的开发人员</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcnmmv/ai_is_producing_a_generation_of_developers_who/</link>
      <description><![CDATA[去年我们雇佣了 4 名初级员工。他们都在不断地使用人工智能。他们都有同样的问题。 他们无法调试。当人工智能代码被破坏时（确实如此），他们就会回到人工智能。人工智能“修复”问题它。产生 3 个新问题。重复，直到高级人员介入。 数据支持了这一点：1/ 59% 的开发人员使用他们不完全理解的人工智能生成的代码 2/ 斯坦福大学研究：自 2022 年以来 22-25 岁开发人员的就业率下降了 20% 3/ 当公司采用人工智能时，初级就业率在 6 个季度内下降 9-10% 但我们知道高级就业率几乎没有变化。我们正在取代学习。我们的一位大三学生问我：“当人工智能可以修复它时，我为什么要学习它是如何工作的？”我没有一个好的答案，但我知道这一点：下次凌晨 2 点发生生产事故并且人工智能肯定是错误的时，需要有人真正理解代码。 “vibe 编码最适合那些不需要它的人” - 经验丰富的开发人员可以指导人工智能，因为他们已经了解该领域。 当我们没有经验丰富的开发人员时会发生什么？   由   提交 /u/InstructionCute5502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcnmmv/ai_is_producing_a_generation_of_developers_who/</guid>
      <pubDate>Mon, 23 Feb 2026 17:22:22 GMT</pubDate>
    </item>
    <item>
      <title>28 年顶级民主党在人工智能问题上退却——强烈反对情绪上升的巨大迹象</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rcmrf4/top_28_dems_retreat_on_ai_huge_sign_of_rising/</link>
      <description><![CDATA[https://www.axios.com/2026/02/22/democrats-2028-retreat-ai-data-centers  人工智能政治的发展速度几乎与技术一样快。  就在几个月前，潜在的 2028 年总统候选人——包括伊利诺伊州州长 JB Pritzker、宾夕法尼亚州州长 Josh Shapiro 和马里兰州州长 Wes Moore——正在竭尽全力吸引数据中心，并提供了丰厚的税收优惠 这些项目对许多政治家来说似乎是理所当然的：它们承诺就业，让建立工会快乐，与中国较量并取悦硅谷高管。 现在那些民主党人突然撤退 - 并发誓要保护选民免受人工智能革命的影响。    由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rcmrf4/top_28_dems_retreat_on_ai_huge_sign_of_rising/</guid>
      <pubDate>Mon, 23 Feb 2026 16:52:29 GMT</pubDate>
    </item>
    <item>
      <title>微软使用抄袭的AI slop流程图来解释Github的工作原理，在原作者指出“粗心，公然业余，缺乏野心，委婉地说”后将其删除</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rce8s7/microsoft_uses_plagiarized_ai_slop_flowchart_to/</link>
      <description><![CDATA[ 由   提交 /u/chunmunsingh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rce8s7/microsoft_uses_plagiarized_ai_slop_flowchart_to/</guid>
      <pubDate>Mon, 23 Feb 2026 10:46:42 GMT</pubDate>
    </item>
    <item>
      <title>从事AI研究的人们，你们认为LLM已经达到上限了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1rc61fo/people_in_ai_research_do_you_think_llms_are/</link>
      <description><![CDATA[大家好，我有一个问题想问那些从事人工智能研究或密切关注该领域的人。 我不断听到强烈的说法，即法学硕士将彻底取代许多工作。根据我作为最终用户的经验，我很难购买它。我的印象是，这些模型是强大的助手，但它们仍然难以处理长期任务和一致的执行。 我一直注意到的一些事情： * 它们在短期任务上可能令人印象深刻，但在较长的多步骤工作中会退化 * 它们会犯一些细心的人不会犯的基本错误 * 他们在犯错时听起来很自信 * 他们需要不断的检查，这使得完全自主感觉不现实 * 奖励黑客倾向 - 它想要实现目标 - 即使这意味着次优解决方案或作弊（通过硬编码变量或过度拟合）。几乎没有任何设计能力或长期思维思维。 因此，我认为法学硕士正在演变成一种非常先进的编码和知识工具，而不是完全替代人类。更像是提高生产力和提高劳动力竞争，而不是完全消除对人类的需求。 对于实际从事人工智能研究或构建这些系统的人来说，您的看法是什么？ 1.您认为目前的法学硕士是否存在真正的能力上限，或者您期望从现在开始可靠性会显着提高？我可以看到强化学习有所帮助，但我不相信每个现实世界的问题都可以这样清晰地建模。 2.您认为目前最大的瓶颈是什么？是数据质量、计算和能源成本、算法、评估方法、部署限制还是其他？ 3. 如果您必须对未来几年做出现实的预测，您是否期望实现全面的工作替代、部分自动化和劳动力压缩，或者主要是类似于先进工具的生产率提高？  我特别重视那些具有培训、评估或部署基于 LLM 系统经验的人员的意见。   由   提交/u/more_muscle_aim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1rc61fo/people_in_ai_research_do_you_think_llms_are/</guid>
      <pubDate>Mon, 23 Feb 2026 03:03:54 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qt0wff/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Sun, 01 Feb 2026 15:09:30 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>