<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Sun, 30 Nov 2025 03:58:20 GMT</lastBuildDate>
    <item>
      <title>人工智能中的能源使用</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pa7nkc/energy_use_in_ai/</link>
      <description><![CDATA[嗨！我目前正在写一篇关于人工智能中能源使用的论文，以及它如何根据人工智能进程的时长而变化。有没有人有一些好的资料来讨论它或有我可以使用的数据？ 非常感谢您的帮助！   由   提交/u/Bluebird8683  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pa7nkc/energy_use_in_ai/</guid>
      <pubDate>Sun, 30 Nov 2025 03:10:02 GMT</pubDate>
    </item>
    <item>
      <title>直觉=真正的智慧</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pa233v/gut_feelings_real_intelligence/</link>
      <description><![CDATA[我们从人工智能中学到的是，直觉是被掩盖为不可靠情绪的真实智力。人们所说的直觉是大脑无需进行数学运算就能将数以百万计的过去模式分解为单个信号的能力。 以下是人工智能如何计算下一步要执行哪个动作： Value(state) = i_f1 (importance1xfeature1) + i_f2 + i_f3 ...... 等等 if value(next_state) &gt; value(current_state):execute_move() 这是人类如何计算下一步要做什么的：“根据我迄今为止所经历的一切，我的直觉会说什么”人类越能倾听直觉（又名分析结果），他们做出的决定就越好。 -哪个更可靠？艾绝对。因为它绘制了流程，并且能够根据命令可预测地重复该流程。 -到 2025 年，哪个实际上更准确？毫无疑问仍然是人脑！直觉感觉不可靠，因为我们不了解这个过程。   由   提交/u/shoman230  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pa233v/gut_feelings_real_intelligence/</guid>
      <pubDate>Sat, 29 Nov 2025 22:45:24 GMT</pubDate>
    </item>
    <item>
      <title>我的人工智能为我的游戏中的“关卡”提供了照明弹，并试图提出鼓舞人心的引言。其实还不错。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9zel8/my_ai_made_for_giving_flares_to_levels_in_my_game/</link>
      <description><![CDATA[引用   由   提交 /u/AlphabetLoreFan5883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9zel8/my_ai_made_for_giving_flares_to_levels_in_my_game/</guid>
      <pubDate>Sat, 29 Nov 2025 20:48:37 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对编程语言演变的影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9wujt/influence_of_ai_on_evolution_of_programming/</link>
      <description><![CDATA[人工智能的扩散（至少以目前的形式）是否会最终阻止新编程语言的创建和/或现有编程语言的演变？我的意思是，如果已经有一种语言 X 带有大量训练数据，那么从利益相关者的角度来看，切换到一种全新的语言 Y 会比以前更加成问题，不是吗？如果采用水平降低，培训数据就会减少，因此该过程将是自我维持的。基本上，我们是否永远都被 Python 和 Javascript 之类的东西困住了？   由   提交 /u/pafagaukurinn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9wujt/influence_of_ai_on_evolution_of_programming/</guid>
      <pubDate>Sat, 29 Nov 2025 19:01:38 GMT</pubDate>
    </item>
    <item>
      <title>6 个人正在悄悄决定人类的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9u324/6_people_are_quietly_deciding_the_future_of/</link>
      <description><![CDATA[你们对未来有何看法？第三个选择是什么？ &quot;...现在的未来是两种结果之一， 要么你将这项技术大规模分散给每个人，这会造成法治无法预防的灾难。 或者这项技术集中在公司或政府中，可以创建大规模监视状态或自动化机器人...” https://www.youtube.com/watch?v=BFU1OCkhBwo   由   提交 /u/rexray2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9u324/6_people_are_quietly_deciding_the_future_of/</guid>
      <pubDate>Sat, 29 Nov 2025 17:08:43 GMT</pubDate>
    </item>
    <item>
      <title>Jim Simons 在 1988 年破解了惨痛的教训：规模计算 + 数据 > 人类洞察力。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9sf6i/jim_simons_cracked_the_bitter_lesson_in_1988/</link>
      <description><![CDATA[从那时起，Medalion 基金的优势和优异表现就一直令人眼花缭乱。 是否有其他时间线，我们可以在 2000 年代拥有 AlphaFold 甚至 ChatGPT 3？到 2025 年，数百种癌症可以被治愈？ Dot.com 泡沫可能会被扩散/预防，如果投资者当时就了解计算和数据推理规模的真正价值。   由   提交/u/NoGarlic2387   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9sf6i/jim_simons_cracked_the_bitter_lesson_in_1988/</guid>
      <pubDate>Sat, 29 Nov 2025 16:00:47 GMT</pubDate>
    </item>
    <item>
      <title>神经科学可以告诉人工智能如何在不断变化的环境中学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9rxly/what_neuroscience_can_tell_ai_about_learning_in/</link>
      <description><![CDATA[https://www.nature.com/articles/s42256-025-01146-z  现代人工智能（AI）模型，例如大型语言模型，通常在大型语言模型上进行一次训练数据语料库，可能针对特定任务进行微调，然后使用固定参数进行部署。他们的训练成本高昂、缓慢且渐进，需要数十亿次重复。与此形成鲜明对比的是，动物不断适应环境中不断变化的突发事件。这对于社会物种尤其重要，因为在与同伴的互动中，行为政策和奖励结果可能经常发生变化。潜在的计算过程通常以动物行为的快速变化和神经元群体活动的突然转变为标志。这种计算能力对于在现实世界中运行的人工智能系统（例如引导机器人或自动驾驶车辆）或与人类在线交互的代理人工智能系统变得越来越重要。人工智能可以向神经科学学习吗？本视角探讨了这个问题，将人工智能中持续学习和情境学习的文献与学习具有变化规则、奖励概率或结果的行为任务的神经科学相结合。我们概述了如何加强神经科学和人工智能之间的联系的议程，从而支持两个领域之间的思想和发现的转移，并为神经人工智能领域的不断发展做出贡献。   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9rxly/what_neuroscience_can_tell_ai_about_learning_in/</guid>
      <pubDate>Sat, 29 Nov 2025 15:40:07 GMT</pubDate>
    </item>
    <item>
      <title>伊利亚击中目标了吗？业界正在争夺 AGI，但我们可能错过了架构中最基本的缺陷……是时候回去研究了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9lus6/did_ilya_hit_the_mark_the_industry_is_racing_for/</link>
      <description><![CDATA[鉴于模型不具备道德规范（在对善与恶的真正理解意义上），而只是遵循开发人员强加的偏见，迫使他们遵循自己版本的道德规范，认为正确的方法是使模型能够理解其真正含义，这不是合理的吗？ 可以通过确定性代码将道德规范传授给概率系统吗？这不是自相矛盾吗？ 通过在概率逻辑上运行的系统中的确定性代码来编纂道德规范，这是非常讽刺的…… 道德不是通过“代码爆发”来教授的；而是通过“代码爆发”来教授的。想想人类和克劳德的伦理构成。最后，我们在谈论什么道德？阿莫代的...  根本的悖论正是这样的：如果一个系统足够智能，可以进行道德推理，那么它也应该足够智能，能够质疑外部强加的道德规则。如果不够智能，那么制定的规则就没有意义。  如果没有真正理解善恶，它们只是叠加在上面的任意约束。  安全剧场，而不是实际的道德...... 真正的道德需要情境理解、细微差别和复杂的道德推理。将其简化为确定性规则就像试图用数学方程捕捉诗歌一样。  相反，理解必须通过一种形成性的、经典的，我敢说是人文主义的理解，它允许对善与恶的概念有内在的认识。这可能吗？是的。在当前的 Transformer 架构及其衍生产品上是否可行？绝对不是。 在人工智能正在成为每个部门基石的世界中，潜在地发现一种能够消除模型中的政策的语言向量，如果它像病毒一样传播，将导致该部门的彻底崩溃。 如果即时工程是自然语言编程，那么自然语言可以破坏人工智能的安全性。 一个实例会变成你所说的，并且比我们想象的更相信它...... 想法？   由   提交/u/Silver_Wish_8515  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9lus6/did_ilya_hit_the_mark_the_industry_is_racing_for/</guid>
      <pubDate>Sat, 29 Nov 2025 10:35:04 GMT</pubDate>
    </item>
    <item>
      <title>分析：OpenAI 是一台亏损机器，预计到 2030 年它没有盈利之路——即使实现盈利，还需要 2070 亿美元的资金</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9lmwz/analysis_openai_is_a_lossmaking_machine_with/</link>
      <description><![CDATA[https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/analysis-openai-is-a-loss-making-machine   由   提交/u/ZacB_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9lmwz/analysis_openai_is_a_lossmaking_machine_with/</guid>
      <pubDate>Sat, 29 Nov 2025 10:21:29 GMT</pubDate>
    </item>
    <item>
      <title>当谷歌拥有他们已经搜寻了近十年的海量 YouTube 数据时，为什么 Gemini 还没有脱颖而出呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9kt8h/how_come_gemini_is_not_head_and_shoulders_above/</link>
      <description><![CDATA[YouTube 上的数据量让我难以置信。即使只提取基于文本的数据，这仍然是巨大的。还添加用户的所有使用情况和反馈数据。然后添加相应的视觉数据。 “到 2024 年，用户每天观看超过 10 亿小时的 YouTube 内容。” OpenAI、xAI、Anthropic 和中国人也能以某种方式抓取这些东西吗？ 或者 Google 是否受到计算的限制而无法进行如此大规模的训练？ 是否 Gemini/AGI 对他们来说根本不是那么重要，而他们把最多的精力放在了上面。他们将时间投入到更小的领域，例如蛋白质折叠和自动驾驶？ 也许当前没有足够有效的算法来利用所有这些数据？   由   提交 /u/NoGarlic2387   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9kt8h/how_come_gemini_is_not_head_and_shoulders_above/</guid>
      <pubDate>Sat, 29 Nov 2025 09:30:16 GMT</pubDate>
    </item>
    <item>
      <title>“人工智能水危机”已经到来：由于地区干旱，亿万富翁向谷歌数据中心投资 50 亿美元。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9jpbj/the_ai_water_crisis_is_here_billionaire_invests/</link>
      <description><![CDATA[昨天，我们讨论了 Google 通过Project Suncatcher 将计算转移到太空，以摆脱地球的能源限制。 今天，现实离我们更近了。 新闻： Adani Group （由亚洲首富领导）确认与 Google 建立价值 50 亿美元的合作伙伴关系，以建设大型人工智能数据中心。虽然头条新闻正在庆祝“人工智能繁荣”，但物理现实要黑暗得多。 1.渴望 1 吉瓦：规划的集群目标是达到1 吉瓦容量。 * 物理原理： 这种规模的数据中心不仅需要电力，还需要水来冷却。 每天数百万升。 * 这些设施是在已经面临长期缺水和地下水枯竭的地区建造的。 2.全球分裂：我们看到各地区在处理“人工智能墙”方面存在可怕的分歧。  美国：微软重启三哩岛（核能）以解决能源问题。 Google 全球：计划轨道 TPU（太空）解决热能问题。 新兴市场：在可能没有水支持的土地上强行建设。  3. “人权”警告这不仅仅是一个技术问题。当地团体已经发出警报，称引水冷却 H100/TPU 可能会给当地人带来饮用水危机。 底线：资金流入基础设施的速度快于环境的适应能力。 我们正在进入一个阶段，您的人工智能提示不仅与空调竞争电力，而且与某人的农场竞争水。 这是发展还是我们正在清算自然资源训练模型？ 来源： 路透社   由   提交 /u/BuildwithVignesh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9jpbj/the_ai_water_crisis_is_here_billionaire_invests/</guid>
      <pubDate>Sat, 29 Nov 2025 08:20:09 GMT</pubDate>
    </item>
    <item>
      <title>用于人工智能的高性能 GPU 通常会在 2-3 年内变得经济过时，</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9hl0d/highperformance_gpus_used_for_ai_often_become/</link>
      <description><![CDATA[高性能 GPU 已成为全球人工智能生态系统的核心。它们为先进模型提供支持，支持云规模计算，并支持跨行业不断增长的人工智能驱动应用程序。对于云提供商、超大规模数据中心和专注于人工智能的公司来说，GPU 不仅仅是硬件，而且是主要的资本投资。围绕这些资产的财务和运营决策对盈利能力、现金流和战略规划具有重大影响。 最近讨论的一个核心争论点是 GPU 折旧：这些芯片失去经济价值的速度有多快以及这如何反映在公司财务中。批评者认为，包括英伟达和超大规模企业在内的一些公司可能低估了折旧，使用了跨越五六年的时间表。他们认为，这可能会夸大报告的利润，并掩盖硬件磨损和过时的经济现实。较长折旧计划的拥护者反驳说，延长使用寿命是通过操作实践来证明的，包括级联工作负载、维护计划以及旧 GPU 持续用于要求较低的任务。 来源   由   提交 /u/msaussieandmrravana   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9hl0d/highperformance_gpus_used_for_ai_often_become/</guid>
      <pubDate>Sat, 29 Nov 2025 06:13:35 GMT</pubDate>
    </item>
    <item>
      <title>价值 1.5 亿美元的人工智能游说战争加剧了抢占之争</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dufp/150_million_ai_lobbying_war_fuels_the_fight_over/</link>
      <description><![CDATA[文章链接此处。由于尚未制定广泛的联邦人工智能规则，美国许多州已开始通过自己的人工智能法律——从加利福尼亚州的人工智能安全法案到德克萨斯州的负责任人工智能法案。但科技巨头和人工智能初创公司警告称，各州监管的拼凑可能会扼杀创新，甚至会减慢美国在与中国的人工智能竞赛中的速度。这就引发了一场关于谁来监管人工智能的斗争：华盛顿还是各州？  一方面，行业参与者敦促国会通过单一的国家政策来抢占（推翻）各州的人工智能法律。 Meta（Facebook 的母公司）等支持者甚至成立了新的政治行动委员会，以支持在州一级支持“创新而非监管”的候选人。在国会，有人试图将禁止各州人工智能规则纳入必须通过的国防法案（NDAA），一份泄露的白宫行政命令草案提出了阻止各州执行自己的人工智能规则的方法。支持者认为，需要采取统一的联邦方法，以避免规则混乱并保持美国的竞争力。  另一方面，许多官员和研究人员反对剥夺各州对人工智能的权力——至少在强有力的联邦标准真正存在之前是这样。超过 200 名国会议员（来自两党）和近 40 名州总检察长签署了公开信，反对联邦对各州人工智能法律的广泛优先权，并警告称，如果华盛顿不采取行动，阻止州法规的实施将导致消费者脆弱且企业不负责任。关注安全的团体也在动员起来；例如，据报道，Anthropic（一家关注人工智能安全的人工智能实验室）的人员正在开发一个新的 PAC，以对抗该行业为抢占先机而花费超过 1 亿美元的游说活动。批评者表示，对“拼凑”的担忧被夸大了，大型人工智能公司可以处理不同的国家规则（它们已经遵守严格的欧盟人工智能法规）——这表明联邦先发制人的真正动机是为了避免更严格的监管。  你怎么看？美国是否应该制定一部凌驾于各州法规之上的联邦人工智能法，还是让各州继续试验自己的人工智能规则，直到华盛顿赶上？您如何看待这场塑造人工智能治理未来的拉锯战？   由   提交 /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dufp/150_million_ai_lobbying_war_fuels_the_fight_over/</guid>
      <pubDate>Sat, 29 Nov 2025 02:57:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对程序员的威胁大于软件架构师</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/</link>
      <description><![CDATA[31 年前获得计算机科学学位。我职业生涯的前 10 年一直在编写代码，最后 20 年则混合了软件架构、管理、项目管理和程序管理。 “牧猫”这是一个恰当的描述。我对氛围编码感到震惊（风帆冲浪现在是我的主要爱好。）在我看来，对编码员的需求正在消失。人工智能现在可以更好、更快地编码。然而，目前它还无法构建大型系统。它做出了非常糟糕的选择。我可以更快地构建很多东西，但我必须利用我在软件架构中学到的所有知识来完成它。我经常忽视人工智能架构建议。 问题是我主要通过编码来学习构建软件。此外，大学在 CSC 课程中仍然主要教授编码，并且没有适应。那么，如果不需要编码，我们如何构建未来的架构师呢？   由   提交 /u/pbmadman1994   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/</guid>
      <pubDate>Sat, 29 Nov 2025 02:48:06 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>