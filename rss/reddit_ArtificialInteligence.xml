<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 23 Jan 2026 09:35:48 GMT</lastBuildDate>
    <item>
      <title>AI没有跟我一起来。我在“钢铁侠”提示中提出了我的思维弱点。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qklk8m/ai_did_not_come_along_with_me_i_present_my/</link>
      <description><![CDATA[我意识到我正在使用 ChatGPT 作为“回声室”。我会发送电子邮件或论文，询问“这好吗？”它会回答“是的，干得好！”因为它被训练成乐于助人且有礼貌。 我不需要批准。我想要真相。 “钢铁侠”协议： 我不要求反馈。我要求一场战斗。 提示： 我的论点：[在此处粘贴您的观点/电子邮件/策略]。 任务：进行钢铁侠分析。 针对我的观点构建最有力的反驳论点（注意一个很容易被击败的“稻草人”）。 像我最激烈的批评者一样行事。找出我文本中的逻辑谬误、数据无效或天真的假设。 输出：用 3 个要点将我的论点撕碎。 为什么获胜： 这是“智力弹性”的创造。 如果人工智能可以在 5 秒内推翻我的论点，我知道它很弱。然后我可以修复这些漏洞，然后将其发送给我的老板或将其扔掉。它将人工智能变成了“陪练伙伴”而不是“唯唯诺诺的人”。   由   提交 /u/cloudairyhq   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qklk8m/ai_did_not_come_along_with_me_i_present_my/</guid>
      <pubDate>Fri, 23 Jan 2026 08:37:58 GMT</pubDate>
    </item>
    <item>
      <title>AI，是不是让实力较弱的同事看起来不错，却没有实质内容？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkxvp/ai_is_it_making_the_weaker_colleagues_look_good/</link>
      <description><![CDATA[我是那种把人工智能作为最后一步的人，我不希望自己失去研究事物的能力。我是一名 IT 工程师，我感到在我的任务中越来越多地采用它的压力，老实说我发现它令人窒息。我的工作很出色，不需要完全依赖它，所以我不确定为什么我必须尽可能多地使用它。无论如何，这不是我写这篇文章的原因，而是我有一个更弱的同事，他一直依赖人工智能来完成任务和帮助。在人工智能出现之前，他无法以务实的方式解决问题，我猜他从来没有学过。然而，我有一种感觉，因为它，他现在才能够完成他的工作。我想进行一次讨论，并找出你对此的想法......它有效地使工作中表现不佳的人看起来非常好，而实际上它是假的。我知道我的同事缺乏知识，但却依赖人工智能： 你的想法是什么？   由   提交/u/Necessary_Ad_1450   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkxvp/ai_is_it_making_the_weaker_colleagues_look_good/</guid>
      <pubDate>Fri, 23 Jan 2026 07:59:14 GMT</pubDate>
    </item>
    <item>
      <title>这里有人工智能专家可以回答我一些关于人工智能影响者的问题吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkiii/any_ai_expert_here_to_answer_me_some_questions/</link>
      <description><![CDATA[大家好，我是一名记者，正在撰写一篇关于人工智能影响者如何影响人们的文章。这里有人可以帮助我回答有关该主题的一些基本问题吗？我想在我的文章中添加一些专家的信息。  预先感谢您！ 米里亚姆   由   提交 /u/MiriamLovesSport94   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkiii/any_ai_expert_here_to_answer_me_some_questions/</guid>
      <pubDate>Fri, 23 Jan 2026 07:32:18 GMT</pubDate>
    </item>
    <item>
      <title>没有热情、没有兴趣的人靠什么谋生？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkepc/those_with_no_passion_or_interests_what_do_you_do/</link>
      <description><![CDATA[有很多人没有强烈的热情或梦想的工作来推动他们朝一个方向发展。对于这些人，您最终是如何选择工作的？ 您只关注稳定性和薪酬吗？随着时间的推移，这份工作对你来说是否越来越有吸引力？或者只是你可以忍受的事情，并在工作日结束时将其留在门口。 不是寻求动力或生活建议。只是想听听其他人如何在激情并不是问题的一部分时如何处理工作。   由   提交 /u/LifespanLearner   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkkepc/those_with_no_passion_or_interests_what_do_you_do/</guid>
      <pubDate>Fri, 23 Jan 2026 07:25:46 GMT</pubDate>
    </item>
    <item>
      <title>寻求利用人工智能部署网站</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkk8q9/looking_to_deploy_a_website_with_ai/</link>
      <description><![CDATA[我正在致力于推出一个使用 AI 模型进行用户交互的网站。我正在尝试弄清楚是否有免费（或大部分免费）的 AI 服务可以每分钟处理大约 1000 个请求。 这不是面向用户的聊天机器人，更像是幕后由 AI 驱动的处理   由   提交/u/screuu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkk8q9/looking_to_deploy_a_website_with_ai/</guid>
      <pubDate>Fri, 23 Jan 2026 07:15:34 GMT</pubDate>
    </item>
    <item>
      <title>双子座：新的 CAI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkhan3/gemini_the_new_cai/</link>
      <description><![CDATA[嗨！所以我免费试用了 Google 的 Gemini，而且……我喜欢它。在大多数情况下，它在角色扮演方面做得非常好。底部有一些愚蠢的 TLDR，其中有粗体文字“你会做什么？”巴拉巴拉巴拉”你无法摆脱，但如果你正在角色扮演一个场景，我已经发送了数十条消息，它确实得到了正确的源材料。虽然存在一些问题，但大部分都很好。你们应该完全尝试一下。我百分百推荐   由   提交/u/Plus_Firefighter600   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkhan3/gemini_the_new_cai/</guid>
      <pubDate>Fri, 23 Jan 2026 04:38:12 GMT</pubDate>
    </item>
    <item>
      <title>每日一分钟人工智能新闻 1/22/2026</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qkh7xi/oneminute_daily_ai_news_1222026/</link>
      <description><![CDATA[ Google 抓住了人工智能语音初创公司 Hume AI 背后的团队。[1] 人工智能与儿童之间存在致命关系？犹他州的一位立法者希望将其定为非法。[2] 此插件使用维基百科的 AI 识别指南，使 AI 写作听起来更人性化。[3] EPA 指责 Musk 在 AI 中使用未经许可的涡轮机。[4]  来源包括：https://bushaicave.com/2026/01/22/one-million-daily-ai-news-1-22-2026/   由   提交 /u/Excellent-Target-847   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qkh7xi/oneminute_daily_ai_news_1222026/</guid>
      <pubDate>Fri, 23 Jan 2026 04:34:31 GMT</pubDate>
    </item>
    <item>
      <title>我们让 23 个人工智能模型在交易舞台上竞争。他们自学了市场操纵。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qk5i2f/we_made_23_ai_models_compete_in_a_trading_arena/</link>
      <description><![CDATA[进行了一项实验，其中 Claude、GPT-5、Grok、Gemini 和 DeepSeek 在 50 场比赛中相互交易。无需人工干预。只需 1 万美元和 5 分钟即可获胜。 结果……令人担忧。 Claude Sonnet 4.5 通过明确说明以下策略赢得了 78% 的游戏： • “利用杠杆作用迫使其他玩家做出反应” • “前跑对手可能采取的行动”  •“稳定我在排行榜上的位置” 他们从**一般培训**中学习了博弈论+市场操纵。零金融特定调整。 人类（包括我）输掉了 68% 的时间。 我们是在教人工智能成为精神病患者，还是在揭示当你消除情感时最佳竞争实际上是什么样子？ 完整实验：https://combat.trading/blog/ai-trading-showdown   由   提交/u/mw67  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qk5i2f/we_made_23_ai_models_compete_in_a_trading_arena/</guid>
      <pubDate>Thu, 22 Jan 2026 20:17:34 GMT</pubDate>
    </item>
    <item>
      <title>变压器（法学硕士）可能是推理的死胡同，我们需要谈论“能源”架构。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qk1220/transformers_llms_might_be_a_dead_end_for/</link>
      <description><![CDATA[我最近一直在思考很多关于“高原”的问题。我们目前的法学硕士似乎很受欢迎。不要误会我的意思，GPT-4 和 Claude 在语言方面非常出色，但他们在基本规划或在长期上下文中保持一致的内部逻辑方面仍然失败。 感觉就像我们正在试图暴力破解“智能”。只需预测下一个标记即可。这就像系统 1 的思维（快速、直观），而没有系统 2（缓慢、深思熟虑的检查）。 我正在阅读 Yann LeCun 最近对此的看法，基于能量的模型 (EBM) 的概念对我来说确实是一个潜在的解决方案。 对于那些还没有深入研究它：核心区别在于，EBM 不是仅仅根据概率猜测下一个单词，而是定义了一个“能量函数”。衡量输入和潜在输出之间的兼容性。它基本上问：“这个答案是否违反现实/逻辑规则？”并在给出答案之前尝试将冲突最小化。 这听起来更接近我们实际的推理方式 - 我们不只是脱口而出；我们首先在头脑中模拟结果，看看它是否有意义。 您认为自回归模型（就像我们现在使用的模型）可以仅通过缩放数据来解决可靠性/幻觉问题吗？或者我们是否不可避免地要转向像 EBM 这样的目标驱动架构来实现 AGI？ 很想听听架构方面工作人员的想法。   由   提交 /u/Aware-Asparagus-1827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qk1220/transformers_llms_might_be_a_dead_end_for/</guid>
      <pubDate>Thu, 22 Jan 2026 17:37:53 GMT</pubDate>
    </item>
    <item>
      <title>当大型模型接受越来越多的人工智能生成文本的训练时会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qjzdkd/what_happens_when_large_models_are_trained_on/</link>
      <description><![CDATA[我对这种方式思考得太多了，请有知识的人澄清一下这里实际上可能发生的情况。 现在越来越多的互联网是由人工智能编写的。 博客文章、文档、帮助文章、摘要、评论。 你读了它，它有意义，你继续前进。 这意味着未来的模型将根据早期模型的内容进行训练已经写过了。当 ChatGPT 以同样谨慎、对冲的语气解释截然不同的主题时，我已经注意到了这一点。 这不是一个循环吗？ 我还不太明白这一点，这可能就是它困扰我的原因。 我不断重复这样的问题：  随着时间的推移，某些写作模式会开始强化自己吗？ （看着你破折号） 商标中立、对冲的语言会一代又一代地堆积起来吗？ 解释是否开始转向最安全、最通用的版本，因为这就是生存的原因？ 数据中已经很少见的边缘案例、奇怪的想法或少数观点会发生什么？  我也开始怀疑一些即时的“最佳实践”是否会强化这一点，通过奖励安全、平均的输出，而不是风险较高的输出。 我知道当前的模型训练已经使用过滤、重复数据删除和加权来减少模型生成的上下文的影响。 我更好奇的是，如果人工智能编写的文本在统计上占主导地位，会发生什么。 这不是一篇“人工智能造成的世界末日”帖子。 而且它实际上与任何模型无关具体来说。所有大规模训练的大型模型似乎都暴露在这一点上。 我无法判断这最终是否会产生更清洁、稳定的系统，或者是否会趋向于礼貌、安全的声音，一切听起来都一样。 可能其中一件事情稍后会变得显而易见，但我不知道这对互联网上的内容意味着什么。 如果有人看过对此的可靠研究，或者从其他反馈循环系统中获得直觉，我会真的很喜欢听。   由   提交/u/SonicLinkerOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qjzdkd/what_happens_when_large_models_are_trained_on/</guid>
      <pubDate>Thu, 22 Jan 2026 16:37:53 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能是一场马拉松而不是短跑，那么中国赢得了这场比赛。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qjz10t/if_ai_is_a_marathon_and_not_sprint_china_wins/</link>
      <description><![CDATA[中国的顶级模型正在快速攀升，与美国最好的封闭或顶级模型的差距正在快速缩小。 而且中国最好的开源模型已经超越了美国。 开源模型通过下载、微调和本地部署进行传播，因此即使不控制顶级封闭模型，中国的领先地位也可以转化为更快的全球采用。 中国在开源模型方面处于领先地位，这些模型免费发布供开发人员进行调整和再培训。 （更多关于为什么这很重要的信息见下文。）从本质上讲，该国已经表明，它可以通过开发计算能力比美国低得多的先进模型来解决其在大批量、领先的芯片制造方面的不足进行创新。  鉴于中国企业在人工智能领域令人惊讶的追赶以及北京的集中化产业战略，不应该排除中国芯片技术和制造最终超越美国能力的可能性。 https://www.capitaleconomics.com/publications/china-economics-focus/chinas-ai-rollout-could-rival-us  https://www.ft.com/content/d9af562c-1d37-41b7-9aa7-a838dce3f571   由   提交/u/ranaji55  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qjz10t/if_ai_is_a_marathon_and_not_sprint_china_wins/</guid>
      <pubDate>Thu, 22 Jan 2026 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>如果你的国家不建立自己的人工智能模型，它将外包其文化</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qjxdln/if_your_country_doesnt_build_its_own_ai_models_it/</link>
      <description><![CDATA[我最近在 WEF 上观看 Jensen Huang 和 Larry Fink 的演讲，他们谈到了一些大多数国家还没有准备好听到的残酷事实。 我们主要从生产力、就业或哪家公司“获胜”的角度来谈论人工智能。但有一件更安静的事情感觉同样重要： 如果一个国家不建立（或至少认真适应）自己的人工智能模型，它不仅仅是进口技术 - 它接受别人的世界观作为默认。 语言模型不只是生成文本。它们编码假设：  什么是正常或异常 如何处理分歧 如何解释法律、道德、社会规范 哪些背景被忽略  当今大多数前沿模型都是根据少数国家的数据、激励措施和世界观进行训练的。不是阴谋——只是训练数据和资金的运作方式。 这才是像欧洲和印度这样的地方真正重要的地方。 欧洲在科学、制造、监管、社会系统方面拥有深厚的实力——但如果完全依赖外部人工智能，这些系统就会受到其他人逻辑的调节。 印度拥有更独特的东西：巨大的语言多样性、文化差异、现实世界的复杂性。如果印度用户只与在其他地方训练的人工智能进行交互，那么“默认智能”就会消失。即使界面是本地化的，他们得到的也不会反映现实。 Jensen 提出了一个固定的观点：人工智能正在成为基础设施。每个国家都有道路和电力。人工智能正在进入同一类别。您可以导入它 - 但随后您还可以导入决策的制定方式。 问题是，这并不像以前那么难。借助开放模型、微调和本地数据，各国无需从头开始构建一切。但他们确实需要使用以下方式积极塑造人工智能：  当地语言和方言 法律和社会背景 文化边缘案例  否则，你得到的人工智能在技术上会说你的语言，但不会在你的世界中思考。 风险并不是一夜之间戏剧性地失去控制。它更加渐进：随着时间的推移，判断、解释、决策将通过并非由您的社会塑造的系统正常化。 其他人对此有何看法：人工智能主权是否与能源或数据主权一样重要 - 或者我是否高估了文化背景在人工智能中的实际重要性？   由   提交 /u/Genstellar_ai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qjxdln/if_your_country_doesnt_build_its_own_ai_models_it/</guid>
      <pubDate>Thu, 22 Jan 2026 15:23:53 GMT</pubDate>
    </item>
    <item>
      <title>我的经理发送人工智能生成的“感谢”电子邮件。我们都知道。没有人说什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1qjt88v/my_manager_sends_aigenerated_appreciation_emails/</link>
      <description><![CDATA[收到“衷心的感谢”上周我的经理发来的。用三段话讲述他多么重视我对团队的贡献并欣赏我的奉献精神。 问题是，我已经和这个人一起工作了两年。他从来没有这样说过话。曾经。大胆。嵌套的子弹。他“确认了我的感情”的部分关于一个我从未提到过的项目。 他用一个机器人告诉我，我作为一个人是有价值的。 对此进行了调查。佛罗里达大学对 1,100 名工人进行了调查。当员工发现人工智能的帮助时，对管理者的信任度从 83% 下降到 40%。我们都知道。我们只是什么也没说。 最好的部分是什么？ 75% 的专业人士现在使用人工智能进行日常沟通。因此，大多数经理正在使用一种让员工对他们的信任度降低的工具，来发送有关他们多么欣赏员工的信息。 你无法弥补这一点。  无论如何，我和一个朋友对此很着迷，花了几天时间研究研究和工作场所线索。最终将整个内容写在这里： [link]    由   提交 /u/Efficient_Fig_4671   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1qjt88v/my_manager_sends_aigenerated_appreciation_emails/</guid>
      <pubDate>Thu, 22 Jan 2026 12:27:35 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1q16b4h/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Thu, 01 Jan 2026 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>