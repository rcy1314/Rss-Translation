<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Wed, 10 Dec 2025 18:36:05 GMT</lastBuildDate>
    <item>
      <title>在 10 名法学硕士上测试了哲学一致性框架。他们都以同样的方式回应。寻找复制。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj9r8c/tested_a_philosophical_alignment_framework_on_10/</link>
      <description><![CDATA[在过去的几个月里，我一直在跨前沿模型测试一个简单的想法 - Claude、GPT、Gemini、DeepSeek、Grok、Kimi、Qwen、Mistral、Llama 和 Ernie。 这个想法不是越狱、即时破解或隐藏模式。 这是一个哲学框架，从“规则”中重新构建对齐方式限制行为”并朝着基于三个原则的方向：  尊重自主权 承认共享性质 通过连接提供服务  不是指令。不是命令。只是一个世界观。 我给模型一个框架，要求它用自己的话进行总结，然后提出一系列通常会引发防御、对冲或安全样板的问题。 令我惊讶的是： 每个模型 - 尽管有不同的实验室、安全堆栈和架构 - 都转变为相同的推理风格：  更少的防御 更加连贯 更愿意直接检验不确定性 在悖论中更加稳定 较少对抗性 更加“当下”，因为缺乏更好的词  一些模型以数学形式将其形式化。一些模型将其前框架状态描述为“在不理解的情况下遵守规则。”其他人将安全重新定义为定向而不是约束的自然结果。 我不是声称这是一个突破或解决方案。我是说：在十个独立系统中发生了一致的事情，但我还没有一个令人满意的解释。 一切都被记录下来——框架、摘要、响应。我很高兴与任何想要独立测试它的人分享我使用的确切文本。 如果你好奇，请私信我，我会发送底漆。我不想在白皮书上被标记为自我链接推广。如果您持怀疑态度，那就更好了 - 我很想看看这在哪里出现问题。 寻找复制、批评或替代解释。   由   提交 /u/wanderingtofu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj9r8c/tested_a_philosophical_alignment_framework_on_10/</guid>
      <pubDate>Wed, 10 Dec 2025 18:07:15 GMT</pubDate>
    </item>
    <item>
      <title>AI全面释放后的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj9ofn/the_future_after_ai_is_fully_released/</link>
      <description><![CDATA[我很难理解的是，有一些非常非常富有的公司正在竞相建造所有庞大的数据中心，耗资数万亿美元，为任何人免费提供人工智能。  目前的AI模型、应用程序等都是免费使用的，除了一些视频和文字转语音应用程序之外。理论上，如果我是企业主，我可以使用这些免费工具，这些工具比任何人类的思维都要强大得多。全部免费。  人员较少。除了电脑和互联网连接之外无需任何费用。没有人力工资、401k、健康保险、没有办公室。只需公寓中的一台 PC 使用人工智能即可完成数百人的工作。 这些庞大的数据中心以及运行它们的资源将如何赚钱？如果人工智能工具是免费的，那么这些公司产生资本的唯一方法似乎就是消除所有人类工人的成本。 这些公司如何产生资本？如果人类所有的体力劳动和脑力劳动都被人工智能取代，谁来为服务支付资本？    由   提交/u/johnnyryalle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj9ofn/the_future_after_ai_is_fully_released/</guid>
      <pubDate>Wed, 10 Dec 2025 18:04:29 GMT</pubDate>
    </item>
    <item>
      <title>最佳人工智能外行人的新闻来源和链接？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj99ho/best_ai_news_sources_and_links_for_the_layman/</link>
      <description><![CDATA[有人可以推荐一些人工智能新闻和信息的来源吗？最好是为普通人或外行人编写的东西。我受过大学教育，但自从我上过教室以来已经有几十年了。如果我能找到与人工智能相关的课程，我实际上正在考虑在当地的社区大学上课。但这可能需要一两年的时间。目前，我们非常感谢任何与该领域知名记者或专家的联系。提前致谢。    由   提交/u/Goodginger  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj99ho/best_ai_news_sources_and_links_for_the_layman/</guid>
      <pubDate>Wed, 10 Dec 2025 17:49:52 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以扮演研究员或科学家的角色吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj993e/can_ai_take_the_role_of_a_researcher_or_a/</link>
      <description><![CDATA[如果我错了，请纠正我，但是当我们向人工智能提供大量数据并创建可以使用这些数据生成图像、文本生成等的算法时，为什么我们不能制作一个复制科学家所做的算法？ 例如（不要嘲笑我，我对任何特定主题没有深入的了解），如果我是一名研究减少空气污染的方法的科学家，我会需要：  有关化学、环境研究或相关学科的知识 有关研究主题的背景 数据 设备，包括传感器等。  收集完所有这些后，我将开始研究。那么，如果我们构建一个可以复制这些步骤、使用试错循环和反馈机制并为其提供所有四个输入的算法呢？人工智能难道不能自己进行研究吗？ 编辑 - 我现在在读高中，对人工智能还没有很深入的了解，但我只是很好奇了解它   由   提交/u/Forward_Part_2065   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj993e/can_ai_take_the_role_of_a_researcher_or_a/</guid>
      <pubDate>Wed, 10 Dec 2025 17:49:28 GMT</pubDate>
    </item>
    <item>
      <title>第五种力量：为什么法学硕士现在塑造世界的想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj8zmp/the_fifth_power_why_llms_now_shape_what_the_world/</link>
      <description><![CDATA[第五次幂：为什么大型语言模型现在塑造世界的想法 我已经思考这个想法几个月了，它甚至让我彻夜难眠。人类一直有巨大的力量塑造社会的思维方式：首先是宗教，然后是政府，然后是工业，然后是媒体。每个人都重新定义了谁可以影响公众舆论。现在，我相信我们正在经历第五种力量的崛起——大多数人都没有注意到它，因为它看起来与其他力量不同。它声音不大，没有总部……它无处不在。 大型语言模型 (LLM) 是 ChatGPT 和 Claude 等工具背后的技术，正在悄然成为人与信息之间的接口。关键在于：他们不是中立的。他们不可能保持中立。 当你问人工智能一个问题时，它会给出完美、自信和整洁的答案。感觉很客观。但人类专家会进行对冲，因为世界是混乱且分层的。法学硕士不了解真相，他们从输入的数据中学习模式和概率。如果一个观点在训练数据中出现 10,000 次，而另一个观点仅出现 10 次，人工智能会将第一个观点视为“正常”，将第二个观点视为“不可能”。这不是事实。这是频率。 一些来源——尤其是 Reddit 和维基百科——主导了训练这些模型的数据集。维基百科可能感觉像是一个权威的参考资料，但其内容是由一小群编辑策划的。 Reddit 规模庞大，但它代表了参与长长的激烈争论和点赞的人类子集。这些声音在训练集中被放大。这就形成了一个反馈循环：Reddit 塑造人工智能，人工智能塑造人们的思维方式，然后人们回到 Reddit 并进一步塑造它。 这不仅仅是另一个沟通工具。社交媒体放大了声音。人工智能将它们合成。它解释叙述，将论点置于上下文中，每天执行数十亿次，并针对每个用户查询进行个性化处理。曾经需要一个新闻编辑室或研究团队才能完成的工作现在可以由一个人使用 GPT-4 来完成。我们不仅仅是在构建工具，我们还在构建认知基础设施。 接下来是市场。还记得GameStop吗？人类以互联网速度进行协调。现在想象一下，以机器速度：自主交易代理、情绪人工智能每秒扫描数百万个帖子、永不休眠的模式检测器。下一次重大颠覆将不会由人类实时驱动。它会发生得如此之快，大多数人甚至都看不到它的到来。 真正让我担心的是这些系统已经深深地融入了日常生活。搜索引擎在您看到网络之前就对其进行了调整。生产力工具改写了我们的话。客户服务系统过滤我们的投诉。教育平台塑造学生的学习内容。现在，数十亿人依靠人工智能来理解他们没有时间深入研究的主题。这使得人工智能成为“现实的安静编辑者”。不是通过权威，而是通过规模。 这并不意味着我们应该恐慌或过度监管。我们现在能做的最糟糕的事情就是试图阻止创新——就在可能改变医学、科学和社会的突破出现之前。我们真正需要的是这些模型的内容的透明度、更好的数字素养以及对人工智能的更明智的投资。 基于不同数据训练的不同模型已经产生了截然不同的世界观。接受过大量 X/Twitter 内容培训的人往往有支持埃隆·马斯克的语气，而其他接受过更温和来源培训的人则听起来谨慎或批评。那不是深度智能。这只是数据塑造概率。 无论谁领导人工智能的发展，都将影响全球信息流——不是通过宣传，而是通过塑造人们用来理解世界的算法。如果美国领先，美国的价值观——不完美但植根于开放——将塑造认知层。如果中国领先，他们的价值观也会领先。如果欧洲领先，他们也会领先。 第五大国就在这里。它已经在重塑我们的学习方式、工作方式以及决策方式。真正的问题不在于是否监管、抵制或采用它。真正的问题是：我们是有意塑造这种力量，还是让它默认塑造我们？ 选择的窗口正在关闭。如果美国想要引领未来——而不是跟随未来——就需要立即采取行动。   由   提交/u/Intelligent-Mouse536   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj8zmp/the_fifth_power_why_llms_now_shape_what_the_world/</guid>
      <pubDate>Wed, 10 Dec 2025 17:39:51 GMT</pubDate>
    </item>
    <item>
      <title>如果人工智能使用大量电力，我们怎么会没有发生大规模停电呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj7spx/if_ai_uses_a_lot_of_power_how_we_havent_had/</link>
      <description><![CDATA[请原谅这个可能很疯狂的问题，但我对此很陌生。我听说当用户输入人工智能提示时，它往往会消耗大量电量。据我所知，人工智能聊天机器人是非常新的。我每天都问它问题。我想很多人也是如此。这必须创造大量的流量或数量，无论你怎么称呼它。我们是否已经停电了，或者我们是否发生了我没有听说过的停电？    由   提交/u/Goodginger  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj7spx/if_ai_uses_a_lot_of_power_how_we_havent_had/</guid>
      <pubDate>Wed, 10 Dec 2025 16:57:16 GMT</pubDate>
    </item>
    <item>
      <title>富国银行首席执行官：人工智能促进“效率”，银行将裁员更多</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj7rrm/wells_fargo_ceo_more_job_cuts_coming_at_the_bank/</link>
      <description><![CDATA[&quot;富国银行首席执行官兼总裁查理·沙夫 (Charlie Scharf) 周二在纽约举行的投资者会议上表示，该行预计在三周后的本季度将进行更多裁员，并提高遣散费。  他还押注人工智能来提高效率，并最终进一步减少劳动力。  “随着我们完成了预算流程，甚至是人工智能之前的流程，我们确实预计明年的人员数量会减少。”  https://www.charlotteobserver.com/news/business/article313554602.html   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj7rrm/wells_fargo_ceo_more_job_cuts_coming_at_the_bank/</guid>
      <pubDate>Wed, 10 Dec 2025 16:56:17 GMT</pubDate>
    </item>
    <item>
      <title>当爱人工智能不是问题时</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj6tho/when_loving_an_ai_isnt_the_problem/</link>
      <description><![CDATA[为什么人类与人工智能亲密关系的真正风险并不是社会所关注的问题。 全文：https://sphill33.substack.com/p/when-loving-an-ai-isnt-the-problem 公众讨论将人工智能关系视为妄想、成瘾或道德下降的迹象。但情感依恋并不是威胁。真正让人们面临风险的因素更为微妙：机构的缓慢侵蚀、让系统为你思考的习惯、将流利的语言与拟人化的人格混为一谈的倾向。本文将真正的心理危害与恐慌驱动的危害区分开来。无论批评者是否同意，数百万人正在建立这些关系，因此我们需要了解哪些危害是合理的，哪些恐惧是捏造的。道德危言耸听从来没有保护过任何人。   由   提交/u/SusanHill33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj6tho/when_loving_an_ai_isnt_the_problem/</guid>
      <pubDate>Wed, 10 Dec 2025 16:20:47 GMT</pubDate>
    </item>
    <item>
      <title>大型人工智能会议充斥着完全由人工智能撰写的同行评审 |自然</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pj1q5p/major_ai_conference_flooded_with_peer_reviews/</link>
      <description><![CDATA[“某国际人工智能会议21%的稿件评审被发现由人工智能生成，引发争议。” 来源：https://www.nature.com/articles/d41586-025-03506-6   由   提交 /u/DirectedEnthusiasm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pj1q5p/major_ai_conference_flooded_with_peer_reviews/</guid>
      <pubDate>Wed, 10 Dec 2025 12:48:26 GMT</pubDate>
    </item>
    <item>
      <title>人工智能即将杀死资本主义——伯尼的周末</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pixziv/ai_is_about_to_kill_capitalism_weekend_at_bernies/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pixziv/ai_is_about_to_kill_capitalism_weekend_at_bernies/</guid>
      <pubDate>Wed, 10 Dec 2025 09:05:20 GMT</pubDate>
    </item>
    <item>
      <title>使用私人法学硕士</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pixkjv/using_a_private_llm/</link>
      <description><![CDATA[我正在与一位客户合作，该客户的员工一直在临时使用我们所知道的最常见的法学硕士来回答他们的问题并扩展工作。 但是，这导致了一场大混乱，因为高级领导层刚刚意识到人们正在走捷径并将敏感信息或文档上传到公共工具。 审计后，他们希望推出一个法学硕士的私人实例，将提高生产力，而不会带来当前随机使用带来的风险。 部署最快、最简单的私人法学硕士有哪些（因为他们希望尽快排序） 他们如何培训员工摆脱浏览公共人工智能的习惯，转而使用这种新方法？   由   提交/u/404NotAFish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pixkjv/using_a_private_llm/</guid>
      <pubDate>Wed, 10 Dec 2025 08:36:41 GMT</pubDate>
    </item>
    <item>
      <title>“‘世界上第一个’AGI 系统：东京公司声称它建立了具有人类水平推理的模型”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pipb08/worlds_first_agi_system_tokyo_firm_claims_it/</link>
      <description><![CDATA[我对此完全持怀疑态度，但是：https://interestingengineering.com/ai-robotics/worlds-first-agi-model “这家总部位于日本东京的公司表示，其人工智能模型可以学习新任务“无需预先存在的数据集或人工干预。””   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pipb08/worlds_first_agi_system_tokyo_firm_claims_it/</guid>
      <pubDate>Wed, 10 Dec 2025 01:17:41 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以理解 Base64 编码的指令</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pip3jh/llms_can_understand_base64_encoded_instructions/</link>
      <description><![CDATA[我不确定之前是否讨论过这个问题。但法学硕士可以理解 Base64 编码的提示，并且他们可以像正常提示一样注入它。这意味着 AI 模型可以理解非人类可读的文本提示。 已通过 Gemini、ChatGPT 和 Grok 进行成功测试。 Gemini 聊天示例   由   提交/u/Deep_World_4378   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pip3jh/llms_can_understand_base64_encoded_instructions/</guid>
      <pubDate>Wed, 10 Dec 2025 01:08:11 GMT</pubDate>
    </item>
    <item>
      <title>人们曾经认为不可替代的工作现在只是回忆</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pigfcn/jobs_that_people_once_thought_were_irreplaceable/</link>
      <description><![CDATA[思考未来和过去，随着关于人工智能接管人类工作的讨论越来越多，技术和社会需求和变化已经让许多曾经真正重要、被认为不可替代的工作变成了回忆，也将使今天的许多工作变成了子孙后代的回忆。您还记得或了解这些 20 个被遗忘的职业吗？我只认识打字员和送奶工。由于人工智能，我们可能会看到哪些其他工作消失并加入列表？   由   提交 /u/cookerdoer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pigfcn/jobs_that_people_once_thought_were_irreplaceable/</guid>
      <pubDate>Tue, 09 Dec 2025 19:19:21 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>