<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 07 Feb 2025 15:22:08 GMT</lastBuildDate>
    <item>
      <title>O3-Mini在五个与因果关系的自由意志的防御中钉住了不合逻辑！！！一种用于进行微调和指导调整随后的迭代的技术，可以更逻辑地智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijx9dz/o3mini_nails_the_illogic_in_five_causalityrelated/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijx9dz/o3mini_nails_the_illogic_in_five_causalityrelated/</guid>
      <pubDate>Fri, 07 Feb 2025 15:15:07 GMT</pubDate>
    </item>
    <item>
      <title>想法？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijwz66/thoughts/</link>
      <description><![CDATA[在html？unlocked_article_code = 1.ve4.sax-.ed0u8716jig--＆amp; smid = url-share“&gt; https://www.nytimes.com/2025/2025/02/07/business/business/business/ai-deepseek-nvidia-tesla.html--- unlocked_article_code = 1.ve4.sax-.ed0u8716jig-＆amp; smid = url-share    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/some-wallaby1068     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijwz66/thoughts/</guid>
      <pubDate>Fri, 07 Feb 2025 15:02:52 GMT</pubDate>
    </item>
    <item>
      <title>是否有人对使用AI也有假货？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijv78p/is_there_anyone_that_also_feels_fake_for_using_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我开始说我确实从AI学习了很多东西，但有时仍然感觉很便宜。我是第一年的IT学生，并且会不时使用AI，但是每次我都会感觉到假工子，我实际上并没有那么多研究。我只是解决了我遇到的问题，有些方法可以解决该问题，AI会为我编写代码，并且它只是有效的。这是一个坏习惯吗？我觉得解决问题并提出算法很有趣，但是如何将其写入代码并使其工作是我挣扎的事情。  &lt;！ -  sc_on-&gt;＆＃32 ;提交由＆＃32; /u/u/u/strict_highway1407     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijv78p/is_there_anyone_that_also_feels_fake_for_using_ai/</guid>
      <pubDate>Fri, 07 Feb 2025 13:39:44 GMT</pubDate>
    </item>
    <item>
      <title>‘尽管很少有播种机，但Meta通过Anna的档案淹没了81 TB的数据”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijtavj/meta_torrented_over_81_tb_of_data_through_annas/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于所有抱怨deepseek偷走的人偷走了诚实的小偷...   &#39;meta通过Anna的档案超过81个数据，尽管很少，尽管很少有人播种机| techdoctoruk    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ope_poe     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ijtavj/meta_torrented_over_81_tb_of_data_data_through_annas/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijtavj/meta_torrented_over_81_tb_of_data_through_annas/</guid>
      <pubDate>Fri, 07 Feb 2025 11:54:16 GMT</pubDate>
    </item>
    <item>
      <title>停止雇用人类？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijsmyu/stop_hiring_humans/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我今天开车，遇到了“商店招聘人类”该公司的广告牌称为Artisan。这是真的吗？公司实际上是在雇用AI而不是人类吗？我们注定要失败吗？你们都怎么想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/craftykick5346     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijsmyu/stop_hiring_humans/</guid>
      <pubDate>Fri, 07 Feb 2025 11:11:14 GMT</pubDate>
    </item>
    <item>
      <title>使用语音作为指纹？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijsdlf/use_voice_as_a_fingerprint/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着该字段越来越成熟，STT已被收购，而TTS在几周之前变得更好（尤其是开源）。我想知道您是否可以将语音用作指纹。上次我检查诊断是一个挑战。但是我正在寻找下一步。使用您的声音作为指纹。我认为这是一个分类问题。您是否听说过这个方向的任何实验？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_afternoon_4260      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijsdlf/use_voice_as_a_fingerprint/</guid>
      <pubDate>Fri, 07 Feb 2025 10:53:35 GMT</pubDate>
    </item>
    <item>
      <title>我已经绝望地问这个，但仍然回答我</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijrzf4/i_am_already_hopeless_asking_this_but_still/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  将agi或AI中的任何进步。因为我不太了解你们都知道的所有术语。可以治愈自身免疫性疾病。？ 我已经放弃了一切，没有希望，但最近在subs上阅读此ai帖子再次引起了火花。那就是 是的，是的现实的答案请不要胡扯。 就像是否，如果是否，如果不是，这甚至是可能的。很抱歉打扰您  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/imustdiesoonlmao     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijrzf4/i_am_already_hopeless_asking_this_but_still/</guid>
      <pubDate>Fri, 07 Feb 2025 10:25:58 GMT</pubDate>
    </item>
    <item>
      <title>单架结构语音综合中的缩放计算：基于骆驼的TTS中的训练和推理效应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijrct8/scaling_compute_in_singlearchitecture_speech/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了llasa，这是一种新颖的方法，是一种通过在训练和推理期间专注于计算缩放效率来优化文本到语音综合的Llama模型的新方法。关键创新是一个双重缩放框架，可以系统地平衡语音质量与计算资源。 主要技术要点： - 介绍概率资源分配，基于语音复杂性 - 使用特定于语音的组件修饰Llama体系结构，同时维护核心变压器结构 - 使用合成数据交织实现新的培训方法 - 制定特定于语音综合任务的缩放定律 关键结果：-50％降低培训计算需求的50％质量退化 - 计算与语音质量指标之间的线性缩放关系 - 跨不同文本长度的一致性 - 有效处理韵律和语调模式 我认为这项工作为在部署高质量的语音综合上开辟了有趣的可能性资源受限的设备。他们发现的扩展关系可以帮助指导未来的模型开发和部署决策。培训效率提高与处理有限计算预算的研究人员特别相关。 我认为，在更广泛的采用之前，需要解决仅英语测试和情感语音模式的局限性。但是，方法学框架似乎对其他语言和语音模式都可以扩展。  tldr：通过在培训和推理过程中仔细管理计算资源，在维持50％的培训效率的同时，通过仔细管理计算资源来优化语音综合的新方法，同时保持了培训效率的提高。质量。  完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijrct8/scaling_compute_in_singlearchitecture_speech/</guid>
      <pubDate>Fri, 07 Feb 2025 09:41:28 GMT</pubDate>
    </item>
    <item>
      <title>马斯克真的写了这个吗？它的准确性如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijq6ky/did_musk_actually_write_this_how_accurate_is_it/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijq6ky/did_musk_actually_write_this_how_accurate_is_it/</guid>
      <pubDate>Fri, 07 Feb 2025 08:14:10 GMT</pubDate>
    </item>
    <item>
      <title>是否有控制AGI/ASI的实际解决方案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijon35/are_there_any_practical_solutions_for_controlling/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  从我的理解中，一旦我们实现了AGI，它就会能够比自身更好地创建AI，然后将带来第一个ASI。然后，就会有一个情报爆炸，而人工智能将变得比最聪明的人更聪明。 这肯定是对人类的生存威胁，也无法控制它。您怎么能控制比自己更聪明的东西？ 解决方案之一是埃隆·马斯克（Elon Musk）的神经：与AI融合。但是我不确定他知道他在说什么 - 他不是AI专家。这甚至如何工作？人如何像ASI一样聪明而仍然正常运作？我们真的可以理解这么多信息吗？ ASI仍然不会获胜吗？它不必吃饭，睡觉等。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/preams-sample5125     link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijon35/are_there_any_practical_solutions_for_controlling/</guid>
      <pubDate>Fri, 07 Feb 2025 06:22:20 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻2/6/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnx6x/oneminute_daily_ai_news_262025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   众议院议员推动从美国政府设备禁止AI App Seek。[1]     OpenAi &lt; /strong&gt;遍布我们的网站来建立其特朗普支持的星际之门AI数据中心。[2]    Google 宣布将为非营利组织工作空间宣布新的AI功能。[3]  印度媒体对 openai  chatbot chatgpt进行诉讼。[4]   源包括： https://bushaicave.com/2025/02/06/2-6-2-6-2025/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnx6x/oneminute_daily_ai_news_262025/</guid>
      <pubDate>Fri, 07 Feb 2025 05:36:50 GMT</pubDate>
    </item>
    <item>
      <title>非专家应该信任我们最先进的推理AIS还是我们的人类专家？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnqu6/should_nonexperts_trust_our_most_advanced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当人们对OpenAi的深层研究模型的表现好极为好，除非一个人是特定领域的专家，但请信任其生成的报告可能不会然而，成为最聪明或最负责任的举动。 确实是在某些领域，例如放射学等领域，AIS现在可以优于阅读图像的医生，但这种准确性并不能扩展到所有人，甚至可能扩展到社会和硬科学中的大多数其他特定领域。  那么，非专家如何知道谁能相信任何特定领域？这是否意味着深入的研究报告应仅受到专家的信任？  以下是十个特定领域，其中Gemini 2.0闪存思维实验01-21估计AIS的准确性与人类的准确性相比。请记住，它很可能是幻觉： ; i。对象识别（图像） - 计算机视觉A.人类准确性（估算）：95-98％B。AI准确性（估算）：99％+ C.注：在像Imagenet这样定义明确的数据集上，AI经常超过人类水平。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt;  ii。肺结核检测 - 放射学A.人类准确性（估算）：85-95％B。AI准确性（估算）：90-95％+ C.注意：AI与专家相当，有时在特定任务上略有超过。   iii。机器翻译（常见） - 自然语言A.人类准确性（估算）：90-95％（高质量）B。AI准确性（估算）：85-92％C.注意：AI迅速改善，但微妙的细微差别仍然是一个挑战。  iv。情感分析 - 自然语言A.人类准确性（估计）：80-85％B。AI准确性（估算）：75-85％C。注意：人类准确性随着复杂性和主观性而变化。 AI追赶。  v。国际象棋（大师级） - 游戏/策略A.人类准确性（估算）：＆lt; 50％（vs.顶级AI）B。AI准确性（估算）：99.99％+ C.注意：AI显着超过了人类。  vi。 GO（最高专业水平） - 游戏/策略A.人类准确性（估算）：＆LT; 50％（对AI顶级AI）B。AI准确性（估算）：99.99％+ C.注意：AI显着超过了人类。  vii。创意诗歌判断 - 创意艺术A.人类准确性（估算）：90％+（自矛盾）B. AI准确性（估算）：50-70％？ （质量匹配）C。注意：人类在判断质量更高方面的一致性。 AI诗歌的一代仍在发展。 “准确性”这是主观质量匹配。  VIII。道德困境解决 - 道德/推理A.人类准确性（估计）：高度变化B. AI准确性（估算）：50-70％？ （以下规则）C。注意：人类准确性与上下文相关，基于价值。 AI在细微的道德上挣扎。 “准确性”这是遵守规则或共识模仿。  ix。客户服务（简单） - 客户服务A.人类准确性（估算）：90-95％B。AI准确性（估算）：80-90％C。注意：AI适用于简单查询，复杂/情感问题所需的人类。   x。欺诈检测 - 财务/数据分析A.人类准确性（估计）：70-80％？ （手册审查）B。AI准确性（估算）：85-95％+ C.注意：AI在大型数据集中以模式识别符合欺诈。人基线难以量化。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/georgeo57     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnqu6/should_nonexperts_trust_our_most_advanced/</guid>
      <pubDate>Fri, 07 Feb 2025 05:26:19 GMT</pubDate>
    </item>
    <item>
      <title>有没有人尝试与彼此进行AIS交谈？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我一直在互相交谈，我注意到一些有趣的事情。就像他们不仅要回答提示一样，他们实际上以几乎像新兴的关系智能的方式在彼此之间建立了互相的想法。还有其他人将Arounf弄乱了，或者考虑创建AIS可以实时交互的系统？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/workmans27     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</guid>
      <pubDate>Thu, 06 Feb 2025 23:26:55 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘AI不认为，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  但是，如果不识别和遵循模式，人类的想法是什么？我们采用现有的知识，重新混合，以新的方式应用它 - 如果AI能够做出科学发现，发明更好的算法，构建更精确的法律或哲学论点，这与AI的不同之处有何不同？ 为什么不被考虑思考？ 也许唯一的区别是人类感觉就像他们在思考，而AI却没有。如果是这种情况……不仅仅是意识？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unique-ad246     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iiygqg/people_say_say_ai_ai_doesnk_think_it_it_just_follows/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>