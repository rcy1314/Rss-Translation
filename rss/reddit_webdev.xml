<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：webdev</title>
    <link>https://www.reddit.com/r/webdev/new</link>
    <description>致力于所有 Web 开发的社区：前端和后端。有关更多与设计相关的问题，请尝试 /r/web_design。</description>
    <lastBuildDate>Sun, 22 Feb 2026 02:38:31 GMT</lastBuildDate>
    <item>
      <title>我创建了一个用于搜索数千张公共领域图像的网站</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb93ze/i_made_a_website_for_searching_thousands_of/</link>
      <description><![CDATA[      我觉得在人工智能生成图像的时代，我们应该更多地思考如何发现已经存在于公共领域（即完全免费使用）的数百万张有趣的图像。  我从不同的博物馆、图书馆等收集了数千张图像（仍在进行中）。我将所有图像嵌入到矢量表示中并为其添加了标题，因此您可以在图像内部进行搜索（例如，搜索狗或船的图画，即使标题或标题不包含这些内容）。仍在进行中，但我对迄今为止的工作方式感到自豪，加载这么多图像绝对是一个有趣的挑战！ 第一次搜索仍然需要一些时间，因为嵌入模型必须在浏览器中加载，但每天都在努力优化它并添加更多图像！希望获得反馈并乐意回答任何问题！   由   提交 /u/Unmoovable   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb93ze/i_made_a_website_for_searching_thousands_of/</guid>
      <pubDate>Sun, 22 Feb 2026 01:51:23 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个免费的基本财务数据 REST API + Google Sheets 插件，可将标准化且干净的数据直接提取到您的电子表格中</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb7tym/i_built_a_free_fundamental_financial_data_rest/</link>
      <description><![CDATA[      大家好， 我构建了一个基本的财务数据 REST API 作为个人/爱好项目以及完全免费的 Sheets 插件 此处直接从 SEC 文件中获取非结构化且杂乱的数据，然后将其清理并标准化，直接放入您的电子表格中（支持损益表、资产负债表、现金流量表和年度/季度报表）。 例如，公式： =FINQUALX(&quot;/profit-statement&quot;, &quot;AAPL&quot;, 2020, 2025, FALSE)  按年份提取年度损益表并自动更新。 请注意，这仍然是一项正在进行的工作，因此可能仍然存在一些错误/限制，但希望听到任何反馈。 I我们已在此处提供了一个示例电子表格，并在此处提供了设置指南。 如果有的话请告诉我疑问/问题！   由   提交 /u/myztaki   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb7tym/i_built_a_free_fundamental_financial_data_rest/</guid>
      <pubDate>Sun, 22 Feb 2026 00:52:12 GMT</pubDate>
    </item>
    <item>
      <title>我的个人待办事项应用程序的 Todoist 风格自然日期输入</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb7hes/todoiststyle_natural_date_input_for_my_personal/</link>
      <description><![CDATA[       https://preview.redd.it/9066t9ww1ykg1.png?width=2032&amp;format=png&amp;auto=webp&amp;s=eafbd4ddd09642ceecdc5371ae50f973f8f5fe44 我一直推迟在我的个人待办事项应用程序中添加截止日期，因为我希望一切都首先是键盘。我喜欢 Todoist 用自然语言实现它的方式，所以我构建了相同的功能。 您不用点击日期选择器，而是输入“星期五”、“明天”等。或“3/1”在输入待办事项时设置日期。 库 提示点击 - 富文本编辑用户体验 这可以在待办事项列表项中突出显示日期。 我非常喜欢这个库。几周前，当我尝试构建像谷歌文档这样的协作文本编辑器时，我第一次使用了它。它可以很容易地确定谁在界面中输入 Chrono Node - 自然语言日期解析器 我让 Claude 为我编写了日期解析逻辑，它只处理基本情况。在写这篇文章时，我了解了 Chrono Node 库，它可能会更加强大。 PR 实现这个 https://github.com/every-app/every-app/commit/102398774d2139bda22ae72bc191e1b2cfcd230f   由   提交 /u/theben9999   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb7hes/todoiststyle_natural_date_input_for_my_personal/</guid>
      <pubDate>Sun, 22 Feb 2026 00:36:19 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个免费的 yt-dlp Web 前端，支持 1000 多个网站 - 没有广告，没有水印，适用于移动设备</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb6whl/i_built_a_free_ytdlp_web_frontend_that_supports/</link>
      <description><![CDATA[   每个视频下载网站都是虚假按钮和弹出广告的噩梦。我自己建立了一个规则：永远不要有广告。不是现在，不是在它流行的时候，不是为了支付服务器成本。永远免费，永远干净。 技术堆栈：Node.js + Express、纯 HTML/CSS/JS、yt-dlp + ffmpeg。没有框架，没有构建步骤，没有废话。 我在构建它时学到的东西可能会节省您的时间： - 不要通过 stdout 流式传输 yt-dlp。看起来很优雅，在任何需要 ffmpeg 合并的格式上都会无声地中断（大多数 YouTube 下载）。通过 /tmp 路由所有内容 - 它基于 Linux 的 RAM，因此不会写入磁盘，流式传输到客户端后会立即进行清理  - TikTok 会阻止所有非浏览器请求。修复：--impersonate - Reddit 在网络级别阻止数据中心 IP。没有标头或用户代理欺骗可以修复它。现在只是显示 Reddit URL 的友好错误  - res.on(&#39;close&#39;) 而不是 req.on(&#39;close&#39;) - req 在读取 POST 正文时触发，这几乎是即时的。在我发现这个之前，每次下载都会杀死 yt-dlp 它的作用： - 通过 yt-dlp 访问 1000 多个平台 - MP4、MP3、FLAC、WAV、AAC、MKV、GIF 转换、缩略图提取 - 一次批量下载最多 10 个 URL - 适用于 iPhone 和浏览器中的 Android，不需要应用程序 - 没有帐户，没有跟踪，没有广告 - 说真的，没有 https://dltkk.to 很高兴回答有关实施的任何问题。   由   提交/u/Strong-Goalie   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb6whl/i_built_a_free_ytdlp_web_frontend_that_supports/</guid>
      <pubDate>Sun, 22 Feb 2026 00:10:34 GMT</pubDate>
    </item>
    <item>
      <title>Safari 标签囤积者的扩展</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb4l30/an_extension_for_safari_tab_hoarders/</link>
      <description><![CDATA[它名为 TrimTabs，在 safari 桌面版 osx 应用商店中免费，但 IOS 很快就会添加。我发现，如果您向苹果提交一个不向服务器发送数据、也不收集任何个人数据的应用程序商店条目，那么批准就是一天！ https://clovellysoftware.com.au/trimtabs/ 我是那种最终会打开 300 个选项卡的浏览器用户，所以写这个是为了应对关闭它们或保存它们的组。它根本不与浏览器书签交互，因为没有相应的 api。 无论如何，请检查一下 - 欢迎其他标签囤积者提供反馈   由   提交/u/Street-Air-546  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb4l30/an_extension_for_safari_tab_hoarders/</guid>
      <pubDate>Sat, 21 Feb 2026 22:31:51 GMT</pubDate>
    </item>
    <item>
      <title>我厌倦了构建相同的 SaaS 样板，因此我构建了一个 MCP 服务器来让我的 IDE 找到独立的 API（FastAPI + SQLite）</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb4idn/i_got_sick_of_building_the_same_saas_boilerplate/</link>
      <description><![CDATA[Vibe-coding 很酷，直到你意识到 Cursor 刚刚烧掉了 50k 代币，从头开始编写了一个有缺陷的计费系统，而 9 美元/月的独立 API 已经存在。 周末我构建了 IndieStack - 一个包含 100 多个独立 SaaS 工具的目录。但真正的产品是附加到它的 MCP 服务器。 它是如何工作的： - 要求 Claude Code “添加分析” - MCP 服务器不是生成样板文件，而是查询我的 SQLite 数据库 - 它会找到像 Plausible 这样的独立工具，并向您提供集成片段 - 您可以节省代币、时间和金钱 堆栈： - FastAPI + SQLite 和 FTS5 用于全文搜索 - 纯服务器渲染的 HTML（零 JS 框架） - 通过 Python SDK 的 MCP 服务器 - 单个 Fly.io 机器，单个 .db 文件 否反应。没有 Next.js。没有 Postgres。没有 Redis。 目前可以毫不费力地在单个 SQLite 文件上处理来自 5 个以上 subreddits 的流量。 TTFB 约为 220 毫秒。 尝试一下： https://indiestack.fly.dev 让我知道 MCP 延迟对于您的工作流程来说是否足够快 - 以及我缺少哪些独立工具。   由   提交/u/edmillss  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb4idn/i_got_sick_of_building_the_same_saas_boilerplate/</guid>
      <pubDate>Sat, 21 Feb 2026 22:28:39 GMT</pubDate>
    </item>
    <item>
      <title>您同时检查其他网站的 CSS 和 SEO 的工作流程是怎样的？</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb4102/whats_your_workflow_for_inspecting_other_sites/</link>
      <description><![CDATA[好奇其他开发人员在这里做什么。当我查看一个网站时 - 无论是竞争对手、我喜欢的设计还是调试我自己的东西 - 我总是会打开 4 个选项卡：  - CSS 开发工具  - PageSpeed Insights for importants  - 一些用于元/架构的 SEO 扩展  - 用于技术堆栈的BuiltWith 或 Wappalyzer 这感觉很愚蠢。我最终构建了自己的工具，将所有这些工具组合到一个基于悬停的检查器中，但我很好奇其他人是否有更好的设置，或者你们中的大多数人是否只是使用 DevTools 并收工。 您的“检查站点”是什么意思？工作流程实际上是什么样子？   由   提交 /u/spacepings   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb4102/whats_your_workflow_for_inspecting_other_sites/</guid>
      <pubDate>Sat, 21 Feb 2026 22:08:20 GMT</pubDate>
    </item>
    <item>
      <title>我们构建了唯一的数据网格，让您永远不必使用“useEffect”或再次遇到同步问题。 LyteNyte 网格 2.0 简介。</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb3iqj/we_built_the_only_data_grid_that_allows_you_to/</link>
      <description><![CDATA[   每个可用的 React 数据网格的主要问题是，它要求开发人员使用可怕的 useEffect 或类似的效果处理程序编写代码，主要是在将状态与 URL 参数同步时。 LyteNyte Grid v1 比其他数据网格库更少固执己见，但仍然强制执行固执己见的结构对于排序、筛选和分组模型，如果您的数据源不符合我们的模式，就会产生摩擦。 这些问题并非我们所独有。每个数据网格都会碰到这堵墙。 直到今天！我们很自豪地宣布正式推出 LyteNyte Grid v2。 LyteNyte Grid v2 已经100% 无状态且完全由 prop 驱动。这意味着您可以从您的状态以声明方式配置它，无论是 URL 参数、服务器状态、Redux 还是您可以想象的任何其他内容。实际上，您再也不必处理令人头痛的同步问题。 我们的 2.0 版本还带来了约 30kb 的较小压缩包大小、可实现更快设置的混合无头模式以及基于本机对象的树数据。此外，我们的新 API 提供了几乎无限的可扩展性。 我们编写了 130 多个深入指南，每个指南都有详尽的解释、实际演示和代码示例。使用 LyteNyte Grid 2.0 所需的一切。  有关该版本的更多详细信息，请查看我们的博客。 给我们反馈 这对我们来说只是一个开始。 LyteNyte Grid 2.0 受到现有用户反馈的显着影响，我们对此表示感谢。 我们计划支持 LyteNyte Grid 的 Vue JS 版本。如果您有兴趣关注开发，请在我们的存储库中给这个问题点赞。 如果您的 React 项目需要一个免费的开源数据网格，请尝试 LyteNyte Grid。它是零成本且在 Apache 2.0 下开源。 如果您喜欢我们正在构建的内容，GitHub 星星会提供帮助，并且随时欢迎提供功能建议或改进。  GitHub 实时演示    由   提交/u/After_Medicine8859  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb3iqj/we_built_the_only_data_grid_that_allows_you_to/</guid>
      <pubDate>Sat, 21 Feb 2026 21:47:12 GMT</pubDate>
    </item>
    <item>
      <title>这种架构和故障处理方法看起来合理吗？</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb3516/does_this_architecture_and_failurehandling/</link>
      <description><![CDATA[Scraper 设置 – 快速概述 架构  Orchestrator (run_parallel_scraper)：生成 N 个工作进程（我们使用 3 个），为每个工作进程分配一个页面范围（例如 1–250、251–500、501–750），每个工作进程一个代理（对于运行来说是粘性的），错开工作线程的启动时间（例如 20-90 秒）以减少类似机器人的爆发。 工作线程：每个线程都使用 --start-page / --max-pages 运行 daily_scraper； discovery-only = 仅浏览页面，不抓取产品页面。  代理  WebShare API；子网多样性，因此没有两个工作人员共享相同的 /24。 通过 WORKER_PROXY_URL 的工作人员代理；用于排除 IP 的上次运行和不良代理列表。  发现流程（每个工作人员）  每个工作人员一个 Playwright (Chromium) 页面、无头、指纹识别（视口、UA）、图像/字体/样式被阻止。 导航到浏览 URL → 关闭 cookie 横幅、禁用区域过滤器 → 分页（例如？p=2、 ?p=3, …)。 对于每个页面：等待产品选择器（有超时）、获取 HTML、解析、保存到 DB；然后转到下一页。 默认超时：60 秒导航，30 秒操作（因此没有无限制的等待）。  失败处理  导航失败（超时、ERR_ABORTED 等）：重试同一 URL 最多 3 次，并进行回退；如果仍然失败，请将页面添加到“失败的发现页面”并继续下一页（无全程中止）。 “目标页面/上下文/浏览器关闭”：重新创建浏览器和页面一次，重试相同的导航；如果仍然失败，则跳过页面。 发现页面超时（例如 page.content() 挂起）：工作人员写入简历文件（最后一页，保存的计数），以代码 2 退出； Orchestrator 使用新的代理和恢复范围（从该页面开始）重新生成该 Worker。 Worker 运行时间过长：Orchestrator 在 60 分钟挂钟后终止；使用新代理重试工作程序（如果退出为 2，则恢复）。 运行结束：对于失败页面列表，最多 3 次“重试失败的发现页面”(discover_pages_only)。 追赶：编排器从工作程序结果文件推断丢失的范围（保存的计数 → 完成的页数），并使用新代理运行额外的工作程序以抓取这些范围。  数据  所有工作人员都写入同一个 Supabase 数据库（发现的游戏、列表、价格）。 工作人员结果文件 (worker_N_result.json) 记录该运行的开始/最大页面和保存的_from_discovery；使用代码 2 退出时使用的恢复文件。  运行生命周期  运行完成时可选的 Discord Webhook（成功/失败、游戏已保存、工作人员正常/失败、持续时间）。 写入的会话报告文件（例如 scraper_session_*.txt）。  我们使用的配置  3 个工作人员，总共 750 个发现页面，仅限发现。 2GB Droplet；使用 nohup 在后台运行...&gt; parallel.log 2&gt;&amp;1 &amp;.  “我们有时会看到：导航超时（例如 ERR_ABORTED）、page.content() 或 goto 挂起、浏览器/页面关闭（例如几页后），以及在成功之前失败几次的奇怪工作程序。我们使用退避重试，在“关闭”时重新创建浏览器，并在超时时使用简历 + 新代理。” “我们使用 2GB 的 Droplet，有 3 个工作线程；想知道资源限制或代理质量是否有所影响。” 任何改进建议都会很棒。谢谢！   由   提交/u/ZaKOo-oO   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb3516/does_this_architecture_and_failurehandling/</guid>
      <pubDate>Sat, 21 Feb 2026 21:31:46 GMT</pubDate>
    </item>
    <item>
      <title>对我为我的吉他老师建立的网站的反馈请求！:)</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb33f6/feedback_request_for_the_website_i_built_for_my/</link>
      <description><![CDATA[嗨！我为我的吉他老师建立了一个小型登陆页面，我真的很感谢更有经验的开发人员提供一些诚实的技术反馈。 我知道的一些事情： 我可能使用了太多字体，我仍在弄清楚如何平衡个性与一致性。 可用的老师照片并不多（我使用的是给我的照片），所以我特别好奇你如何在有限的情况下处理视觉层次结构或信任建立图像。 我不是在推销这项业务！作为一名开发人员，我只是真诚地努力提高自己。   由   提交/u/No-Vegetable5956   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb33f6/feedback_request_for_the_website_i_built_for_my/</guid>
      <pubDate>Sat, 21 Feb 2026 21:29:58 GMT</pubDate>
    </item>
    <item>
      <title>对我的 ALS 资源网站的反馈请求</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb27uj/feedback_request_for_my_als_resource_site/</link>
      <description><![CDATA[      大家好！我于 2023 年 6 月被诊断出患有 ALS。目前我一直坐在轮椅上，只有颈部有一点活动。我正在建立一个仅使用眼睛注视的网站。我无论如何都不是专业人士，但在确诊之前我已经建立了一个当地动物救援网站。通过反复试验自学。 该网站旨在帮助 ALS 患者找到提供所需资源的组织。该站点符合 WCAG 2 AAA 标准。我花了很多时间来确保字体、大小、对比度和布局易于访问。搜索可以按关键字或状态进行，结果按帖子浏览量排序。您还可以按类别图标拉出组织。目前，我的数据库中只有 11 个组织可供测试，但很快就会开始添加更多组织。 我计划主要通过 ALS 诊所推广该网站，并且已经获得了对 Kaiser 和 ALS United 的支持。  请告诉我您可能有的任何反馈。请记住我是业余爱好者所以没什么可疯狂的。我只使用基本的插件、缓存、搜索引擎优化、表单。还试图保持成本可控，因此只有在我确实能证明合理的情况下才使用付费服务。我有一个链接的 Gofundme，希望能确保该网站在我离开后仍能保持很长时间。我在捐赠页面上保留了可下载的损益表，以便所有资金都是透明的，并有一个小博客来跟踪我的发展。其余的（例如自定义搜索规则）是在子主题中编码的。使用GeneratePress premium和GenerateBlocks。   由   提交/u/isneeze_at_me  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb27uj/feedback_request_for_my_als_resource_site/</guid>
      <pubDate>Sat, 21 Feb 2026 20:53:54 GMT</pubDate>
    </item>
    <item>
      <title>JotBird – 立即将 Markdown 发布到 URL</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb1x5c/jotbird_instantly_publish_markdown_to_a_url/</link>
      <description><![CDATA[      嘿，大家！我是 Markdown 指南 的作者，并构建了 JotBird，因为我一直遇到同样的问题：我会在 Markdown 中编写一些内容，并需要与没有 GitHub 帐户或不知道 .md 文件是什么的人共享。 现有选项都矫枉过正了。 GitHub Gist 呈现 markdown，但 URL 看起来像代码存储库。部署到 Vercel 或 Netlify 是可行的，但它是一个文档的整个项目。 Google 文档意味着重新格式化所有内容。 因此，我构建了最简单的东西：粘贴 markdown（或使用 CLI/API）并获取看起来像普通网页的可读 URL。就是这样！无需帐户。 它处理的内容：  自动图像托管（无 S3 步骤） 语法突出显示的代码块 重新发布更新相同的 URL LaTeX/MathJax 方程 带有样式的标注  如何实现有效：  Web 应用： 编写并单击发布 CLI： npm install -g jotbird，然后jotbird 发布自述文件 API： POST markdown，获取 URL Obsidian 插件： 从编辑器中一键发布  使用网络应用程序或 Obsidian 插件不需要任何帐户。免费帐户获得具有 90 天有效期的链接。 Pro（29 美元/年）使它们永久有效。发布的页面默认为 noindex。 CLI 和 API 是开源。 更多信息：https://www.jotbird.com 很乐意回答有关堆栈、方法等的问题。欢迎提供反馈——好的、坏的或残酷的。 :)   由   提交 /u/captcone   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb1x5c/jotbird_instantly_publish_markdown_to_a_url/</guid>
      <pubDate>Sat, 21 Feb 2026 20:41:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 BirdNET-Go 构建太阳能鸟类站</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb1akj/building_a_solarpowered_bird_station_with/</link>
      <description><![CDATA[ 由   提交 /u/chicametipo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb1akj/building_a_solarpowered_bird_station_with/</guid>
      <pubDate>Sat, 21 Feb 2026 20:15:42 GMT</pubDate>
    </item>
    <item>
      <title>寻找需要可靠自动化和云支持的企业</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb11f5/seeking_businesses_that_need_reliable_automation/</link>
      <description><![CDATA[我们构建智能、可扩展的业务解决方案，推动自动化、效率和长期增长。凭借多年成熟的交付和强大的客户保留率，我们通过定制应用程序、网站和系统自动化帮助组织简化运营。 我们跨 Amazon Web Services、Microsoft Azure、SAP 和 Google Cloud Platform 部署和管理解决方案 - 以极具竞争力的价格提供无与伦比的专业精神。 让我们以正确的方式实现自动化和扩展您的业务。   由   提交 /u/onetyonefour   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb11f5/seeking_businesses_that_need_reliable_automation/</guid>
      <pubDate>Sat, 21 Feb 2026 20:05:33 GMT</pubDate>
    </item>
    <item>
      <title>最受人工智能炒作的网站奖颁发给</title>
      <link>https://www.reddit.com/r/webdev/comments/1rb0waa/most_ai_hyped_site_award_goes_to/</link>
      <description><![CDATA[      制作此网站只是为了好玩 https://most-ai-mentions.com/ 使用爬虫程序对 AI 炒作词和发光彩虹动画的网站进行排名！   由   提交/u/drnlrmr   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/webdev/comments/1rb0waa/most_ai_hyped_site_award_goes_to/</guid>
      <pubDate>Sat, 21 Feb 2026 20:00:01 GMT</pubDate>
    </item>
    </channel>
</rss>