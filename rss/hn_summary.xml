<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>HN 摘要</title>
    <link>https://tg.i-c-a.su</link>
    <description>由大型语言模型编写的热门 Hacker News 故事的自动摘要。</description>
    <lastBuildDate>Sat, 06 Jul 2024 06:14:24 GMT</lastBuildDate>
    <item>
      <title>19 世纪，随着铁路在美国各地扩张，平克顿侦探社填补了 [...]</title>
      <link>https://t.me/hn_summary/98298</link>
      <description><![CDATA[私营公司和公开消息源让间谍们忙得不可开交
19 世纪，随着铁路在美国各地扩张，平克顿侦探社通过招募线人并将档案交给警长填补了执法部门的空白。如今，互联网发挥着类似的作用，由前情报官员 Andrew Borene 领导的 Flashpoint 等私营公司在线监视恐怖组织和敌对情报机构。这项工作曾经是间谍机构的专属，现在由政府和企业共同承担。私营部门情报的兴起为传统情报机构提供了新工具和非机密数据，但也模糊了公开信息和秘密信息之间的界限，引发了法律、道德和隐私问题。前中央情报局官员杜亚内·诺曼指出，私营部门和公共部门利益的分离是西方独有的构想，具有显著的优势和后果。]]></description>
      <guid>https://t.me/hn_summary/98298</guid>
      <pubDate>Sat, 06 Jul 2024 06:14:24 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 标题：商店扒手爱乐高</title>
      <link>https://t.me/hn_summary/98297</link>
      <description><![CDATA[商店扒手喜欢乐高
标题：商店扒手喜欢乐高

网站：www.cnn.com

乐高深受各个年龄段的粉丝喜爱，但它也越来越成为盗窃的目标，无论是个人商店扒手还是有组织的犯罪团伙都觊觎这些可以赚取可观转售利润的高价值套装。洛杉矶县一家乐高转售店的老板米格尔·祖尼加 (Miguel Zuniga) 就曾遭遇过入室盗窃，窃贼偷走了价值 5,000 至 7,000 美元的乐高积木。零售犯罪专家指出，乐高玩具很容易转售，而且很难追踪，因此成为首要目标。最近，多个州甚至加拿大都报告了盗窃事件。乐高玩具的不断更新和流行文化的结合推动了人们对乐高玩具的需求，这也刺激了假冒市场的发展。尽管面临挑战，但社区仍对受影响的零售商表现出了强烈的支持，凸显了许多人与该品牌的情感联系。]]></description>
      <guid>https://t.me/hn_summary/98297</guid>
      <pubDate>Sat, 06 Jul 2024 06:09:20 GMT</pubDate>
    </item>
    <item>
      <title>布罗德研究所研究员索尼娅·瓦拉巴 (Sonia Vallabh) 最初认为基因组编辑是一种 [...]</title>
      <link>https://t.me/hn_summary/98296</link>
      <description><![CDATA[为了摆脱疾病，研究人员创造了强大的表观遗传编辑器
Broad Institute 的研究员 Sonia Vallabh 最初认为基因组编辑是治疗朊病毒病的可行方法，尽管经常有人建议使用 CRISPR。Vallabh 和她的丈夫 Eric Minikel 正在紧急致力于开发一种治疗这种罕见神经退行性疾病的方法，这种疾病夺走了她 51 岁母亲的生命，也威胁着 Vallabh 本人。朊病毒病是由一种基因突变引起的，这种突变会导致产生错误折叠的朊病毒蛋白，这些蛋白会扩散并杀死神经元。本文探讨了为什么 CRISPR 尽管前景光明，但对于这种疾病来说却并不简单。本内容仅供 STAT+ 订阅者使用。]]></description>
      <guid>https://t.me/hn_summary/98296</guid>
      <pubDate>Sat, 06 Jul 2024 06:04:15 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 网站：how.wtf</title>
      <link>https://t.me/hn_summary/98295</link>
      <description><![CDATA[Curl 原生支持 –aws-sigv4 (2023)
标题：Curl 原生支持 –aws-sigv4 (2023)
网站：how.wtf

Thomas Taylor 解释了 Curl 现在如何原生支持 AWS 签名版本 4 (SigV4) 的 API 请求，从而更轻松地与 AWS IAM 授权的 API 网关集成。通过将 Curl 与 --aws-sigv4 选项结合使用，用户可以无缝验证 HTTP 请求。提供的示例演示了如何构造 Curl 命令，包括必要的 AWS 凭证和特定的 AWS 服务 (execute-api)。此集成简化了开发人员使用 AWS 服务的流程，确保了安全且经过身份验证的 API 交互。这里的独特之处在于 Curl 的原生支持，它简化了 AWS API 请求，无需额外的工具或库。]]></description>
      <guid>https://t.me/hn_summary/98295</guid>
      <pubDate>Sat, 06 Jul 2024 05:59:10 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 1Password 和 2FA：将密码和一次性代码一起存储是错误的吗？</title>
      <link>https://t.me/hn_summary/98294</link>
      <description><![CDATA[1Password 和 2FA：将密码和一次性代码一起存储是错误的吗？（2023）
2015 年，1Password 引入了对基于时间的一次性密码 (TOTP) 的支持，允许用户将其用作双因素身份验证 (2FA) 的身份验证器。随着 2FA 变得越来越普遍，人们开始质疑在 1Password 中而不是专用的身份验证器应用程序中同时存储密码和 TOTP 的安全性。简短的回答是它更安全、更方便。文章解释说，真正的 2FA 需要单独且不同的因素，如果两个秘密都存储在同一设备上，则无法实现。然而，对于大多数用户来说，在 1Password 中存储 TOTP 的便利性超过了最小的安全风险。关键点是，没有错误的方式来增强帐户安全性；最佳选择取决于个人需求和风险承受能力。]]></description>
      <guid>https://t.me/hn_summary/98294</guid>
      <pubDate>Sat, 06 Jul 2024 05:36:00 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 你是否厌倦了总是使用 ChatGPT，并且对如何构建自己的语言感到好奇 [...]</title>
      <link>https://t.me/hn_summary/98293</link>
      <description><![CDATA[以下是如何使用 PyTorch 从头开始​​构建和训练 GPT-2
您是否厌倦了总是使用 ChatGPT，并对如何构建自己的语言模型感到好奇？好吧，您来对地方了！今天，我们将从头开始创建 GPT-2，这是 OpenAI 开发的一种强大的语言模型，它可以通过预测序列中的下一个单词来生成类似人类的文本。为了更深入地了解 GPT-2 的理论和架构，我强烈建议您阅读 Jay Alammar 的《The Illustrated GPT-2》。本文对 GPT-2 及其内部工作原理进行了出色的视觉和直观解释。我将参考文章中的一些视觉效果来更好地解释事情。

我试图让它尽可能简单。任何具有 Python 或机器学习水平的人都可以跟着一起构建模型。这个项目将带你完成构建简单 GPT-2 模型的所有步骤，并在一系列 Taylor Swift 和 Ed Sheeran 的歌曲上进行训练。我们最后会看到它会产生什么结果 :)。本文的数据集和源代码将在 Github 上提供。我还将添加一个 Jupyter Notebook 来复制这篇文章，这样你就可以跟着一起运行代码并理解。

我们将逐步完成这个项目，不断改进一个基本模型，并在原始 GPT-2 实现的基础上添加层。以下是我们将遵循的步骤：

1. 构建自定义 Tokenizer
2. 构建数据加载器
3. 训练简单的语言模型
4. 实现 GPT-2 架构（第 2 部分）

该项目分为两部分，第一部分介绍语言建模的基础知识，第二部分直接进入 GPT-2 实现。我建议您按照文章进行操作并自行构建，这会使学习 GPT-2 更加有趣和有趣。

注意：整个项目将在一个 python 文件中完成，因此您可以轻松地逐块进行操作。

最终模型输出：

你的夏天可能有一个问题，你正在尝试
我希望你会打电话
哦，哦，
我会成为很多人的我只是走了
你很抱歉“你站在爱中，
有些事情会永远等待带来&#39;你不想想这个故事如果你是完美的
我想要你的美丽
你偷偷摸摸地让你让我
这不认为它想要你这个足以孤独的事情
这是一位公爵夫人，我什么也没做，家里没有头
哦，但是你离开了我
是掌声的少了一对
亲爱的，他现在拥有我了
但是你在找我们吗？“
如果我看到你会没事的
你明白，一个出局的等我我不能打电话
一切
哦，没有文字不要读我
你应该是这样的
你正在做你这么累的事情，
如果你，你得到了完美的秋天

喜欢这首歌吗？那么让我们开始构建...

1.构建自定义Tokenizer
语言模型不像我们那样看待文本。相反，它们将数字序列识别为特定文本的标记。因此，第一步是导入我们的数据并构建我们自己的字符级标记器。

2. 构建数据加载器
现在，在构建我们的模型之前，我们必须定义如何将数据输入模型进行训练，以及数据在维度和批量大小方面是什么样子。

3. 训练一个简单的语言模型
现在我们准备使用刚刚加载的数据构建和训练一个简单的语言模型。对于本节，我们将保持非常简单并实现一个简单的 Bi-Gram 模型，其中给定最后一个标记预测下一个标记。

您会惊讶于仅使用嵌入，模型就能表现得如此出色。我们将通过添加更多层逐步改进模型，所以请耐心等待并继续。（基于 75% 的故事文本的总结。）]]></description>
      <guid>https://t.me/hn_summary/98293</guid>
      <pubDate>Sat, 06 Jul 2024 05:08:48 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 在“如何在 C 语言中实现哈希表”(2021)中，Ben Hoyt 提供了有关 [...] 的详细指南。</title>
      <link>https://t.me/hn_summary/98292</link>
      <description><![CDATA[如何用 C 实现哈希表 (2021)
在“如何用 C 实现哈希表”(2021) 中，Ben Hoyt 提供了使用 C 创建简单哈希表数据结构的详细指南。他首先解释了线性和二进制搜索方法，强调了它们的效率和局限性。线性搜索很简单，但对于大型数据集来说速度很慢，而二进制搜索速度更快，但需要排序的数据。然后，Hoyt 揭开了哈希表的神秘面纱，解释了它们的结构和功能。他使用 FNV-1a 哈希函数和线性探测来解决冲突，使实现变得易于访问且高效。本文强调，从头开始构建哈希表是可管理的，并且有利于满足自定义需求，尤其是在缺乏标准哈希表库的 C 中。值得注意的是，霍伊特的二分搜索方法包括非理想溢出检查，他承认这一点，但出于教育目的而保留了它。（基于 28% 的故事文本的摘要。）]]></description>
      <guid>https://t.me/hn_summary/98292</guid>
      <pubDate>Sat, 06 Jul 2024 04:36:29 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] PBS 美国经验：1988-2022</title>
      <link>https://t.me/hn_summary/98291</link>
      <description><![CDATA[PBS 美国体验：1988-2022
PBS 美国体验：1988-2022

美国体验是 PBS 的著名纪录片系列，深入探讨了美国历史上的关键事件和人物。该节目于 1988 年 10 月 4 日首播，最初名为美国体验，后来更名。该系列主要由波士顿的 WGBH-TV 制作，也得到了其他 PBS 电视台的贡献，例如纽约的 WNET。值得注意的是，一些纪录片，如《越南：电视史》（1983 年）和《关注奖品》（2006 年），在创作后被整合到该系列中。自 1995 年以来，该节目一直保持着强大的在线影响力，提供大量背景信息和教育资源。

争议：一位评论员警告垃圾评论链接到 ISIS 网站，敦促用户不要点击它们。

独特/巧妙：该系列将现有的纪录片与其广泛的在线教育资源整合在一起，显得尤为创新。]]></description>
      <guid>https://t.me/hn_summary/98291</guid>
      <pubDate>Sat, 06 Jul 2024 04:25:22 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] 欢迎来到 PBS.org 上的新美国大师数字档案馆。</title>
      <link>https://t.me/hn_summary/98290</link>
      <description><![CDATA[美国大师数字档案
欢迎来到 PBS.org 上的全新美国大师数字档案。深入了解为过去的美国大师纪录片拍摄的未发布的采访宝库，其中包含该系列历史上 40 多集的 1,000 多条记录。这个独特的收藏包括对大卫·鲍伊、帕蒂·史密斯、赫比·汉考克、格洛丽亚·斯泰纳姆、迈克·尼科尔斯、梅尔·布鲁克斯、卡罗尔·伯内特、沃尔特·克朗凯特、唐·里克斯和玛雅·安吉洛等标志性人物的罕见采访。立即探索，揭开音乐家、电影制作人、艺术家、历史学家、作家、喜剧演员、记者等的故事和见解。在此详细了解这个非凡的收藏。]]></description>
      <guid>https://t.me/hn_summary/98290</guid>
      <pubDate>Sat, 06 Jul 2024 04:24:18 GMT</pubDate>
    </item>
    <item>
      <title>[媒体] Txtai 为向量图提供了 ChromaDB 和 LangChain 的简化和高效替代方案 [...]</title>
      <link>https://t.me/hn_summary/98289</link>
      <description><![CDATA[Txtai – 用于向量搜索和 RAG 的 ChromaDB 和 LangChain 的强大替代方案
Txtai 为向量搜索和检索增强生成 (RAG) 提供了一种精简而高效的 ChromaDB 和 LangChain 替代方案。提供的代码演示了 txtai 如何处理来自其测试数据集的文档，提取和分块文本，然后再将其加载到 Faiss 中。值得注意的是，txtai 用更少的代码实现了这一点。虽然 LangChain 使用非结构化库进行文本提取，但 txtai 利用 Apache Tika，它可以更好地保留表格和列表等结构化格式，从而从 LLM 获得更相关的答案。此外，txtai 建议使用 BLIP 模型进行图像字幕，而 LangChain 则偏爱图像字幕标签模型。 Txtai 的 LLM 管道非常用户友好，可以自动从各种来源（包括 Hugging Face 和 OpenAI）加载模型。]]></description>
      <guid>https://t.me/hn_summary/98289</guid>
      <pubDate>Sat, 06 Jul 2024 04:23:15 GMT</pubDate>
    </item>
    </channel>
</rss>